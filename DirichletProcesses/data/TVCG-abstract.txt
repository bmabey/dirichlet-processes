Year: 2010
Title: Preface
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613419
Abstract: These are the proceedings of the IEEE Visualization Conference 2010 (Vis 2010) and the IEEE Information Visualization Conference 2010 (InfoVis 2010) held during October 24 to 29, 2010 in Salt Lake City, Utah, USA.
Keywords: null
Author: Fekete, Jean-Daniel; van Ham, Frank; Machiraju, Raghu; Moller, Torsten; Pfister, Hanspeter  

Year: 2010
Title: Necklace Maps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613424
Abstract: Statistical data associated with geographic regions is nowadays globally available in large amounts and hence automated methods to visually display these data are in high demand. There are several well-established thematic map types for quantitative data on the ratio-scale associated with regions: choropleth maps, cartograms, and proportional symbol maps. However, all these maps suffer from limitations, especially if large data values are associated with small regions. To overcome these limitations, we propose a novel type of quantitative thematic map, the necklace map. In a necklace map, the regions of the underlying two-dimensional map are projected onto intervals on a one-dimensional curve (the necklace) that surrounds the map regions. Symbols are scaled such that their area corresponds to the data of their region and placed without overlap inside the corresponding interval on the necklace. Necklace maps appear clear and uncluttered and allow for comparatively large symbol sizes. They visualize data sets well which are not proportional to region sizes. The linear ordering of the symbols along the necklace facilitates an easy comparison of symbol sizes. One map can contain several nested or disjoint necklaces to visualize clustered data. The advantages of necklace maps come at a price: the association between a symbol and its region is weaker than with other types of maps. Interactivity can help to strengthen this association if necessary. We present an automated approach to generate necklace maps which allows the user to interactively control the final symbol placement. We validate our approach with experiments using various data sets and maps.
Keywords: Automated Cartography;Geographic Visualization;Necklace Maps;Proportional Symbol Maps;automated cartography;cartogram;cartography;choropleth map;clustered data;data visualisation;data visualization;geographic information systems;geographic region;geographic visualization;map region;necklace map;pattern clustering;proportional symbol map;statistical data;symbol linear ordering;symbol placement;symbol size;thematic map;two-dimensional map;visual display;
Author: Speckmann, B.; Verbeek, K.

Year: 2010
Title: Rethinking Map Legends with Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613425
Abstract: This design paper presents new guidance for creating map legends in a dynamic environment. Our contribution is a set ofguidelines for legend design in a visualization context and a series of illustrative themes through which they may be expressed. Theseare demonstrated in an applications context through interactive software prototypes. The guidelines are derived from cartographicliterature and in liaison with EDINA who provide digital mapping services for UK tertiary education. They enhance approaches tolegend design that have evolved for static media with visualization by considering: selection, layout, symbols, position, dynamismand design and process. Broad visualization legend themes include: The Ground Truth Legend, The Legend as Statistical Graphicand The Map is the Legend. Together, these concepts enable us to augment legends with dynamic properties that address specificneeds, rethink their nature and role and contribute to a wider re-evaluation of maps as artifacts of usage rather than statements offact. EDINA has acquired funding to enhance their clients with visualization legends that use these concepts as a consequence ofthis work. The guidance applies to the design of a wide range of legends and keys used in cartography and information visualization.
Keywords: Cartography;Digimap service;EDINA;UK tertiary education;cartography;cartography;data visualisation;design;digital mapping service;dynamic environment;information visualization;interactive software;interactive systems;legend;map legend creation;online web mapping;visualization;visualization legend;
Author: Dykes, J.; Wood, J.; Slingsby, A.

Year: 2010
Title: SignalLens: Focus+Context Applied to Electronic Time Series
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613426
Abstract: Electronic test and measurement systems are becoming increasingly sophisticated in order to match the increased complexity and ultra-high speed of the devices under test. A key feature in many such instruments is a vastly increased capacity for storage of digital signals. Storage of 109 time points or more is now possible. At the same time, the typical screens on such measurement devices are relatively small. Therefore, these instruments can only render an extremely small fraction of the complete signal at any time. SignalLens uses a Focus+Context approach to provide a means of navigating to and inspecting low-level signal details in the context of the entire signal trace. This approach provides a compact visualization suitable for embedding into the small displays typically provided by electronic measurement instruments. We further augment this display with computed tracks which display time-aligned computed properties of the signal. By combining and filtering these computed tracks it is possible to easily and quickly find computationally detected features in the data which are often obscured by the visual compression required to render the large data sets on a small screen. Further, these tracks can be viewed in the context of the entire signal trace as well as visible high-level signal features. Several examples using real-world electronic measurement data are presented, which demonstrate typical use cases and the effectiveness of the design.
Keywords: Electronic Signal;Focus+Context;Lens;Signal Processing;SignalLens;Test and Measurement;automatic test equipment;compact visualization;devices under test;digital signals;electronic measurement instruments;electronic test;electronic time series;focus+context approach;measurement devices;measurement systems;measurement systems;portable instruments;small displays;time series;visual compression;
Author: Kincaid, R.

Year: 2010
Title: MulteeSum: A Tool for Comparative Spatial and Temporal Gene Expression Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613427
Abstract: Cells in an organism share the same genetic information in their DNA, but have very different forms and behavior because of the selective expression of subsets of their genes. The widely used approach of measuring gene expression over time from a tissue sample using techniques such as microarrays or sequencing do not provide information about the spatial position with in the tissue where these genes are expressed. In contrast, we are working with biologists who use techniques that measure gene expression in every individual cell of entire fruitfly embryos over an hour of their development, and do so for multiple closely-related subspecies of Drosophila. These scientists are faced with the challenge of integrating temporal gene expression data with the spatial location of cells and, moreover, comparing this data across multiple related species. We have worked with these biologists over the past two years to develop MulteeSum, a visualization system that supports inspection and curation of data sets showing gene expression over time, in conjunction with the spatial location of the cells where the genes are expressed - it is the first tool to support comparisons across multiple such data sets. MulteeSum is part of a general and flexible framework we developed with our collaborators that is built around multiple summaries for each cell, allowing the biologists to explore the results of computations that mix spatial information, gene expression measurements over time, and data from multiple related species or organisms. We justify our design decisions based on specific descriptions of the analysis needs of our collaborators, and provide anecdotal evidence of the efficacy of MulteeSum through a series of case studies.
Keywords: DNA;MulteeSum;biocomputing;biological tissues;biology computing;comparative analysis;data analysis;data visualisation;gene expression;genetic information;genetics;organism;quantitative data analysis;spatial data;temporal data;tissue sample;visualization system;
Author: Meyer, M.; Munzner, T.; DePace, A.; Pfister, H.

Year: 2010
Title: Gremlin: An Interactive Visualization Model for Analyzing Genomic Rearrangements
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613428
Abstract: In this work we present, apply, and evaluate a novel, interactive visualization model for comparative analysis of structural variants and rearrangements in human and cancer genomes, with emphasis on data integration and uncertainty visualization. To support both global trend analysis and local feature detection, this model enables explorations continuously scaled from the high-level, complete genome perspective, down to the low-level, structural rearrangement view, while preserving global context at all times. We have implemented these techniques in Gremlin, a genomic rearrangement explorer with multi-scale, linked interactions, which we apply to four human cancer genome data sets for evaluation. Using an insight-based evaluation methodology, we compare Gremlin to Circos, the state-of-the-art in genomic rearrangement visualization, through a small user study with computational biologists working in rearrangement analysis. Results from user study evaluations demonstrate that this visualization model enables more total insights, more insights per minute, and more complex insights than the current state-of-the-art for visual analysis and exploration of genome rearrangements.
Keywords: Circos;Gremlin;Information visualization;bioinformatics;biology computing;cancer;cancer genomes;comparative analysis;computational biologists;data integration;data visualisation;feature extraction;genomic rearrangement explorer;genomic rearrangement visualization;genomic rearrangements;genomics;global trend analysis;human genomes;insight-based evaluation methodology;insight-based evaluation.;interactive visualization model;local feature detection;rearrangement analysis;structural variants;uncertainty visualization;visual analysis;
Author: O'Brien, T.M.; Ritz, A.M.; Raphael, B.J.; Laidlaw, D.H.

Year: 2010
Title: Graphical Perception of Multiple Time Series
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613429
Abstract: Line graphs have been the visualization of choice for temporal data ever since the days of William Playfair (1759-1823), but realistic temporal analysis tasks often include multiple simultaneous time series. In this work, we explore user performance for comparison, slope, and discrimination tasks for different line graph techniques involving multiple time series. Our results show that techniques that create separate charts for each time series--such as small multiples and horizon graphs--are generally more efficient for comparisons across time series with a large visual span. On the other hand, shared-space techniques--like standard line graphs--are typically more efficient for comparisons over smaller visual spans where the impact of overlap and clutter is reduced.
Keywords: braided graphs;charts;clutter;data visualisation;design guidelines;evaluation;graphical perception;graphs;horizon graphs;line graph;line graphs;multiple time series;realistic temporal analysis task;shared-space technique;simultaneous time series;small multiples;stacked graphs;temporal data;temporal data visualization;time series;visual span;
Author: Javed, W.; McDonnel, B.; Elmqvist, N.

Year: 2010
Title: Uncovering Strengths and Weaknesses of Radial Visualizations---an Empirical Approach
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613430
Abstract: Radial visualizations play an important role in the information visualization community. But the decision to choose a radial coordinate system is rather based on intuition than on scientific foundations. The empirical approach presented in this paper aims at uncovering strengths and weaknesses of radial visualizations by comparing them to equivalent ones in Cartesian coordinate systems. We identified memorizing positions of visual elements as a generic task when working with visualizations. A first study with 674 participants provides a broad data spectrum for exploring differences between the two visualization types. A second, complementing study with fewer participants focuses on further questions raised by the first study. Our findings document that Cartesian visualizations tend to outperform their radial counterparts especially with respect to answer times. Nonetheless, radial visualization seem to be more appropriate for focusing on a particular data dimension.
Keywords: Cartesian coordinate system;Cartesian visualization;data visualisation;information visualization;radial coordinate system;radial visualization;radial visualization;user study;visual memory;
Author: Diehl, S.; Beck, F.; Burch, M.

Year: 2010
Title: How Information Visualization Novices Construct Visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613431
Abstract: It remains challenging for information visualization novices to rapidly construct visualizations during exploratory data analysis. We conducted an exploratory laboratory study in which information visualization novices explored fictitious sales data by communicating visualization specifications to a human mediator, who rapidly constructed the visualizations using commercial visualization software. We found that three activities were central to the iterative visualization construction process: data attribute selection, visual template selection, and visual mapping specification. The major barriers faced by the participants were translating questions into data attributes, designing visual mappings, and interpreting the visualizations. Partial specification was common, and the participants used simple heuristics and preferred visualizations they were already familiar with, such as bar, line and pie charts. We derived abstract models from our observations that describe barriers in the data exploration process and uncovered how information visualization novices think about visualization specifications. Our findings support the need for tools that suggest potential visualizations and support iterative refinement, that provide explanations and help with learning, and that are tightly integrated into tool support for the overall visual analytics process.
Keywords: Empirical study;data analysis;data attribute selection;data visualisation;exploratory data analysis;human mediator;information visualization;iterative refinement;iterative visualization construction;novices;sales data;visual analytics;visual analytics process;visual mapping;visual mapping specification;visual template selection;visualization;visualization construction;visualization interpretation;visualization specifications;
Author: Grammel, L.; Tory, M.; Storey, M.

Year: 2010
Title: eSeeTrack&amp;#8212;Visualizing Sequential Fixation Patterns
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613432
Abstract: We introduce eSeeTrack, an eye-tracking visualization prototype that facilitates exploration and comparison of sequential gaze orderings in a static or a dynamic scene. It extends current eye-tracking data visualizations by extracting patterns of sequential gaze orderings, displaying these patterns in a way that does not depend on the number of fixations on a scene, and enabling users to compare patterns from two or more sets of eye-gaze data. Extracting such patterns was very difficult with previous visualization techniques. eSeeTrack combines a timeline and a tree-structured visual representation to embody three aspects of eye-tracking data that users are interested in: duration, frequency and orderings of fixations. We demonstrate the usefulness of eSeeTrack via two case studies on surgical simulation and retail store chain data. We found that eSeeTrack allows ordering of fixations to be rapidly queried, explored and compared. Furthermore, our tool provides an effective and efficient mechanism to determine pattern outliers. This approach can be effective for behavior analysis in a variety of domains that are described at the end of this paper.
Keywords: data visualisation;data visualizations;eSeeTrack;eye;eye-tracking;eye-tracking visualization;fixation pattern;graphical user interfaces;sequential fixation patterns;timeline;tree-structured visualization;
Author: Hoi Ying Tsang; Tory, M.; Swindells, C.

Year: 2010
Title: Evaluating the impact of task demands and block resolution on the effectiveness of pixel-based visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613433
Abstract: Pixel-based visualization is a popular method of conveying large amounts of numerical data graphically. Application scenarios include business and finance, bioinformatics and remote sensing. In this work, we examined how the usability of such visual representations varied across different tasks and block resolutions. The main stimuli consisted of temporal pixel-based visualization with a white-red color map, simulating monthly temperature variation over a six-year period. In the first study, we included 5 separate tasks to exert different perceptual loads. We found that performance varied considerably as a function of task, ranging from 75% correct in low-load tasks to below 40% in high-load tasks. There was a small but consistent effect of resolution, with the uniform patch improving performance by around 6% relative to higher block resolution. In the second user study, we focused on a high-load task for evaluating month-to-month changes across different regions of the temperature range. We tested both CIE L*u*v* and RGB color spaces. We found that the nature of the change-evaluation errors related directly to the distance between the compared regions in the mapped color space. We were able to reduce such errors by using multiple color bands for the same data range. In a final study, we examined more fully the influence of block resolution on performance, and found block resolution had a limited impact on the effectiveness of pixel-based visualization.
Keywords: CIE L*u*v* color spaces;Pixel-based visualization;RGB color spaces;block resolution;change detection.;data visualisation;evaluation;image colour analysis;image resolution;pixel-based visualization;task demands;user interfaces;user study;visual search;white-red color map;
Author: Borgo, R.; Proctor, K.; Min Chen; Ja&#x0308;nicke, H.; Murray, T.; Thornton, I.M.

Year: 2010
Title: Graphical inference for infovis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613434
Abstract: How do we know if what we see is really there? When visualizing data, how do we avoid falling into the trap of apophenia where we see patterns in random noise? Traditionally, infovis has been concerned with discovering new relationships, and statistics with preventing spurious relationships from being reported. We pull these opposing poles closer with two new techniques for rigorous statistical inference of visual discoveries. The "Rorschach" helps the analyst calibrate their understanding of uncertainty and "line-up" provides a protocol for assessing the significance of visual discoveries, protecting against the discovery of spurious structure.
Keywords: Statistics;data plot;data visualisation;data visualization;graphical inference;infovis;null hypotheses;permutation tests;statistical inference;statistics;visual testing;
Author: Wickham, H.; Cook, D.; Hofmann, H.; Buja, A.

Year: 2010
Title: Matching Visual Saliency to Confidence in Plots of Uncertain Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613435
Abstract: Conveying data uncertainty in visualizations is crucial for preventing viewers from drawing conclusions based on untrustworthy data points. This paper proposes a methodology for efficiently generating density plots of uncertain multivariate data sets that draws viewers to preattentively identify values of high certainty while not calling attention to uncertain values. We demonstrate how to augment scatter plots and parallel coordinates plots to incorporate statistically modeled uncertainty and show how to integrate them with existing multivariate analysis techniques, including outlier detection and interactive brushing. Computing high quality density plots can be expensive for large data sets, so we also describe a probabilistic plotting technique that summarizes the data without requiring explicit density plot computation. These techniques have been useful for identifying brain tumors in multivariate magnetic resonance spectroscopy data and we describe how to extend them to visualize ensemble data sets.
Keywords: Uncertainty visualization;brushing;data visualisation;data visualization;density plot;interactive brushing;multivariate analysis technique;multivariate data;outlier detection;parallel coordinates;probabilistic plotting technique;probability;scatter plots;statistical analysis;uncertain multivariate data set;visual saliency;
Author: Feng, D.; Kwock, L.; Yueh Lee; Taylor, R.M.

Year: 2010
Title: Perceptual Guidelines for Creating Rectangular Treemaps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613436
Abstract: Treemaps are space-filling visualizations that make efficient use of limited display space to depict large amounts of hierarchical data. Creating perceptually effective treemaps requires carefully managing a number of design parameters including the aspect ratio and luminance of rectangles. Moreover, treemaps encode values using area, which has been found to be less accurate than judgments of other visual encodings, such as length. We conduct a series of controlled experiments aimed at producing a set of design guidelines for creating effective rectangular treemaps. We find no evidence that luminance affects area judgments, but observe that aspect ratio does have an effect. Specifically, we find that the accuracy of area comparisons suffers when the compared rectangles have extreme aspect ratios or when both are squares. Contrary to common assumptions, the optimal distribution of rectangle aspect ratios within a treemap should include non-squares, but should avoid extremes. We then compare treemaps with hierarchical bar chart displays to identify the data densities at which length-encoded bar charts become less effective than area-encoded treemaps. We report the transition points at which treemaps exhibit judgment accuracy on par with bar charts for both leaf and non-leaf tree nodes. We also find that even at relatively low data densities treemaps result in faster comparisons than bar charts. Based on these results, we present a set of guidelines for the effective use of treemaps and suggest alternate approaches for treemap layout.
Keywords: Experiment;Graphical Perception;Mechanical Turk;Rectangular Area;Treemaps;Visual Encoding;Visualization;area-encoded treemap;data density;data visualisation;design guideline;design parameter;hierarchical bar chart display;hierarchical data;length-encoded bar chart;limited display space;nonleaf tree node;perceptual guideline;rectangle aspect ratio;rectangle luminance;rectangular treemap;space-filling visualization;tree data structures;treemap layout;visual encoding;
Author: Kong, N.; Heer, J.; Agrawala, M.

Year: 2010
Title: Mental Models, Visual Reasoning and Interaction in Information Visualization: A Top-down Perspective
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613437
Abstract: Although previous research has suggested that examining the interplay between internal and external representations can benefit our understanding of the role of information visualization (InfoVis) in human cognitive activities, there has been little work detailing the nature of internal representations, the relationship between internal and external representations and how interaction is related to these representations. In this paper, we identify and illustrate a specific kind of internal representation, mental models, and outline the high-level relationships between mental models and external visualizations. We present a top-down perspective of reasoning as model construction and simulation, and discuss the role of visualization in model based reasoning. From this perspective, interaction can be understood as active modeling for three primary purposes: external anchoring, information foraging, and cognitive offloading. Finally we discuss the implications of our approach for design, evaluation and theory development.
Keywords: InfoVis;cognition;cognitive offloading;data visualisation;distributed cognition;external anchoring;human cognitive activity;information foraging;information visualization;information visualization;interaction;mental model;mental model;model-based reasoning;theory;visual reasoning;
Author: Zhicheng Liu; Stasko, J.T.

Year: 2010
Title: Laws of Attraction: From Perceptual Forces to Conceptual Similarity
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613438
Abstract: Many of the pressing questions in information visualization deal with how exactly a user reads a collection of visual marks as information about relationships between entities. Previous research has suggested that people see parts of a visualization as objects, and may metaphorically interpret apparent physical relationships between these objects as suggestive of data relationships. We explored this hypothesis in detail in a series of user experiments. Inspired by the concept of implied dynamics in psychology, we first studied whether perceived gravity acting on a mark in a scatterplot can lead to errors in a participant's recall of the mark's position. The results of this study suggested that such position errors exist, but may be more strongly influenced by attraction between marks. We hypothesized that such apparent attraction may be influenced by elements used to suggest relationship between objects, such as connecting lines, grouping elements, and visual similarity. We further studied what visual elements are most likely to cause this attraction effect, and whether the elements that best predicted attraction errors were also those which suggested conceptual relationships most strongly. Our findings show a correlation between attraction errors and intuitions about relatedness, pointing towards a possible mechanism by which the perception of visual marks becomes an interpretation of data relationships.
Keywords: Perceptual cognition;attraction effect;attraction errors;cognition theory;conceptual similarity;data relationships;data visualisation;grouping elements;information visualization;laboratory studies;laws of attraction;perceptual forces;psychology;psychology;visual marks;visual perception;visual similarity;visualization models;
Author: Ziemkiewicz, C.; Kosara, R.

Year: 2010
Title: Pargnostics: Screen-Space Metrics for Parallel Coordinates
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613439
Abstract: Interactive visualization requires the translation of data into a screen space of limited resolution. While currently ignored by most visualization models, this translation entails a loss of information and the introduction of a number of artifacts that can be useful, (e.g., aggregation, structures) or distracting (e.g., over-plotting, clutter) for the analysis. This phenomenon is observed in parallel coordinates, where overlapping lines between adjacent axes form distinct patterns, representing the relation between variables they connect. However, even for a small number of dimensions, the challenge is to effectively convey the relationships for all combinations of dimensions. The size of the dataset and a large number of dimensions only add to the complexity of this problem. To address these issues, we propose Pargnostics, parallel coordinates diagnostics, a model based on screen-space metrics that quantify the different visual structures. Pargnostics metrics are calculated for pairs of axes and take into account the resolution of the display as well as potential axis inversions. Metrics include the number of line crossings, crossing angles, convergence, overplotting, etc. To construct a visualization view, the user can pick from a ranked display showing pairs of coordinate axes and the structures between them, or examine all possible combinations of axes at once in a matrix display. Picking the best axes layout is an NP-complete problem in general, but we provide a way of automatically optimizing the display according to the user's preferences based on our metrics and model.
Keywords: NP-complete problem;Parallel Coordinates;computational complexity;data visualisation;display optimization;interactive programming;interactive visualization;matrix algebra;matrix display;metrics;parallel coordinates diagnostics;parallel programming;pargnostics;program diagnostics;screen space;screen-space metrics;visualization models.;
Author: Dasgupta, A.; Kosara, R.

Year: 2010
Title: Comparative Analysis of Multidimensional, Quantitative Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613440
Abstract: When analyzing multidimensional, quantitative data, the comparison of two or more groups of dimensions is a common task. Typical sources of such data are experiments in biology, physics or engineering, which are conducted in different configurations and use replicates to ensure statistically significant results. One common way to analyze this data is to filter it using statistical methods and then run clustering algorithms to group similar values. The clustering results can be visualized using heat maps, which show differences between groups as changes in color. However, in cases where groups of dimensions have an a priori meaning, it is not desirable to cluster all dimensions combined, since a clustering algorithm can fragment continuous blocks of records. Furthermore, identifying relevant elements in heat maps becomes more difficult as the number of dimensions increases. To aid in such situations, we have developed Matchmaker, a visualization technique that allows researchers to arbitrarily arrange and compare multiple groups of dimensions at the same time. We create separate groups of dimensions which can be clustered individually, and place them in an arrangement of heat maps reminiscent of parallel coordinates. To identify relations, we render bundled curves and ribbons between related records in different groups. We then allow interactive drill-downs using enlarged detail views of the data, which enable in-depth comparisons of clusters between groups. To reduce visual clutter, we minimize crossings between the views. This paper concludes with two case studies. The first demonstrates the value of our technique for the comparison of clustering algorithms. In the second, biologists use our system to investigate why certain strains of mice develop liver disease while others remain healthy, informally showing the efficacy of our system when analyzing multidimensional data containing distinct groups of dimensions.
Keywords: Matchmaker;bioinformatics visualization.;biology;cluster comparison;clustering algorithm;comparative analysis;data analysis;data visualisation;engineering;heat maps;interactive drill-downs;liver disease;multidimensional data;multidimensional data;multidimensional quantitative data;pattern clustering;physics;statistical analysis;statistical method;visual clutter;visualization technique;
Author: Lex, A.; Streit, M.; Partl, C.; Kashofer, K.; Schmalstieg, D.

Year: 2010
Title: An Extension of Wilkinson&amp;#8217;s Algorithm for Positioning Tick Labels on Axes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613441
Abstract: The non-data components of a visualization, such as axes and legends, can often be just as important as the data itself. They provide contextual information essential to interpreting the data. In this paper, we describe an automated system for choosing positions and labels for axis tick marks. Our system extends Wilkinson's optimization-based labeling approach to create a more robust, full-featured axis labeler. We define an expanded space of axis labelings by automatically generating additional nice numbers as needed and by permitting the extreme labels to occur inside the data range. These changes provide flexibility in problematic cases, without degrading quality elsewhere. We also propose an additional optimization criterion, legibility, which allows us to simultaneously optimize over label formatting, font size, and orientation. To solve this revised optimization problem, we describe the optimization function and an efficient search algorithm. Finally, we compare our method to previous work using both quantitative and qualitative metrics. This paper is a good example of how ideas from automated graphic design can be applied to information visualization.
Keywords: Wilkinson algorithm;Wilkinson optimization-based labeling;axis labeling;axis tick marks;contextual information;data interpretation;data legend;data visualisation;data visualization;font size;graphic design;information visualization;label formatting;label orientation;nice numbers;optimisation;optimization function;search algorithm;search problems;tick label positioning;
Author: Talbot, J.; Lin, S.; Hanrahan, P.

Year: 2010
Title: Stacking Graphic Elements to Avoid Over-Plotting
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613442
Abstract: An ongoing challenge for information visualization is how to deal with over-plotting forced by ties or the relatively limited visual field of display devices. A popular solution is to represent local data density with area (bubble plots, treemaps), color(heatmaps), or aggregation (histograms, kernel densities, pixel displays). All of these methods have at least one of three deficiencies:1) magnitude judgments are biased because area and color have convex downward perceptual functions, 2) area, hue, and brightnesshave relatively restricted ranges of perceptual intensity compared to length representations, and/or 3) it is difficult to brush or link toindividual cases when viewing aggregations. In this paper, we introduce a new technique for visualizing and interacting with datasets that preserves density information by stacking overlapping cases. The overlapping data can be points or lines or other geometric elements, depending on the type of plot. We show real-dataset applications of this stacking paradigm and compare them to other techniques that deal with over-plotting in high-dimensional displays.
Keywords: Density-based visualization;Multidimensional data;Parallel coordinate plots;bubble plots;data visualisation;dot plots;graphic element;heatmaps;histogram;information visualization;kernel densities;local data density;over-plotting;pixel display;treemaps;
Author: Tuan Nhon Dang; Wilkinson, L.; Anand, A.

Year: 2010
Title: Visualization of Diversity in Large Multivariate Data Sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613443
Abstract: Understanding the diversity of a set of multivariate objects is an important problem in many domains, including ecology, college admissions, investing, machine learning, and others. However, to date, very little work has been done to help users achieve this kind of understanding. Visual representation is especially appealing for this task because it offers the potential to allow users to efficiently observe the objects of interest in a direct and holistic way. Thus, in this paper, we attempt to formalize the problem of visualizing the diversity of a large (more than 1000 objects), multivariate (more than 5 attributes) data set as one worth deeper investigation by the information visualization community. In doing so, we contribute a precise definition of diversity, a set of requirements for diversity visualizations based on this definition, and a formal user study design intended to evaluate the capacity of a visual representation for communicating diversity information. Our primary contribution, however, is a visual representation, called the Diversity Map, for visualizing diversity. An evaluation of the Diversity Map using our study design shows that users can judge elements of diversity consistently and as or more accurately than when using the only other representation specifically designed to visualize diversity.
Keywords: categorical data;college admissions;data visualisation;diversity;diversity map;diversity visualization;ecology;evaluation;information visualization;information visualization community;investing;large multivariate data sets;machine learning;multivariate data;multivariate objects;visual representation;
Author: Pham, T.; Hess, R.; Ju, C.; Zhang, E.; Metoyer, R.

Year: 2010
Title: PedVis: A Structured, Space-Efficient Technique for Pedigree Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613444
Abstract: Public genealogical databases are becoming increasingly populated with historical data and records of the current population's ancestors. As this increasing amount of available information is used to link individuals to their ancestors, the resulting trees become deeper and more dense, which justifies the need for using organized, space-efficient layouts to display the data. Existing layouts are often only able to show a small subset of the data at a time. As a result, it is easy to become lost when navigating through the data or to lose sight of the overall tree structure. On the contrary, leaving space for unknown ancestors allows one to better understand the tree's structure, but leaving this space becomes expensive and allows fewer generations to be displayed at a time. In this work, we propose that the H-tree based layout be used in genealogical software to display ancestral trees. We will show that this layout presents an increase in the number of displayable generations, provides a nicely arranged, symmetrical, intuitive and organized fractal structure, increases the user's ability to understand and navigate through the data, and accounts for the visualization requirements necessary for displaying such trees. Finally, user-study results indicate potential for user acceptance of the new layout.
Keywords: Genealogy;H-Tree;H-tree based layout;PedVis;Pedigree;ancestral tree;data navigation;data visualisation;genealogical software;genetics;historical data;history;organized fractal structure;pedigree visualization;population ancestor;public genealogical database;space-efficient layout;tree data structures;tree structure;user acceptance;visualization requirement;
Author: Tuttle, C.; Nonato, L.G.; Silva, C.

Year: 2010
Title: GeneaQuilts: A System for Exploring Large Genealogies
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613445
Abstract: GeneaQuilts is a new visualization technique for representing large genealogies of up to several thousand individuals. The visualization takes the form of a diagonally-filled matrix, where rows are individuals and columns are nuclear families. After identifying the major tasks performed in genealogical research and the limits of current software, we present an interactive genealogy exploration system based on GeneaQuilts. The system includes an overview, a timeline, search and filtering components, and a new interaction technique called Bring &amp; Slide that allows fluid navigation in very large genealogies. We report on preliminary feedback from domain experts and show how our system supports a number of their tasks.
Keywords: GeneaQuilts;bring &amp; slide technique;data visualisation;diagonally-filled matrix;domain experts;genealogy visualization;interaction;interactive genealogy exploration system;interactive systems;visualization technique;
Author: Bezerianos, A.; Dragicevic, P.; Fekete, J.-D.; Juhee Bae; Watson, B.

Year: 2010
Title: Visualization of Graph Products
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613446
Abstract: Graphs are a versatile structure and abstraction for binary relationships between objects. To gain insight into such relationships, their corresponding graph can be visualized. In the past, many classes of graphs have been defined, e.g. trees, planar graphs, directed acyclic graphs, and visualization algorithms were proposed for these classes. Although many graphs may only be classified as "general" graphs, they can contain substructures that belong to a certain class. Archambault proposed the TopoLayout framework: rather than draw any arbitrary graph using one method, split the graph into components that are homogeneous with respect to one graph class and then draw each component with an algorithm best suited for this class. Graph products constitute a class that arises frequently in graph theory, but for which no visualization algorithm has been proposed until now. In this paper, we present an algorithm for drawing graph products and the aesthetic criterion graph product's drawings are subject to. We show that the popular High-Dimensional Embedder approach applied to cartesian products already respects this aestetic criterion, but has disadvantages. We also present how our method is integrated as a new component into the TopoLayout framework. Our implementation is used for further research of graph products in a biological context.
Keywords: Archambault;Cartesian products;Graph drawing;TopoLayout framework;TopoLayout.;binary relationships;data visualisation;directed acyclic graphs;graph class;graph products;graph products visualization;graph theory;graph theory;high-dimensional embedder;planar graphs;trees;versatile structure;visualization algorithms;
Author: Ja&#x0308;nicke, S.; Heine, C.; Hellmuth, M.; Stadler, P.F.; Scheuermann, G.

Year: 2010
Title: Untangling Euler Diagrams
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613447
Abstract: In many common data analysis scenarios the data elements are logically grouped into sets. Venn and Euler style diagrams are a common visual representation of such set membership where the data elements are represented by labels or glyphs and sets are indicated by boundaries surrounding their members. Generating such diagrams automatically such that set regions do not intersect unless the corresponding sets have a non-empty intersection is a difficult problem. Further, it may be impossible in some cases if regions are required to be continuous and convex. Several approaches exist to draw such set regions using more complex shapes, however, the resulting diagrams can be difficult to interpret. In this paper we present two novel approaches for simplifying a complex collection of intersecting sets into a strict hierarchy that can be more easily automatically arranged and drawn (Figure 1). In the first approach, we use compact rectangular shapes for drawing each set, attempting to improve the readability of the set intersections. In the second approach, we avoid drawing intersecting set regions by duplicating elements belonging to multiple sets. We compared both of our techniques to the traditional non-convex region technique using five readability tasks. Our results show that the compact rectangular shapes technique was often preferred by experimental subjects even though the use of duplications dramatically improves the accuracy and performance time for most of our tasks. In addition to general set representation our techniques are also applicable to visualization of networks with intersecting clusters of nodes.
Keywords: Euler diagrams;Euler style diagrams;Graph Visualization.;Information Visualization;Set Visualization;Venn style diagrams;data analysis;data analysis;data elements;data visualisation;graph visualization;information visualization;nonconvex region technique;nonempty intersection;set theory;set visualization;
Author: Riche, N.H.; Dwyer, T.

Year: 2010
Title: The FlowVizMenu and Parallel Scatterplot Matrix: Hybrid Multidimensional Visualizations for Network Exploration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613448
Abstract: A standard approach for visualizing multivariate networks is to use one or more multidimensional views (for example, scatterplots) for selecting nodes by various metrics, possibly coordinated with a node-link view of the network. In this paper, we present three novel approaches for achieving a tighter integration of these views through hybrid techniques for multidimensional visualization, graph selection and layout. First, we present the FlowVizMenu, a radial menu containing a scatterplot that can be popped up transiently and manipulated with rapid, fluid gestures to select and modify the axes of its scatterplot. Second, the FlowVizMenu can be used to steer an attribute-driven layout of the network, causing certain nodes of a node-link diagram to move toward their corresponding positions in a scatterplot while others can be positioned manually or by force-directed layout. Third, we describe a novel hybrid approach that combines a scatterplot matrix (SPLOM) and parallel coordinates called the Parallel Scatterplot Matrix (P-SPLOM), which can be used to visualize and select features within the network. We also describe a novel arrangement of scatterplots called the Scatterplot Staircase (SPLOS) that requires less space than a traditional scatterplot matrix. Initial user feedback is reported.
Keywords: FlowVizMenu;Scatterplot Staircase;attribute-driven layout;data visualisation;force-directed layout;graph selection;hybrid multidimensional visualization;interactive graph drawing;matrix algebra;multidimensional view;multivariate network;network exploration;network layout;node-link diagram;parallel coordinates;parallel scatterplot matrix;radial menu;radial menu;scatterplot matrix;user feedback;
Author: Viau, C.; McGuffin, M.J.; Chiricota, Y.; Jurisica, I.

Year: 2010
Title: OpinionSeer: Interactive Visualization of Hotel Customer Feedback
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613449
Abstract: The rapid development of Web technology has resulted in an increasing number of hotel customers sharing their opinions on the hotel services. Effective visual analysis of online customer opinions is needed, as it has a significant impact on building a successful business. In this paper, we present OpinionSeer, an interactive visualization system that could visually analyze a large collection of online hotel customer reviews. The system is built on a new visualization-centric opinion mining technique that considers uncertainty for faithfully modeling and analyzing customer opinions. A new visual representation is developed to convey customer opinions by augmenting well-established scatterplots and radial visualization. To provide multiple-level exploration, we introduce subjective logic to handle and organize subjective opinions with degrees of uncertainty. Several case studies illustrate the effectiveness and usefulness of OpinionSeer on analyzing relationships among multiple data dimensions and comparing opinions of different groups. Aside from data on hotel customer feedback, OpinionSeer could also be applied to visually analyze customer opinions on other products or services.
Keywords: Internet;OpinionSeer;Web technology;data mining;data visualisation;feedback;hotel customer feedback;hotel industry;hotel services;interactive systems;interactive visualization system;online customer opinions;opinion visualization;radial visualization;radial visualization;scatterplots;subjective logic;uncertainty visualization;visual analysis;visualization-centric opinion mining technique;
Author: Yingcai Wu; Furu Wei; Shixia Liu; Au, N.; Weiwei Cui; Hong Zhou; Huamin Qu

Year: 2010
Title: The Streams of Our Lives: Visualizing Listening Histories in Context
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613450
Abstract: The choices we take when listening to music are expressions of our personal taste and character. Storing and accessing our listening histories is trivial due to services like Last.fm, but learning from them and understanding them is not. Existing solutions operate at a very abstract level and only produce statistics. By applying techniques from information visualization to this problem, we were able to provide average people with a detailed and powerful tool for accessing their own musical past. LastHistory is an interactive visualization for displaying music listening histories, along with contextual information from personal photos and calendar entries. Its two main user tasks are (1) analysis, with an emphasis on temporal patterns and hypotheses related to musical genre and sequences, and (2) reminiscing, where listening histories and context represent part of one's past. In this design study paper we give an overview of the field of music listening histories and explain their unique characteristics as a type of personal data. We then describe the design rationale, data and view transformations of LastHistory and present the results from both a laband a large-scale online study. We also put listening histories in contrast to other lifelogging data. The resonant and enthusiastic feedback that we received from average users shows a need for making their personal data accessible. We hope to stimulate such developments through this research.
Keywords: Information visualization;LastHistory;calendar entry;calendars;contextual information;data visualisation;design study;information visualization;interactive visualization;lifelogging;lifelogging data;listening history;music;music;music listening history visualization;musical past;personal character;personal data;personal photo;personal taste;photos;timelines;user interfaces;user task;
Author: Baur, D.; Seiffert, F.; Sedlmair, M.; Boring, S.

Year: 2010
Title: A Visual Backchannel for Large-Scale Events
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613451
Abstract: We introduce the concept of a Visual Backchannel as a novel way of following and exploring online conversations about large-scale events. Microblogging communities, such as Twitter, are increasingly used as digital backchannels for timely exchange of brief comments and impressions during political speeches, sport competitions, natural disasters, and other large events. Currently, shared updates are typically displayed in the form of a simple list, making it difficult to get an overview of the fast-paced discussions as it happens in the moment and how it evolves over time. In contrast, our Visual Backchannel design provides an evolving, interactive, and multi-faceted visual overview of large-scale ongoing conversations on Twitter. To visualize a continuously updating information stream, we include visual saliency for what is happening now and what has just happened, set in the context of the evolving conversation. As part of a fully web-based coordinated-view system we introduce Topic Streams, a temporally adjustable stacked graph visualizing topics over time, a People Spiral representing participants and their activity, and an Image Cloud encoding the popularity of event photos by size. Together with a post listing, these mutually linked views support cross-filtering along topics, participants, and time ranges. We discuss our design considerations, in particular with respect to evolving visualizations of dynamically changing data. Initial feedback indicates significant interest and suggests several unanticipated uses.
Keywords: People Spiral;Topic Streams;Twitter;Web-based coordinated-view system;World Wide Web;backchannel;cross-filtering;data visualisation;data visualization;digital backchannel;events;graph visualization;image cloud encoding;information filtering;information retrieval;information retrieval;information stream visualization;information visualization;interactive systems;interactive visual overview;large-scale event;microblogging;microblogging community;multifaceted visual overview;multiple views;natural disaster;online conversation;political speech;social networking (online);sport competition;visual backchannel;visual saliency;
Author: Do&#x0308;rk, M.; Gruen, D.; Williamson, C.; Carpendale, S.

Year: 2010
Title: Narrative Visualization: Telling Stories with Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613452
Abstract: Data visualization is regularly promoted for its ability to reveal stories within data, yet these &#x201C;data stories&#x201D; differ in important ways from traditional forms of storytelling. Storytellers, especially online journalists, have increasingly been integrating visualizations into their narratives, in some cases allowing the visualization to function in place of a written story. In this paper, we systematically review the design space of this emerging class of visualizations. Drawing on case studies from news media to visualization research, we identify distinct genres of narrative visualization. We characterize these design differences, together with interactivity and messaging, in terms of the balance between the narrative flow intended by the author (imposed by graphical elements and the interface) and story discovery on the part of the reader (often through interactive exploration). Our framework suggests design strategies for narrative visualization, including promising under-explored approaches to journalistic storytelling and educational media.
Keywords: Narrative visualization;case study;data story;data visualisation;data visualization;design differences;design methods;educational aids;educational media;humanities;journalism;journalistic storytelling;narrative visualization;online journalists;social data analysis;storytelling;telling story;visualization research;
Author: Segel, E.; Heer, J.

Year: 2010
Title: Declarative Language Design for Interactive Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613453
Abstract: We investigate the design of declarative, domain-specific languages for constructing interactive visualizations. By separating specification from execution, declarative languages can simplify development, enable unobtrusive optimization, and support retargeting across platforms. We describe the design of the Protovis specification language and its implementation within an object-oriented, statically-typed programming language (Java). We demonstrate how to support rich visualizations without requiring a toolkit-specific data model and extend Protovis to enable declarative specification of animated transitions. To support cross-platform deployment, we introduce rendering and event-handling infrastructures decoupled from the runtime platform, letting designers retarget visualization specifications (e.g., from desktop to mobile phone) with reduced effort. We also explore optimizations such as runtime compilation of visualization specifications, parallelized execution, and hardware-accelerated rendering. We present benchmark studies measuring the performance gains provided by these optimizations and compare performance to existing Java-based visualization tools, demonstrating scalability improvements exceeding an order of magnitude.
Keywords: Java;Java;Protovis specification language;animated transition;data visualisation;declarative domain-specific language;declarative language design;declarative languages;domain specific languages;event handling;hardware-accelerated rendering;information visualization;interactive programming;interactive visualization;object-oriented language;object-oriented programming;optimization;parallelized execution;rendering (computer graphics);runtime compilation;specification languages;statically-typed programming language;toolkits;unobtrusive optimization;user interfaces;visualization specification;
Author: Heer, J.; Bostock, M.

Year: 2010
Title: WebCharts: Extending Applications with Web-Authored, Embeddable Visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613454
Abstract: In order to use new visualizations, most toolkits require application developers to rebuild their applications and distribute new versions to users. The WebCharts Framework take a different approach by hosting Javascript from within an application and providing a standard data and events interchange.. In this way, applications can be extended dynamically, with a wide variety of visualizations. We discuss the benefits of this architectural approach, contrast it to existing techniques, and give a variety of examples and extensions of the basic system.
Keywords: Internet;Javascript;Visualization systems;Web-authored embeddable visualizations;WebCharts framework;data interchange;data transformation and representation;data visualisation;electronic data interchange;events interchange;toolkit design;
Author: Fisher, D.; Drucker, S.M.; Fernandez, R.; Ruble, S.

Year: 2010
Title: behaviorism: a framework for dynamic data visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613455
Abstract: While a number of information visualization software frameworks exist, creating new visualizations, especially those that involve novel visualization metaphors, interaction techniques, data analysis strategies, and specialized rendering algorithms, is still often a difficult process. To facilitate the creation of novel visualizations we present a new software framework, behaviorism, which provides a wide range of flexibility when working with dynamic information on visual, temporal, and ontological levels, but at the same time providing appropriate abstractions which allow developers to create prototypes quickly which can then easily be turned into robust systems. The core of the framework is a set of three interconnected graphs, each with associated operators: a scene graph for high-performance 3D rendering, a data graph for different layers of semantically-linked heterogeneous data, and a timing graph for sophisticated control of scheduling, interaction, and animation. In particular, the timing graph provides a unified system to add behaviors to both data and visual elements, as well as to the behaviors themselves. To evaluate the framework we look briefly at three different projects all of which required novel visualizations in different domains, and all of which worked with dynamic data in different ways: an interactive ecological simulation, an information art installation, and an information visualization technique.
Keywords: Animation;Streaming Data;Time-varying Data;Visual Design;Visualization System and Toolkit Design (primary keyword);data visualisation;dynamic data visualization;high-performance 3D rendering;information art;information visualization software;rendering (computer graphics);
Author: Forbes, A.G.; Ho&#x0308;llerer, T.; Legrady, G.

Year: 2010
Title: FacetAtlas: Multifaceted Visualization for Rich Text Corpora
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613456
Abstract: Documents in rich text corpora usually contain multiple facets of information. For example, an article about a specific disease often consists of different facets such as symptom, treatment, cause, diagnosis, prognosis, and prevention. Thus, documents may have different relations based on different facets. Powerful search tools have been developed to help users locate lists of individual documents that are most related to specific keywords. However, there is a lack of effective analysis tools that reveal the multifaceted relations of documents within or cross the document clusters. In this paper, we present FacetAtlas, a multifaceted visualization technique for visually analyzing rich text corpora. FacetAtlas combines search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. We describe several unique aspects of FacetAtlas, including (1) node cliques and multifaceted edges, (2) an optimized density map, and (3) automated opacity pattern enhancement for highlighting visual patterns, (4) interactive context switch between facets. In addition, we demonstrate the power of FacetAtlas through a case study that targets patient education in the health care domain. Our evaluation shows the benefits of this work, especially in support of complex multifaceted data analysis.
Keywords: FacetAtlas;Multi-relational Graph;Multifaceted visualization;Search UI;Text visualization;automated opacity pattern enhancement;complex multifaceted data analysis;data analysis;data visualisation;document clusters;health care domain;multifaceted edges;multifaceted relations;multifaceted visualization technique;multiple facets;node cliques;optimized density map;patient education;pattern clustering;rich text corpora;search problems;search technology;search tools;text analysis;visual analytical tools;visual patterns;
Author: Nan Cao; Jimeng Sun; Yu-Ru Lin; Gotz, D.; Shixia Liu; Huamin Qu

Year: 2010
Title: SparkClouds: Visualizing Trends in Tag Clouds
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613457
Abstract: Tag clouds have proliferated over the web over the last decade. They provide a visual summary of a collection of texts by visually depicting the tag frequency by font size. In use, tag clouds can evolve as the associated data source changes over time. Interesting discussions around tag clouds often include a series of tag clouds and consider how they evolve over time. However, since tag clouds do not explicitly represent trends or support comparisons, the cognitive demands placed on the person for perceiving trends in multiple tag clouds are high. In this paper, we introduce SparkClouds, which integrate sparklines into a tag cloud to convey trends between multiple tag clouds. We present results from a controlled study that compares SparkClouds with two traditional trend visualizations-multiple line graphs and stacked bar charts-as well as Parallel Tag Clouds. Results show that SparkClouds' ability to show trends compares favourably to the alternative visualizations.
Keywords: Internet;SparkClouds;Tag clouds;World Wide Web;data visualisation;evaluation;multiple line graphs;stacked bar charts;tag clouds;tag frequency;trend visualization;trend visualization;
Author: Bongshin Lee; Riche, N.H.; Karlson, A.K.; Carpendale, S.

Year: 2010
Title: ManiWordle: Providing Flexible Control over Wordle
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613458
Abstract: Among the multifarious tag-clouding techniques, Wordle stands out to the community by providing an aesthetic layout, eliciting the emergence of the participatory culture and usage of tag-clouding in the artistic creations. In this paper, we introduce ManiWordle, a Wordle-based visualization tool that revamps interactions with the layout by supporting custom manipulations. ManiWordle allows people to manipulate typography, color, and composition not only for the layout as a whole, but also for the individual words, enabling them to have better control over the layout result. We first describe our design rationale along with the interaction techniques for tweaking the layout. We then present the results both from the preliminary usability study and from the comparative study between ManiWordle and Wordle. The results suggest that ManiWordle provides higher user satisfaction and an efficient method of creating the desired "art work," harnessing the power behind the ever-increasing popularity of Wordle.
Keywords: Interaction design;ManiWordle;Wordle-based visualization tool;aesthetic layout;art work;custom manipulations;data visualisation;design rationale;direct manipulation;flexibilty-usability tradeoff;flexible control;interaction techniques;layout tweaking;multifarious tag-clouding techniques;participatory culture;participatory visualization;tag-cloud;text analysis;typography;user satisfaction;user study.;wordle;
Author: Kyle Koh; Bongshin Lee; Bohyoung Kim; Jinwook Seo

Year: 2010
Title: On the Fractal Dimension of Isosurfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613459
Abstract: A (3D) scalar grid is a regular n<sub>1</sub> &#x00D7; n<sub>2</sub> &#x00D7; n<sub>3</sub> grid of vertices where each vertex v is associated with some scalar value s<sub>v</sub>. Applying trilinear interpolation, the scalar grid determines a scalar function g where g(v) = s<sub>v</sub> for each grid vertex v. An isosurface with isovalue &#x03C3; is a triangular mesh which approximates the level set g<sup>-1</sup> (&#x03C3;). The fractal dimension of an isosurface represents the growth in the isosurface as the number of grid cubes increases. We define and discuss the fractal isosurface dimension. Plotting the fractal dimension as a function of the isovalues in a data set provides information about the isosurfaces determined by the data set. We present statistics on the average fractal dimension of 60 publicly available benchmark data sets. We also show the fractal dimension is highly correlated with topological noise in the benchmark data sets, measuring the topological noise by the number of connected components in the isosurface. Lastly, we present a formula predicting the fractal dimension as a function of noise and validate the formula with experimental results.
Keywords: 3D scalar grid;Isosurfaces;data set;fractal dimension;fractal dimension plotting;fractal isosurface dimension;fractals;grid cube;grid vertex;interpolation;isovalue;mesh generation;scalar data;scalar function;solid modelling;statistical analysis;statistics;topological noise;triangular mesh;trilinear interpolation;
Author: Khoury, M.; Wenger, R.

Year: 2010
Title: An Information-theoretic Framework for Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613460
Abstract: In this paper, we examine whether or not information theory can be one of the theoretic frameworks for visualization. We formulate concepts and measurements for qualifying visual information. We illustrate these concepts with examples that manifest the intrinsic and implicit use of information theory in many existing visualization techniques. We outline the broad correlation between visualization and the major applications of information theory, while pointing out the difference in emphasis and some technical gaps. Our study provides compelling evidence that information theory can explain a significant number of phenomena or events in visualization, while no example has been found which is fundamentally in conflict with information theory. We also notice that the emphasis of some traditional applications of information theory, such as data compression or data communication, may not always suit visualization, as the former typically focuses on the efficient throughput of a communication channel, whilst the latter focuses on the effectiveness in aiding the perceptual and cognitive process for data understanding and knowledge discovery. These findings suggest that further theoretic developments are necessary for adopting and adapting information theory for visualization.
Keywords: Information theory;communication channel;data communication;data compression;data mining;data visualisation;information theory;information-theoretic framework;knowledge discovery;quantitative evaluation;theory of visualization;visual information qualification;visualization techniques;
Author: Min Chen; Ja&#x0308;enicke, H.

Year: 2010
Title: An Information-Theoretic Framework for Flow Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613461
Abstract: The process of visualization can be seen as a visual communication channel where the input to the channel is the raw data, and the output is the result of a visualization algorithm. From this point of view, we can evaluate the effectiveness of visualization by measuring how much information in the original data is being communicated through the visual communication channel. In this paper, we present an information-theoretic framework for flow visualization with a special focus on streamline generation. In our framework, a vector field is modeled as a distribution of directions from which Shannon's entropy is used to measure the information content in the field. The effectiveness of the streamlines displayed in visualization can be measured by first constructing a new distribution of vectors derived from the existing streamlines, and then comparing this distribution with that of the original data set using the conditional entropy. The conditional entropy between these two distributions indicates how much information in the original data remains hidden after the selected streamlines are displayed. The quality of the visualization can be improved by progressively introducing new streamlines until the conditional entropy converges to a small value. We describe the key components of our framework with detailed analysis, and show that the framework can effectively visualize 2D and 3D flow data.
Keywords: 2D flow data visualization;3D flow data.visualization;Flow field visualization;Shannon's entropy;computational fluid dynamics;conditional entropy;data visualisation;entropy;flow visualisation;information theory;information-theoretic framework;streamline generation;streamline generation.;vector field;visual communication channel;
Author: Lijie Xu; Teng-Yok Lee; Han-Wei Shen

Year: 2010
Title: Streak Lines as Tangent Curves of a Derived Vector Field
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613462
Abstract: Characteristic curves of vector fields include stream, path, and streak lines. Stream and path lines can be obtained by a simple vector field integration of an autonomous ODE system, i.e., they can be described as tangent curves of a vector field. This facilitates their mathematical analysis including the extraction of core lines around which stream or path lines exhibit swirling motion, or the computation of their curvature for every point in the domain without actually integrating them. Such a description of streak lines is not yet available, which excludes them from most of the feature extraction and analysis tools that have been developed in our community. In this paper, we develop the first description of streak lines as tangent curves of a derived vector field - the streak line vector field - and show how it can be computed from the spatial and temporal gradients of the flow map, i.e., a dense path line integration is required. We demonstrate the high accuracy of our approach by comparing it to solutions where the ground truth is analytically known and to solutions where the ground truth has been obtained using the classic streak line computation. Furthermore, we apply a number of feature extraction and analysis tools to the new streak line vector field including the extraction of cores of swirling streak lines and the computation of streak line curvature fields. These first applications foreshadow the large variety of possible future research directions based on our new mathematical description of streak lines.
Keywords: autonomous ODE system;characteristic curve;curve fitting;data visualisation;derived vector field;feature extraction;feature extraction;feature extraction;flow map;flow visualisation;mathematical analysis;mathematical analysis;streak line curvature field;streak lines;streak surfaces;swirling motion;tangent curve;unsteady flow visualization;vector field integration;
Author: Weinkauf, T.; Theisel, H.

Year: 2010
Title: A Curved Ray Camera for Handling Occlusions through Continuous Multiperspective Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613463
Abstract: Most images used in visualization are computed with the planar pinhole camera. This classic camera model has important advantages such as simplicity, which enables efficient software and hardware implementations, and similarity to the human eye, which yields images familiar to the user. However, the planar pinhole camera has only a single viewpoint, which limits images to parts of the scene to which there is direct line of sight. In this paper we introduce the curved ray camera to address the single viewpoint limitation. Rays are C<sup>1</sup>-continuous curves that bend to circumvent occluders. Our camera is designed to provide a fast 3-D point projection operation, which enables interactive visualization. The camera supports both 3-D surface and volume datasets. The camera is a powerful tool that enables seamless integration of multiple perspectives for overcoming occlusions in visualization while minimizing distortions.
Keywords: 3D point projection operation;Alleviating occlusions;C1-continuous curves;camera model;cameras;continuous multiperspective visualization;curved ray camera;curved rays;data visualisation;interactive systems;interactive visualization;interactive visualization;multiperspective visualization;occlusions handling;planar pinhole camera;single viewpoint limitation;
Author: Jian Cui; Rosen, P.; Popescu, V.; Hoffmann, C.

Year: 2010
Title: Special Relativistic Visualization by Local Ray Tracing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613464
Abstract: Special relativistic visualization offers the possibility of experiencing the optical effects of traveling near the speed of light, including apparent geometric distortions as well as Doppler and searchlight effects. Early high-quality computer graphics images of relativistic scenes were created using offline, computationally expensive CPU-side 4D ray tracing. Alternate approaches such as image-based rendering and polygon-distortion methods are able to achieve interactivity, but exhibit inferior visual quality due to sampling artifacts. In this paper, we introduce a hybrid rendering technique based on polygon distortion and local ray tracing that facilitates interactive high-quality visualization of multiple objects moving at relativistic speeds in arbitrary directions. The method starts by calculating tight image-space footprints for the apparent triangles of the 3D scene objects. The final image is generated using a single image-space ray tracing step incorporating Doppler and searchlight effects. Our implementation uses GPU shader programming and hardware texture filtering to achieve high rendering speed.
Keywords: CPU-side 4D ray tracing;Doppler effect;Doppler effect;Doppler effects;GPU ray tracing;GPU shader programming;Poincare transformation;aberration of light;computational geometry;computer graphic equipment;coprocessors;data visualisation;geometric distortions;hardware texture filtering;illumination;image texture;image-based rendering;interactive high-quality visualization;local ray tracing;polygon-distortion methods;ray tracing;rendering (computer graphics);searchlight effect;searchlight effects;special relativistic visualization;special relativity;
Author: Mu&#x0308;ller, T.; Grottel, S.; Weiskopf, D.

Year: 2010
Title: Computing Robustness and Persistence for Images
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613465
Abstract: We are interested in 3-dimensional images given as arrays of voxels with intensity values. Extending these values to a continuous function, we study the robustness of homology classes in its level and interlevel sets, that is, the amount of perturbation needed to destroy these classes. The structure of the homology classes and their robustness, over all level and interlevel sets, can be visualized by a triangular diagram of dots obtained by computing the extended persistence of the function. We give a fast hierarchical algorithm using the dual complexes of oct-tree approximations of the function. In addition, we show that for balanced oct-trees, the dual complexes are geometrically realized in R<sup>3</sup> and can thus be used to construct level and interlevel sets. We apply these tools to study 3-dimensional images of plant root systems.
Keywords: 3-dimensional images;approximations;balanced oct-trees;botany;data visualisation;data visualization;dual complexes;extended persistence;hierarchical algorithm;homology classes;image processing;intensity values;interlevel sets;level sets;oct-tree approximations;oct-trees;octrees;persistence diagrams;persistent homology;perturbation;plant root systems;plant roots;robustness;triangular diagram;voxel arrays;
Author: Bendich, P.; Edelsbrunner, H.; Kerber, M.

Year: 2010
Title: Browsing Large Image Datasets through Voronoi Diagrams
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613466
Abstract: Conventional browsing of image collections use mechanisms such as thumbnails arranged on a regular grid or on a line, often mounted over a scrollable panel. However, this approach does not scale well with the size of the datasets (number of images). In this paper, we propose a new thumbnail-based interface to browse large collections of images. Our approach is based on weighted centroidal anisotropic Voronoi diagrams. A dynamically changing subset of images is represented by thumbnails and shown on the screen. Thumbnails are shaped like general polygons, to better cover screen space, while still reflecting the original aspect ratios or orientation of the represented images. During the browsing process, thumbnails are dynamically rearranged, reshaped and rescaled. The objective is to devote more screen space (more numerous and larger thumbnails) to the parts of the dataset closer to the current region of interest, and progressively lesser away from it, while still making the dataset visible as a whole. During the entire process, temporal coherence is always maintained. GPU implementation easily guarantees the frame rates needed for fully smooth interactivity.
Keywords: Scalability Issues;User Interfaces;Zooming and Navigation Techniques;computational geometry;image collection browsing;image dataset browsing;polygon;scrollable panel;smooth interactivity;thumbnail-based interface;thumbnails;visual databases;visualization System and Toolkit Design;weighted centroidal anisotropic Voronoi diagram;
Author: Brivio, P.; Tarini, M.; Cignoni, P.

Year: 2010
Title: Visual Exploration of High Dimensional Scalar Functions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613467
Abstract: An important goal of scientific data analysis is to understand the behavior of a system or process based on a sample of the system. In many instances it is possible to observe both input parameters and system outputs, and characterize the system as a high-dimensional function. Such data sets arise, for instance, in large numerical simulations, as energy landscapes in optimization problems, or in the analysis of image data relating to biological or medical parameters. This paper proposes an approach to analyze and visualizing such data sets. The proposed method combines topological and geometric techniques to provide interactive visualizations of discretely sampled high-dimensional scalar fields. The method relies on a segmentation of the parameter space using an approximate Morse-Smale complex on the cloud of point samples. For each crystal of the Morse-Smale complex, a regression of the system parameters with respect to the output yields a curve in the parameter space. The result is a simplified geometric representation of the Morse-Smale complex in the high dimensional input domain. Finally, the geometric representation is embedded in 2D, using dimension reduction, to provide a visualization platform. The geometric properties of the regression curves enable the visualization of additional information about each crystal such as local and global shape, width, length, and sampling densities. The method is illustrated on several synthetic examples of two dimensional functions. Two use cases, using data sets from the UCI machine learning repository, demonstrate the utility of the proposed approach on real data. Finally, in collaboration with domain experts the proposed method is applied to two scientific challenges. The analysis of parameters of climate simulations and their relationship to predicted global energy flux and the concentrations of chemical species in a combustion simulation and their integration with temperature.
Keywords: High-dimensional visualization;Morse theory;Morse-Smale complex;Morse-Smale complex;UCI;biological parameter;chemical species;climate simulation;computational geometry;curve fitting;data set visualization;data visualisation;dimension reduction;energy landscape;geometric property;geometric representation;geometric technique;global energy flux;high dimensional scalar function;image data analysis;image processing;interactive visualization;machine learning repository;medical parameter;optimization problem;parameter space segmentation;regression curve;scientific data analysis;scientific information systems;system behavior;topological technique;topology;visual exploration;
Author: Gerber, S.; Bremer, P.; Pascucci, V.; Whitaker, R.

Year: 2010
Title: Two-Phase Mapping for Projecting Massive Data Sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613468
Abstract: Most multidimensional projection techniques rely on distance (dissimilarity) information between data instances to embed high-dimensional data into a visual space. When data are endowed with Cartesian coordinates, an extra computational effort is necessary to compute the needed distances, making multidimensional projection prohibitive in applications dealing with interactivity and massive data. The novel multidimensional projection technique proposed in this work, called Part-Linear Multidimensional Projection (PLMP), has been tailored to handle multivariate data represented in Cartesian high-dimensional spaces, requiring only distance information between pairs of representative samples. This characteristic renders PLMP faster than previous methods when processing large data sets while still being competitive in terms of precision. Moreover, knowing the range of variation for data instances in the high-dimensional space, we can make PLMP a truly streaming data projection technique, a trait absent in previous methods.
Keywords: Cartesian coordinates;Dimensionality Reduction;Projection Methods;Streaming Technique;Visual Data Mining;data mining;data visualisation;massive data set projection;part-linear multidimensional projection;rendering (computer graphics);streaming data projection technique;two-phase mapping;visual data mining;
Author: Paulovich, F.V.; Silva, C.T.; Nonato, L.G.

Year: 2010
Title: Discontinuities in Continuous Scatter Plots
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613469
Abstract: The concept of continuous scatterplot (CSP) is a modern visualization technique. The idea is to define a scalar density value based on the map between an n-dimensional spatial domain and an m-dimensional data domain, which describe the CSP space. Usually the data domain is two-dimensional to visually convey the underlying, density coded, data. In this paper we investigate kinds of map-based discontinuities, especially for the practical cases n = m = 2 and n = 3 | m = 2, and we depict relations between them and attributes of the resulting CSP itself. Additionally, we show that discontinuities build critical line structures, and we introduce algorithms to detect them. Further, we introduce a discontinuity-based visualization approach - called contribution map (CM) -which establishes a relationship between the CSP's data domain and the number of connected components in the spatial domain. We show that CMs enhance the CSP-based linking &amp; brushing interaction. Finally, we apply our approaches to a number of synthetic as well as real data sets.
Keywords: Data Visualization;Discontinuity;Scatterplot;Topology;continuous scatterplots;contribution map;critical line structures;data visualisation;m-dimensional data domain;n-dimensional spatial domain;scalar density value;visualization technique;
Author: Lehmann, D.J.; Theisel, H.

Year: 2010
Title: Spatial Conditioning of Transfer Functions Using Local Material Distributions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613470
Abstract: In many applications of Direct Volume Rendering (DVR) the importance of a certain material or feature is highly dependent on its relative spatial location. For instance, in the medical diagnostic procedure, the patient's symptoms often lead to specification of features, tissues and organs of particular interest. One such example is pockets of gas which, if found inside the body at abnormal locations, are a crucial part of a diagnostic visualization. This paper presents an approach that enhances DVR transfer function design with spatial localization based on user specified material dependencies. Semantic expressions are used to define conditions based on relations between different materials, such as only render iodine uptake when close to liver. The underlying methods rely on estimations of material distributions which are acquired by weighing local neighborhoods of the data against approximations of material likelihood functions. This information is encoded and used to influence rendering according to the user's specifications. The result is improved focus on important features by allowing the user to suppress spatially less-important data. In line with requirements from actual clinical DVR practice, the methods do not require explicit material segmentation that would be impossible or prohibitively time-consuming to achieve in most real cases. The scheme scales well to higher dimensions which accounts for multi-dimensional transfer functions and multivariate data. Dual-Energy Computed Tomography, an important new modality in radiology, is used to demonstrate this scalability. In several examples we show significantly improved focus on clinically important aspects in the rendered images.
Keywords: Direct Volume Rendering;Neighborhood Meta-Data.;Spatial Conditioning;Transfer Function;diagnostic visualization;direct volume rendering;dual-energy computed tomography;local material distribution;material likelihood function;medical diagnostic procedure;medical image processing;modality;multidimensional transfer function;multivariate data;radiology;rendered image;rendering (computer graphics);solid modelling;spatial conditioning;spatial localization;user specification;
Author: Lindholm, S.; Ljung, P.; Lundstro&#x0308;m, C.; Persson, A.; Ynnerman, A.

Year: 2010
Title: Exploded View Diagrams of Mathematical Surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613471
Abstract: We present a technique for visualizing complicated mathematical surfaces that is inspired by hand-designed topological illustrations. Our approach generates exploded views that expose the internal structure of such a surface by partitioning it into parallel slices, which are separated from each other along a single linear explosion axis. Our contributions include a set of simple, prescriptive design rules for choosing an explosion axis and placing cutting planes, as well as automatic algorithms for applying these rules. First we analyze the input shape to select the explosion axis based on the detected rotational and reflective symmetries of the input model. We then partition the shape into slices that are designed to help viewers better understand how the shape of the surface and its cross-sections vary along the explosion axis. Our algorithms work directly on triangle meshes, and do not depend on any specific parameterization of the surface. We generate exploded views for a variety of mathematical surfaces using our system.
Keywords: complicated mathematical surface visualization;data visualisation;exploded view diagrams;exploded view diagrams;geometry;hand-designed topological illustration;mathematical surfaces;mathematical visualization;mathematical visualization;mesh generation;parallel slices;prescriptive design rules;symmetry;topology;triangle meshes;
Author: Karpenko, O.; Li, W.; Mitra, N.; Agrawala, M.

Year: 2010
Title: IRIS: Illustrative Rendering for Integral Surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613472
Abstract: Integral surfaces are ideal tools to illustrate vector fields and fluid flow structures. However, these surfaces can be visually complex and exhibit difficult geometric properties, owing to strong stretching, shearing and folding of the flow from which they are derived. Many techniques for non-photorealistic rendering have been presented previously. It is, however, unclear how these techniques can be applied to integral surfaces. In this paper, we examine how transparency and texturing techniques can be used with integral surfaces to convey both shape and directional information. We present a rendering pipeline that combines these techniques aimed at faithfully and accurately representing integral surfaces while improving visualization insight. The presented pipeline is implemented directly on the GPU, providing real-time interaction for all rendering modes, and does not require expensive preprocessing of integral surfaces after computation.
Keywords: GPU;computational fluid dynamics;flow visualisation;flow visualization;flow visualization;fluid flow structures;geometric property;geometry;illustrative rendering;illustrative rendering;integral surfaces;integral surfaces;nonphotorealistic rendering;rendering (computer graphics);rendering pipeline;texturing technique;transparency technique;vector fields;
Author: Hummel, M.; Garth, C.; Hamann, B.; Hagen, H.; Joy, K.I.

Year: 2010
Title: Illustrative Stream Surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613473
Abstract: Stream surfaces are an intuitive approach to represent 3D vector fields. In many cases, however, they are challenging objects to visualize and to understand, due to a high degree of self-occlusion. Despite the need for adequate rendering methods, little work has been done so far in this important research area. In this paper, we present an illustrative rendering strategy for stream surfaces. In our approach, we apply various rendering techniques, which are inspired by the traditional flow illustrations drawn by Dallmann and Abraham &amp;#x0026; Shaw in the early 1980s. Among these techniques are contour lines and halftoning to show the overall surface shape. Flow direction as well as singularities on the stream surface are depicted by illustrative surface streamlines. ;To go beyond reproducing static text book images, we provide several interaction features, such as movable cuts and slabs allowing an interactive exploration of the flow and insights into subjacent structures, e.g., the inner windings of vortex breakdown bubbles. These methods take only the parameterized stream surface as input, require no further preprocessing, and can be freely combined by the user. We explain the design, GPU-implementation, and combination of the different illustrative rendering and interaction methods and demonstrate the potential of our approach by applying it to stream surfaces from various flow simulations. ;
Keywords: 3D vector fields;3D vector fields;3D vector fields;3D vector fields;GPU implementation;GPU technique;GPU technique;GPU technique;computational geometry;computer graphic equipment;contour lines;coprocessors;data visualisation;flow simulations;flow visualization;flow visualization;flow visualization;halftoning;illustrative rendering;illustrative rendering;illustrative rendering;illustrative stream surfaces;rendering (computer graphics);rendering methods;self occlusion;silhouettes;silhouettes;silhouettes;stream surfaces;stream surfaces;stream surfaces;
Author: Born, S.; Wiebel, A.; Friedrich, J.; Scheuermann, G.; Bartz, D.

Year: 2010
Title: Exploration of 4D MRI Blood Flow using Stylistic Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613474
Abstract: Insight into the dynamics of blood-flow considerably improves the understanding of the complex cardiovascular system and its pathologies. Advances in MRI technology enable acquisition of 4D blood-flow data, providing quantitative blood-flow velocities over time. The currently typical slice-by-slice analysis requires a full mental reconstruction of the unsteady blood-flow field, which is a tedious and highly challenging task, even for skilled physicians. We endeavor to alleviate this task by means of comprehensive visualization and interaction techniques. In this paper we present a framework for pre-clinical cardiovascular research, providing tools to both interactively explore the 4D blood-flow data and depict the essential blood-flow characteristics. The framework encompasses a variety of visualization styles, comprising illustrative techniques as well as improved methods from the established field of flow visualization. Each of the incorporated styles, including exploded planar reformats, flow-direction highlights, and arrow-trails, locally captures the blood-flow dynamics and may be initiated by an interactively probed vessel cross-section. Additionally, we present the results of an evaluation with domain experts, measuring the value of each of the visualization styles and related rendering parameters.
Keywords: 4D MRI blood flow;4D MRI blood-flow;Flow visualization;Illustrative visualization;MRI technology;Phase-contrast cine MRI;Probing;biomedical MRI;blood flow characteristics;blood flow dynamics;complex cardiovascular system;comprehensive visualization;data visualisation;interaction techniques;medical image processing;mental reconstruction;quantitative blood flow velocities;slice-by-slice analysis;stylistic visualization;
Author: van Pelt, R.; Besco&#x0301;s, J.O.; Breeuwer, M.; Clough, R.E.; Gro&#x0308;ller, M.E.; ter Haar Romenij, B.; Vilanova, A.

Year: 2010
Title: Supine and Prone Colon Registration Using Quasi-Conformal Mapping
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613475
Abstract: In virtual colonoscopy, CT scans are typically acquired with the patient in both supine (facing up) and prone (facing down) positions. The registration of these two scans is desirable so that the user can clarify situations or confirm polyp findings at a location in one scan with the same location in the other, thereby improving polyp detection rates and reducing false positives. However, this supine-prone registration is challenging because of the substantial distortions in the colon shape due to the patient's change in position. We present an efficient algorithm and framework for performing this registration through the use of conformal geometry to guarantee that the registration is a diffeomorphism (a one-to-one and onto mapping). The taeniae coli and colon flexures are automatically extracted for each supine and prone surface, employing the colon geometry. The two colon surfaces are then divided into several segments using the flexures, and each segment is cut along a taenia coli and conformally flattened to the rectangular domain using holomorphic differentials. The mean curvature is color encoded as texture images, from which feature points are automatically detected using graph cut segmentation, mathematic morphological operations, and principal component analysis. Corresponding feature points are found between supine and prone and are used to adjust the conformal flattening to be quasi-conformal, such that the features become aligned. We present multiple methods of visualizing our results, including 2D flattened rendering, corresponding 3D endoluminal views, and rendering of distortion measurements. We demonstrate the efficiency and efficacy of our registration method by illustrating matched views on both the 2D flattened colon images and in the 3D volume rendered colon endoluminal view. We analytically evaluate the correctness of the results by measuring the distance between features on the registered colons.
Keywords: 2D flattened colon images;2D flattened rendering;3D endoluminal views;3D volume rendered colon endoluminal view;CT scans;Data registration;colon flexures;colon geometry;colon shape;colon surfaces;computerised tomography;conformal flattening;conformal geometry;conformal mapping;diffeomorphism;distortion measurements;geometry-based techniques;graph cut segmentation;graph theory;holomorphic differentials;image registration;image segmentation;image texture;mathematic morphological operations;mathematical foundations for visualization.;mean curvature;medical image processing;medical visualization;polyp detection rates;polyp findings;principal component analysis;principal component analysis;prone colon registration;quasiconformal mapping;rectangular domain;registration method;rendering (computer graphics);substantial distortions;supine colon registration;supine-prone registration;taeniae coli;texture images;virtual colonoscopy;
Author: Wei Zeng; Marino, J.; Chaitanya Gurijala, K.; Gu, X.; Kaufman, A.

Year: 2010
Title: Uncertainty-Aware Guided Volume Segmentation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613476
Abstract: Although direct volume rendering is established as a powerful tool for the visualization of volumetric data, efficient and reliable feature detection is still an open topic. Usually, a tradeoff between fast but imprecise classification schemes and accurate but time-consuming segmentation techniques has to be made. Furthermore, the issue of uncertainty introduced with the feature detection process is completely neglected by the majority of existing approaches.In this paper we propose a guided probabilistic volume segmentation approach that focuses on the minimization of uncertainty. In an iterative process, our system continuously assesses uncertainty of a random walker-based segmentation in order to detect regions with high ambiguity, to which the user's attention is directed to support the correction of potential misclassifications. This reduces the risk of critical segmentation errors and ensures that information about the segmentation's reliability is conveyed to the user in a dependable way. In order to improve the efficiency of the segmentation process, our technique does not only take into account the volume data to be segmented, but also enables the user to incorporate classification information. An interactive workflow has been achieved by implementing the presented system on the GPU using the OpenCL API. Our results obtained for several medical data sets of different modalities, including brain MRI and abdominal CT, demonstrate the reliability and efficiency of our approach.
Keywords: GPU;OpenCL API;abdominal CT;brain MRI;classification;classification information;critical segmentation error;direct volume rendering;feature detection process;guided probabilistic volume segmentation;image segmentation;imprecise classification scheme;interactive workflow;iterative process;medical image processing;potential misclassification;random walker;random walker-based segmentation;reliable feature detection;rendering (computer graphics);time-consuming segmentation;uncertainty;uncertainty-aware guided volume segmentation;visualization;volume segmentation;volumetric data;
Author: Prassni, J.-S.; Ropinski, T.; Hinrichs, K.

Year: 2010
Title: Exploration and Visualization of Segmentation Uncertainty using Shape and Appearance Prior Information
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613477
Abstract: We develop an interactive analysis and visualization tool for probabilistic segmentation in medical imaging. The originality of our approach is that the data exploration is guided by shape and appearance knowledge learned from expert-segmented images of a training population. We introduce a set of multidimensional transfer function widgets to analyze the multivariate probabilistic field data. These widgets furnish the user with contextual information about conformance or deviation from the population statistics. We demonstrate the user's ability to identify suspicious regions (e.g. tumors) and to correct the misclassification results. We evaluate our system and demonstrate its usefulness in the context of static anatomical and time-varying functional imaging datasets.
Keywords: Medical imaging;Probabilistic segmentation;Uncertainty visualization;appearance knowledge;appearance prior information;data exploration;data visualisation;expert-segmented image;image segmentation;interactive analysis;medical image processing;medical imaging;multidimensional transfer function widget;multivariate probabilistic field data;population statistics;probabilistic segmentation;probability;segmentation uncertainty;shape;shape recognition;time-varying functional imaging dataset;visualization tool;
Author: Saad, A.; Hamarneh, G.; Mo&#x0308;ller, T.

Year: 2010
Title: Edge Aware Anisotropic Diffusion for 3D Scalar Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613478
Abstract: In this paper we present a novel anisotropic diffusion model targeted for 3D scalar field data. Our model preserves material boundaries as well as fine tubular structures while noise is smoothed out. One of the major novelties is the use of the directional second derivative to define material boundaries instead of the gradient magnitude for thresholding. This results in a diffusion model that has much lower sensitivity to the diffusion parameter and smoothes material boundaries consistently compared to gradient magnitude based techniques. We empirically analyze the stability and convergence of the proposed diffusion and demonstrate its de-noising capabilities for both analytic and real data. We also discuss applications in the context of volume rendering.
Keywords: 3D scalar field data;Anisotropic diffusion;De-noising;PDE;Principle Curvatures;Scale-Space;denoising capabilities;directional second derivative;edge aware anisotropic diffusion model;edge detection;fine tubular structures;gradient magnitude based technique;gradient methods;image denoising;material boundaries;rendering (computer graphics);volume rendering;
Author: Hosssain, Z.; Moller, T.

Year: 2010
Title: Interactive Histology of Large-Scale Biomedical Image Stacks
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613479
Abstract: Histology is the study of the structure of biological tissue using microscopy techniques. As digital imaging technology advances, high resolution microscopy of large tissue volumes is becoming feasible; however, new interactive tools are needed to explore and analyze the enormous datasets. In this paper we present a visualization framework that specifically targets interactive examination of arbitrarily large image stacks. Our framework is built upon two core techniques: display-aware processing and GPU-accelerated texture compression. With display-aware processing, only the currently visible image tiles are fetched and aligned on-the-fly, reducing memory bandwidth and minimizing the need for time-consuming global pre-processing. Our novel texture compression scheme for GPUs is tailored for quick browsing of image stacks. We evaluate the usability of our viewer for two histology applications: digital pathology and visualization of neural structure at nanoscale-resolution in serial electron micrographs.
Keywords: GPU;GPU-accelerated texture compression;Gigapixel viewer;biological tissue;biological tissues;biomedical image processing;data compression;digital imaging technology;digital pathology;display-aware processing;image coding;image resolution;image texture;interactive histology;large-scale biomedical image stacks;medical image processing;microscopy;microscopy techniques;nanoscale-resolution;serial electron micrographs;texture compression;
Author: Won-Ki Jeong; Schneider, J.; Turney, S.G.; Faulkner-Jones, B.E.; Meyer, D.; Westermann, R.; Reid, R.C.; Lichtman, J.; Pfister, H.

Year: 2010
Title: Articulated Planar Reformation for Change Visualization in Small Animal Imaging
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613480
Abstract: The analysis of multi-timepoint whole-body small animal CT data is greatly complicated by the varying posture of the subject at different timepoints. Due to these variations, correctly relating and comparing corresponding regions of interest is challenging.In addition, occlusion may prevent effective visualization of these regions of interest. To address these problems, we have developed a method that fully automatically maps the data to a standardized layout of sub-volumes, based on an articulated atlas registration.We have dubbed this process articulated planar reformation, or APR. A sub-volume can be interactively selected for closer inspection and can be compared with the corresponding sub-volume at the other timepoints, employing a number of different comparative visualization approaches. We provide an additional tool that highlights possibly interesting areas based on the change of bone density between timepoints. Furthermore we allow visualization of the local registration error, to give an indication of the accuracy of the registration. We have evaluated our approach on a case that exhibits cancer-induced bone resorption.
Keywords: articulated atlas registration;articulated planar reformation;articulated planar reformation;biology computing;cancer-induced bone resorption;change visualization;comparative visualization;computerised tomography;data analysis;data visualisation;image registration;medical image processing;molecular biophysics;molecular imaging;multi-timepoint;multitimepoint whole-body small animal CT data analysis;small animal imaging;small animal imaging;
Author: Kok, P.; Baiker, M.; Hendriks, E.A.; Post, F.H.; Dijkstra, J.; Lowik, C.W.G.M.; Lelieveldt, B.P.F.; Botha, C.P.

Year: 2010
Title: Volumetric Modeling in Laser BPH Therapy Simulation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613481
Abstract: In this paper, we introduce a novel application of volume modeling techniques on laser Benign Prostatic Hyperplasia (BPH) therapy simulation. The core technique in our system is an algorithm for simulating the tissue vaporization process by laser heating. Different from classical volume CSG operations, our technique takes experimental data as the guidance to determine the vaporization amount so that only a specified amount of tissue is vaporized in each time. Our algorithm uses a predictor-corrector strategy. First, we apply the classical CSG algorithm on a tetrahedral grid based distance field to estimate the vaporized tissue amount. Then, a volume-correction phase is applied on the distance field. To improve the performance, we further propose optimization approaches for efficient implementation.
Keywords: CSG algorithm;Volume modeling;biological tissues;controlled-volume vaporization;diseases;laser BPH simulator;laser BPH therapy simulation;laser applications in medicine;laser benign prostatic hyperplasia therapy simulation;laser heating;medical image processing;medical simulation;patient treatment;predictor-corrector methods;predictor-corrector strategy;solid modelling;tetrahedral grid based distance field;tissue vaporization;volume CSG;volume-correction phase;volumetric modeling;
Author: Nan Zhang; Xiangmin Zhou; Yunhe Shen; Sweet, R.

Year: 2010
Title: Scalable Multi-variate Analytics of Seismic and Satellite-based Observational Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613482
Abstract: Over the past few years, large human populations around the world have been affected by an increase in significant seismic activities. For both conducting basic scientific research and for setting critical government policies, it is crucial to be able to explore and understand seismic and geographical information obtained through all scientific instruments. In this work, we present a visual analytics system that enables explorative visualization of seismic data together with satellite-based observational data, and introduce a suite of visual analytical tools. Seismic and satellite data are integrated temporally and spatially. Users can select temporal ;and spatial ranges to zoom in on specific seismic events, as well as to inspect changes both during and after the events. Tools for designing high dimensional transfer functions have been developed to enable efficient and intuitive comprehension of the multi-modal data. Spread-sheet style comparisons are used for data drill-down as well as presentation. Comparisons between distinct seismic events are also provided for characterizing event-wise differences. Our system has been designed for scalability in terms of data size, complexity (i.e. number of modalities), and varying form factors of display environments.
Keywords: Earth Science Visualization;Multivariate Visualization;Scalable Visualization;Seismic Data;data visualisation;geographic information systems;geographical information;research and development;satellite based observational data;scalable multivariate analytics;scientific research;seismic based observational data;seismology;visual analytics system;
Author: Xiaoru Yuan; He Xiao; Hanqi Guo; Peihong Guo; Kendall, W.; Jian Huang; Yongxian Zhang

Year: 2010
Title: Noodles: A Tool for Visualization of Numerical Weather Model Ensemble Uncertainty
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613483
Abstract: Numerical weather prediction ensembles are routinely used for operational weather forecasting. The members of these ensembles are individual simulations with either slightly perturbed initial conditions or different model parameterizations, or occasionally both. Multi-member ensemble output is usually large, multivariate, and challenging to interpret interactively. Forecast meteorologists are interested in understanding the uncertainties associated with numerical weather prediction; specifically variability between the ensemble members. Currently, visualization of ensemble members is mostly accomplished through spaghetti plots of a single midtroposphere pressure surface height contour. In order to explore new uncertainty visualization methods, the Weather Research and Forecasting (WRF) model was used to create a 48-hour, 18 member parameterization ensemble of the 13 March 1993 "Superstorm". A tool was designed to interactively explore the ensemble uncertainty of three important weather variables: water-vapor mixing ratio, perturbation potential temperature, and perturbation pressure. Uncertainty was quantified using individual ensemble member standard deviation, inter-quartile range, and the width of the 95% confidence interval. Bootstrapping was employed to overcome the dependence on normality in the uncertainty metrics. A coordinated view of ribbon and glyph-based uncertainty visualization, spaghetti plots, iso-pressure colormaps, and data transect plots was provided to two meteorologists for expert evaluation. They found it useful in assessing uncertainty in the data, especially in finding outliers in the ensemble run and therefore avoiding the WRF parameterizations that lead to these outliers. Additionally, the meteorologists could identify spatial regions where the uncertainty was significantly high, allowing for identification of poorly simulated storm environments and physical interpretation of these model issues.
Keywords: Noodles;Uncertainty visualization;bootstrapping;data transect plots;data visualisation;ensemble member standard deviation;geographic/geospatial visualization;geophysics computing;glyph-based techniques;glyph-based uncertainty visualization;interquartile range;isopressure colormaps;midtroposphere pressure surface height contour;numerical weather model ensemble uncertainty;numerical weather prediction ensembles;operational weather forecasting;perturbation potential temperature;perturbation pressure;qualitative evaluation;spaghetti plots;timevarying data;visualization tool;water-vapor mixing ratio;weather ensemble;weather forecasting;
Author: Sanyal, J.; Song Zhang; Dyer, J.; Mercer, A.; Amburn, P.; Moorhead, R.J.

Year: 2010
Title: Analysis of Recurrent Patterns in Toroidal Magnetic Fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613484
Abstract: In the development of magnetic confinement fusion which will potentially be a future source for low cost power, physicists must be able to analyze the magnetic field that confines the burning plasma. While the magnetic field can be described as a vector field, traditional techniques for analyzing the field's topology cannot be used because of its Hamiltonian nature. In this paper we describe a technique developed as a collaboration between physicists and computer scientists that determines the topology of a toroidal magnetic field using fieldlines with near minimal lengths. More specifically, we analyze the Poincare&#x0301; map of the sampled fieldlines in a Poincare&#x0301; section including identifying critical points and other topological features of interest to physicists. The technique has been deployed into an interactiveparallel visualization tool which physicists are using to gain new insight into simulations of magnetically confined burning plasmas.
Keywords: Confined magnetic fusion;Poincar&amp;#x00E9;Poincare map;Poincare mapping;Poincare section;critical points;critical points;interactive parallel visualization tool;magnetic confinement fusion;magnetic field visualization;magnetically confined burning plasma simulation;map;near minimal lengths;periodic magnetic fieldlines;physics computing;plasma simulation;plasma toroidal confinement;recurrent patterns;recurrent patterns;toroidal magnetic field;toroidal magnetic field topology;
Author: Sanderson, A.; Guoning Chen; Tricoche, X.; Pugmire, D.; Kruger, S.; Breslau, J.

Year: 2010
Title: Interactive Visualization of Hyperspectral Images of Historical Documents
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613485
Abstract: This paper presents an interactive visualization tool to study and analyze hyperspectral images (HSI) of historical documents. This work is part of a collaborative effort with the Nationaal Archief of the Netherlands (NAN) and Art Innovation, a manufacturer of hyperspectral imaging hardware designed for old and fragile documents. The NAN is actively capturing HSI of historical documents for use in a variety of tasks related to the analysis and management of archival collections, from ink and paper analysis to monitoring the effects of environmental aging. To assist their work, we have developed a comprehensive visualization tool that offers an assortment of visualization and analysis methods, including interactive spectral selection, spectral similarity analysis, time-varying data analysis and visualization, and selective spectral band fusion. This paper describes our visualization software and how it is used to facilitate the tasks needed by our collaborators. Evaluation feedback from our collaborators on how this tool benefits their work is included.
Keywords: Hyperspectral visualization;Nationaal Archief of the Netherlands;archival collections management;art;art innovation;data analysis;data exploration;data visualisation;document handling;document processing and analysis;historical documents;hyperspectral images;image fusion;interactive spectral selection;interactive visualization tool;spectral band fusion;spectral similarity analysis;time varying data analysis;
Author: Seon Joo Kim; Shaojie Zhuo; Fanbo Deng; Chi-Wing Fu; Brown, M.

Year: 2010
Title: Interactive Visual Analysis of Multiple Simulation Runs Using the Simulation Model View: Understanding and Tuning of an Electronic Unit Injector
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613486
Abstract: Multiple simulation runs using the same simulation model with different values of control parameters generate a large data set that captures the behavior of the modeled phenomenon. However, there is a conceptual and visual gap between the simulation model behavior and the data set that makes data analysis more difficult. We propose a simulation model view that helps to bridge that gap by visually combining the simulation model description and the generated data. The simulation model view provides a visual outline of the simulation process and the corresponding simulation model. The view is integrated in a Coordinated Multiple Views; (CMV) system. As the simulation model view provides a limited display space, we use three levels of details. We explored the use of the simulation model view, in close collaboration with a domain expert, to understand and tune an electronic unit injector (EUI). We also developed analysis procedures based on the view. The EUI is mostly used in heavy duty Diesel engines. We were mainly interested in understanding the model and how to tune it for three different operation modes: low emission, low consumption, and high power. Very positive feedback from the domain expert shows that the use of the simulation model view and the corresponding ;analysis procedures within a CMV system represents an effective technique for interactive visual analysis of multiple simulation runs.
Keywords: coordinated multiple view;coordinated multiple views;data analysis;data visualisation;domain expert;electronic unit injector;heavy duty diesel engine;interactive systems;interactive visual analysis;mechanical engineering computing;multiple simulation run;simulation;simulation model behavior;simulation model description;simulation model view;time series data;visual gap;visualization in physical sciences and engineering;
Author: Matkovic&#x0301;, K.; Grac&#x030C;anin, D.; Jelovic&#x0301;, M.; Ammer, A.; Lez&#x030C;, A.; Hauser, H.

Year: 2010
Title: World Lines
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613487
Abstract: In this paper we present World Lines as a novel interactive visualization that provides complete control over multiple heterogeneous simulation runs. In many application areas, decisions can only be made by exploring alternative scenarios. The goal of the suggested approach is to support users in this decision making process. In this setting, the data domain is extended to a set of alternative worlds where only one outcome will actually happen. World Lines integrate simulation, visualization and computational steering into a single unified system that is capable of dealing with the extended solution space. World Lines represent simulation runs as causally connected tracks that share a common time axis. This setup enables users to interfere and add new information quickly. A World Line is introduced as a visual combination of user events and their effects in order to present a possible future. To quickly find the most attractive outcome, we suggest World Lines as the governing component in a system of multiple linked views and a simulation component. World Lines employ linking and brushing to enable comparative visual analysis of multiple simulations in linked views. Analysis results can be mapped to various visual variables that World Lines provide in order to highlight the most compelling solutions. To demonstrate this technique we present a flooding scenario and show the usefulness of the integrated approach to support informed decision making.
Keywords: CFD;Problem solving environment;computational steering;data domain;data visualisation;decision making;decision making;decision making process;digital simulation;heterogeneous simulation;interactive visualization;parallel worlds;simulation steering;smoothed particle hydrodynamics;visual combination;world lines;
Author: Waser, J.; Fuchs, R.; Ribic&#x030C;ic&#x030C;, H.; Schindler, B.; Blo&#x0308;schl, G.; Gro&#x0308;ller, E.

Year: 2010
Title: Result-Driven Exploration of Simulation Parameter Spaces for Visual Effects Design
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613488
Abstract: Graphics artists commonly employ physically-based simulation for the generation of effects such as smoke, explosions, and similar phenomena. The task of finding the correct parameters for a desired result, however, is difficult and time-consuming as current tools provide little to no guidance. In this paper, we present a new approach for the visual exploration of such parameter spaces. Given a three-dimensional scene description, we utilize sampling and spatio-temporal clustering techniques to generate a concise overview of the achievable variations and their temporal evolution. Our visualization system then allows the user to explore the simulation space in a goal-oriented manner. Animation sequences with a set of desired characteristics can be composed using a novel search-by-example approach and interactive direct volume rendering is employed to provide instant visual feedback.
Keywords: Visual exploration;animation sequences;clustering;computer animation;data visualisation;explosions;explosions;instant visual feedback;interactive direct volume rendering;pattern clustering;physically-based simulation;rendering (computer graphics);result-driven exploration;search-by-example approach;simulation parameter spaces;smoke;smoke;spatio-temporal clustering techniques;temporal evolution;three-dimensional scene description;time-dependent volume data;visual effects;visual effects design;visual exploration;visualization system;
Author: Bruckner, S.; Mo&#x0308;ller, T.

Year: 2010
Title: Visual Optimality and Stability Analysis of 3DCT Scan Positions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613489
Abstract: Industrial cone-beam X-Ray computed tomography (CT) systems often face problems due to artifacts caused by a bad placement of the specimen on the rotary plate. This paper presents a visual-analysis tool for CT systems, which provides a simulation-based preview and estimates artifacts and deviations of a specimen's placement using the corresponding 3D geometrical surface model as input. The presented tool identifies potentially good or bad placements of a specimen and regions of a specimen, which cause the major portion of artefacts. The tool can be used for a preliminary analysis of the specimen before CT scanning, in order to determine the optimal way of placing the object. The analysis includes: penetration lengths, placement stability and an investigation in Radon space. Novel visualization techniques are applied to the simulation data. A stability widget is presented for determining the placement parameters' robustness. The performance and the comparison of results provided by the tool compared with real world data is demonstrated using two specimens.
Keywords: 3D geometrical surface model;3DCT scan positions;CT scanning;CT systems;Industrial 3DCT;Radon space;Radon-space analysis;computerised tomography;data visualisation;industrial cone-beam X-ray computed tomography systems;penetration lengths;penetration-length analysis;placement stability;rotary plate;simulation;simulation data;simulation-based preview;solid modelling;specimen placement;stability analysis;stability analysis;stability widget;visual optimality;visual-analysis tool;visualization techniques;
Author: Amirkhanov, A.; Heinzl, C.; Reiter, M.; Gro&#x0308;ller, E.

Year: 2010
Title: Pre-Integrated Volume Rendering with Non-Linear Gradient Interpolation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613490
Abstract: Shading is an important feature for the comprehension of volume datasets, but is difficult to implement accurately. Current techniques based on pre-integrated direct volume rendering approximate the volume rendering integral by ignoring non-linear gradient variations between front and back samples, which might result in cumulated shading errors when gradient variations are important and / or when the illumination function features high frequencies. In this paper, we explore a simple approach for pre-integrated volume rendering with non-linear gradient interpolation between front and back samples. We consider that the gradient smoothly varies along a quadratic curve instead of a segment in-between consecutive samples. This not only allows us to compute more accurate shaded pre-integrated look-up tables, but also allows us to more efficiently process shading amplifying effects, based on gradient filtering. An interesting property is that the pre-integration tables we use remain two-dimensional as for usual pre-integrated classification. We conduct experiments using a full hardware approach with the Blinn-Phong illumination model as well as with a non-photorealistic illumination model.
Keywords: Blinn Phong illumination model;direct volume rendering;gradient filtering;gradient interpolation;gradient methods;interpolation;lighting;lookup tables;nonlinear gradient interpolation;nonphotorealistic illumination model;pre-integration;preintegrated volume rendering;rendering (computer graphics);shading;table lookup;
Author: Guetat, A.; Ancel, A.; Marchesin, S.; Dischler, J.-M.

Year: 2010
Title: Gradient Estimation Revitalized
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613491
Abstract: We investigate the use of a Fourier-domain derivative error kernel to quantify the error incurred while estimating the gradient of a function from scalar point samples on a regular lattice. We use the error kernel to show that gradient reconstruction quality is significantly enhanced merely by shifting the reconstruction kernel to the centers of the principal lattice directions. Additionally, we exploit the algebraic similarities between the scalar and derivative error kernels to design asymptotically optimal gradient estimation filters that can be factored into an infinite impulse response interpolation prefilter and a finite impulse response directional derivative filter. This leads to a significant performance gain both in terms of accuracy and computational efficiency. The interpolation prefilter provides an accurate scalar approximation and can be re-used to cheaply compute directional derivatives on-the-fly without the need to store gradients. We demonstrate the impact of our filters in the context of volume rendering of scalar data sampled on the Cartesian and Body-Centered Cubic lattices. Our results rival those obtained from other competitive gradient estimation methods while incurring no additional computational or storage overhead.
Keywords: Approximation;Body Centered Cubic Lattice;Derivative;Fourier analysis;Fourier domain derivative error kernel;Frequency Error Kernel;Gradient;Interpolation;Lattice;Reconstruction;Sampling;body centered cubic lattices;computational complexity;computational efficiency;gradient estimation revitalized;gradient methods;gradient reconstruction quality;optimal gradient estimation filters;regular lattice;rendering (computer graphics);scalar point samples;volume rendering;
Author: Alim, U.; Mo&#x0308;ller, T.; Condat, L.

Year: 2010
Title: Direct Interval Volume Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613492
Abstract: We extend direct volume rendering with a unified model for generalized isosurfaces, also called interval volumes, allowing a wider spectrum of visual classification. We generalize the concept of scale-invariant opacity-typical for isosurface rendering-to semi-transparent interval volumes. Scale-invariant rendering is independent of physical space dimensions and therefore directly facilitates the analysis of data characteristics. Our model represents sharp isosurfaces as limits of interval volumes and combines them with features of direct volume rendering. Our objective is accurate rendering, guaranteeing that all isosurfaces and interval volumes are visualized in a crack-free way with correct spatial ordering. We achieve simultaneous direct and interval volume rendering by extending preintegration and explicit peak finding with data-driven splitting of ray integration and hybrid computation in physical and data domains. Our algorithm is suitable for efficient parallel processing for interactive applications as demonstrated by our CUDA implementation.
Keywords: CUDA;data visualisation;direct interval volume visualization;direct volume rendering;direct volume rendering;generalized isosurfaces;interval volume;interval volume rendering;isosurface;isosurface rendering;parallel processing;parallel processing;pattern classification;preintegration;ray casting;ray integration;rendering (computer graphics);scale-invariant opacity;scale-invariant opacity;scale-invariant rendering;spatial ordering;visual classification;
Author: Ament, M.; Weiskopf, D.; Carr, H.

Year: 2010
Title: VDVR: Verifiable Volume Visualization of Projection-Based Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613493
Abstract: Practical volume visualization pipelines are never without compromises and errors. A delicate and often-studied component is the interpolation of off-grid samples, where aliasing can lead to misleading artifacts and blurring, potentially hiding fine details of critical importance. The verifiable visualization framework we describe aims to account for these errors directly in the volume generation stage, and we specifically target volumetric data obtained via computed tomography (CT) reconstruction. In this case the raw data are the X-ray projections obtained from the scanner and the volume data generation process is the CT algorithm. Our framework informs the CT reconstruction process of the specific filter intended for interpolation in the subsequent visualization process, and this in turn ensures an accurate interpolation there at a set tolerance. Here, we focus on fast trilinear interpolation in conjunction with an octree-type mixed resolution volume representation without T-junctions. Efficient rendering is achieved by a space-efficient and locality-optimized representation, which can straightforwardly exploit fast fixed-function pipelines on GPUs.
Keywords: Direct volume rendering;X-ray projection;blurring;computed tomography;computed tomography reconstruction;computerised tomography;data visualisation;filtered back-projection;locality-optimized representation;mixed resolution volume representation;projection-based data;rendering;rendering (computer graphics);solid modelling;space-efficient representation;trilinear interpolation;verifiable visualization;verifiable volume visualization;volume data generation process;volume visualization pipeline;
Author: Ziyi Zheng; Wei Xu; Mueller, K.

Year: 2010
Title: Fast High-Quality Volume Ray Casting with Virtual Samplings
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613494
Abstract: Volume ray-casting with a higher order reconstruction filter and/or a higher sampling rate has been adopted in direct volume rendering frameworks to provide a smooth reconstruction of the volume scalar and/or to reduce artifacts when the combined frequency of the volume and transfer function is high. While it enables high-quality volume rendering, it cannot support interactive rendering due to its high computational cost. In this paper, we propose a fast high-quality volume ray-casting algorithm which effectively increases the sampling rate. While a ray traverses the volume, intensity values are uniformly reconstructed using a high-order convolution filter. Additional samplings, referred to as virtual samplings, are carried out within a ray segment from a cubic spline curve interpolating those uniformly reconstructed intensities. These virtual samplings are performed by evaluating the polynomial function of the cubic spline curve via simple arithmetic operations. The min max blocks are refined accordingly for accurate empty space skipping in the proposed method. Experimental results demonstrate that the proposed algorithm, also exploiting fast cubic texture filtering supported by programmable GPUs, offers renderings as good as a conventional ray-casting algorithm using high-order reconstruction filtering at the same sampling rate, while delivering 2.5x to 3.3x rendering speed-up.
Keywords: GPU;computer graphic equipment;coprocessors;cubic spline curve;cubic texture filtering;curve interpolation.;direct volume rendering;direct volume rendering frameworks;fast high-quality volume ray casting algorithm;high quality;high-order convolution filter;higher order reconstruction filter;interactive rendering;polynomial function;programmable GPU;rendering (computer graphics);splines (mathematics);transfer function;transfer functions;virtual samplings;volume scalar smooth reconstruction;
Author: Byeonghun Lee; Jihye Yun; Jinwook Seo; Byonghyo Shim; Yeong-Gil Shin; Bohyoung Kim

Year: 2010
Title: Efficient High-Quality Volume Rendering of SPH Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613495
Abstract: High quality volume rendering of SPH data requires a complex order-dependent resampling of particle quantities along the view rays. In this paper we present an efficient approach to perform this task using a novel view-space discretization of the simulation domain. Our method draws upon recent work on GPU-based particle voxelization for the efficient resampling of particles into uniform grids. We propose a new technique that leverages a perspective grid to adaptively discretize the view-volume, giving rise to a continuous level-of-detail sampling structure and reducing memory requirements compared to a uniform grid. In combination with a level-of-detail representation of the particle set, the perspective grid allows effectively reducing the amount of primitives to be processed at run-time. We demonstrate the quality and performance of our method for the rendering of fluid and gas dynamics SPH simulations consisting of many millions of particles.
Keywords: GPU;GPU resampling;Particle visualization;complex order-dependent resampling;coprocessors;fluid rendering;hydrodynamics;particle resampling;particle voxelization;ray-casting;rendering (computer graphics);smoothed particle hydrodynamics;view-space discretization;volume rendering;volume rendering;
Author: Fraedrich, R.; Auer, S.; Westermann, R.

Year: 2010
Title: Fast, Memory-Efficient Cell Location in Unstructured Grids for Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613496
Abstract: Applying certain visualization techniques to datasets described on unstructured grids requires the interpolation of variables of interest at arbitrary locations within the dataset's domain of definition. Typical solutions to the problem of finding the grid element enclosing a given interpolation point make use of a variety of spatial subdivision schemes. However, existing solutions are memory- intensive, do not scale well to large grids, or do not work reliably on grids describing complex geometries. In this paper, we propose a data structure and associated construction algorithm for fast cell location in unstructured grids, and apply it to the interpolation problem. Based on the concept of bounding interval hierarchies, the proposed approach is memory-efficient, fast and numerically robust. We examine the performance characteristics of the proposed approach and compare it to existing approaches using a number of benchmark problems related to vector field visualization. Furthermore, we demonstrate that our approach can successfully accommodate large datasets, and discuss application to visualization on both CPUs and GPUs.
Keywords: associated construction algorithm;cell location;complex geometries;computational geometry;data structure;data visualisation;interpolation;interpolation;interpolation problem;memory-efficient cell location;spatial subdivision schemes;tree data structures;unstructured grids;unstructured grids;vector field visualization;visualization techniques;
Author: Garth, C.; Joy, K.I.

Year: 2010
Title: Visualization by Proxy: A Novel Framework for Deferred Interaction with Volume Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613497
Abstract: Interactivity is key to exploration of volume data. Interactivity may be hindered due to many factors, e.g. large data size,high resolution or complexity of a data set, or an expensive rendering algorithm. We present a novel framework for visualizing volumedata that enables interactive exploration using proxy images, without accessing the original 3D data. Data exploration using directvolume rendering requires multiple (often redundant) accesses to possibly large amounts of data. The notion of visualization by proxyrelies on the ability to defer operations traditionally used for exploring 3D data to a more suitable intermediate representation forinteraction - proxy images. Such operations include view changes, transfer function exploration, and relighting. While previous workhas addressed specific interaction needs, we provide a complete solution that enables real-time interaction with large data sets andhas low hardware and storage requirements.
Keywords: computational complexity;data exploration;data set complexity;data visualisation;deferred interaction;deferred interaction;image-based rendering;interactive systems;interactivity;proxy images;rendering (computer graphics);rendering algorithm;transfer function exploration;transfer functions;visualization;volume data;volume distortion camera;volume visualization;
Author: Tikhonova, A.; Correa, C.D.; Kwan-Liu Ma

Year: 2010
Title: Interactive Vector Field Feature Identification
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613498
Abstract: We introduce a flexible technique for interactive exploration of vector field data through classification derived from user-specified feature templates. Our method is founded on the observation that, while similar features within the vector field may be spatially disparate, they share similar neighborhood characteristics. Users generate feature-based visualizations by interactively highlighting well-accepted and domain specific representative feature points. Feature exploration begins with the computation of attributes that describe the neighborhood of each sample within the input vector field. Compilation of these attributes forms a representation of the vector field samples in the attribute space. We project the attribute points onto the canonical 2D plane to enable interactive exploration of the vector field using a painting interface. The projection encodes the similarities between vector field points within the distances computed between their associated attribute points. The proposed method is performed at interactive rates for enhanced user experience and is completely flexible as showcased by the simultaneous identification of diverse feature types.
Keywords: data clustering;data visualisation;diverse feature types;feature based visualizations;feature classification;feature exploration;high-dimensional data;interactive exploration;interactive vector field feature identification;simultaneous identification;user interaction;user specified feature templates;vector field;vector field data;vector field points;vectors;
Author: Daniels, J.; Anderson, E.W.; Nonato, L.G.; Silva, C.T.

Year: 2010
Title: Interactive Separating Streak Surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613499
Abstract: Streak surfaces are among the most important features to support 3D unsteady flow exploration, but they are also among the computationally most demanding. Furthermore, to enable a feature driven analysis of the flow, one is mainly interested in streak surfaces that show separation profiles and thus detect unstable manifolds in the flow. The computation of such separation surfaces requires to place seeding structures at the separation locations and to let the structures move correspondingly to these locations in the unsteady flow. Since only little knowledge exists about the time evolution of separating streak surfaces, at this time, an automated exploration of 3D unsteady flows using such surfaces is not feasible. Therefore, in this paper we present an interactive approach for the visual analysis of separating streak surfaces. Our method draws upon recent work on the extraction of Lagrangian coherent structures (LCS) and the real-time visualization of streak surfaces on the GPU. We propose an interactive technique for computing ridges in the finite time Lyapunov exponent (FTLE) field at each time step, and we use these ridges as seeding structures to track streak surfaces in the time-varying flow. By showing separation surfaces in combination with particle trajectories, and by letting the user interactively change seeding parameters such as particle density and position, visually guided exploration of separation profiles in 3D is provided. To the best of our knowledge, this is the first time that the reconstruction and display of semantic separable surfaces in 3D unsteady flows can be performed interactively, giving rise to new possibilities for gaining insight into complex flow phenomena.
Keywords: 3D unsteady flow exploration;GPU;GPUs;Lagrangian coherent structure;Unsteady flow visualization;data visualisation;feature extraction;feature extraction;feature extraction;finite time Lyapunov exponent;interactive systems;interactive technique;particle density;particle trajectory;real-time visualization;ridges;seeding structure;semantic separable surface;separation profile;separation surface;solid modelling;streak surface;streak surface generation;visual analysis;
Author: Ferstl, F.; Burger, K.; Theisel, H.; Westermann, R.

Year: 2010
Title: View-Dependent Streamlines for 3D Vector Fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613500
Abstract: This paper introduces a new streamline placement and selection algorithm for 3D vector fields. Instead of considering the problem as a simple feature search in data space, we base our work on the observation that most streamline fields generate a lot of self-occlusion which prevents proper visualization. In order to avoid this issue, we approach the problem in a view-dependent fashion and dynamically determine a set of streamlines which contributes to data understanding without cluttering the view. Since our technique couples flow characteristic criteria and view-dependent streamline selection we are able achieve the best of both worlds: relevant flow description and intelligible, uncluttered pictures. We detail an efficient GPU implementation of our algorithm, show comprehensive visual results on multiple datasets and compare our method with existing flow depiction techniques. Our results show that our technique greatly improves the readability of streamline visualizations on different datasets without requiring user intervention.
Keywords: 3D vector fields;GPU implementation;Streamlines;Vector fields;View-dependent.;data space;data visualisation;feature search;graphical user interfaces;proper visualization;self-occlusion;user intervention;vectors;view-dependent streamlines;
Author: Marchesin, S.; Cheng-Kai Chen; Ho, C.; Kwan-Liu Ma

Year: 2010
Title: Visualizing Flow Trajectories Using Locality-based Rendering and Warped Curve Plots
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613501
Abstract: In flow simulations the behavior and properties of particle trajectories often depend on the physical geometry contained in the simulated environment. Understanding the flow in and around the geometry itself is an important part of analyzing the data. Previous work has often utilized focus+context rendering techniques, with an emphasis on showing trajectories while simplifying or illustratively rendering the physical areas. Our research instead emphasizes the local relationship between particle paths and geometry by using a projected multi-field visualization technique. The correlation between a particle path and its surrounding area is calculated on-the-fly and displayed in a non-intrusive manner. In addition, we support visual exploration and comparative analysis through the use of linked information visualization, such as manipulatable curve plots and one-on-one similarity plots. Our technique is demonstrated on particle trajectories from a groundwater simulation and a computer room airflow simulation, where the flow of particles is highly influenced by the dense geometry.
Keywords: computational geometry;computer room airflow simulation;coordinated linked views;curve fitting;data analysis;data visualisation;dense geometry;flow simulation;flow trajectory visualization;flow visualization;focus+context visualization;groundwater simulation;linked information visualization;locality-based rendering;manipulatable curve plot;multi-field visualization;multifield visualization;particle path;particle trajectory;rendering (computer graphics);similarity plot;visual exploration;warped curve plot;
Author: Jones, C.; Kwan-Liu Ma

Year: 2010
Title: Superquadric Glyphs for Symmetric Second-Order Tensors
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613502
Abstract: Symmetric second-order tensor fields play a central role in scientific and biomedical studies as well as in image analysis and feature-extraction methods. The utility of displaying tensor field samples has driven the development of visualization techniques that encode the tensor shape and orientation into the geometry of a tensor glyph. With some exceptions, these methods work only for positive-definite tensors (i.e. having positive eigenvalues, such as diffusion tensors). We expand the scope of tensor glyphs to all symmetric second-order tensors in two and three dimensions, gracefully and unambiguously depicting any combination of positive and negative eigenvalues. We generalize a previous method of superquadric glyphs for positive-definite tensors by drawing upon a larger portion of the superquadric shape space, supplemented with a coloring that indicates the tensor's quadratic form. We show that encoding arbitrary eigenvalue sign combinations requires design choices that differ fundamentally from those in previous work on traceless tensors (arising in the study of liquid crystals). Our method starts with a design of 2-D tensor glyphs guided by principles of symmetry and continuity, and creates 3-D glyphs that include the 2-D glyphs in their axis-aligned cross-sections. A key ingredient of our method is a novel way of mapping from the shape space of three-dimensional symmetric second-order tensors to the unit square. We apply our new glyphs to stress tensors from mechanics, geometry tensors and Hessians from image analysis, and rate-of-deformation tensors in computational fluid dynamics.
Keywords: Geometry Tensors;Glyph Design;Rate-of-Deformation Tensors;Stress Tensors;Tensor Glyphs;biomedical studies;computational geometry;data visualisation;feature extraction methods;image analysis;positive definite tensors;rate-of-deformation tensors;scientific studies;superquadric glyphs;superquadric shape space;symmetric second order tensors;tensor glyph;tensor shape;tensors;traceless tensors;visualization techniques;
Author: Schultz, T.; Kindlmann, G.L.

Year: 2010
Title: TanGeoMS: Tangible Geospatial Modeling System
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613503
Abstract: We present TanGeoMS, a tangible geospatial modeling visualization system that couples a laser scanner, projector, and a flexible physical three-dimensional model with a standard geospatial information system (GIS) to create a tangible user interface for terrain data. TanGeoMS projects an image of real-world data onto a physical terrain model. Users can alter the topography of the model by modifying the clay surface or placing additional objects on the surface. The modified model is captured by an overhead laser scanner then imported into a GIS for analysis and simulation of real-world processes. The results are projected back onto the surface of the model providing feedback on the impact of the modifications on terrain parameters and simulated processes. Interaction with a physical model is highly intuitive, allowing users to base initial design decisions on geospatial data, test the impact of these decisions in GIS simulations, and use the feedback to improve their design. We demonstrate the system on three applications: investigating runoff management within a watershed, assessing the impact of storm surge on barrier islands, and exploring landscape rehabilitation in military training areas.
Keywords: TanGeoMS;barrier islands;collaborative visualization;data visualisation;geographic information systems;geographic/geospatial visualization;geospatial information system;human-computer interaction;landscape rehabilitation;military training areas;physical terrain model;runoff management;storm surge;tangible geospatial modeling visualization system;tangible user interface;tangible user interface;terrain data;terrain mapping;terrain visualization;user interfaces;visualization system;watershed;
Author: Tateosian, L.; Mitasova, H.; Harmon, B.; Fogleman, B.; Weaver, K.; Harmon, R.

Year: 2010
Title: FI3D: Direct-Touch Interaction for the Exploration of 3D Scientific Visualization Spaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5613504
Abstract: We present the design and evaluation of FI3D, a direct-touch data exploration technique for 3D visualization spaces. The exploration of three-dimensional data is core to many tasks and domains involving scientific visualizations. Thus, effective data navigation techniques are essential to enable comprehension, understanding, and analysis of the information space. While evidence exists that touch can provide higher-bandwidth input, somesthetic information that is valuable when interacting with virtual worlds, and awareness when working in collaboration, scientific data exploration in 3D poses unique challenges to the development of effective data manipulations. We present a technique that provides touch interaction with 3D scientific data spaces in 7 DOF. This interaction does not require the presence of dedicated objects to constrain the mapping, a design decision important for many scientific datasets such as particle simulations in astronomy or physics. We report on an evaluation that compares the technique to conventional mouse-based interaction. Our results show that touch interaction is competitive in interaction speed for translation and integrated interaction, is easy to learn and use, and is preferred for exploration and wayfinding tasks. To further explore the applicability of our basic technique for other types of scientific visualizations we present a second case study, adjusting the interaction to the illustrative visualization of fiber tracts of the brain and the manipulation of cutting planes in this context.
Keywords: 3D navigation and exploration;3D scientific visualization spaces;Direct-touch interaction;FI3D;astronomy;brain fiber tracts;data manipulations;data visualisation;direct touch data exploration;direct touch interaction;evaluation;illustrative visualization;interactive systems;mouse based interaction;natural sciences computing;physics;wall displays;
Author: Lingyun Yu; Svetachov, P.; Isenberg, P.; Everts, M.H.; Isenberg, T.

Year: 2009
Title: ABySS-Explorer: Visualizing Genome Sequence Assemblies
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290690
Abstract: One bottleneck in large-scale genome sequencing projects is reconstructing the full genome sequence from the short subsequences produced by current technologies. The final stages of the genome assembly process inevitably require manual inspection of data inconsistencies and could be greatly aided by visualization. This paper presents our design decisions in translating key data features identified through discussions with analysts into a concise visual encoding. Current visualization tools in this domain focus on local sequence errors making high-level inspection of the assembly difficult if not impossible. We present a novel interactive graph display, ABySS-Explorer, that emphasizes the global assembly structure while also integrating salient data features such as sequence length. Our tool replaces manual and in some cases pen-and-paper based analysis tasks, and we discuss how user feedback was incorporated into iterative design refinements. Finally, we touch on applications of this representation not initially considered in our design phase, suggesting the generality of this encoding for DNA sequence data.
Keywords: ABySS-Explorer;Base Sequence;Bioinformatics visualization;Chromosome Mapping;Computational Biology;Computer Graphics;DNA;DNA;DNA sequence;DNA sequence data;bioinformatics;bioinformatics visualization;data visualisation;design study;genome assembly;genome assembly process;genome sequence assemblies;genome sequencing projects;genomics;interactive graph display;interactive systems;pen-and-paper based analysis tasks;user feedback;visualization tools;
Author: Nielsen, C.B.; Jackman, S.D.; Birol, I.; Jones, S.J.M.

Year: 2009
Title: Constructing Overview + Detail Dendrogram-Matrix Views
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290691
Abstract: A dendrogram that visualizes a clustering hierarchy is often integrated with a re-orderable matrix for pattern identification. The method is widely used in many research fields including biology, geography, statistics, and data mining. However, most dendrograms do not scale up well, particularly with respect to problems of graphical and cognitive information overload. This research proposes a strategy that links an overview dendrogram and a detail-view dendrogram, each integrated with a re-orderable matrix. The overview displays only a user-controlled, limited number of nodes that represent the ldquoskeletonrdquo of a hierarchy. The detail view displays the sub-tree represented by a selected meta-node in the overview. The research presented here focuses on constructing a concise overview dendrogram and its coordination with a detail view. The proposed method has the following benefits: dramatic alleviation of information overload, enhanced scalability and data abstraction quality on the dendrogram, and the support of data exploration at arbitrary levels of detail. The contribution of the paper includes a new metric to measure the ldquoimportancerdquo of nodes in a dendrogram; the method to construct the concise overview dendrogram from the dynamically-identified, important nodes; and measure for evaluating the data abstraction quality for dendrograms. We evaluate and compare the proposed method to some related existing methods, and demonstrating how the proposed method can help users find interesting patterns through a case study on county-level U.S. cervical cancer mortality and demographic data.
Keywords: Algorithms;Cluster Analysis;Computational Biology;Dendrogram;Female;Humans;Pattern Recognition, Automated;Uterine Cervical Neoplasms;clustering hierarchy;compound graphs;data abstraction quality;data abstraction quality metrics;data exploration;data structures;dendrogram-matrix views;detail view dendrogram;hierarchical clusters;matrix algebra;overview dendrogram;pattern clustering;pattern identification;reorderable matrix;reorderable matrix;
Author: Jin Chen; MacEachren, A.M.; Peuquet, D.J.

Year: 2009
Title: MizBee: A Multiscale Synteny Browser
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290692
Abstract: In the field of comparative genomics, scientists seek to answer questions about evolution and genomic function by comparing the genomes of species to find regions of shared sequences. Conserve dsyntenic blocks are an important biological data abstraction for indicating regions of shared sequences. The goal of this work is to show multiple types of relationships at multiple scales in a way that is visually comprehensible in accordance with known perceptual principles. We present a task analysis for this domain where the fundamental questions asked by biologists can be understood by a characterization of relationships into the four types of proximity/location, size, orientation, and similarity/strength, and the four scales of genome, chromosome, block, and genomic feature. We also propose a new taxonomy of the design space for visually encoding conservation data. We present MizBee, a multiscale synteny browser with the unique property of providing interactive side-by-side views of the data across the range of scales supporting exploration of all of these relationship types. We conclude with case studies from two biologists who used MizBee to augment their previous automatic analysis work flow, providing anecdotal evidence about the efficacy of the system for the visualization of syntenic data, the analysis of conservation relationships, and the communication of scientific insights.
Keywords: Algorithms;Animals;Computational Biology;Computer Graphics;Fishes;Genes;Genome;Information visualization;MizBee;Rhizopus;bioinformatics;biological data abstraction;biology computing;chromosome;comparative genomics;data structures;data visualisation;data visualization;design study;dsyntenic blocks;genome;genomics;multiscale synteny browser;synteny.;
Author: Meyer, M.; Munzner, T.; Pfister, H.

Year: 2009
Title: GeneShelf: A Web-based Visual Interface for Large Gene Expression Time-Series Data Repositories
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290693
Abstract: A widespread use of high-throughput gene expression analysis techniques enabled the biomedical research community to share a huge body of gene expression datasets in many public databases on the web. However, current gene expression data repositories provide static representations of the data and support limited interactions. This hinders biologists from effectively exploring shared gene expression datasets. Responding to the growing need for better interfaces to improve the utility of the public datasets, we have designed and developed a new web-based visual interface entitled GeneShelf (http://bioinformatics.cnmcresearch.org/GeneShelf). It builds upon a zoomable grid display to represent two categorical dimensions. It also incorporates an augmented timeline with expandable time points that better shows multiple data values for the focused time point by embedding bar charts. We applied GeneShelf to one of the largest microarray datasets generated to study the progression and recovery process of injuries at the spinal cord of mice and rats. We present a case study and a preliminary qualitative user study with biologists to show the utility and usability of GeneShelf.
Keywords: Animals;Computational Biology;Computer Graphics;Database Management Systems;Databases, Genetic;Gene Regulatory Networks;GeneShelf;Internet;Internet;Mice;Oligonucleotide Array Sequence Analysis;Rats;Spinal Cord Injuries;User-Computer Interface;Web-based visual interface;animation;augmented timeline;bar charts;bioinformatics visualization;biology computing;data structures;gene expression profiling;genetics;large gene expression time-series data repositories;public databases;static data representations;user interfaces;zoomable grid;
Author: Bohyoung Kim; Bongshin Lee; Knoblach, S.; Hoffman, E.; Jinwook Seo

Year: 2009
Title: Spatiotemporal Analysis of Sensor Logs using Growth Ring Maps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290694
Abstract: Spatiotemporal analysis of sensor logs is a challenging research field due to three facts: a) traditional two-dimensional maps do not support multiple events to occur at the same spatial location, b) three-dimensional solutions introduce ambiguity and are hard to navigate, and c) map distortions to solve the overlap problem are unfamiliar to most users. This paper introduces a novel approach to represent spatial data changing over time by plotting a number of non-overlapping pixels, close to the sensor positions in a map. Thereby, we encode the amount of time that a subject spent at a particular sensor to the number of plotted pixels. Color is used in a twofold manner; while distinct colors distinguish between sensor nodes in different regions, the colors' intensity is used as an indicator to the temporal property of the subjects' activity. The resulting visualization technique, called growth ring maps, enables users to find similarities and extract patterns of interest in spatiotemporal data by using humans' perceptual abilities. We demonstrate the newly introduced technique on a dataset that shows the behavior of healthy and Alzheimer transgenic, male and female mice. We motivate the new technique by showing that the temporal analysis based on hierarchical clustering and the spatial analysis based on transition matrices only reveal limited results. Results and findings are cross-validated using multidimensional scaling. While the focus of this paper is to apply our visualization for monitoring animal behavior, the technique is also applicable for analyzing data, such as packet tracing, geographic monitoring of sales development, or mobile phone capacity planning.
Keywords: Alzheimer Disease;Alzheimer transgenic mice;Animals;Animals, Genetically Modified;Behavior, Animal;Cluster Analysis;Computational Biology;Computer Graphics;Disease Models, Animal;Female;Male;Mice;Spatial Behavior;Time Factors;animal behavior;biology computing;biosensors;colors intensity;colour graphics;data loggers;data visualisation;dense pixel displays;distinct colors;geographic monitoring;growth ring maps;hierarchical clustering;map distortions;mobile phone capacity planning;multidimensional scaling;nonoverlapping pixels;packet tracing;sensor logs spatiotemporal analysis;spatial data;spatiotemporal visualization;visual analytics;visualization technique;
Author: Bak, P.; Mansmann, F.; Janetzko, H.; Keim, D.A.

Year: 2009
Title: A Nested Process Model for Visualization Design and Validation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290695
Abstract: We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.
Keywords: Models;data visualisation;design;domain characterization;evaluation.;frameworks;nested process model;visual encoding;visualization design;
Author: Munzner, T.

Year: 2009
Title: Conjunctive Visual Forms
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290696
Abstract: Visual exploration of multidimensional data is a process of isolating and extracting relationships within and between dimensions. Coordinated multiple view approaches are particularly effective for visual exploration because they support precise expression of heterogeneous multidimensional queries using simple interactions. Recent visual analytics research has made significant progress in identifying and understanding patterns of composed views and coordinations that support fast, flexible, and open-ended data exploration. What is missing is formalization of the space of expressible queries in terms of visual representation and interaction. This paper introduces the conjunctive visual form model in which visual exploration consists of interactively-driven sequences of transitions between visual states that correspond to conjunctive normal forms in boolean logic. The model predicts several new and useful ways to extend the space of rapidly expressible queries through addition of simple interactive capabilities to existing compositional patterns. Two recent related visual tools offer a subset of these capabilities, providing a basis for conjecturing about such extensions.
Keywords: Boolean query;boolean logic;brushing;conjunctive normal form;conjunctive visual form model;data visualisation;exploratory visualization;heterogeneous multidimensional queries;multidimensional data visual exploration;multiple views;query processing;visual abstraction.;visual representation;
Author: Weaver, C.

Year: 2009
Title: Interaction Techniques for Selecting and Manipulating Subgraphs in Network Visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290697
Abstract: We present a novel and extensible set of interaction techniques for manipulating visualizations of networks by selecting subgraphs and then applying various commands to modify their layout or graphical properties. Our techniques integrate traditional rectangle and lasso selection, and also support selecting a node's neighbourhood by dragging out its radius (in edges) using a novel kind of radial menu. Commands for translation, rotation, scaling, or modifying graphical properties (such as opacity) and layout patterns can be performed by using a hotbox (a transiently popped-up, semi-transparent set of widgets) that has been extended in novel ways to integrate specification of commands with 1D or 2D arguments. Our techniques require only one mouse button and one keyboard key, and are designed for fast, gestural, in-place interaction. We present the design and integration of these interaction techniques, and illustrate their use in interactive graph visualization. Our techniques are implemented in NAViGaTOR, a software package for visualizing and analyzing biological networks. An initial usability study is also reported.
Keywords: Computational Biology;Computer Graphics;NAViGaTOR;Principal Component Analysis;Software;User-Computer Interface;biological networks;biological networks;biology computing;data visualisation;graph theory;hotbox;interaction techniques;interactive graph drawing;interactive graph visualization;interactive systems;lasso selection;marking menus;network layout;network visualizations;radial menus;selecting subgraphs;software package;usability study;
Author: McGuffin, M.J.; Jurisica, I.

Year: 2009
Title: ActiviTree: Interactive Visual Exploration of Sequences in Event-Based Data Using Graph Similarity
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290698
Abstract: The identification of significant sequences in large and complex event-based temporal data is a challenging problem with applications in many areas of today's information intensive society. Pure visual representations can be used for the analysis, but are constrained to small data sets. Algorithmic search mechanisms used for larger data sets become expensive as the data size increases and typically focus on frequency of occurrence to reduce the computational complexity, often overlooking important infrequent sequences and outliers. In this paper we introduce an interactive visual data mining approach based on an adaptation of techniques developed for Web searching, combined with an intuitive visual interface, to facilitate user-centred exploration of the data and identification of sequences significant to that user. The search algorithm used in the exploration executes in negligible time, even for large data, and so no pre-processing of the selected data is required, making this a completely interactive experience for the user. Our particular application area is social science diary data but the technique is applicable across many other disciplines.
Keywords: ActiviTree;Web searching;algorithmic search mechanisms;complex event-based temporal data;computational complexity;computational complexity;data mining;event-based data;event-based data;graph similarity;graph similarity;graph theory;interactive visual data mining;interactive visual exploration;interactive visual sequence exploration;node similarity;sequence identification;
Author: Vrotsou, K.; Johansson, J.; Cooper, M.

Year: 2009
Title: &#x0201C;Search, Show Context, Expand on Demand&#x0201D;: Supporting Large Graph Exploration with Degree-of-Interest
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290699
Abstract: A common goal in graph visualization research is the design of novel techniques for displaying an overview of an entire graph. However, there are many situations where such an overview is not relevant or practical for users, as analyzing the global structure may not be related to the main task of the users that have semi-specific information needs. Furthermore, users accessing large graph databases through an online connection or users running on less powerful (mobile) hardware simply do not have the resources needed to compute these overviews. In this paper, we advocate an interaction model that allows users to remotely browse the immediate context graph around a specific node of interest. We show how Furnas' original degree of interest function can be adapted from trees to graphs and how we can use this metric to extract useful contextual subgraphs, control the complexity of the generated visualization and direct users to interesting datapoints in the context. We demonstrate the effectiveness of our approach with an exploration of a dense online database containing over 3 million legal citations.
Keywords: Graph visualization;citation analysis;contextual subgraph;data visualisation;degree of interest;dense online database;focus+context;graph theory;graph visualization;immediate context graph;large graph database;large graph exploration;legal citation;legal citation networks;mathematics computing;network visualization;
Author: van Ham, F.; Perer, A.

Year: 2009
Title: A Comparison of User-Generated and Automatic Graph Layouts
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290700
Abstract: The research presented in this paper compares user-generated and automatic graph layouts. Following the methods suggested by van Ham et al. (2008), a group of users generated graph layouts using both multi-touch interaction on a tabletop display and mouse interaction on a desktop computer. Users were asked to optimize their layout for aesthetics and analytical tasks with a social network. We discuss characteristics of the user-generated layouts and interaction methods employed by users in this process. We then report on a web-based study to compare these layouts with the output of popular automatic layout algorithms. Our results demonstrate that the best of the user-generated layouts performed as well as or better than the physics-based layout. Orthogonal and circular automatic layouts were found to be considerably less effective than either the physics-based layout or the best of the user-generated layouts. We highlight several attributes of the various layouts that led to high accuracy and improved task completion time, as well as aspects in which traditional automatic layout methods were unsuccessful for our tasks.
Keywords: Graph layout;automatic graph layouts;automatic layout algorithms;circular automatic layouts;desktop computer;graph theory;graph-drawing aesthetics;mouse interaction;multitouch interaction;network layout;orthogonal automatic layouts;physics-based layout;social networking (online);tabletop display;user interfaces;user-generated layout;user-generated layouts;
Author: Dwyer, T.; Bongshin Lee; Fisher, D.; Quinn, K.I.; Isenberg, P.; Robertson, G.; North, C.

Year: 2009
Title: Smooth Graphs for Visual Exploration of Higher-Order State Transitions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290701
Abstract: In this paper, we present a new visual way of exploring state sequences in large observational time-series. A key advantage of our method is that it can directly visualize higher-order state transitions. A standard first order state transition is a sequence of two states that are linked by a transition. A higher-order state transition is a sequence of three or more states where the sequence of participating states are linked together by consecutive first order state transitions. Our method extends the current state-graph exploration methods by employing a two dimensional graph, in which higher-order state transitions are visualized as curved lines. All transitions are bundled into thick splines, so that the thickness of an edge represents the frequency of instances. The bundling between two states takes into account the state transitions before and after the transition. This is done in such a way that it forms a continuous representation in which any subsequence of the timeseries is represented by a continuous smooth line. The edge bundles in these graphs can be explored interactively through our incremental selection algorithm. We demonstrate our method with an application in exploring labeled time-series data from a biological survey, where a clustering has assigned a single label to the data at each time-point. In these sequences, a large number of cyclic patterns occur, which in turn are linked to specific activities. We demonstrate how our method helps to find these cycles, and how the interactive selection process helps to find and investigate activities.
Keywords: Animals;Behavior, Animal;Biological data;Cluster Analysis;Computational Biology;Computer Graphics;Databases, Factual;Graph drawing;Spheniscidae;State transitions;Time Factors;Time series;biological data;biology computing;graph theory;higher-order state transitions;large observational time series;smooth graphs;splines;splines (mathematics);state sequences;state-graph exploration methods;time series;
Author: Blaas, J.; Botha, C.; Grundy, E.; Jones, M.; Laramee, R.; Post, F.

Year: 2009
Title: Configuring Hierarchical Layouts to Address Research Questions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290702
Abstract: We explore the effects of selecting alternative layouts in hierarchical displays that show multiple aspects of large multivariate datasets, including spatial and temporal characteristics. Hierarchical displays of this type condition a dataset by multiple discrete variable values, creating nested graphical summaries of the resulting subsets in which size, shape and colour can be used to show subset properties. These 'small multiples' are ordered by the conditioning variable values and are laid out hierarchically using dimensional stacking. Crucially, we consider the use of different layouts at different hierarchical levels, so that the coordinates of the plane can be used more effectively to draw attention to trends and anomalies in the data. We argue that these layouts should be informed by the type of conditioning variable and by the research question being explored. We focus on space-filling rectangular layouts that provide data-dense and rich overviews of data to address research questions posed in our exploratory analysis of spatial and temporal aspects of property sales in London. We develop a notation ('HiVE') that describes visualisation and layout states and provides reconfiguration operators, demonstrate its use for reconfiguring layouts to pursue research questions and provide guidelines for this process. We demonstrate how layouts can be related through animated transitions to reduce the cognitive load associated with their reconfiguration whilst supporting the exploratory process.
Keywords: Geovisualization;cognitive load;data visualisation;dimensional stacking;exploratory;geography;guidelines;hierarchical;hierarchical displays;hierarchical layouts;layout;multivariate datasets;notation.;research questions;space-filling rectangular layouts;temporal databases;visual databases;
Author: Slingsby, A.; Dykes, J.; Wood, J.

Year: 2009
Title: Visualizing Social Photos on a Hasse Diagram for Eliciting Relations and Indexing New Photos
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290703
Abstract: Social photos, which are taken during family events or parties, represent individuals or groups of people. We show in this paper how a Hasse diagram is an efficient visualization strategy for eliciting different groups and navigating through them. However, we do not limit this strategy to these traditional uses. Instead we show how it can also be used for assisting in indexing new photos. Indexing consists of identifying the event and people in photos. It is an integral phase that takes place before searching and sharing. In our method we use existing indexed photos to index new photos. This is performed through a manual drag and drop procedure followed by a content fusion process that we call 'propagation'. At the core of this process is the necessity to organize and visualize the photos that will be used for indexing in a manner that is easily recognizable and accessible by the user. In this respect we make use of an object Galois sub-hierarchy and display it using a Hasse diagram. The need for an incremental display that maintains the user's mental map also leads us to propose a novel way of building the Hasse diagram. To validate the approach, we present some tests conducted with a sample of users that confirm the interest of this organization, visualization and indexation approach. Finally, we conclude by considering scalability, the possibility to extract social networks and automatically create personalised albums.
Keywords: Galois fields;Galois sub-hierarchy.;Hasse Diagram;Hasse diagram;Information visualization;content fusion process;data analysis;data visualisation;eliciting relations;formal concept analysis;formal concept analysis;human computer interaction;indexation;indexing;indexing new photos;information visualization;object Galois sub-hierarchy;social networking (online);social photos;social photos;visualization strategy;
Author: Crampes, M.; de Oliveira-Kumar, J.; Ranwez, S.; Villerd, J.

Year: 2009
Title: Interactive Dimensionality Reduction Through User-defined Combinations of Quality Metrics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290704
Abstract: Multivariate data sets including hundreds of variables are increasingly common in many application areas. Most multivariate visualization techniques are unable to display such data effectively, and a common approach is to employ dimensionality reduction prior to visualization. Most existing dimensionality reduction systems focus on preserving one or a few significant structures in data. For many analysis tasks, however, several types of structures can be of high significance and the importance of a certain structure compared to the importance of another is often task-dependent. This paper introduces a system for dimensionality reduction by combining user-defined quality metrics using weight functions to preserve as many important structures as possible. The system aims at effective visualization and exploration of structures within large multivariate data sets and provides enhancement of diverse structures by supplying a range of automatic variable orderings. Furthermore it enables a quality-guided reduction of variables through an interactive display facilitating investigation of trade-offs between loss of structure and the number of variables to keep. The generality and interactivity of the system is demonstrated through a case scenario.
Keywords: Information Visualization;Multidimensional Scaling;Parallel Coordinates;Scatterplots;data reduction;data visualisation;interactive dimensionality reduction;interactive systems;multivariate data sets;multivariate visualization technique;quality metrics;user-defined combinations;
Author: Johansson, S.; Johansson, J.

Year: 2009
Title: Scattering Points in Parallel Coordinates
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290705
Abstract: In this paper, we present a novel parallel coordinates design integrated with points (scattering points in parallel coordinates, SPPC), by taking advantage of both parallel coordinates and scatterplots. Different from most multiple views visualization frameworks involving parallel coordinates where each visualization type occupies an individual window, we convert two selected neighboring coordinate axes into a scatterplot directly. Multidimensional scaling is adopted to allow converting multiple axes into a single subplot. The transition between two visual types is designed in a seamless way. In our work, a series of interaction tools has been developed. Uniform brushing functionality is implemented to allow the user to perform data selection on both points and parallel coordinate polylines without explicitly switching tools. A GPU accelerated dimensional incremental multidimensional scaling (DIMDS) has been developed to significantly improve the system performance. Our case study shows that our scheme is more efficient than traditional multi-view methods in performing visual analysis tasks.
Keywords: Dimensionality reduction;GPU;data selection;data visualisation;data visualization;dimensional incremental multidimensional scaling;interactivity;multidimensional scaling;parallel coordinates;quality metrics;scattering points;variable ordering.;visual analysis tasks;
Author: Xiaoru Yuan; Peihong Guo; He Xiao; Hong Zhou; Huamin Qu

Year: 2009
Title: Bubble Sets: Revealing Set Relations with Isocontours over Existing Visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290706
Abstract: While many data sets contain multiple relationships, depicting more than one data relationship within a single visualization is challenging. We introduce Bubble Sets as a visualization technique for data that has both a primary data relation with a semantically significant spatial organization and a significant set membership relation in which members of the same set are not necessarily adjacent in the primary layout. In order to maintain the spatial rights of the primary data relation, we avoid layout adjustment techniques that improve set cluster continuity and density. Instead, we use a continuous, possibly concave, isocontour to delineate set membership, without disrupting the primary layout. Optimizations minimize cluster overlap and provide for calculation of the isocontours at interactive speeds. Case studies show how this technique can be used to indicate multiple sets on a variety of common visualizations.
Keywords: Bubble sets;clustering;data relationship;data sets;data visualisation;data visualization;graph visualization;isocontours;primary data relation;set cluster continuity;set relation;set theory;spatial layout;tree visualization;
Author: Collins, C.; Penn, G.; Carpendale, S.

Year: 2009
Title: FromDaDy: Spreading Aircraft Trajectories Across Views to Support Iterative Queries
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290707
Abstract: When displaying thousands of aircraft trajectories on a screen, the visualization is spoiled by a tangle of trails. The visual analysis is therefore difficult, especially if a specific class of trajectories in an erroneous dataset has to be studied. We designed FromDaDy, a trajectory visualization tool that tackles the difficulties of exploring the visualization of multiple trails. This multidimensional data exploration is based on scatterplots, brushing, pick and drop, juxtaposed views and rapid visual design. Users can organize the workspace composed of multiple juxtaposed views. They can define the visual configuration of the views by connecting data dimensions from the dataset to Bertin's visual variables. They can then brush trajectories, and with a pick and drop operation they can spread the brushed information across views. They can then repeat these interactions, until they extract a set of relevant data, thus formulating complex queries. Through two real-world scenarios, we show how FromDaDy supports iterative queries and the extraction of trajectories in a dataset that contains up to 5 million data.
Keywords: FromDaDy;air traffic;aircraft trajectories;data visualisation;direct manipulation;iterative exploration;iterative queries;multidimensional data exploration;pick and drop operation;query processing;trajectories;trajectory visualization tool;visual analysis;visualization;
Author: Hurter, C.; Tissoires, B.; Conversy, S.

Year: 2009
Title: SellTrend: Inter-Attribute Visual Analysis of Temporal Transaction Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290708
Abstract: We present a case study of our experience designing SellTrend, a visualization system for analyzing airline travel purchase requests. The relevant transaction data can be characterized as multi-variate temporal and categorical event sequences, and the chief problem addressed is how to help company analysts identify complex combinations of transaction attributes that contribute to failed purchase requests. SellTrend combines a diverse set of techniques ranging from time series visualization to faceted browsing and historical trend analysis in order to help analysts make sense of the data. We believe that the combination of views and interaction capabilities in SellTrend provides an innovative approach to this problem and to other similar types of multivariate, temporally driven transaction data analysis. Initial feedback from company analysts confirms the utility and benefits of the system.
Keywords: SellTrend;airline travel purchase requests;categorical data;categorical event sequences;data analysis;data visualisation;historical trend analysis;information visualization;inter-attribute visual analysis;investigative analysis;multi-variate temporal event sequences;multiple attributes;multiple views;temporal transaction data analysis;time series;time series data;time series visualization;transaction analysis;travel industry;
Author: Zhicheng Liu; Stasko, J.; Sullivan, T.

Year: 2009
Title: Comparing Dot and Landscape Spatializations for Visual Memory Differences
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290709
Abstract: Spatialization displays use a geographic metaphor to arrange non-spatial data. For example, spatializations are commonly applied to document collections so that document themes appear as geographic features such as hills. Many common spatialization interfaces use a 3-D landscape metaphor to present data. However, it is not clear whether 3-D spatializations afford improved speed and accuracy for user tasks compared to similar 2-D spatializations. We describe a user study comparing users' ability to remember dot displays, 2-D landscapes, and 3-D landscapes for two different data densities (500 vs. 1000 points). Participants' visual memory was statistically more accurate when viewing dot displays and 3-D landscapes compared to 2-D landscapes. Furthermore, accuracy remembering a spatialization was significantly better overall for denser spatializations. Theseresults are of benefit to visualization designers who are contemplating the best ways to present data using spatialization techniques.
Keywords: 2D landscapes;3D landscapes;Information interfaces and presentation;data visualisation;document collections;document handling;dot displays;dot spatializations;evaluation / methodology;geographic metaphor;landscape spatializations;landscape visualization.;nonspatial data;screen design;software psychology;spatialization displays;spatialization interfaces;user / machine systems;visual memory differences;
Author: Tory, M.; Swindells, C.; Dreezer, R.

Year: 2009
Title: Flow Mapping and Multivariate Visualization of Large Spatial Interaction Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290710
Abstract: Spatial interactions (or flows), such as population migration and disease spread, naturally form a weighted location-to-location network (graph). Such geographically embedded networks (graphs) are usually very large. For example, the county-to-county migration data in the U.S. has thousands of counties and about a million migration paths. Moreover, many variables are associated with each flow, such as the number of migrants for different age groups, income levels, and occupations. It is a challenging task to visualize such data and discover network structures, multivariate relations, and their geographic patterns simultaneously. This paper addresses these challenges by developing an integrated interactive visualization framework that consists three coupled components: (1) a spatially constrained graph partitioning method that can construct a hierarchy of geographical regions (communities), where there are more flows or connections within regions than across regions; (2) a multivariate clustering and visualization method to detect and present multivariate patterns in the aggregated region-to-region flows; and (3) a highly interactive flow mapping component to map both flow and multivariate patterns in the geographic space, at different hierarchical levels. The proposed approach can process relatively large data sets and effectively discover and visualize major flow structures and multivariate relations at the same time. User interactions are supported to facilitate the understanding of both an overview and detailed patterns.
Keywords: cartography;contiguity constraints;coordinated views;county-to-county migration data;data mining;data visualisation;flow mapping;geographic space;graph partitioning;hierarchical clustering;integrated interactive visualization framework;interactive flow mapping;large spatial interaction data;multidimensional visualization;multivariate clustering;multivariate visualization;spatial interaction;spatially constrained graph partitioning method;user interfaces;weighted location-to-location network;
Author: Diansheng Guo

Year: 2009
Title: Temporal Summaries: Supporting Temporal Categorical Searching, Aggregation and Comparison
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290711
Abstract: When analyzing thousands of event histories, analysts often want to see the events as an aggregate to detect insights and generate new hypotheses about the data. An analysis tool must emphasize both the prevalence and the temporal ordering of these events. Additionally, the analysis tool must also support flexible comparisons to allow analysts to gather visual evidence. In a previous work, we introduced align, rank, and filter (ARF) to accentuate temporal ordering. In this paper, we present temporal summaries, an interactive visualization technique that highlights the prevalence of event occurrences. Temporal summaries dynamically aggregate events in multiple granularities (year, month, week, day, hour, etc.) for the purpose of spotting trends over time and comparing several groups of records. They provide affordances for analysts to perform temporal range filters. We demonstrate the applicability of this approach in two extensive case studies with analysts who applied temporal summaries to search, filter, and look for patterns in electronic health records and academic records.
Keywords: Computational Biology;Computer Graphics;Databases, Factual;Heparin;Human-computer interaction;Humans;Information Visualization;Interaction design;Medical Records Systems, Computerized;Pattern Recognition, Automated;Thrombocytopenia;Time Factors;data visualisation;human computer interaction;interactive visualization technique;temporal categorical data visualization;temporal categorical searching;temporal ordering;temporal summaries;
Author: Wang, T.D.; Plaisant, C.; Shneiderman, B.; Spring, N.; Roseman, D.; Marchand, G.; Mukherjee, V.; Smith, M.

Year: 2009
Title: ResultMaps: Visualization for Search Interfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290712
Abstract: Hierarchical representations are common in digital repositories, yet are not always fully leveraged in their online search interfaces. This work describes ResultMaps, which use hierarchical treemap representations with query string-driven digital library search engines. We describe two lab experiments, which find that ResultsMap users yield significantly better results over a control condition on some subjective measures, and we find evidence that ResultMaps have ancillary benefits via increased understanding of some aspects of repository content. The ResultMap system and experiments contribute an understanding of the benefits-direct and indirect-of the ResultMap approach to repository search visualization.
Keywords: ResultMap system;Treemap;data visualisation;digital libraries;digital library;digital repositories;digital repository;evaluation;hierarchical treemap representations;infovis;online search interfaces;query processing;query string-driven digital library search engines;repository search visualization;search engine;search engines;search visualization;trees (mathematics);user interfaces;user studies;
Author: Clarkson, E.; Desai, K.; Foley, J.

Year: 2009
Title: Lark: Coordinating Co-located Collaboration with Information Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290713
Abstract: Large multi-touch displays are expanding the possibilities of multiple-coordinated views by allowing multiple people to interact with data in concert or independently. We present Lark, a system that facilitates the coordination of interactions with information visualizations on shared digital workspaces. We focus on supporting this coordination according to four main criteria: scoped interaction, temporal flexibility, spatial flexibility, and changing collaboration styles. These are achieved by integrating a representation of the information visualization pipeline into the shared workspace, thus explicitly indicating coordination points on data, representation, presentation, and view levels. This integrated meta-visualization supports both the awareness of how views are linked and the freedom to work in concert or independently. Lark incorporates these four main criteria into a coherent visualization collaboration interaction environment by providing direct visual and algorithmic support for the coordination of data analysis actions over shared large displays.
Keywords: Co-located work;Collaboration;Coordination;Information visualization;Lark;Meta-visualization;Workspace awareness;colocated collaboration;data analysis;data analysis;data visualisation;information visualization;integrated meta-visualization;multitouch displays;scoped interaction;spatial flexibility;temporal flexibility;touch sensitive screens;
Author: Tobiasz, M.; Isenberg, P.; Carpendale, S.

Year: 2009
Title: The Benefits of Synchronous Collaborative Information Visualization: Evidence from an Experimental Evaluation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290714
Abstract: A great corpus of studies reports empirical evidence of how information visualization supports comprehension and analysis of data. The benefits of visualization for synchronous group knowledge work, however, have not been addressed extensively. Anecdotal evidence and use cases illustrate the benefits of synchronous collaborative information visualization, but very few empirical studies have rigorously examined the impact of visualization on group knowledge work. We have consequently designed and conducted an experiment in which we have analyzed the impact of visualization on knowledge sharing in situated work groups. Our experimental study consists of evaluating the performance of 131 subjects (all experienced managers) in groups of 5 (for a total of 26 groups), working together on a real-life knowledge sharing task. We compare (1) the control condition (no visualization provided), with two visualization supports: (2) optimal and (3) suboptimal visualization (based on a previous survey). The facilitator of each group was asked to populate the provided interactive visual template with insights from the group, and to organize the contributions according to the group consensus. We have evaluated the results through both objective and subjective measures. Our statistical analysis clearly shows that interactive visualization has a statistically significant, objective and positive impact on the outcomes of knowledge sharing, but that the subjects seem not to be aware of this. In particular, groups supported by visualization achieved higher productivity, higher quality of outcome and greater knowledge gains. No statistically significant results could be found between an optimal and a suboptimal visualization though (as classified by the pre-experiment survey). Subjects also did not seem to be aware of the benefits that the visualizations provided as no difference between the visualization and the control conditions was found for the self-reported measures of satisfaction a--nd participation. An implication of our study for information visualization applications is to extend them by using real-time group annotation functionalities that aid in the group sense making process of the represented data.
Keywords: Collaborative and Distributed Visualization;Laboratory Studies;Visual Knowledge Representation;data analysis;data analysis;data visualisation;experiment;group annotation;group work;knowledge sharing;knowledge sharing;statistical analysis;statistical analysis;suboptimal visualization;synchronous collaborative information visualization;synchronous group knowledge work;synchronous situated collaboration;
Author: Bresciani, S.; Eppler, M.J.

Year: 2009
Title: Harnessing the Information Ecosystem with Wiki-based Visualization Dashboards
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290715
Abstract: We describe the design and deployment of Dashiki, a public Website where users may collaboratively build visualization dashboards through a combination of a wiki-like syntax and interactive editors. Our goals are to extend existing research on social data analysis into presentation and organization of data from multiple sources, explore new metaphors for these activities, and participate more fully in the Web's information ecology by providing tighter integration with real-time data. To support these goals, our design includes novel and low-barrier mechanisms for editing and layout of dashboard pages and visualizations, connection to data sources, and coordinating interaction between visualizations. In addition to describing these technologies, we provide a preliminary report on the public launch of a prototype based on this design, including a description of the activities of our users derived from observation and interviews.
Keywords: Dashiki;Internet;Web information ecology;Web information ecosystem;Wiki-based visualization dashboards;collaboration;coordinating interaction;dashboard pages;dashboards;data analysis;data visualisation;public Web site;social data analysis;social data analysis;social networking (online);social software;visual analytics.;visualization;web;wiki-like syntax;wikis;
Author: McKeon, M.

Year: 2009
Title: SpicyNodes: Radial Layout Authoring for the General Public
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290716
Abstract: Trees and graphs are relevant to many online tasks such as visualizing social networks, product catalogs, educational portals, digital libraries, the semantic web, concept maps and personalized information management. SpicyNodes is an information-visualization technology that builds upon existing research on radial tree layouts and graph structures. Users can browse a tree, clicking from node to node, as well as successively viewing a node, immediately related nodes and the path back to the ldquohomerdquo nodes. SpicyNodes' layout algorithms maintain balanced layouts using a hybrid mixture of a geometric layout (a succession of spanning radial trees) and force-directed layouts to minimize overlapping nodes, plus several other improvements over prior art. It provides XML-based API and GUI authoring tools. The goal of the SpicyNodes project is to implement familiar principles of radial maps and focus+context with an attractive and inviting look and feel in an open system that is accessible to virtually any Internet user.
Keywords: GUI authoring tools;SpicyNodes;Trees and network visualization;XML-based API;authoring systems;data visualisation;focus+context;force-directed layouts;geometric layout;graph structures;hierarchy visualization;human-computer interaction;information visualization;information-visualization technology;interaction;radial layout authoring;radial tree layout;radial tree layouts;trees (mathematics);
Author: Douma, M.; Ligierko, G.; Ancuta, O.; Gritsai, P.; Liu, S.

Year: 2009
Title: code_swarm: A Design Study in Organic Software Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290717
Abstract: In May of 2008, we published online a series of software visualization videos using a method called code_swarm. Shortly thereafter, we made the code open source and its popularity took off. This paper is a study of our code swarm application, comprising its design, results and public response. We share our design methodology, including why we chose the organic information visualization technique, how we designed for both developers and a casual audience, and what lessons we learned from our experiment. We validate the results produced by code_swarm through a qualitative analysis and by gathering online user comments. Furthermore, we successfully released the code as open source, and the software community used it to visualize their own projects and shared their results as well. In the end, we believe code_swarm has positive implications for the future of organic information design and open source information visualization practice.
Keywords: Software visualization;code_swarm;data visualisation;design methodology;open source information visualization practice;organic information design;organic information visualization;organic information visualization technique;organic software visualization;public domain software;software development evolution;software development history;software development history and evolution.;software maintenance;software visualization videos;video signal processing;
Author: Ogawa, M.; Kwan-Liu Ma

Year: 2009
Title: Towards Utilizing GPUs in Information Visualization: A Model and Implementation of Image-Space Operations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290718
Abstract: Modern programmable GPUs represent a vast potential in terms of performance and visual flexibility for information visualization research, but surprisingly few applications even begin to utilize this potential. In this paper, we conjecture that this may be due to the mismatch between the high-level abstract data types commonly visualized in our field, and the low-level floating-point model supported by current GPU shader languages. To help remedy this situation, we present a refinement of the traditional information visualization pipeline that is amenable to implementation using GPU shaders. The refinement consists of a final image-space step in the pipeline where the multivariate data of the visualization is sampled in the resolution of the current view. To concretize the theoretical aspects of this work, we also present a visual programming environment for constructing visualization shaders using a simple drag-and-drop interface. Finally, we give some examples of the use of shaders for well-known visualization techniques.
Keywords: GPU shader languages;GPU-acceleration;abstract data types;coprocessors;data visualisation;drag-and-drop interface;high-level abstract data type;high-performance visualization;image-space operation;information visualization;interaction;low-level floating-point model;shader programming;visual programming;visual programming environment;
Author: McDonnel, B.; Elmqvist, N.

Year: 2009
Title: A Multi-Threading Architecture to Support Interactive Visual Exploration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290719
Abstract: During continuous user interaction, it is hard to provide rich visual feedback at interactive rates for datasets containing millions of entries. The contribution of this paper is a generic architecture that ensures responsiveness of the application even when dealing with large data and that is applicable to most types of information visualizations. Our architecture builds on the separation of the main application thread and the visualization thread, which can be cancelled early due to user interaction. In combination with a layer mechanism, our architecture facilitates generating previews incrementally to provide rich visual feedback quickly. To help avoiding common pitfalls of multi-threading, we discuss synchronization and communication in detail. We explicitly denote design choices to control trade-offs. A quantitative evaluation based on the system VI S P L ORE shows fast visual feedback during continuous interaction even for millions of entries. We describe instantiations of our architecture in additional tools.
Keywords: Information visualization architecture;VISPLORE;continuous interaction;continuous user interaction;data visualisation;information visualizations;interactive visual exploration;layer;multi-threading;multi-threading;multi-threading architecture;preview;software architecture;user interfaces;visual feedback;
Author: Piringer, H.; Tominski, C.; Muigg, P.; Berger, W.

Year: 2009
Title: Protovis: A Graphical Toolkit for Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290720
Abstract: Despite myriad tools for visualizing data, there remains a gap between the notational efficiency of high-level visualization systems and the expressiveness and accessibility of low-level graphical systems. Powerful visualization systems may be inflexible or impose abstractions foreign to visual thinking, while graphical systems such as rendering APIs and vector-based drawing programs are tedious for complex work. We argue that an easy-to-use graphical system tailored for visualization is needed. In response, we contribute Protovis, an extensible toolkit for constructing visualizations by composing simple graphical primitives. In Protovis, designers specify visualizations as a hierarchy of marks with visual properties defined as functions of data. This representation achieves a level of expressiveness comparable to low-level graphics systems, while improving efficiency - the effort required to specify a visualization - and accessibility - the effort required to learn and modify the representation. We substantiate this claim through a diverse collection of examples and comparative analysis with popular visualization tools.
Keywords: 2D graphics.;Information visualization;Protovis;application program interfaces;data visualisation;data visualization;graphical visualization toolkit;high-level visualization systems;low-level graphical systems;rendering (computer graphics);rendering API;toolkits;user interfaces;vector-based drawing programs;
Author: Bostock, M.; Heer, J.

Year: 2009
Title: Visual Analysis of Inter-Process Communication for Large-Scale Parallel Computing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290721
Abstract: In serial computation, program profiling is often helpful for optimization of key sections of code. When moving to parallel computation, not only does the code execution need to be considered but also communication between the different processes which can induce delays that are detrimental to performance. As the number of processes increases, so does the impact of the communication delays on performance. For large-scale parallel applications, it is critical to understand how the communication impacts performance in order to make the code more efficient. There are several tools available for visualizing program execution and communications on parallel systems. These tools generally provide either views which statistically summarize the entire program execution or process-centric views. However, process-centric visualizations do not scale well as the number of processes gets very large. In particular, the most common representation of parallel processes is a Gantt chart with a row for each process. As the number of processes increases, these charts can become difficult to work with and can even exceed screen resolution. We propose a new visualization approach that affords more scalability and then demonstrate it on systems running with up to 16,384 processes.
Keywords: Gantt chart;Information Visualization;MPI Profiling;MPI Profiling;Scalability;application program interfaces;data visualisation;information visualization;interprocess communication;large-scale parallel computing;message passing;parallel processes;parallel systems;program execution;program profiling;visual analysis;
Author: Muelder, C.; Gygi, F.; Kwan-Liu Ma

Year: 2009
Title: Participatory Visualization with Wordle
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290722
Abstract: We discuss the design and usage of ldquoWordle,rdquo a Web-based tool for visualizing text. Wordle creates tag-cloud-like displays that give careful attention to typography, color, and composition. We describe the algorithms used to balance various aesthetic criteria and create the distinctive Wordle layouts. We then present the results of a study of Wordle usage, based both on spontaneous behaviour observed in the wild, and on a large-scale survey of Wordle users. The results suggest that Wordles have become a kind of medium of expression, and that a ldquoparticipatory culturerdquo has arisen around them.
Keywords: Visualization;Web sites;Web-based tool;Wordle;Wordle layouts;data analysis;data visualisation;educational visualization;memory;participatory culture;social data analysis;tag cloud;tag-cloud-like displays;text;text analysis;text visualisation;
Author: Viegas, F.B.; Wattenberg, M.; Feinberg, J.

Year: 2009
Title: Document Cards: A Top Trumps Visualization for Documents
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290723
Abstract: Finding suitable, less space consuming views for a document's main content is crucial to provide convenient access to large document collections on display devices of different size. We present a novel compact visualization which represents the document's key semantic as a mixture of images and important key terms, similar to cards in a top trumps game. The key terms are extracted using an advanced text mining approach based on a fully automatic document structure extraction. The images and their captions are extracted using a graphical heuristic and the captions are used for a semi-semantic image weighting. Furthermore, we use the image color histogram for classification and show at least one representative from each non-empty image class. The approach is demonstrated for the IEEE InfoVis publications of a complete year. The method can easily be applied to other publication collections and sets of documents which contain images.
Keywords: IEEE InfoVis publications;advanced text mining;compact visualization;content extraction;data mining;data visualisation;display devices;document cards;document collection browsing;document image processing;document structure extraction;document visualization;image color histogram;semi-semantic image weighting;top trumps document visualization;visual summary;
Author: Strobelt, H.; Oelke, D.; Rohrdantz, C.; Stoffel, A.; Keim, D.A.; Deussen, O.

Year: 2009
Title: Visualizing the Intellectual Structure with Paper-Reference Matrices
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290724
Abstract: Visualizing the intellectual structure of scientific domains using co-cited units such as references or authors has become a routine for domain analysis. In previous studies, paper-reference matrices are usually transformed into reference-reference matrices to obtain co-citation relationships, which are then visualized in different representations, typically as node-link networks, to represent the intellectual structures of scientific domains. Such network visualizations sometimes contain tightly knit components, which make visual analysis of the intellectual structure a challenging task. In this study, we propose a new approach to reveal co-citation relationships. Instead of using a reference-reference matrix, we directly use the original paper-reference matrix as the information source, and transform the paper-reference matrix into an FP-tree and visualize it in a Java-based prototype system. We demonstrate the usefulness of our approach through visual analyses of the intellectual structure of two domains: information visualization and Sloan Digital Sky Survey (SDSS). The results show that our visualization not only retains the major information of co-citation relationships, but also reveals more detailed sub-structures of tightly knit clusters than a conventional node-link network visualization.
Keywords: Co-citation;FP-tree;FP-tree;Intellectual Structure;Java;Java-based prototype system;Paper-reference Matrix;SDSS;Sloan Digital Sky Survey;astronomical surveys;astronomy computing;author analysis;citation analysis;co-citation relationship;co-cited unit;data visualisation;information source;information visualization;intellectual structure visualization;network theory (graphs);node-link network visualization;paper-reference matrix;pattern clustering;reference analysis;reference-reference matrix;scientific domain analysis;scientific information systems;tightly-knit cluster;trees (mathematics);visual analysis;
Author: Jian Zhang; Chaomei Chen; Jiexun Li

Year: 2009
Title: Exemplar-based Visualization of Large Document Corpus (InfoVis2009-1115)
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290725
Abstract: With the rapid growth of the World Wide Web and electronic information services, text corpus is becoming available online at an incredible rate. By displaying text data in a logical layout (e.g., color graphs), text visualization presents a direct way to observe the documents as well as understand the relationship between them. In this paper, we propose a novel technique, Exemplar-based visualization (EV), to visualize an extremely large text corpus. Capitalizing on recent advances in matrix approximation and decomposition, EV presents a probabilistic multidimensional projection model in the low-rank text subspace with a sound objective function. The probability of each document proportion to the topics is obtained through iterative optimization and embedded to a low dimensional space using parameter embedding. By selecting the representative exemplars, we obtain a compact approximation of the data. This makes the visualization highly efficient and flexible. In addition, the selected exemplars neatly summarize the entire data set and greatly reduce the cognitive overload in the visualization, leading to an easier interpretation of large text corpus. Empirically, we demonstrate the superior performance of EV through extensive experiments performed on the publicly available text data sets.
Keywords: Exemplar;biology computing;data visualisation;exemplar-based visualization;iterative methods;iterative optimization;large document corpus;large-scale document visualization;matrix approximation;multidimensional projection.;optimisation;parameter embedding;text corpus;text visualization;
Author: Yanhua Chen; Lijun Wang; Ming Dong; Jing Hua

Year: 2009
Title: Mapping Text with Phrase Nets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290726
Abstract: We present a new technique, the phrase net, for generating visual overviews of unstructured text. A phrase net displays a graph whose nodes are words and whose edges indicate that two words are linked by a user-specified relation. These relations may be defined either at the syntactic or lexical level; different relations often produce very different perspectives on the same text. Taken together, these perspectives often provide an illuminating visual overview of the key concepts and relations in a document or set of documents.
Keywords: Text visualization;data visualisation;natural language processing;phrase nets;semantic net;tag cloud;text analysis;text mapping;user-specified relation;visual overviews;
Author: van Ham, F.; Wattenberg, M.; Viegas, F.B.

Year: 2009
Title: Loop surgery for volumetric meshes: Reeb graphs reduced to contour trees
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290727
Abstract: This paper introduces an efficient algorithm for computing the Reeb graph of a scalar function f defined on a volumetric mesh M in Ropf<sup>3</sup>. We introduce a procedure called "loop surgery" that transforms M into a mesh M' by a sequence of cuts and guarantees the Reeb graph of f(M') to be loop free. Therefore, loop surgery reduces Reeb graph computation to the simpler problem of computing a contour tree, for which well-known algorithms exist that are theoretically efficient (O(n log n)) and fast in practice. Inverse cuts reconstruct the loops removed at the beginning. The time complexity of our algorithm is that of a contour tree computation plus a loop surgery overhead, which depends on the number of handles of the mesh. Our systematic experiments confirm that for real-life data, this overhead is comparable to the computation of the contour tree, demonstrating virtually linear scalability on meshes ranging from 70 thousand to 3.5 million tetrahedra. Performance numbers show that our algorithm, although restricted to volumetric data, has an average speedup factor of 6,500 over the previous fastest techniques, handling larger and more complex data-sets. We demonstrate the verstility of our approach by extending fast topologically clean isosurface extraction to non simply-connected domains. We apply this technique in the context of pressure analysis for mechanical design. In this case, our technique produces results in matter of seconds even for the largest meshes. For the same models, previous Reeb graph techniques do not produce a result.
Keywords: Reeb graph;Reeb graphs;computational complexity;contour trees;data visualisation;graph theory;isosurfaces;loop surgery;mechanical design pressure analysis;mesh generation;scalar field topology;scalar function;time complexity;topological simplification;volumetric meshes;
Author: Tierny, J.; Gyulassy, A.; Simon, E.; Pascucci, V.

Year: 2009
Title: Applying Manifold Learning to Plotting Approximate Contour Trees
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290728
Abstract: A contour tree is a powerful tool for delineating the topological evolution of isosurfaces of a single-valued function, and thus has been frequently used as a means of extracting features from volumes and their time-varying behaviors. Several sophisticated algorithms have been proposed for constructing contour trees while they often complicate the software implementation especially for higher-dimensional cases such as time-varying volumes. This paper presents a simple yet effective approach to plotting in 3D space, approximate contour trees from a set of scattered samples embedded in the high-dimensional space. Our main idea is to take advantage of manifold learning so that we can elongate the distribution of high-dimensional data samples to embed it into a low-dimensional space while respecting its local proximity of sample points. The contribution of this paper lies in the introduction of new distance metrics to manifold learning, which allows us to reformulate existing algorithms as a variant of currently available dimensionality reduction scheme. Efficient reduction of data sizes together with segmentation capability is also developed to equip our approach with a coarse-to-fine analysis even for large-scale datasets. Examples are provided to demonstrate that our proposed scheme can successfully traverse the features of volumes and their temporal behaviors through the constructed contour trees.
Keywords: Contour trees;computer graphics;contour tree;data analysis;dimensionality reduction scheme;edge detection;high-dimensional data analysis;high-dimensional data samples;isosurfaces;large-scale datasets;manifold learning;manifold learning;plotting approximation;segmentation capability;single-valued function;time-varying volumes;time-varying volumes;
Author: Takahashi, S.; Fujishiro, I.; Okada, M.

Year: 2009
Title: Intrinsic Geometric Scale Space by Shape Diffusion
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290729
Abstract: This paper formalizes a novel, intrinsic geometric scale space (IGSS) of 3D surface shapes. The intrinsic geometry of a surface is diffused by means of the Ricci flow for the generation of a geometric scale space. We rigorously prove that this multiscale shape representation satisfies the axiomatic causality property. Within the theoretical framework, we further present a feature-based shape representation derived from IGSS processing, which is shown to be theoretically plausible and practically effective. By integrating the concept of scale-dependent saliency into the shape description, this representation is not only highly descriptive of the local structures, but also exhibits several desired characteristics of global shape representations, such as being compact, robust to noise and computationally efficient. We demonstrate the capabilities of our approach through salient geometric feature detection and highly discriminative matching of 3D scans.
Keywords: 3D surface shapes;Ricci flow;Riemannian manifolds;Scale space;axiomatic causality property;computer graphics;feature extraction;feature extraction;feature-based shape representation;geometric flow;global shape representations;image matching;image representation;intrinsic geometric scale space;multiscale shape representation;salient geometric feature detection;scale-dependent saliency;shape diffusion;
Author: Guangyu Zou; Jing Hua; Zhaoqiang Lai; Xianfeng Gu; Ming Dong

Year: 2009
Title: Multi-Scale Surface Descriptors
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290730
Abstract: Local shape descriptors compactly characterize regions of a surface, and have been applied to tasks in visualization, shape matching, and analysis. Classically, curvature has be used as a shape descriptor; however, this differential property characterizes only an infinitesimal neighborhood. In this paper, we provide shape descriptors for surface meshes designed to be multi-scale, that is, capable of characterizing regions of varying size. These descriptors capture statistically the shape of a neighborhood around a central point by fitting a quadratic surface. They therefore mimic differential curvature, are efficient to compute, and encode anisotropy. We show how simple variants of mesh operations can be used to compute the descriptors without resorting to expensive parameterizations, and additionally provide a statistical approximation for reduced computational cost. We show how these descriptors apply to a number of uses in visualization, analysis, and matching of surfaces, particularly to tasks in protein surface analysis.
Keywords: Curvature;anisotropy;approximation theory;curve fitting;data visualisation;data visualization;descriptors;differential curvature;image matching;infinitesimal neighborhood;local shape descriptor;mesh generation;multiscale surface mesh descriptor;npr;protein surface analysis;quadratic surface fitting;rendering (computer graphics);shape matching;shape matching.;shape recognition;statistical analysis;statistical approximation;stylized rendering;stylized rendering;surface fitting;
Author: Cipriano, G.; Phillips, G.N.; Gleicher, M.

Year: 2009
Title: A User Study to Compare Four Uncertainty Visualization Methods for 1D and 2D Datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290731
Abstract: Many techniques have been proposed to show uncertainty in data visualizations. However, very little is known about their effectiveness in conveying meaningful information. In this paper, we present a user study that evaluates the perception of uncertainty amongst four of the most commonly used techniques for visualizing uncertainty in one-dimensional and two-dimensional data. The techniques evaluated are traditional errorbars, scaled size of glyphs, color-mapping on glyphs, and color-mapping of uncertainty on the data surface. The study uses generated data that was designed to represent the systematic and random uncertainty components. Twenty-seven users performed two types of search tasks and two types of counting tasks on 1D and 2D datasets. The search tasks involved finding data points that were least or most uncertain. The counting tasks involved counting data features or uncertainty features. A 4 times 4 full-factorial ANOVA indicated a significant interaction between the techniques used and the type of tasks assigned for both datasets indicating that differences in performance between the four techniques depended on the type of task performed. Several one-way ANOVAs were computed to explore the simple main effects. Bonferronni's correction was used to control for the family-wise error rate for alpha-inflation. Although we did not find a consistent order among the four techniques for all the tasks, there are several findings from the study that we think are useful for uncertainty visualization design. We found a significant difference in user performance between searching for locations of high and searching for locations of low uncertainty. Errorbars consistently underperformed throughout the experiment. Scaling the size of glyphs and color-mapping of the surface performed reasonably well. The efficiency of most of these techniques were highly dependent on the tasks performed. We believe that these findings can be used in future uncertainty visualization desig--n. In addition, the framework developed in this user study presents a structured approach to evaluate uncertainty visualization techniques, as well as provides a basis for future research in uncertainty visualization.
Keywords: ANOVA;User study;counting task;data surface;data visualisation;data visualization;error rate;errorbars;glyphs;search task;surface color-mapping;uncertainty visualization;uncertainty visualization;
Author: Sanyal, J.; Song Zhang; Bhattacharya, G.; Amburn, P.; Moorhead, R.

Year: 2009
Title: Comparing 3D Vector Field Visualization Methods: A User Study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290732
Abstract: In a user study comparing four visualization methods for three-dimensional vector data, participants used visualizations from each method to perform five simple but representative tasks: 1) determining whether a given point was a critical point, 2) determining the type of a critical point, 3) determining whether an integral curve would advect through two points, 4) determining whether swirling movement is present at a point, and 5) determining whether the vector field is moving faster at one point than another. The visualization methods were line and tube representations of integral curves with both monoscopic and stereoscopic viewing. While participants reported a preference for stereo lines, quantitative results showed performance among the tasks varied by method. Users performed all tasks better with methods that: 1) gave a clear representation with no perceived occlusion, 2) clearly visualized curve speed and direction information, and 3) provided fewer rich 3D cues (e.g., shading, polygonal arrows, overlap cues, and surface textures). These results provide quantitative support for anecdotal evidence on visualization methods. The tasks and testing framework also give a basis for comparing other visualization methods, for creating more effective methods, and for defining additional tasks to explore further the tradeoffs among the methods.
Keywords: 3D vector field visualization methods;3D vector fields;data visualisation;integral curve;lines;monoscopic viewing;stereo lines;stereoscopic and monoscopic viewing;stereoscopic viewing;swirling movement;tubes;user study;visualization;
Author: Forsberg, A.; Jian Chen; Laidlaw, D.

Year: 2009
Title: Verifiable Visualization for Isosurface Extraction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290733
Abstract: Visual representations of isosurfaces are ubiquitous in the scientific and engineering literature. In this paper, we present techniques to assess the behavior of isosurface extraction codes. Where applicable, these techniques allow us to distinguish whether anomalies in isosurface features can be attributed to the underlying physical process or to artifacts from the extraction process. Such scientific scrutiny is at the heart of verifiable visualization - subjecting visualization algorithms to the same verification process that is used in other components of the scientific pipeline. More concretely, we derive formulas for the expected order of accuracy (or convergence rate) of several isosurface features, and compare them to experimentally observed results in the selected codes. This technique is practical: in two cases, it exposed actual problems in implementations. We provide the reader with the range of responses they can expect to encounter with isosurface techniques, both under ldquonormal operating conditionsrdquo and also under adverse conditions. Armed with this information - the results of the verification process - practitioners can judiciously select the isosurface extraction technique appropriate for their problem of interest, and have confidence in its behavior.
Keywords: Isosurface Extraction;Marching Cubes;V&amp;V;Verification;convergence rate;image coding;image representation;isosurface extraction codes;isosurface features;visual representations;
Author: Etiene, T.; Scheidegger, C.; Nonato, L.G.; Kirby, R.M.; Silva, C.

Year: 2009
Title: Curve-Centric Volume Reformation for Comparative Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290734
Abstract: We present two visualization techniques for curve-centric volume reformation with the aim to create compelling comparative visualizations. A curve-centric volume reformation deforms a volume, with regards to a curve in space, to create a new space in which the curve evaluates to zero in two dimensions and spans its arc-length in the third. The volume surrounding the curve is deformed such that spatial neighborhood to the curve is preserved. The result of the curve-centric reformation produces images where one axis is aligned to arc-length, and thus allows researchers and practitioners to apply their arc-length parameterized data visualizations in parallel for comparison. Furthermore we show that when visualizing dense data, our technique provides an inside out projection, from the curve and out into the volume, which allows for inspection what is around the curve. Finally we demonstrate the usefulness of our techniques in the context of two application cases. We show that existing data visualizations of arc-length parameterized data can be enhanced by using our techniques, in addition to creating a new view and perspective on volumetric data around curves. Additionally we show how volumetric data can be brought into plotting environments that allow precise readouts. In the first case we inspect streamlines in a flow field around a car, and in the second we inspect seismic volumes and well logs from drilling.
Keywords: Comparative Visualization;Curve-Centric-Reformation;Radial Ray-Casting;Volume Deformation;arc-length parameterized data visualizations;compelling comparative visualizations;computational geometry;curve-centric volume reformation;data visualisation;radial-ray casting;volume deformation;
Author: Lampe, O.D.; Correa, C.; Kwan-Liu Ma; Hauser, H.

Year: 2009
Title: Predictor-Corrector Schemes for Visualization ofSmoothed Particle Hydrodynamics Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290735
Abstract: In this paper we present a method for vortex core line extraction which operates directly on the smoothed particle hydrodynamics (SPH) representation and, by this, generates smoother and more (spatially and temporally) coherent results in an efficient way. The underlying predictor-corrector scheme is general enough to be applied to other line-type features and it is extendable to the extraction of surfaces such as isosurfaces or Lagrangian coherent structures. The proposed method exploits temporal coherence to speed up computation for subsequent time steps. We show how the predictor-corrector formulation can be specialized for several variants of vortex core line definitions including two recent unsteady extensions, and we contribute a theoretical and practical comparison of these. In particular, we reveal a close relation between unsteady extensions of Fuchs et al. and Weinkauf et al. and we give a proof of the Galilean invariance of the latter. When visualizing SPH data, there is the possibility to use the same interpolation method for visualization as has been used for the simulation. This is different from the case of finite volume simulation results, where it is not possible to recover from the results the spatial interpolation that was used during the simulation. Such data are typically interpolated using the basic trilinear interpolant, and if smoothness is required, some artificial processing is added. In SPH data, however, the smoothing kernels are specified from the simulation, and they provide an exact and smooth interpolation of data or gradients at arbitrary points in the domain.
Keywords: Lagrangian coherent structures;Smoothed particle hydrodynamics;basic trilinear interpolant;data visualisation;feature extraction;flow visualisation;flow visualization;hydrodynamics;interpolation;interpolation method;isosurfaces;physics computing;predictor-corrector methods;predictor-corrector schemes;smoothed particle hydrodynamics data visualization;unsteady flow;vortex core line extraction;vortex core lines;
Author: Schindler, B.; Fuchs, R.; Biddiscombe, J.; Peikert, R.

Year: 2009
Title: Exploring the Millennium Run - Scalable Rendering of Large-Scale Cosmological Datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290736
Abstract: In this paper we investigate scalability limitations in the visualization of large-scale particle-based cosmological simulations, and we present methods to reduce these limitations on current PC architectures. To minimize the amount of data to be streamed from disk to the graphics subsystem, we propose a visually continuous level-of-detail (LOD) particle representation based on a hierarchical quantization scheme for particle coordinates and rules for generating coarse particle distributions. Given the maximal world space error per level, our LOD selection technique guarantees a sub-pixel screen space error during rendering. A brick-based page-tree allows to further reduce the number of disk seek operations to be performed. Additional particle quantities like density, velocity dispersion, and radius are compressed at no visible loss using vector quantization of logarithmically encoded floating point values. By fine-grain view-frustum culling and presence acceleration in a geometry shader the required geometry throughput on the GPU can be significantly reduced. We validate the quality and scalability of our method by presenting visualizations of a particle-based cosmological dark-matter simulation exceeding 10 billion elements.
Keywords: Cosmology;GPU;Particle Visualization;Scalability;astronomy computing;brick-based page-tree;coarse particle distribution;cosmology;dark matter;data visualisation;fine-grain view-frustum culling;graphics subsystem;hierarchical quantization scheme;large-scale cosmological datasets;large-scale particle-based cosmological simulations;logarithmically encoded floating point value;particle-based cosmological dark-matter simulation;rendering (computer graphics);scalable rendering;subpixel screen space error;vector quantisation;vector quantization;visually continuous level-of-detail particle representation;
Author: Fraedrich, R.; Schneider, J.; Westermann, R.

Year: 2009
Title: Interactive Streak Surface Visualization on the GPU
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290737
Abstract: In this paper we present techniques for the visualization of unsteady flows using streak surfaces, which allow for the first time an adaptive integration and rendering of such surfaces in real-time. The techniques consist of two main components, which are both realized on the GPU to exploit computational and bandwidth capacities for numerical particle integration and to minimize bandwidth requirements in the rendering of the surface. In the construction stage, an adaptive surface representation is generated. Surface refinement and coarsening strategies are based on local surface properties like distortion and curvature. We compare two different methods to generate a streak surface: a) by computing a patch-based surface representation that avoids any interdependence between patches, and b) by computing a particle-based surface representation including particle connectivity, and by updating this connectivity during particle refinement and coarsening. In the rendering stage, the surface is either rendered as a set of quadrilateral surface patches using high-quality point-based approaches, or a surface triangulation is built in turn from the given particle connectivity and the resulting triangle mesh is rendered. We perform a comparative study of the proposed techniques with respect to surface quality, visual quality and performance by visualizing streak surfaces in real flows using different rendering options.
Keywords: GPU;GPUs;Unsteady flow visualization;adaptive surface representation;coprocessors;flow visualisation;image representation;interactive streak surface visualization;mesh generation;numerical particle integration;particle-based surface representation;patch-based surface representation;physics computing;quadrilateral surface patches;rendering (computer graphics);streak surface generation;surface quality;surface rendering;surface triangulation;triangle mesh;visual quality;
Author: Burger, K.; Ferstl, F.; Theisel, H.; Westermann, R.

Year: 2009
Title: Time and Streak Surfaces for Flow Visualization in Large Time-Varying Data Sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290738
Abstract: Time and streak surfaces are ideal tools to illustrate time-varying vector fields since they directly appeal to the intuition about coherently moving particles. However, efficient generation of high-quality time and streak surfaces for complex, large and time-varying vector field data has been elusive due to the computational effort involved. In this work, we propose a novel algorithm for computing such surfaces. Our approach is based on a decoupling of surface advection and surface adaptation and yields improved efficiency over other surface tracking methods, and allows us to leverage inherent parallelization opportunities in the surface advection, resulting in more rapid parallel computation. Moreover, we obtain as a result of our algorithm the entire evolution of a time or streak surface in a compact representation, allowing for interactive, high-quality rendering, visualization and exploration of the evolving surface. Finally, we discuss a number of ways to improve surface depiction through advanced rendering and texturing, while preserving interactivity, and provide a number of examples for real-world datasets and analyze the behavior of our algorithm on them.
Keywords: 3D vector field visualization;data visualisation;flow visualisation;flow visualization;flow visualization;large time-varying data sets;rendering;rendering (computer graphics);streak surface;surface adaptation;surface advection;surface extraction.;time and streak surfaces;time surface;time-varying;
Author: Krishnan, H.; Garth, C.; Joy, K.

Year: 2009
Title: Hue-Preserving Color Blending
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290739
Abstract: We propose a new perception-guided compositing operator for color blending. The operator maintains the same rules for achromatic compositing as standard operators (such as the over operator), but it modifies the computation of the chromatic channels. Chromatic compositing aims at preserving the hue of the input colors; color continuity is achieved by reducing the saturation of colors that are to change their hue value. The main benefit of hue preservation is that color can be used for proper visual labeling, even under the constraint of transparency rendering or image overlays. Therefore, the visualization of nominal data is improved. Hue-preserving blending can be used in any existing compositing algorithm, and it is particularly useful for volume rendering. The usefulness of hue-preserving blending and its visual characteristics are shown for several examples of volume visualization.
Keywords: Color;Computer Graphics;Diagnostic Imaging;Image Processing, Computer-Assisted;achromatic compositing;chromatic compositing;color blending;colour graphics;data visualisation;hue-preserving color blending;illustrative visualization;image compositing;image overlay;nominal data visualization;perception-guided compositing operator;perceptual transparency;rendering (computer graphics);transparency rendering;visual characteristics;visual labeling;volume rendering;volume rendering;volume visualization;
Author: Chuang, J.; Weiskopf, D.; Moller, T.

Year: 2009
Title: Perception-Based Transparency Optimization for Direct Volume Rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290740
Abstract: The semi-transparent nature of direct volume rendered images is useful to depict layered structures in a volume. However, obtaining a semi-transparent result with the layers clearly revealed is difficult and may involve tedious adjustment on opacity and other rendering parameters. Furthermore, the visual quality of layers also depends on various perceptual factors. In this paper, we propose an auto-correction method for enhancing the perceived quality of the semi-transparent layers in direct volume rendered images. We introduce a suite of new measures based on psychological principles to evaluate the perceptual quality of transparent structures in the rendered images. By optimizing rendering parameters within an adaptive and intuitive user interaction process, the quality of the images is enhanced such that specific user requirements can be met. Experimental results on various datasets demonstrate the effectiveness and robustness of our method.
Keywords: Computer Graphics;Diagnostic Imaging;Direct volume rendering;Image Processing, Computer-Assisted;User-Computer Interface;auto-correction method;direct volume rendered images;image enhancement;intuitive user interaction process;layer perception.;perception-based transparency optimization;psychological principles;rendering (computer graphics);user interfaces;visual quality;
Author: Ming-Yuen Chan; Yingcai Wu; Wai-Ho Mak; Wei Chen; Huamin Qu

Year: 2009
Title: A Physiologically-based Model for Simulation of Color Vision Deficiency
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290741
Abstract: Color vision deficiency (CVD) affects approximately 200 million people worldwide, compromising the ability of these individuals to effectively perform color and visualization-related tasks. This has a significant impact on their private and professional lives. We present a physiologically-based model for simulating color vision. Our model is based on the stage theory of human color vision and is derived from data reported in electrophysiological studies. It is the first model to consistently handle normal color vision, anomalous trichromacy, and dichromacy in a unified way. We have validated the proposed model through an experimental evaluation involving groups of color vision deficient individuals and normal color vision ones. Our model can provide insights and feedback on how to improve visualization experiences for individuals with CVD. It also provides a framework for testing hypotheses about some aspects of the retinal photoreceptors in color vision deficient individuals.
Keywords: Algorithms;Anomalous Trichromacy;Color;Color Perception;Color Vision Defects;Computer Simulation;Dichromacy.;Electrophysiology;Female;Humans;Male;Models of Color Vision;Models, Biological;Reproducibility of Results;Simulation of Color Vision Deficiency;Visual Perception;anomalous trichromacy;biology computing;color vision deficiency simulation;data visualisation;dichromacy;electrophysiological studies;human color vision;image colour analysis;physiologically-based model;visual perception;
Author: Machado, G.M.; Oliveira, M.M.; Fernandes, L.

Year: 2009
Title: Depth-Dependent Halos: Illustrative Rendering of Dense Line Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290742
Abstract: We present a technique for the illustrative rendering of 3D line data at interactive frame rates. We create depth-dependent halos around lines to emphasize tight line bundles while less structured lines are de-emphasized. Moreover, the depth-dependent halos combined with depth cueing via line width attenuation increase depth perception, extending techniques from sparse line rendering to the illustrative visualization of dense line data. We demonstrate how the technique can be used, in particular, for illustrating DTI fiber tracts but also show examples from gas and fluid flow simulations and mathematics as well as describe how the technique extends to point data. We report on an informal evaluation of the illustrative DTI fiber tract visualizations with domain experts in neurosurgery and tractography who commented positively about the results and suggested a number of directions for future work.
Keywords: DTI;GPU technique.;Illustrative rendering and visualization;NPR;black-and-white rendering;data visualisation;dense line data;dense line data;depth-dependent halos;fluid flow simulations;gas flow simulations;illustrative DTI fiber tract visualizations;illustrative rendering;interactive frame rates;line width attenuation;mathematics;neurosurgery;rendering (computer graphics);sparse line rendering;tractography;
Author: Everts, M.H.; Bekker, H.; Roerdink, J.B.T.M.; Isenberg, T.

Year: 2009
Title: Markerless View-Independent Registration of Multiple Distorted Projectors on Extruded Surfaces Using an Uncalibrated Camera
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290743
Abstract: In this paper, we present the first algorithm to geometrically register multiple projectors in a view-independent manner (i.e. wallpapered) on a common type of curved surface, vertically extruded surface, using an uncalibrated camera without attaching any obtrusive markers to the display screen. Further, it can also tolerate large non-linear geometric distortions in the projectors as is common when mounting short throw lenses to allow a compact set-up. Our registration achieves sub-pixel accuracy on a large number of different vertically extruded surfaces and the image correction to achieve this registration can be run in real time on the GPU. This simple markerless registration has the potential to have a large impact on easy set-up and maintenance of large curved multi-projector displays, common for visualization, edutainment, training and simulation applications.
Keywords: Calibration;Multi-Projector Displays;Registration;Tiled Displays;computer displays;coprocessors;data visualisation;geometrically register multiple projectors;graphical processing unit;image registration;image sensors;markerless view-independent registration;multiple distorted projectors;nonlinear geometric distortions;uncalibrated camera;
Author: Sajadi, B.; Majumder, A.

Year: 2009
Title: Color Seamlessness in Multi-Projector Displays Using Constrained Gamut Morphing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290744
Abstract: Multi-projector displays show significant spatial variation in 3D color gamut due to variation in the chromaticity gamuts across the projectors, vignetting effect of each projector and also overlap across adjacent projectors. In this paper we present a new constrained gamut morphing algorithm that removes all these variations and results in true color seamlessness across tiled multi-projector displays. Our color morphing algorithm adjusts the intensities of light from each pixel of each projector precisely to achieve a smooth morphing from one projector's gamut to the other's through the overlap region. This morphing is achieved by imposing precise constraints on the perceptual difference between the gamuts of two adjacent pixels. In addition, our gamut morphing assures a C1 continuity yielding visually pleasing appearance across the entire display. We demonstrate our method successfully on a planar and a curved display using both low and high-end projectors. Our approach is completely scalable, efficient and automatic. We also demonstrate the real-time performance of our image correction algorithm on GPUs for interactive applications. To the best of our knowledge, this is the first work that presents a scalable method with a strong foundation in perception and realizes, for the first time, a truly seamless display where the number of projectors cannot be deciphered.
Keywords: 3D color gamut;Color Calibration;GPU;Multi-Projector Displays;Tiled Displays.;chromaticity gamuts;color morphing algorithm;color seamlessness;computer graphics;constrained gamut morphing;coprocessors;display devices;image colour analysis;multi-projector displays;optical projectors;
Author: Sajadi, B.; Lazarov, M.; Gopi, M.; Majumder, A.

Year: 2009
Title: Visual Human+Machine Learning
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290745
Abstract: In this paper we describe a novel method to integrate interactive visual analysis and machine learning to support the insight generation of the user. The suggested approach combines the vast search and processing power of the computer with the superior reasoning and pattern recognition capabilities of the human user. An evolutionary search algorithm has been adapted to assist in the fuzzy logic formalization of hypotheses that aim at explaining features inside multivariate, volumetric data. Up to now, users solely rely on their knowledge and expertise when looking for explanatory theories. However, it often remains unclear whether the selected attribute ranges represent the real explanation for the feature of interest. Other selections hidden in the large number of data variables could potentially lead to similar features. Moreover, as simulation complexity grows, users are confronted with huge multidimensional data sets making it almost impossible to find meaningful hypotheses at all. We propose an interactive cycle of knowledge-based analysis and automatic hypothesis generation. Starting from initial hypotheses, created with linking and brushing, the user steers a heuristic search algorithm to look for alternative or related hypotheses. The results are analyzed in information visualization views that are linked to the volume rendering. Individual properties as well as global aggregates are visually presented to provide insight into the most relevant aspects of the generated hypotheses. This novel approach becomes computationally feasible due to a GPU implementation of the time-critical parts in the algorithm. A thorough evaluation of search times and noise sensitivity as well as a case study on data from the automotive domain substantiate the usefulness of the suggested approach.
Keywords: Computer-assisted Multivariate Data Exploration;Curse of Dimensionality;GPU implementation;Genetic Algorithm;Interactive Visual Analysis;Knowledge Discovery;Multiple Competing Hypotheses;Predictive Analysis;Volumetric Data;automatic hypothesis generation;data mining;data visualisation;evolutionary computation;evolutionary search algorithm;fuzzy logic;fuzzy logic formalization;heuristic search algorithm;interactive visual analysis;knowledge-based analysis;learning (artificial intelligence);machine learning;pattern recognition;rendering (computer graphics);search problems;superior reasoning;user interfaces;visual human;volume rendering;
Author: Fuchs, R.; Waser, J.; Groller, M.E.

Year: 2009
Title: Interactive Visual Optimization and Analysis for RFID Benchmarking
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290746
Abstract: Radiofrequency identification (RFID) is a powerful automatic remote identification technique that has wide applications. To facilitate RFID deployment, an RFID benchmarking instrument called aGate has been invented to identify the strengths and weaknesses of different RFID technologies in various environments. However, the data acquired by aGate are usually complex time varying multidimensional 3D volumetric data, which are extremely challenging for engineers to analyze. In this paper, we introduce a set of visualization techniques, namely, parallel coordinate plots, orientation plots, a visual history mechanism, and a 3D spatial viewer, to help RFID engineers analyze benchmark data visually and intuitively. With the techniques, we further introduce two workflow procedures (a visual optimization procedure for finding the optimum reader antenna configuration and a visual analysis procedure for comparing the performance and identifying the flaws of RFID devices) for the RFID benchmarking, with focus on the performance analysis of the aGate system. The usefulness and usability of the system are demonstrated in the user evaluation.
Keywords: 3D spatial viewer;RFID;RFID benchmarking;Visual analytics;Visualization;aGate;data visualisation;data visualization;interactive visual optimization;optimisation;orientation plots;parallel coordinate plots;radiofrequency identification;radiofrequency identification;visual history mechanism;
Author: Yingcai Wu; Ka-Kei Chung; Huamin Qu; Xiaoru Yuan; Cheung, S.C.

Year: 2009
Title: A Visual Approach to Efficient Analysis and Quantification of Ductile Iron and Reinforced Sprayed Concrete
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290747
Abstract: This paper describes advanced volume visualization and quantification for applications in non-destructive testing (NDT), which results in novel and highly effective interactive workflows for NDT practitioners. We employ a visual approach to explore and quantify the features of interest, based on transfer functions in the parameter spaces of specific application scenarios. Examples are the orientations of fibres or the roundness of particles. The applicability and effectiveness of our approach is illustrated using two specific scenarios of high practical relevance. First, we discuss the analysis of Steel Fibre Reinforced Sprayed Concrete (SFRSpC). We investigate the orientations of the enclosed steel fibres and their distribution, depending on the concrete's application direction. This is a crucial step in assessing the material's behavior under mechanical stress, which is still in its infancy and therefore a hot topic in the building industry. The second application scenario is the designation of the microstructure of ductile cast irons with respect to the contained graphite. This corresponds to the requirements of the ISO standard 945-1, which deals with 2D metallographic samples. We illustrate how the necessary analysis steps can be carried out much more efficiently using our system for 3D volumes. Overall, we show that a visual approach with custom transfer functions in specific application domains offers significant benefits and has the potential of greatly improving and optimizing the workflows of domain scientists and engineers.
Keywords: 2D metallographic samples;Direction Visualization;ISO standard 945-1;Multi-Dimensional Transfer Functions;Non-Destructive Testing;Volume Rendering;cast iron;computerised tomography;ductile cast irons microstructure;mechanical engineering computing;mechanical stress;nondestructive testing;nondestructive testing;particle roundness;reinforced concrete;rendering (computer graphics);steel fibre reinforced sprayed concrete;transfer functions;transfer functions;volume visualization;
Author: Fritz, L.; Hadwiger, M.; Geier, G.; Pittino, G.; Groller, M.E.

Year: 2009
Title: Interactive Visual Analysis of Complex Scientific Data as Families of Data Surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290748
Abstract: The widespread use of computational simulation in science and engineering provides challenging research opportunities. Multiple independent variables are considered and large and complex data are computed, especially in the case of multi-run simulation. Classical visualization techniques deal well with 2D or 3D data and also with time-dependent data. Additional independent dimensions, however, provide interesting new challenges. We present an advanced visual analysis approach that enables a thorough investigation of families of data surfaces, i.e., datasets, with respect to pairs of independent dimensions. While it is almost trivial to visualize one such data surface, the visual exploration and analysis of many such data surfaces is a grand challenge, stressing the users' perception and cognition. We propose an approach that integrates projections and aggregations of the data surfaces at different levels (one scalar aggregate per surface, a 1D profile per surface, or the surface as such). We demonstrate the necessity for a flexible visual analysis system that integrates many different (linked) views for making sense of this highly complex data. To demonstrate its usefulness, we exemplify our approach in the context of a meteorological multi-run simulation data case and in the context of the engineering domain, where our collaborators are working with the simulation of elastohydrodynamic (EHD) lubrication bearing in the automotive industry.
Keywords: automobile industry;automotive industry;complex scientific data;computational simulation;coordinated multiple views;data analysis;data surfaces;data visualisation;elastohydrodynamic lubrication;electrohydrodynamics;family of surfaces;interactive systems;interactive visual analysis;interactive visual analysis;lubrication;meteorological multi-run simulation data case;multidimensional multivariate data;
Author: Matkovic, K.; Gracanin, D.; Klarin, B.; Hauser, H.

Year: 2009
Title: Visualization and Exploration of Temporal Trend Relationships in Multivariate Time-Varying Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290749
Abstract: We present a new algorithm to explore and visualize multivariate time-varying data sets. We identify important trend relationships among the variables based on how the values of the variables change over time and how those changes are related to each other in different spatial regions and time intervals. The trend relationships can be used to describe the correlation and causal effects among the different variables. To identify the temporal trends from a local region, we design a new algorithm called SUBDTW to estimate when a trend appears and vanishes in a given time series. Based on the beginning and ending times of the trends, their temporal relationships can be modeled as a state machine representing the trend sequence. Since a scientific data set usually contains millions of data points, we propose an algorithm to extract important trend relationships in linear time complexity. We design novel user interfaces to explore the trend relationships, to visualize their temporal characteristics, and to display their spatial distributions. We use several scientific data sets to test our algorithm and demonstrate its utilities.
Keywords: SUBDTW;computational complexity;data exploration;data visualisation;data visualization;linear time complexity;multivariate time-varying data;spatial distributions;temporal trend relationships;trend sequence;trend sequence clustering;trend sequence clustering;user interfaces;user interfaces;
Author: Teng-Yok Lee; Han-Wei Shen

Year: 2009
Title: Isosurface Extraction and View-Dependent Filtering from Time-Varying Fields Using Persistent Time-Octree (PTOT)
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290750
Abstract: We develop a new algorithm for isosurface extraction and view-dependent filtering from large time-varying fields, by using a novel persistent time-octree (PTOT) indexing structure. Previously, the persistent octree (POT) was proposed to perform isosurface extraction and view-dependent filtering, which combines the advantages of the interval tree (for optimal searches of active cells) and of the branch-on-need octree (BONO, for view-dependent filtering), but it only works for steady-state(i.e., single time step) data. For time-varying fields, a 4D version of POT, 4D-POT, was proposed for 4D isocontour slicing, where slicing on the time domain gives all active cells in the queried timestep and isovalue. However, such slicing is not output sensitive and thus the searching is sub-optimal. Moreover, it was not known how to support view-dependent filtering in addition to time-domain slicing.In this paper, we develop a novel persistent time-octree (PTOT) indexing structure, which has the advantages of POT and performs 4D isocontour slicing on the time domain with an output-sensitive and optimal searching. In addition, when we query the same iso value q over m consecutive time steps, there is no additional searching overhead (except for reporting the additional active cells) compared to querying just the first time step. Such searching performance for finding active cells is asymptotically optimal, with asymptotically optimal space and preprocessing time as well. Moreover, our PTOT supports view-dependent filtering in addition to time-domain slicing. We propose a simple and effective out-of-core scheme, where we integrate our PTOT with implicit occluders, batched occlusion queries and batched CUDA computing tasks, so that we can greatly reduce the I/O cost as well as increase the amount of data being concurrently computed in GPU.This results in an efficient algorithm for isosurface extraction with view-dependent filtering utilizing a state-of-the-art programmable GPU for ti--me-varying fields larger than main memory. Our experiments on datasets as large as 192 GB (with 4 GB per time step) having no more than 870 MB of memory footprint in both preprocessing and run-time phases demonstrate the efficacy of our new technique.
Keywords: 4D isocontour slicing;Isosurface extraction;branch-on-need octree;data visualisation;isosurface extraction;octrees;out-of-core methods;persistent data structure;persistent time-octree indexing structure;state-of-the-art programmable GPU;time-varying fields;time-varying fields;view-dependent filtering;view-dependent filtering;
Author: Cong Wang; Yi-Jen Chiang

Year: 2009
Title: Visual Exploration of Climate Variability Changes Using Wavelet Analysis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290751
Abstract: Due to its nonlinear nature, the climate system shows quite high natural variability on different time scales, including multiyear oscillations such as the El Nino southern oscillation phenomenon. Beside a shift of the mean states and of extreme values of climate variables, climate change may also change the frequency or the spatial patterns of these natural climate variations. Wavelet analysis is a well established tool to investigate variability in the frequency domain. However, due to the size and complexity of the analysis results, only few time series are commonly analyzed concurrently. In this paper we will explore different techniques to visually assist the user in the analysis of variability and variability changes to allow for a holistic analysis of a global climate model data set consisting of several variables and extending over 250 years. Our new framework and data from the IPCC AR4 simulations with the coupled climate model ECHAM5/MPI-OM are used to explore the temporal evolution of El Nino due to climate change.
Keywords: ECHAM5/MPI-OM;El Nino;El Nino southern oscillation phenomenon;IPCC AR4 simulations;Wavelet analysis;climate variability change visualization;climate variability changes;climatology;data visualisation;frequency domain;geophysics computing;multivariate data;multiyear oscillations;time-dependent data;visual exploration;wavelet analysis;wavelet transforms;
Author: Janicke, H.; Bottinger, M.; Mikolajewicz, U.; Scheuermann, G.

Year: 2009
Title: Interactive Coordinated Multiple-View Visualization of Biomechanical Motion Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290752
Abstract: We present an interactive framework for exploring space-time and form-function relationships in experimentally collected high-resolution biomechanical data sets. These data describe complex 3D motions (e.g. chewing, walking, flying) performed by animals and humans and captured via high-speed imaging technologies, such as biplane fluoroscopy. In analyzing these 3D biomechanical motions, interactive 3D visualizations are important, in particular, for supporting spatial analysis. However, as researchers in information visualization have pointed out, 2D visualizations can also be effective tools for multi-dimensional data analysis, especially for identifying trends over time. Our approach, therefore, combines techniques from both 3D and 2D visualizations. Specifically, it utilizes a multi-view visualization strategy including a small multiples view of motion sequences, a parallel coordinates view, and detailed 3D inspection views. The resulting framework follows an overview first, zoom and filter, then details-on-demand style of analysis, and it explicitly targets a limitation of current tools, namely, supporting analysis and comparison at the level of a collection of motions rather than sequential analysis of a single or small number of motions. Scientific motion collections appropriate for this style of analysis exist in clinical work in orthopedics and physical rehabilitation, in the study of functional morphology within evolutionary biology, and in other contexts. An application is described based on a collaboration with evolutionary biologists studying the mechanics of chewing motions in pigs. Interactive exploration of data describing a collection of more than one hundred experimentally captured pig chewing cycles is described.
Keywords: Biomechanics;Bone and Bones;Computational Biology;Computer Graphics;Databases, Factual;Fluoroscopy;Image Processing, Computer-Assisted;Movement;Scientific visualization;biology computing;biomechanical motion data;biomechanics;biomechanics;biplane fluoroscopy;complex 3D motions;coordinated multiple views;data visualisation;high-speed imaging technologies;image motion analysis;information visualization;interactive coordinated multiple-view visualization;multi-dimensional data analysis;spatial analysis;
Author: Keefe, D.; Ewert, M.; Ribarsky, W.; Chang, R.

Year: 2009
Title: Interactive Visualization of Molecular Surface Dynamics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290753
Abstract: Molecular dynamics simulations of proteins play a growing role in various fields such as pharmaceutical, biochemical and medical research. Accordingly, the need for high quality visualization of these protein systems raises. Highly interactive visualization techniques are especially needed for the analysis of time-dependent molecular simulations. Beside various other molecular representations the surface representations are of high importance for these applications. So far, users had to accept a trade-off between rendering quality and performance - particularly when visualizing trajectories of time-dependent protein data. We present a new approach for visualizing the solvent excluded surface of proteins using a GPU ray casting technique and thus achieving interactive frame rates even for long protein trajectories where conventional methods based on precomputation are not applicable. Furthermore, we propose a semantic simplification of the raw protein data to reduce the visual complexity of the surface and thereby accelerate the rendering without impeding perception of the protein's basic shape. We also demonstrate the application of our solvent excluded surface method to visualize the spatial probability density for the protein atoms over the whole period of the trajectory in one frame, providing a qualitative analysis of the protein flexibility.
Keywords: Computational Biology;Computer Graphics;Computer Simulation;GPU;GPU ray casting technique;Isosurfaces;Models, Molecular;Molecular Conformation;Molecular Visualization;Point-based Data;Protein Conformation;Proteins;Ray Casting;Surface Extraction;Surface Properties;Time-varying Data;biology computing;data visualisation;interactive systems;interactive visualization techniques;molecular biophysics;molecular dynamics simulations;molecular surface dynamics;probability;protein flexibility;protein solvent excluded surface;proteins;rendering (computer graphics);rendering quality;spatial probability density;time-dependent protein data;visual complexity;
Author: Krone, M.; Bidmon, K.; Ertl, T.

Year: 2009
Title: Stress Tensor Field Visualization for Implant Planning in Orthopedics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290754
Abstract: We demonstrate the application of advanced 3D visualization techniques to determine the optimal implant design and position in hip joint replacement planning. Our methods take as input the physiological stress distribution inside a patient's bone under load and the stress distribution inside this bone under the same load after a simulated replacement surgery. The visualization aims at showing principal stress directions and magnitudes, as well as differences in both distributions. By visualizing changes of normal and shear stresses with respect to the principal stress directions of the physiological state, a comparative analysis of the physiological stress distribution and the stress distribution with implant is provided, and the implant parameters that most closely replicate the physiological stress state in order to avoid stress shielding can be determined. Our method combines volume rendering for the visualization of stress magnitudes with the tracing of short line segments for the visualization of stress directions. To improve depth perception, transparent, shaded, and antialiased lines are rendered in correct visibility order, and they are attenuated by the volume rendering. We use a focus+context approach to visually guide the user to relevant regions in the data, and to support a detailed stress analysis in these regions while preserving spatial context information. Since all of our techniques have been realized on the GPU, they can immediately react to changes in the simulated stress tensor field and thus provide an effective means for optimal implant selection and positioning in a computational steering environment.
Keywords: Biomechanics;Biomedical Visualization;Comparative Visualization;Computer Graphics;Diagnostic Imaging;Femur Head;GPU;GPU Techniques;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Implant Planning;Orthopedics;Stress Tensor Fields;Stress, Mechanical;biomechanics;bone;bone;computational steering environment;data visualisation;focus+context approach;hip joint replacement planning;implant planning;medical diagnostic computing;normal stress;orthopaedics;orthopedics;physiological models;physiological stress distribution;planning;prosthetics;rendering (computer graphics);shear stress;simulated replacement surgery;spatial context information;stress analysis;stress analysis;stress tensor field visualization;surgery;tensors;volume rendering;
Author: Dick, C.; Georgii, J.; Burgkart, R.; Westermann, R.

Year: 2009
Title: Visual Exploration of Nasal Airflow
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290755
Abstract: Rhinologists are often faced with the challenge of assessing nasal breathing from a functional point of view to derive effective therapeutic interventions. While the complex nasal anatomy can be revealed by visual inspection and medical imaging, only vague information is available regarding the nasal airflow itself: Rhinomanometry delivers rather unspecific integral information on the pressure gradient as well as on total flow and nasal flow resistance. In this article we demonstrate how the understanding of physiological nasal breathing can be improved by simulating and visually analyzing nasal airflow, based on an anatomically correct model of the upper human respiratory tract. In particular we demonstrate how various information visualization (InfoVis) techniques, such as a highly scalable implementation of parallel coordinates, time series visualizations, as well as unstructured grid multi-volume rendering, all integrated within a multiple linked views framework, can be utilized to gain a deeper understanding of nasal breathing. Evaluation is accomplished by visual exploration of spatio-temporal airflow characteristics that include not only information on flow features but also on accompanying quantities such as temperature and humidity. To our knowledge, this is the first in-depth visual exploration of the physiological function of the nose over several simulated breathing cycles under consideration of a complete model of the nasal airways, realistic boundary conditions, and all physically relevant time-varying quantities.
Keywords: Computer Graphics;Computer Simulation;Flow visualization;Humans;Humidity;Image Processing, Computer-Assisted;Models, Anatomic;Nose;Pulmonary Ventilation;Respiration;Temperature;Tomography, X-Ray Computed;biomedical imaging;complex nasal anatomy;data analysis;data visualisation;exploratory data analysis;exploratory data analysis;flow visualisation;information visualization technique;interactive systems;interactive visual analysis of scientific data;interactive visualFlow visualization;medical computing;medical imaging;nasal airflow visual exploration;nasal breathing;physiological nasal breathing;rendering (computer graphics);rhinologists;rhinomanometry;spatio-temporal airflow characteristics;therapeutic interventions;time series;time series visualization;time-dependent data.;unstructured grid multivolume rendering;visual inspection;
Author: Zachow, S.; Muigg, P.; Hildebrandt, T.; Doleisch, H.; Hege, H.-C.

Year: 2009
Title: Sampling and Visualizing Creases with Scale-Space Particles
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290756
Abstract: Particle systems have gained importance as a methodology for sampling implicit surfaces and segmented objects to improve mesh generation and shape analysis. We propose that particle systems have a significantly more general role in sampling structure from unsegmented data. We describe a particle system that computes samplings of crease features (i.e. ridges and valleys, as lines or surfaces) that effectively represent many anatomical structures in scanned medical data. Because structure naturally exists at a range of sizes relative to the image resolution, computer vision has developed the theory of scale-space, which considers an n-D image as an (n + 1)-D stack of images at different blurring levels. Our scale-space particles move through continuous four-dimensional scale-space according to spatial constraints imposed by the crease features, a particle-image energy that draws particles towards scales of maximal feature strength, and an inter-particle energy that controls sampling density in space and scale. To make scale-space practical for large three-dimensional data, we present a spline-based interpolation across scale from a small number of pre-computed blurrings at optimally selected scales. The configuration of the particle system is visualized with tensor glyphs that display information about the local Hessian of the image, and the scale of the particle. We use scale-space particles to sample the complex three-dimensional branching structure of airways in lung CT, and the major white matter structures in brain DTI.
Keywords: Algorithms;Brain;Computer Graphics;Crease Features;Diffusion Tensor MRI;Humans;Image Processing, Computer-Assisted;Lung;Lung CT;Magnetic Resonance Imaging;Normal Distribution;Particle Size;Particle Systems;Ridge and Valley Detection;Sample Size;Surface Properties;Tomography, X-Ray Computed;complex three-dimensional branching structure;computer vision;data visualisation;image resolution;image sampling;image segmentation;implicit surface sampling;interpolation;lung CT;medical image processing;mesh generation;particle-image energy;scale-space particles;scale-space theory;shape analysis;spline-based interpolation;splines (mathematics);
Author: Kindlmann, G.L.; Estepar, R.S.J.; Smith, S.M.; Westin, C.-F.

Year: 2009
Title: Volume Illustration of Muscle from Diffusion Tensor Images
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290757
Abstract: Medical illustration has demonstrated its effectiveness to depict salient anatomical features while hiding the irrelevant details. Current solutions are ineffective for visualizing fibrous structures such as muscle, because typical datasets (CT or MRI) do not contain directional details. In this paper, we introduce a new muscle illustration approach that leverages diffusion tensor imaging (DTI) data and example-based texture synthesis techniques. Beginning with a volumetric diffusion tensor image, we reformulate it into a scalar field and an auxiliary guidance vector field to represent the structure and orientation of a muscle bundle. A muscle mask derived from the input diffusion tensor image is used to classify the muscle structure. The guidance vector field is further refined to remove noise and clarify structure. To simulate the internal appearance of the muscle, we propose a new two-dimensional example based solid texture synthesis algorithm that builds a solid texture constrained by the guidance vector field. Illustrating the constructed scalar field and solid texture efficiently highlights the global appearance of the muscle as well as the local shape and structure of the muscle fibers in an illustrative fashion. We have applied the proposed approach to five example datasets (four pig hearts and a pig leg), demonstrating plausible illustration and expressiveness.
Keywords: Algorithms;Animals;Computer Graphics;Diffusion Magnetic Resonance Imaging;Diffusion Tensor Image;Heart;Hindlimb;Illustrative Visualization;Image Processing, Computer-Assisted;Muscle;Muscle, Skeletal;Myocardium;Normal Distribution;Solid Texture Synthesis;Swine;diffusion tensor image;diffusion tensor imaging;example-based texture synthesis technique;fibrous structures;image texture;medical illustration;medical image processing;muscle volume illustration;solid texture synthesis algorithm;tensors;vectors;
Author: Wei Chen; Zhicheng Yan; Song Zhang; Crow, J.A.; Ebert, D.S.; McLaughlin, R.M.; Mullins, K.B.; Cooper, R.; Zi'ang Ding; Jun Liao

Year: 2009
Title: A Novel Interface for Interactive Exploration of DTI Fibers
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290758
Abstract: Visual exploration is essential to the visualization and analysis of densely sampled 3D DTI fibers in biological speciments, due to the high geometric, spatial, and anatomical complexity of fiber tracts. Previous methods for DTI fiber visualization use zooming, color-mapping, selection, and abstraction to deliver the characteristics of the fibers. However, these schemes mainly focus on the optimization of visualization in the 3D space where cluttering and occlusion make grasping even a few thousand fibers difficult. This paper introduces a novel interaction method that augments the 3D visualization with a 2D representation containing a low-dimensional embedding of the DTI fibers. This embedding preserves the relationship between the fibers and removes the visual clutter that is inherent in 3D renderings of the fibers. This new interface allows the user to manipulate the DTI fibers as both 3D curves and 2D embedded points and easily compare or validate his or her results in both domains. The implementation of the framework is GPU based to achieve real-time interaction. The framework was applied to several tasks, and the results show that our method reduces the user's workload in recognizing 3D DTI fibers and permits quick and accurate DTI fiber selection.
Keywords: 2D representation;3D visualization;Algorithms;Animals;Brain;Cluster Analysis;Computer Graphics;DTI fibers;Diffusion Magnetic Resonance Imaging;Diffusion Tensor Imaging;Fiber Clustering;Fibers;Heart;Hindlimb;Models, Biological;Myofibrils;Nerve Fibers;Swine;User-Computer Interface;Visualization Interface;biological speciments;biology computing;biomedical MRI;cluttering;data visualisation;fiber tracts anatomical complexity;interactive exploration;occlusion;visual exploration;visualization optimization;
Author: Wei Chen; Zi'ang Ding; Song Zhang; MacKay-Brandt, A.; Correia, S.; Huamin Qu; Crow, J.A.; Tate, D.F.; Zhicheng Yan; Qunsheng Peng

Year: 2009
Title: Parameter Sensitivity Visualization for DTI Fiber Tracking
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290759
Abstract: Fiber tracking of diffusion tensor imaging (DTI) data offers a unique insight into the three-dimensional organisation of white matter structures in the living brain. However, fiber tracking algorithms require a number of user-defined input parameters that strongly affect the output results. Usually the fiber tracking parameters are set once and are then re-used for several patient datasets. However, the stability of the chosen parameters is not evaluated and a small change in the parameter values can give very different results. The user remains completely unaware of such effects. Furthermore, it is difficult to reproduce output results between different users. We propose a visualization tool that allows the user to visually explore how small variations in parameter values affect the output of fiber tracking. With this knowledge the user cannot only assess the stability of commonly used parameter values but also evaluate in a more reliable way the output results between different patients. Existing tools do not provide such information. A small user evaluation of our tool has been done to show the potential of the technique.
Keywords: Algorithms;Anisotropy;Brain;Color;Computer Graphics;DTI fiber tracking;Diffusion Magnetic Resonance Imaging;Diffusion Tensor Imaging;Fiber Tracking;Humans;Image Processing, Computer-Assisted;Models, Biological;Myofibrils;Nerve Fibers;Parameter Sensitivity;Sensitivity and Specificity;Stopping Criteria;Uncertainty Visualization;biomedical MRI;brain;data visualisation;diffusion tensor imaging;living brain;medical image processing;parameter sensitivity visualization;white matter structures;
Author: Brecheisen, R.; Vilanova, A.; Platel, B.; ter Haar Romeny, B.

Year: 2009
Title: Exploring 3D DTI Fiber Tracts with Linked 2D Representations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290760
Abstract: We present a visual exploration paradigm that facilitates navigation through complex fiber tracts by combining traditional 3D model viewing with lower dimensional representations. To this end, we create standard streamtube models along with two two-dimensional representations, an embedding in the plane and a hierarchical clustering tree, for a given set of fiber tracts. We then link these three representations using both interaction and color obtained by embedding fiber tracts into a perceptually uniform color space. We describe an anecdotal evaluation with neuroscientists to assess the usefulness of our method in exploring anatomical and functional structures in the brain. Expert feedback indicates that, while a standalone clinical use of the proposed method would require anatomical landmarks in the lower dimensional representations, the approach would be particularly useful in accelerating tract bundle selection. Results also suggest that combining traditional 3D model viewing with lower dimensional representations can ease navigation through the complex fiber tract models, improving exploration of the connectivity in the brain.
Keywords: 3D DTI fiber tracts;Algorithms;Brain;Cluster Analysis;Computer Graphics;DTI fiber tracts;Diffusion Magnetic Resonance Imaging;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Models, Biological;Nerve Fibers;anecdotal evaluation;biology computing;biomedical MRI;brain;brain anatomical structures;brain functional structures;coloring;data visualisation;diffusion tensor magnetic resonance imaging;embedding;hierarchical clustering tree;interaction;linked 2D representations;two-dimensional representations;visual exploration paradigm;
Author: Jianu, R.; Demiralp, C.; Laidlaw, D.H.

Year: 2009
Title: Coloring 3D Line Fields Using Boy&#x02019;s Real Projective Plane Immersion
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290761
Abstract: We introduce a new method for coloring 3D line fields and show results from its application in visualizing orientation in DTI brain data sets. The method uses Boy's surface, an immersion of RP2 in 3D. This coloring method is smooth and one-to-one except on a set of measure zero, the double curve of Boy's surface.
Keywords: 3D line field coloring;Boy's surface real projective plane immersion;Brain;Computer Graphics;DTI brain data set visualization;DTI.;Diffusion Magnetic Resonance Imaging;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Line field;Nerve Fibers;RP2;biodiffusion;biomedical MRI;brain;colormapping;computational geometry;data visualisation;diffusion tensor magnetic resonance imaging;double curve;image colour analysis;measure zero set;medical image processing;orientation;real projective plane;tensor field;
Author: Demiralp, C.; Hughes, J.F.; Laidlaw, D.H.

Year: 2009
Title: The Occlusion Spectrum for Volume Classification and Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290762
Abstract: Despite the ever-growing improvements on graphics processing units and computational power, classifying 3D volume data remains a challenge.In this paper, we present a new method for classifying volume data based on the ambient occlusion of voxels. This information stems from the observation that most volumes of a certain type, e.g., CT, MRI or flow simulation, contain occlusion patterns that reveal the spatial structure of their materials or features. Furthermore, these patterns appear to emerge consistently for different data sets of the same type. We call this collection of patterns the occlusion spectrum of a dataset. We show that using this occlusion spectrum leads to better two-dimensional transfer functions that can help classify complex data sets in terms of the spatial relationships among features. In general, the ambient occlusion of a voxel can be interpreted as a weighted average of the intensities in a spherical neighborhood around the voxel. Different weighting schemes determine the ability to separate structures of interest in the occlusion spectrum. We present a general methodology for finding such a weighting. We show results of our approach in 3D imaging for different applications, including brain and breast tumor detection and the visualization of turbulent flow.
Keywords: 3D volume data;Algorithms;Ambient Occlusion;Brain;Breast;Breast Neoplasms;Computer Graphics;Female;Humans;Image Processing, Computer-Assisted;Imaging, Three-Dimensional;Interactive Classification;Magnetic Resonance Imaging;Normal Distribution;Transfer Functions;Volume Rendering;complex data sets;coprocessors;data visualisation;graphics processing units;medical image processing;occlusion spectrum;volume classification;volume visualization;voxel occlusion;
Author: Correa, C.; Kwan-Liu Ma

Year: 2009
Title: Structuring Feature Space: A Non-Parametric Method for Volumetric Transfer Function Generation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290763
Abstract: The use of multi-dimensional transfer functions for direct volume rendering has been shown to be an effective means of extracting materials and their boundaries for both scalar and multivariate data. The most common multi-dimensional transfer function consists of a two-dimensional (2D) histogram with axes representing a subset of the feature space (e.g., value vs. value gradient magnitude), with each entry in the 2D histogram being the number of voxels at a given feature space pair. Users then assign color and opacity to the voxel distributions within the given feature space through the use of interactive widgets (e.g., box, circular, triangular selection). Unfortunately, such tools lead users through a trial-and-error approach as they assess which data values within the feature space map to a given area of interest within the volumetric space. In this work, we propose the addition of non-parametric clustering within the transfer function feature space in order to extract patterns and guide transfer function generation. We apply a non-parametric kernel density estimation to group voxels of similar features within the 2D histogram. These groups are then binned and colored based on their estimated density, and the user may interactively grow and shrink the binned regions to explore feature boundaries and extract regions of interest. We also extend this scheme to temporal volumetric data in which time steps of 2D histograms are composited into a histogram volume. A three-dimensional (3D) density estimation is then applied, and users can explore regions within the feature space across time without adjusting the transfer function at each time step. Our work enables users to effectively explore the structures found within a feature space of the volume and provide a context in which the user can understand how these structures relate to their volumetric data. We provide tools for enhanced exploration and manipulation of the transfer function, and we show that the initial t--ransfer function generation serves as a reasonable base for volumetric rendering, reducing the trial-and-error overhead typically found in transfer function design.
Keywords: Algorithms;Cluster Analysis;Computer Graphics;Diagnostic Imaging;Humans;Image Processing, Computer-Assisted;Statistics, Nonparametric;Volume rendering;colour graphics;direct volume rendering;kernel density estimation;multi-dimensional transfer functions;nonparametric clustering;rendering (computer graphics);temporal volume rendering;three-dimensional density estimation;transfer function design;transfer function feature space;transfer functions;two-dimensional histogram;volumetric transfer function generation;
Author: Maciejewski, R.; Insoo Woo; Wei Chen; Ebert, D.

Year: 2009
Title: Automatic Transfer Function Generation Using Contour Tree Controlled Residue Flow Model and Color Harmonics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290764
Abstract: Transfer functions facilitate the volumetric data visualization by assigning optical properties to various data features and scalar values. Automation of transfer function specifications still remains a challenge in volume rendering. This paper presents an approach for automating transfer function generations by utilizing topological attributes derived from the contour tree of a volume. The contour tree acts as a visual index to volume segments, and captures associated topological attributes involved in volumetric data. A residue flow model based on Darcy's law is employed to control distributions of opacity between branches of the contour tree. Topological attributes are also used to control color selection in a perceptual color space and create harmonic color transfer functions. The generated transfer functions can depict inclusion relationship between structures and maximize opacity and color differences between them. The proposed approach allows efficient automation of transfer function generations, and exploration on the data to be carried out based on controlling of opacity residue flow rate instead of complex low-level transfer function parameter adjustments. Experiments on various data sets demonstrate the practical use of our approach in transfer function generations.
Keywords: Algorithms;Color;Computer Graphics;Contour Tree;Darcy's law;Foot;Harmonic Color.;Head;Humans;Image Processing, Computer-Assisted;Knee;Models, Theoretical;ResidueFlow;Transfer Function;Volume Rendering;automatic transfer function generation;color harmonics;color selection;colour graphics;contour tree;data visualisation;opacity;optical properties;perceptual color space;rendering (computer graphics);residue flow model;transfer functions;trees (mathematics);volume rendering;volumetric data visualization;
Author: Jianlong Zhou; Takatsuka, M.

Year: 2009
Title: An interactive visualization tool for multi-channel confocal microscopy data in neurobiology research
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290765
Abstract: Confocal microscopy is widely used in neurobiology for studying the three-dimensional structure of the nervous system. Confocal image data are often multi-channel, with each channel resulting from a different fluorescent dye or fluorescent protein; one channel may have dense data, while another has sparse; and there are often structures at several spatial scales: subneuronal domains, neurons, and large groups of neurons (brain regions). Even qualitative analysis can therefore require visualization using techniques and parameters fine-tuned to a particular dataset. Despite the plethora of volume rendering techniques that have been available for many years, the techniques standardly used in neurobiological research are somewhat rudimentary, such as looking at image slices or maximal intensity projections. Thus there is a real demand from neurobiologists, and biologists in general, for a flexible visualization tool that allows interactive visualization of multi-channel confocal data, with rapid fine-tuning of parameters to reveal the three-dimensional relationships of structures of interest. Together with neurobiologists, we have designed such a tool, choosing visualization methods to suit the characteristics of confocal data and a typical biologist's workflow. We use interactive volume rendering with intuitive settings for multidimensional transfer functions, multiple render modes and multi-views for multi-channel volume data, and embedding of polygon data into volume data for rendering and editing. As an example, we apply this tool to visualize confocal microscopy datasets of the developing zebrafish visual system.
Keywords: Animals;Eye;Image Processing, Computer-Assisted;Microscopy, Confocal;Neurobiology;Research;User-Computer Interface;Visualization;Zebrafish;brain;confocal microscopy;data visualisation;interactive visualization tool;medical computing;multichannel confocal microscopy data;neurobiology;neurobiology research;qualitative analysis;qualitative analysis;rendering (computer graphics);three-dimensional structure;volume rendering;volume rendering techniques;
Author: Yong Wan; Otsuna, H.; Chi-Bin Chien; Hansen, C.

Year: 2009
Title: BrainGazer - Visual Queries for Neurobiology Research
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290766
Abstract: Neurobiology investigates how anatomical and physiological relationships in the nervous system mediate behavior. Molecular genetic techniques, applied to species such as the common fruit fly Drosophila melanogaster, have proven to be an important tool in this research. Large databases of transgenic specimens are being built and need to be analyzed to establish models of neural information processing. In this paper we present an approach for the exploration and analysis of neural circuits based on such a database. We have designed and implemented emph{BrainGazer}, a system which integrates visualization techniques for volume data acquired through confocal microscopy as well as annotated anatomical structures with an intuitive approach for accessing the available information. We focus on the ability to visually query the data based on semantic as well as spatial relationships. Additionally, we present visualization techniques for the concurrent depiction of neurobiological volume data and geometric objects which aim to reduce visual clutter. The described system is the result of an ongoing interdisciplinary collaboration between neurobiologists and visualization researchers.
Keywords: Algorithms;Animals;Brain;BrainGazer;Computer Graphics;Database Management Systems;Drosophila melanogaster;Drosophila melanogaster;Image Processing, Computer-Assisted;Information Storage and Retrieval;Microscopy, Confocal;Neurobiology;biology computing;biomedical visualization;brain;confocal microscopy;data visualisation;human computer interaction;interactive systems;molecular genetic techniques;nervous system mediate behavior;neural information processing;neurobiological volume data;neurobiology;neurobiology research;visual queries;visual queries;visualization techniques;volume visualization;
Author: Bruckner, S.; Solteszova, V.; Groller, M.E.; Hladuvka, J.; Buhler, K.; Yu, J.Y.; Dickson, B.J.

Year: 2009
Title: Scalable and Interactive Segmentation and Visualization of Neural Processes in EM Datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290767
Abstract: Recent advances in scanning technology provide high resolution EM (electron microscopy) datasets that allow neuro-scientists to reconstruct complex neural connections in a nervous system. However, due to the enormous size and complexity of the resulting data, segmentation and visualization of neural processes in EM data is usually a difficult and very time-consuming task. In this paper, we present NeuroTrace, a novel EM volume segmentation and visualization system that consists of two parts: a semi-automatic multiphase level set segmentation with 3D tracking for reconstruction of neural processes, and a specialized volume rendering approach for visualization of EM volumes. It employs view-dependent on-demand filtering and evaluation of a local histogram edge metric, as well as on-the-fly interpolation and ray-casting of implicit surfaces for segmented neural structures. Both methods are implemented on the GPU for interactive performance. NeuroTrace is designed to be scalable to large datasets and data-parallel hardware architectures. A comparison of NeuroTrace with a commonly used manual EM segmentation tool shows that our interactive workflow is faster and easier to use for the reconstruction of complex neural processes.
Keywords: Algorithms;Animals;Cerebral Cortex;Chi-Square Distribution;Computer Graphics;Databases, Factual;EM datasets;EM volume segmentation;EM volume visualization system;Image Processing, Computer-Assisted;Mice;Microscopy, Electron;Nerve Net;NeuroTrace;Normal Distribution;Segmentation;connectome;data visualisation;electron microscopy;electron microscopy;graphics hardware;implicit surface rendering;interactive segmentation;neural processes;neurophysiology;neuroscience;on-demand filtering;on-the-fly interpolation;ray-casting;scalable segmentation;semi-automatic multiphase level set segmentation;very large databases;volume rendering;
Author: Won-Ki Jeong; Beyer, J.; Hadwiger, M.; Vazquez, A.; Pfister, H.; Whitaker, R.T.

Year: 2009
Title: Multimodal Vessel Visualization of Mouse Aorta PET/CT Scans
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290768
Abstract: In this paper, we present a visualization system for the visual analysis of PET/CT scans of aortic arches of mice. The system has been designed in close collaboration between researchers from the areas of visualization and molecular imaging with the objective to get deeper insights into the structural and molecular processes which take place during plaque development. Understanding the development of plaques might lead to a better and earlier diagnosis of cardiovascular diseases, which are still the main cause of death in the western world. After motivating our approach, we will briefly describe the multimodal data acquisition process before explaining the visualization techniques used. The main goal is to develop a system which supports visual comparison of the data of different species. Therefore, we have chosen a linked multi-view approach, which amongst others integrates a specialized straightened multipath curved planar reformation and a multimodal vessel flattening technique. We have applied the visualization concepts to multiple data sets, and we will present the results of this investigation.
Keywords: Animals;Aorta;Aortic Valve Stenosis;Atherosclerosis;Disease Models, Animal;Image Interpretation, Computer-Assisted;Mice;PET/CT Scans;Phantoms, Imaging;Positron-Emission Tomography;Reproducibility of Results;Tomography, X-Ray Computed;Vessel visualization;aortic arches;cardiovascular diseases;cardiovascular system;computed tomography;computerised tomography;data acquisition;data visualisation;diseases;medical image processing;molecular imaging;mouse aorta;multimodal data acquisition process;multimodal vessel flattening technique;multimodal vessel visualization;multipath CPR;multipath curved planar reformation;plaque growth;positron emission tomography;positron emission tomography;vessel flattening;visual analysis;
Author: Ropinski, T.; Hermann, S.; Reich, R.; Schafers, M.; Hinrichs, K.

Year: 2009
Title: Quantitative Texton Sequences for Legible Bivariate Maps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290769
Abstract: Representing bivariate scalar maps is a common but difficult visualization problem. One solution has been to use two dimensional color schemes, but the results are often hard to interpret and inaccurately read. An alternative is to use a color sequence for one variable and a texture sequence for another. This has been used, for example, in geology, but much less studied than the two dimensional color scheme, although theory suggests that it should lead to easier perceptual separation of information relating to the two variables. To make a texture sequence more clearly readable the concept of the quantitative texton sequence (QTonS) is introduced. A QTonS is defined a sequence of small graphical elements, called textons, where each texton represents a different numerical value and sets of textons can be densely displayed to produce visually differentiable textures. An experiment was carried out to compare two bivariate color coding schemes with two schemes using QTonS for one bivariate map component and a color sequence for the other. Two different key designs were investigated (a key being a sequence of colors or textures used in obtaining quantitative values from a map). The first design used two separate keys, one for each dimension, in order to measure how accurately subjects could independently estimate the underlying scalar variables. The second key design was two dimensional and intended to measure the overall integral accuracy that could be obtained. The results show that the accuracy is substantially higher for the QTonS/color sequence schemes. A hypothesis that texture/color sequence combinations are better for independent judgments of mapped quantities was supported. A second experiment probed the limits of spatial resolution for QTonSs.
Keywords: Bivariate maps;QTonS;bivariate color coding schemes;bivariate scalar maps;cartography;color sequence;colour graphics;data visualisation;geology;geology;legibility;legible bivariate maps;quantitative texton sequence;quantitative texton sequences;texton;texture;texture sequence;two dimensional color schemes;
Author: Ware, C.

Year: 2009
Title: Continuous Parallel Coordinates
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290770
Abstract: Typical scientific data is represented on a grid with appropriate interpolation or approximation schemes,defined on a continuous domain. The visualization of such data in parallel coordinates may reveal patterns latently contained in the data and thus can improve the understanding of multidimensional relations. In this paper, we adopt the concept of continuous scatterplots for the visualization of spatially continuous input data to derive a density model for parallel coordinates. Based on the point-line duality between scatterplots and parallel coordinates, we propose a mathematical model that maps density from a continuous scatterplot to parallel coordinates and present different algorithms for both numerical and analytical computation of the resulting density field. In addition, we show how the 2-D model can be used to successively construct continuous parallel coordinates with an arbitrary number of dimensions. Since continuous parallel coordinates interpolate data values within grid cells, a scalable and dense visualization is achieved, which will be demonstrated for typical multi-variate scientific data.
Keywords: Parallel coordinates;approximation schemes;approximation theory;continuous parallel coordinates;data visualisation;dense visualization;grid cells;grid computing;integrating spatial and non-spatial datavisualization;interpolation;interpolation;interpolation schemes;mathematical model;multi-variate visualization;nonspatial data visualization;point-line duality;
Author: Heinrich, J.; Weiskopf, D.

Year: 2009
Title: VisMashup: Streamlining the Creation of Custom Visualization Applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290771
Abstract: Visualization is essential for understanding the increasing volumes of digital data. However, the process required to create insightful visualizations is involved and time consuming. Although several visualization tools are available, including tools with sophisticated visual interfaces, they are out of reach for users who have little or no knowledge of visualization techniques and/or who do not have programming expertise. In this paper, we propose VisMashup, a new framework for streamlining the creation of customized visualization applications. Because these applications can be customized for very specific tasks, they can hide much of the complexity in a visualization specification and make it easier for users to explore visualizations by manipulating a small set of parameters. We describe the framework and how it supports the various tasks a designer needs to carry out to develop an application, from mining and exploring a set of visualization specifications (pipelines), to the creation of simplified views of the pipelines, and the automatic generation of the application and its interface. We also describe the implementation of the system and demonstrate its use in two real application scenarios.
Keywords: Brain;Computer Graphics;Databases, Factual;Dataflow;Electroencephalography;Image Processing, Computer-Assisted;Internet;Scientific Visualization;User-Computer Interface;VisMashup;Visualization Systems;custom visualization applications;data visualisation;digital data;pipeline processing;pipelines;sophisticated visual interfaces;user interfaces;visual programming;
Author: Santos, E.; Lins, L.; Ahrens, J.; Freire, J.; Silva, C.

Year: 2009
Title: Focus+Context Route Zooming and Information Overlay in 3D Urban Environments
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290772
Abstract: In this paper we present a novel focus+context zooming technique, which allows users to zoom into a route and its associated landmarks in a 3D urban environment from a 45-degree bird's-eye view. Through the creative utilization of the empty space in an urban environment, our technique can informatively reveal the focus region and minimize distortions to the context buildings. We first create more empty space in the 2D map by broadening the road with an adapted seam carving algorithm. A grid-based zooming technique is then used to enlarge the landmarks to reclaim the created empty space and thus reduce distortions to the other parts. Finally,an occlusion-free route visualization scheme adaptively scales the buildings occluding the route to make the route always visible to users. Our method can be conveniently integrated into Google Earth and Virtual Earth to provide seamless route zooming and help users better explore a city and plan their tours. It can also be used in other applications such as information overlay to a virtual city.
Keywords: 3D urban environment;3D virtual environment;Google Earth;Virtual Earth;cartography;context buildings;focus+context route zooming;focus+context visualization;grid-based zooming technique;occlusion-free route visualization scheme;rendering (computer graphics);road map;seam carving;seam carving algorithm;search engines;solid modelling;town and country planning;zooming;
Author: Huamin Qu; Haomian Wang; Weiwei Cui; Yingcai Wu; Ming-Yuen Chan

Year: 2009
Title: Kd-Jump: a Path-Preserving Stackless Traversal for Faster Isosurface Raytracing on GPUs
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290773
Abstract: Stackless traversal techniques are often used to circumvent memory bottlenecks by avoiding a stack and replacing return traversal with extra computation. This paper addresses whether the stackless traversal approaches are useful on newer hardware and technology (such as CUDA). To this end, we present a novel stackless approach for implicit kd-trees, which exploits the benefits of index-based node traversal, without incurring extra node visitation. This approach, which we term Kd-Jump, enables the traversal to immediately return to the next valid node, like a stack, without incurring extra node visitation (kd-restart). Also, Kd-Jump does not require global memory (stack) at all and only requires a small matrix in fast constant-memory. We report that Kd-Jump outperforms a stack by 10 to 20% and kd-restar t by 100%. We also present a Hybrid Kd-Jump, which utilizes a volume stepper for leaf testing and a run-time depth threshold to define where kd-tree traversal stops and volume-stepping occurs. By using both methods, we gain the benefits of empty space removal, fast texture-caching and realtime ability to determine the best threshold for current isosurface and view direction.
Keywords: Algorithms;Computer Graphics;Foot;GPU;GPU;Humans;Image Processing, Computer-Assisted;Kd-Jump;Raytracing;Skull;computer graphics;coprocessors;index-based node traversal;isosurface;isosurface raytracing;kd-trees;parallel computing;path-preserving stackless traversal;ray tracing;volume visualization;
Author: Hughes, D.M.; Ik Soo Lim

Year: 2009
Title: Mapping High-Fidelity Volume Rendering for Medical Imaging to CPU, GPU and Many-Core Architectures
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290774
Abstract: Medical volumetric imaging requires high fidelity, high performance rendering algorithms. We motivate and analyze new volumetric rendering algorithms that are suited to modern parallel processing architectures. First, we describe the three major categories of volume rendering algorithms and confirm through an imaging scientist-guided evaluation that ray-casting is the most acceptable. We describe a thread- and data-parallel implementation of ray-casting that makes it amenable to key architectural trends of three modern commodity parallel architectures: multi-core, GPU, and an upcoming many-core Intel<sup>reg</sup> architecture code-named Larrabee. We achieve more than an order of magnitude performance improvement on a number of large 3D medical datasets. We further describe a data compression scheme that significantly reduces data-transfer overhead. This allows our approach to scale well to large numbers of Larrabee cores.
Keywords: Algorithms;CPU;Computer Graphics;Databases, Factual;Diagnostic Imaging;GPGPU;GPU;Graphics Architecture;Humans;Image Processing, Computer-Assisted;Larrabee cores;Many-core Computing;Medical Imaging;Parallel Processing;Radiography, Abdominal;Tomography, X-Ray Computed;Volume Compositing;data compression scheme;high-fidelity volume rendering;many-core Intel architecture code;medical image processing;medical volumetric imaging;parallel processing;ray-casting;rendering (computer graphics);
Author: Smelyanskiy, M.; Holmes, D.; Chhugani, J.; Larson, A.; Carmean, D.M.; Hanson, D.; Dubey, P.; Augustine, K.; Kim, D.; Kyker, A.; Lee, V.W.; Nguyen, A.D.; Seiler, L.; Robb, R.

Year: 2009
Title: Volume Ray Casting with Peak Finding and Differential Sampling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290775
Abstract: Direct volume rendering and isosurfacing are ubiquitous rendering techniques in scientific visualization, commonly employed in imaging 3D data from simulation and scan sources. Conventionally, these methods have been treated as separate modalities, necessitating different sampling strategies and rendering algorithms. In reality, an isosurface is a special case of a transfer function, namely a Dirac impulse at a given isovalue. However, artifact-free rendering of discrete isosurfaces in a volume rendering framework is an elusive goal, requiring either infinite sampling or smoothing of the transfer function. While preintegration approaches solve the most obvious deficiencies in handling sharp transfer functions, artifacts can still result, limiting classification. In this paper, we introduce a method for rendering such features by explicitly solving for isovalues within the volume rendering integral. In addition, we present a sampling strategy inspired by ray differentials that automatically matches the frequency of the image plane, resulting in fewer artifacts near the eye and better overall performance. These techniques exhibit clear advantages over standard uniform ray casting with and without preintegration, and allow for high-quality interactive volume rendering with sharp C<sup>0</sup> transfer functions.
Keywords: Dirac impulse;artifact-free rendering;differential sampling;direct volume rendering;direct volume rendering;discrete isosurfaces;isosurface;isosurfacing;peak finding;preintegration;ray casting;ray differentials;ray differentials;rendering (computer graphics);sampling;transfer function;transfer function infinite sampling;transfer function smoothing;transfer functions;ubiquitous rendering techniques;view dependent;volume ray casting;
Author: Knoll, A.; Hijazi, Y.; Westerteiger, R.; Schott, M.; Hansen, C.; Hagen, H.

Year: 2009
Title: Interactive Volume Rendering of Functional Representations in Quantum Chemistry
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5290776
Abstract: Simulation and computation in chemistry studies have been improved as computational power has increased over decades. Many types of chemistry simulation results are available, from atomic level bonding to volumetric representations of electron density. However, tools for the visualization of the results from quantum chemistry computations are still limited to showing atomic bonds and isosurfaces or isocontours corresponding to certain isovalues. In this work, we study the volumetric representations of the results from quantum chemistry computations, and evaluate and visualize the representations directly on the GPU without resampling the result in grid structures. Our visualization tool handles the direct evaluation of the approximated wavefunctions described as a combination of Gaussian-like primitive basis functions. For visualizations, we use a slice based volume rendering technique with a 2D transfer function, volume clipping, and illustrative rendering in order to reveal and enhance the quantum chemistry structure. Since there is no need of resampling the volume from the functional representations, two issues, data transfer and resampling resolution, can be ignored, therefore, it is possible to interactively explore large amount of different information in the computation results.
Keywords: GPU;GPU;GTO;Gaussian processes;Gaussian-like primitive basis functions;Quantum Chemistry;Volume Rendering;atomic bonds;atomic level bonding;chemistry computing;coprocessors;data transfer;electron density;electron density;functional representations;interactive systems;interactive volume rendering;quantum chemistry;quantum chemistry;rendering (computer graphics);slice based volume rendering technique;
Author: Yun Jang; Varetto, U.

Year: 2008
Title: PrePages
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658122
Abstract: Prepages from Vis/InfoVis 2008
Keywords: Index Terms&amp;#8212;
Author: null

Year: 2008
Title: Rolling the Dice: Multidimensional Visual Exploration using Scatterplot Matrix Navigation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658123
Abstract: Scatterplots remain one of the most popular and widely-used visual representations for multidimensional data due to their simplicity, familiarity and visual clarity, even if they lack some of the flexibility and visual expressiveness of newer multidimensional visualization techniques. This paper presents new interactive methods to explore multidimensional data using scatterplots. This exploration is performed using a matrix of scatterplots that gives an overview of the possible configurations, thumbnails of the scatterplots, and support for interactive navigation in the multidimensional space. Transitions between scatterplots are performed as animated rotations in 3D space, somewhat akin to rolling dice. Users can iteratively build queries using bounding volumes in the dataset, sculpting the query from different viewpoints to become more and more refined. Furthermore, the dimensions in the navigation space can be reordered, manually or automatically, to highlight salient correlations and differences among them. An example scenario presents the interaction techniques supporting smooth and effortless visual exploration of multidimensional datasets.
Keywords: Index Terms&amp;#8212;animated rotations;bounding volumes;computer animation;data visualisation;interaction;multidimensional visual exploration;multivariate data;navigation;scatterplot matrix navigation;visual analytics;visual exploration;visual queries;visual queries;
Author: Elmqvist, N.; Dragicevic, P.; Fekete, J.-D.

Year: 2008
Title: A Framework of Interaction Costs in Information Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658124
Abstract: Interaction cost is an important but poorly understood factor in visualization design. We propose a framework of interaction costs inspired by Normanpsilas Seven Stages of Action to facilitate study. From 484 papers, we collected 61 interaction-related usability problems reported in 32 user studies and placed them into our framework of seven costs: (1) Decision costs to form goals; (2) system-power costs to form system operations; (3) Multiple input mode costs to form physical sequences; (4) Physical-motion costs to execute sequences; (5) Visual-cluttering costs to perceive state; (6) View-change costs to interpret perception; (7) State-change costs to evaluate interpretation. We also suggested ways to narrow the gulfs of execution (2-4) and evaluation (5-7) based on collected reports. Our framework suggests a need to consider decision costs (1) as the gulf of goal formation.
Keywords: Framework;Index Terms&amp;#8212;Information Visualization;Interaction;Interface Evaluation;data visualisation;information visualization;interaction cost;multiple input mode costs;physical-motion costs;state-change costs;system-power costs;user interfaces;view-change costs;visual-cluttering costs;visualization design;
Author: Lam, H.

Year: 2008
Title: Balloon Focus: a Seamless Multi-Focus+Context Method for Treemaps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658125
Abstract: The treemap is one of the most popular methods for visualizing hierarchical data. When a treemap contains a large number of items, inspecting or comparing a few selected items in a greater level of detail becomes very challenging. In this paper, we present a seamless multi-focus and context technique, called Balloon Focus, that allows the user to smoothly enlarge multiple treemap items served as the foci, while maintaining a stable treemap layout as the context. Our method has several desirable features. First, this method is quite general and can be used with different treemap layout algorithms. Second, as the foci are enlarged, the relative positions among all items are preserved. Third, the foci are placed in a way that the remaining space is evenly distributed back to the non-focus treemap items. When Balloon Focus enlarges the focus items to a maximum degree, the above features ensure that the treemap will maintain a consistent appearance and avoid any abrupt layout changes. In our algorithm, a DAG (Directed Acyclic Graph) is used to maintain the positional constraints, and an elastic model is employed to govern the placement of the treemap items. We demonstrate a treemap visualization system that integrates data query, manual focus selection, and our novel multi-focus+context technique, Balloon Focus, together. A user study was conducted. Results show that with Balloon Focus, users can better perform the tasks of comparing the values and the distribution of the foci.
Keywords: Index Terms&amp;#8212;Treemap;balloon focus;data query;data visualisation;data visualization;directed acyclic graph;directed graphs;fisheye;focus+context;magnification;multi-focus;multi-scale viewing.;multifocus+context method;treemaps;visualizing query results;
Author: Ying Tu; Han-Wei Shen

Year: 2008
Title: Multi-Focused Geospatial Analysis Using Probes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658126
Abstract: Traditional geospatial information visualizations often present views that restrict the user to a single perspective. When zoomed out, local trends and anomalies become suppressed and lost; when zoomed in for local inspection, spatial awareness and comparison between regions become limited. In our model, coordinated visualizations are integrated within individual probe interfaces, which depict the local data in user-defined regions-of-interest. Our probe concept can be incorporated into a variety of geospatial visualizations to empower users with the ability to observe, coordinate, and compare data across multiple local regions. It is especially useful when dealing with complex simulations or analyses where behavior in various localities differs from other localities and from the system as a whole. We illustrate the effectiveness of our technique over traditional interfaces by incorporating it within three existing geospatial visualization systems: an agent-based social simulation, a census data exploration tool, and an 3D GIS environment for analyzing urban change over time. In each case, the probe-based interaction enhances spatial awareness, improves inspection and comparison capabilities, expands the range of scopes, and facilitates collaboration among multiple users.
Keywords: 3D GIS;Index Terms&amp;#8212;Multiple-view techniques;agent-based social simulation;census data exploration tool;data visualisation;focus + context;geographic information systems;geospatial analysis;geospatial information visualizations;geospatial visualization;local inspection;multifocused geospatial analysis;probes;probes;spatial awareness;user-defined regions-of-interest;
Author: Butkiewicz, T.; Dou, W.; Wartell, Z.; Ribarsky, W.; Chang, R.

Year: 2008
Title: Distributed Cognition as a Theoretical Framework for Information Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658127
Abstract: Even though information visualization (InfoVis) research has matured in recent years, it is generally acknowledged that the field still lacks supporting, encompassing theories. In this paper, we argue that the distributed cognition framework can be used to substantiate the theoretical foundation of InfoVis. We highlight fundamental assumptions and theoretical constructs of the distributed cognition approach, based on the cognitive science literature and a real life scenario. We then discuss how the distributed cognition framework can have an impact on the research directions and methodologies we take as InfoVis researchers. Our contributions are as follows. First, we highlight the view that cognition is more an emergent property of interaction than a property of the human mind. Second, we argue that a reductionist approach to study the abstract properties of isolated human minds may not be useful in informing InfoVis design. Finally we propose to make cognition an explicit research agenda, and discuss the implications on how we perform evaluation and theory building.
Keywords: Biomimetics;Cognition;Computer Graphics;Index Terms&amp;#8212;Informatics;Information Storage and Retrieval;Information visualization;User-Computer Interface;cognition;cognitive science;data visualisation;distributed cognition;distributed cognition;information visualization;informing InfoVis design;interaction;representation;theory and methods;
Author: Zhicheng Liu; Nersessian, N.; Stasko, J.

Year: 2008
Title: EMDialog: Bringing Information Visualization into the Museum
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658128
Abstract: Digital information displays are becoming more common in public spaces such as museums, galleries, and libraries. However, the public nature of these locations requires special considerations concerning the design of information visualization in terms of visual representations and interaction techniques. We discuss the potential for, and challenges of, information visualization in the museum context based on our practical experience with EMDialog, an interactive information presentation that was part of the Emily Carr exhibition at the Glenbow Museum in Calgary. EMDialog visualizes the diverse and multi-faceted discourse about this Canadian artist with the goal to both inform and provoke discussion. It provides a visual exploration environment that offers interplay between two integrated visualizations, one for information access along temporal, and the other along contextual dimensions. We describe the results of an observational study we conducted at the museum that revealed the different ways visitors approached and interacted with EMDialog, as well as how they perceived this form of information presentation in the museum context. Our results include the need to present information in a manner sufficiently attractive to draw attention and the importance of rewarding passive observation as well as both short- and longer term information exploration.
Keywords: Index Terms&amp;#8212;artistic information visualization;data visualisation;digital information display;exhibitions;humanities;information visualization;interaction technique;interactive information visualization;interactive systems;museum;public displays.;visual representation;walk-up-and-use interaction;
Author: Hinrichs, U.; Schmidt, H.; Carpendale, S.

Year: 2008
Title: Graphical Histories for Visualization: Supporting Analysis, Communication, and Evaluation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658129
Abstract: Interactive history tools, ranging from basic undo and redo to branching timelines of user actions, facilitate iterative forms of interaction. In this paper, we investigate the design of history mechanisms for information visualization. We present a design space analysis of both architectural and interface issues, identifying design decisions and associated trade-offs. Based on this analysis, we contribute a design study of graphical history tools for Tableau, a database visualization system. These tools record and visualize interaction histories, support data analysis and communication of findings, and contribute novel mechanisms for presenting, managing, and exporting histories. Furthermore, we have analyzed aggregated collections of history sessions to evaluate Tableau usage. We describe additional tools for analyzing userspsila history logs and how they have been applied to study usage patterns in Tableau.
Keywords: Index Terms&amp;#8212;Tableau;Visualization;analysis;data visualisation;database management systems;database visualization system;design space analysis;evaluation;graphical history tools;history;information visualization;interactive history tools;presentation;undo;user interfaces;
Author: Heer, J.; Mackinlay, J.; Stolte, C.; Agrawala, M.

Year: 2008
Title: Who Votes For What? A Visual Query Language for Opinion Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658130
Abstract: Surveys and opinion polls are extremely popular in the media, especially in the months preceding a general election. However, the available tools for analyzing poll results often require specialized training. Hence, data analysis remains out of reach for many casual computer users. Moreover, the visualizations used to communicate the results of surveys are typically limited to traditional statistical graphics like bar graphs and pie charts, both of which are fundamentally noninteractive. We present a simple interactive visualization that allows users to construct queries on large tabular data sets, and view the results in real time. The results of two separate user studies suggest that our interface lowers the learning curve for naive users, while still providing enough analytical power to discover interesting correlations in the data.
Keywords: Index Terms&amp;#8212;Visual query languages;bar graphs;data analysis;data analysis;data visualisation;general election;human computer interaction;human-computer interaction;interactive visualization;opinion data;pie charts;query languages;radial visualization;statistical graphics;tabular data sets;visual query language;
Author: Draper, G.; Riesenfeld, R.

Year: 2008
Title: VisGets: Coordinated Visualizations for Web-based Information Exploration and Discovery
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658131
Abstract: In common Web-based search interfaces, it can be difficult to formulate queries that simultaneously combine temporal, spatial, and topical data filters. We investigate how coordinated visualizations can enhance search and exploration of information on the World Wide Web by easing the formulation of these types of queries. Drawing from visual information seeking and exploratory search, we introduce VisGets - interactive query visualizations of Web-based information that operate with online information within a Web browser. VisGets provide the information seeker with visual overviews of Web resources and offer a way to visually filter the data. Our goal is to facilitate the construction of dynamic search queries that combine filters from more than one data dimension. We present a prototype information exploration system featuring three linked VisGets (temporal, spatial, and topical), and used it to visually explore news items from online RSS feeds.
Keywords: Index Terms&amp;#8212;Information visualization;Internet;VisGets;Web browser;Web resources;Web-based information discovery;Web-based information exploration;Web-based search interfaces;World Wide Web;World Wide Web;data filters;data mining;data visualisation;dynamic search queries;exploratory search;information filters;information retrieval;interactive query visualizations;online front-ends;query processing;visual information seeking.;
Author: Dork, M.; Carpendale, S.; Collins, C.; Williamson, C.

Year: 2008
Title: Vispedia: Interactive Visual Exploration of Wikipedia Data via Search-Based Integration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658132
Abstract: Wikipedia is an example of the collaborative, semi-structured data sets emerging on the Web. These data sets have large, non-uniform schema that require costly data integration into structured tables before visualization can begin. We present Vispedia, a Web-based visualization system that reduces the cost of this data integration. Users can browse Wikipedia, select an interesting data table, then use a search interface to discover, integrate, and visualize additional columns of data drawn from multiple Wikipedia articles. This interaction is supported by a fast path search algorithm over DBpedia, a semantic graph extracted from Wikipedia's hyperlink structure. Vispedia can also export the augmented data tables produced for use in traditional visualization systems. We believe that these techniques begin to address the "long tail" of visualization by allowing a wider audience to visualize a broader class of data. We evaluated this system in a first-use formative lab study. Study participants were able to quickly create effective visualizations for a diverse set of domains, performing data integration as needed.
Keywords: Index Terms&amp;#8212;Internet;Web;Web-based visualization system;Wikipedia;Wikipedia data;data integration;data integration;data integrity;data visualisation;fast path search algorithm;information visualization;interactive visual exploration;search engines;search interface;search-based integration;semantic Web;semantic web;semistructured data;
Author: Chan, B.; Wu, L.; Talbot, J.; Cammarano, M.; Hanrahan, P.

Year: 2008
Title: The Word Tree, an Interactive Visual Concordance
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658133
Abstract: We introduce the Word Tree, a new visualization and information-retrieval technique aimed at text documents. A Word Tree is a graphical version of the traditional "keyword-in-context" method, and enables rapid querying and exploration of bodies of text. In this paper we describe the design of the technique, along with some of the technical issues that arise in its implementation. In addition, we discuss the results of several months of public deployment of word trees on Many Eyes, which provides a window onto the ways in which users obtain value from the visualization.
Keywords: Index Terms&amp;#8212;Many Eyes;Many Eyes;Text visualization;Word Tree;case study;concordance;data visualisation;document handling;document visualization;information retrieval;information retrieval;information-retrieval technique;interactive visual concordance;keyword-in-context method;search.;
Author: Wattenberg, M.; Viegas, F.B.

Year: 2008
Title: HiPP: A Novel Hierarchical Point Placement Strategy and its Application to the Exploration of Document Collections
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658134
Abstract: Point placement strategies aim at mapping data points represented in higher dimensions to bi-dimensional spaces and are frequently used to visualize relationships amongst data instances. They have been valuable tools for analysis and exploration of data sets of various kinds. Many conventional techniques, however, do not behave well when the number of dimensions is high, such as in the case of documents collections. Later approaches handle that shortcoming, but may cause too much clutter to allow flexible exploration to take place. In this work we present a novel hierarchical point placement technique that is capable of dealing with these problems. While good grouping and separation of data with high similarity is maintained without increasing computation cost, its hierarchical structure lends itself both to exploration in various levels of detail and to handling data in subsets, improving analysis capability and also allowing manipulation of larger data sets.
Keywords: HiPP;Index Terms&amp;#8212;Text and document visualization;analysis capability;data mining;document collections;document handling;hierarchical multidimensional visualization;hierarchical point placement strategy;high-dimensional data.;visual knowledge discovery;visual knowledge discovery;
Author: Paulovich, F.V.; Minghim, R.

Year: 2008
Title: Particle-based labeling: Fast point-feature labeling without obscuring other visual features
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658135
Abstract: In many information visualization techniques, labels are an essential part to communicate the visualized data. To preserve the expressiveness of the visual representation, a placed label should neither occlude other labels nor visual representatives (e.g., icons, lines) that communicate crucial information. Optimal, non-overlapping labeling is an NP-hard problem. Thus, only a few approaches achieve a fast non-overlapping labeling in highly interactive scenarios like information visualization. These approaches generally target the point-feature label placement (PFLP) problem, solving only label-label conflicts. This paper presents a new, fast, solid and flexible 2D labeling approach for the PFLP problem that additionally respects other visual elements and the visual extent of labeled features. The results (number of placed labels, processing time) of our particle-based method compare favorably to those of existing techniques. Although the esthetic quality of non-real-time approaches may not be achieved with our method, it complies with practical demands and thus supports the interactive exploration of information spaces. In contrast to the known adjacent techniques, the flexibility of our technique enables labeling of dense point clouds by the use of non-occluding distant labels. Our approach is independent of the underlying visualization technique, which enables us to demonstrate the application of our labeling method within different information visualization scenarios.
Keywords: Index Terms&amp;#8212;automatic label placement;data visualisation;data visualization;dynamic labeling;fast point feature labeling;flexible 2D labeling;information visualization;information visualization;interactive labeling;non-occluding distant labels;occlusion-free;particle-based labeling;point-feature label placement problem;visual features;visual representation;
Author: Luboschik, M.; Schumann, H.; Cords, H.

Year: 2008
Title: Stacked Graphs &#x02013; Geometry &amp; Aesthetics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658136
Abstract: In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.
Keywords: Index Terms&amp;#8212;Streamgraph;ThemeRiver;aesthetics;aesthetics;communication-minded visualization;communication-minded visualization;complex layered graph;data visualisation;geometry;last.fm;layered graph;listening history;stacked graphs;time series;
Author: Byron, L.; Wattenberg, M.

Year: 2008
Title: Cerebral: Visualizing Multiple Experimental Conditions on a Graph with Biological Context
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658137
Abstract: Systems biologists use interaction graphs to model the behavior of biological systems at the molecular level. In an iterative process, such biologists observe the reactions of living cells under various experimental conditions, view the results in the context of the interaction graph, and then propose changes to the graph model. These graphs serve as a form of dynamic knowledge representation of the biological system being studied and evolve as new insight is gained from the experimental data. While numerous graph layout and drawing packages are available, these tools did not fully meet the needs of our immunologist collaborators. In this paper, we describe the data information display needs of these immunologists and translate them into design decisions. These decisions led us to create Cerebral, a system that uses a biologically guided graph layout and incorporates experimental data directly into the graph display. Small multiple views of different experimental conditions and a data-driven parallel coordinates view enable correlations between experimental conditions to be analyzed at the same time that the data is viewed in the graph context. This combination of coordinated views allows the biologist to view the data from many different perspectives simultaneously. To illustrate the typical analysis tasks performed, we analyze two datasets using Cerebral. Based on feedback from our collaborators we conclude that Cerebral is a valuable tool for analyzing experimental data in the context of an interaction graph model.
Keywords: Biology;Computer Graphics;Computer Simulation;Graph layout;Index Terms&amp;#8212;Models, Biological;Proteome;Signal Transduction;Software;User-Computer Interface;biological system;biology computing;cerebral tool;data information display;data visualisation;decision theory;design decision;design study;drawing package;dynamic knowledge representation;graph theory;interaction graph layout;iterative methods;iterative process;knowledge representation;living cells reaction observation;multiple experimental condition visualization;small multiples;systems biology visualization;
Author: Barsky, A.; Munzner, T.; Gardy, J.; Kincaid, R.

Year: 2008
Title: The Shaping of Information by Visual Metaphors
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658138
Abstract: The nature of an information visualization can be considered to lie in the visual metaphors it uses to structure information. The process of understanding a visualization therefore involves an interaction between these external visual metaphors and the user's internal knowledge representations. To investigate this claim, we conducted an experiment to test the effects of visual metaphor and verbal metaphor on the understanding of tree visualizations. Participants answered simple data comprehension questions while viewing either a treemap or a node-link diagram. Questions were worded to reflect a verbal metaphor that was either compatible or incompatible with the visualization a participant was using. The results suggest that the visual metaphor indeed affects how a user derives information from a visualization. Additionally, we found that the degree to which a user is affected by the metaphor is strongly correlated with the user's ability to answer task questions correctly. These findings are a first step towards illuminating how visual metaphors shape user understanding, and have significant implications for the evaluation, application, and theory of visualization.
Keywords: Biomimetics;Cognition;Cognition;Computer Graphics;Computer Simulation;Index Terms&amp;#8212;Information Dissemination;Information Storage and Retrieval;Models, Theoretical;User-Computer Interface;data visualisation;evaluation;hierarchies;information shaping;information visualization;internal knowledge representations;metaphors;tree visualizations;visual metaphors;visualization theory;
Author: Ziemkiewicz, C.; Kosara, R.

Year: 2008
Title: Viz-A-Vis: Toward Visualizing Video through Computer Vision
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658139
Abstract: In the established procedural model of information visualization, the first operation is to transform raw data into data tables. The transforms typically include abstractions that aggregate and segment relevant data and are usually defined by a human, user or programmer. The theme of this paper is that for video, data transforms should be supported by low level computer vision. High level reasoning still resides in the human analyst, while part of the low level perception is handled by the computer. To illustrate this approach, we present Viz-A-Vis, an overhead video capture and access system for activity analysis in natural settings over variable periods of time. Overhead video provides rich opportunities for long-term behavioral and occupancy analysis, but it poses considerable challenges. We present initial steps addressing two challenges. First, overhead video generates overwhelmingly large volumes of video impractical to analyze manually. Second, automatic video analysis remains an open problem for computer vision.
Keywords: Algorithms;Artificial Intelligence;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Index Terms&amp;#8212;Software;Spatiotemporal visualization;User-Computer Interface;Video Recording;Viz-A-Vis video visualization;automatic video analysis;computer vision;computer vision;data aggregation;data segmentation;data table;data visualisation;image/video analytics;information visualization procedural model;raw data transform;sensor analytics;time series data;video signal processing;video visualization;
Author: Romero, M.; Summet, J.; Stasko, J.; Abowd, G.

Year: 2008
Title: Geometry-Based Edge Clustering for Graph Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658140
Abstract: Graphs have been widely used to model relationships among data. For large graphs, excessive edge crossings make the display visually cluttered and thus difficult to explore. In this paper, we propose a novel geometry-based edge-clustering framework that can group edges into bundles to reduce the overall edge crossings. Our method uses a control mesh to guide the edge-clustering process; edge bundles can be formed by forcing all edges to pass through some control points on the mesh. The control mesh can be generated at different levels of detail either manually or automatically based on underlying graph patterns. Users can further interact with the edge-clustering results through several advanced visualization techniques such as color and opacity enhancement. Compared with other edge-clustering methods, our approach is intuitive, flexible, and efficient. The experiments on some large graphs demonstrate the effectiveness of our method.
Keywords: Graph visualization;Index Terms&amp;#8212;computational geometry;data visualisation;edge clustering;edge crossings;edge-clustering process;geometry-based edge clustering;graph visualization;graphs;mesh;pattern clustering;visual clutter;
Author: Weiwei Cui; Hong Zhou; Huamin Qu; Pak Chung Wong; Xiaoming Li

Year: 2008
Title: On the Visualization of Social and other Scale-Free Networks
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658141
Abstract: This paper proposes novel methods for visualizing specifically the large power-law graphs that arise in sociology and the sciences. In such cases a large portion of edges can be shown to be less important and removed while preserving component connectedness and other features (e.g. cliques) to more clearly reveal the networkpsilas underlying connection pathways. This simplification approach deterministically filters (instead of clustering) the graph to retain important node and edge semantics, and works both automatically and interactively. The improved graph filtering and layout is combined with a novel computer graphics anisotropic shading of the dense crisscrossing array of edges to yield a full social network and scale-free graph visualization system. Both quantitative analysis and visual results demonstrate the effectiveness of this approach.
Keywords: Algorithms;Computer Graphics;Computer Simulation;Index Terms&amp;#8212;Information Storage and Retrieval;Models, Theoretical;Scale-free network;Social Support;User-Computer Interface;anisotropic shading;betweenness centrality;complex networks;computer graphics anisotropic shading;data visualisation;data visualization;dense crisscrossing array;edge filtering;edge semantics;graph filtering;graph theory;network theory (graphs);node semantics;power-law distribution;scale-free network;social network;sociology;statistical distributions;
Author: Yuntao Jia; Hoberock, J.; Garland, M.; Hart, J.

Year: 2008
Title: Exploration of Networks using overview+detail with Constraint-based cooperative layout
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658142
Abstract: A standard approach to large network visualization is to provide an overview of the network and a detailed view of a small component of the graph centred around a focal node. The user explores the network by changing the focal node in the detailed view or by changing the level of detail of a node or cluster. For scalability, fast force-based layout algorithms are used for the overview and the detailed view. However, using the same layout algorithm in both views is problematic since layout for the detailed view has different requirements to that in the overview. Here we present a model in which constrained graph layout algorithms are used for layout in the detailed view. This means the detailed view has high-quality layout including sophisticated edge routing and is customisable by the user who can add placement constraints on the layout. Scalability is still ensured since the slower layout techniques are only applied to the small subgraph shown in the detailed view. The main technical innovations are techniques to ensure that the overview and detailed view remain synchronized, and modifying constrained graph layout algorithms to support smooth, stable layout. The key innovation supporting stability are new dynamic graph layout algorithms that preserve the topology or structure of the network when the user changes the focus node or the level of detail by in situ semantic zooming. We have built a prototype tool and demonstrate its use in two application domains, UML class diagrams and biological networks.
Keywords: Algorithms;Computer Graphics;Computer Simulation;Graph drawing;Index Terms&amp;#8212;Information Storage and Retrieval;Models, Biological;Signal Transduction;Social Support;User-Computer Interface;constrained graph layout algorithms;constraint-based cooperative layout;constraints;data visualisation;force directed algorithms;graph theory;large network visualization;multidimensional scaling.;scalability fast force-based layout algorithms;sophisticated edge routing;stress majorization;
Author: Dwyer, T.; Marriott, K.; Schreiber, F.; Stuckey, P.; Woodward, M.; Wybrow, M.

Year: 2008
Title: Rapid Graph Layout Using Space Filling Curves
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658143
Abstract: Network data frequently arises in a wide variety of fields, and node-link diagrams are a very natural and intuitive representation of such data. In order for a node-link diagram to be effective, the nodes must be arranged well on the screen. While many graph layout algorithms exist for this purpose, they often have limitations such as high computational complexity or node colocation. This paper proposes a new approach to graph layout through the use of space filling curves which is very fast and guarantees that there will be no nodes that are colocated. The resulting layout is also aesthetic and satisfies several criteria for graph layout effectiveness.
Keywords: Graph layout;Index Terms&amp;#8212;Information visualization;Space filling curves;computational complexity;computational complexity;data visualisation;graph layout;graph theory;graph visualization;node colocation;node-link diagrams;space filling curves;
Author: Muelder, C.; Kwan-Liu Ma

Year: 2008
Title: Evaluating the Use of Data Transformation for Information Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658144
Abstract: Data transformation, the process of preparing raw data for effective visualization, is one of the key challenges in information visualization. Although researchers have developed many data transformation techniques, there is little empirical study of the general impact of data transformation on visualization. Without such study, it is difficult to systematically decide when and which data transformation techniques are needed. We thus have designed and conducted a two-part empirical study that examines how the use of common data transformation techniques impacts visualization quality, which in turn affects user task performance. Our first experiment studies the impact of data transformation on user performance in single-step, typical visual analytic tasks. The second experiment assesses the impact of data transformation in multi-step analytic tasks. Our results quantify the benefits of data transformation in both experiments. More importantly, our analyses reveal that (1) the benefits of data transformation vary significantly by task and by visualization, and (2) the use of data transformation depends on a user's interaction context. Based on our findings, we present a set of design recommendations that help guide the development and use of data transformation techniques.
Keywords: Index Terms&amp;#8212;data cleaning;data transformation;data transformation techniques;data visualisation;data visualization;empirical evaluation;human computer interaction;human factors;information visualization;user interaction;user studies;visualization quality;
Author: Zhen Wen; Zhou, M.X.

Year: 2008
Title: Improving the Readability of Clustered Social Networks using Node Duplication
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658145
Abstract: Exploring communities is an important task in social network analysis. Such communities are currently identified using clustering methods to group actors. This approach often leads to actors belonging to one and only one cluster, whereas in real life a person can belong to several communities. As a solution we propose duplicating actors in social networks and discuss potential impact of such a move. Several visual duplication designs are discussed and a controlled experiment comparing network visualization with and without duplication is performed, using 6 tasks that are important for graph readability and visual interpretation of social networks. We show that in our experiment, duplications significantly improve community-related tasks but sometimes interfere with other graph readability tasks. Finally, we propose a set of guidelines for deciding when to duplicate actors and choosing candidates for duplication, and alternative ways to render them in social network representations.
Keywords: Algorithms;Cluster Analysis;Clustering;Computer Graphics;Computer Simulation;Graph Visualization;Index Terms&amp;#8212;Information Storage and Retrieval;Models, Theoretical;Node Duplications;Social Networks;Social Support;User-Computer Interface;clustering method;data visualisation;graph readability;graph theory;group actor;node duplication;pattern clustering;social network visualization;social sciences computing;
Author: Henr, N.; Bezerianos, A.; Fekete, J.-D.

Year: 2008
Title: Effectiveness of Animation in Trend Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658146
Abstract: Animation has been used to show trends in multi-dimensional data. This technique has recently gained new prominence for presentations, most notably with Gapminder Trendalyzer. In Trendalyzer, animation together with interesting data and an engaging presenter helps the audience understand the results of an analysis of the data. It is less clear whether trend animation is effective for analysis. This paper proposes two alternative trend visualizations that use static depictions of trends: one which shows traces of all trends overlaid simultaneously in one display and a second that uses a small multiples display to show the trend traces side-by-side. The paper evaluates the three visualizations for both analysis and presentation. Results indicate that trend animation can be challenging to use even for presentations; while it is the fastest technique for presentation and participants find it enjoyable and exciting, it does lead to many participant errors. Animation is the least effective form for analysis; both static depictions of trends are significantly faster than animation, and the small multiples display is more accurate.
Keywords: Gapminder Trendalyzer;Index Terms&amp;#8212;Information visualization;animation;computer animation;data visualisation;design;experiment;trend animation;trend visualization;trends;
Author: Robertson, G.; Fernandez, R.; Fisher, D.; Lee, B.; Stasko, J.

Year: 2008
Title: Perceptual Organization in User-Generated Graph Layouts
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658147
Abstract: Many graph layout algorithms optimize visual characteristics to achieve useful representations. Implicitly, their goal is to create visual representations that are more intuitive to human observers. In this paper, we asked users to explicitly manipulate nodes in a network diagram to create layouts that they felt best captured the relationships in the data. This allowed us to measure organizational behavior directly, allowing us to evaluate the perceptual importance of particular visual features, such as edge crossings and edge-lengths uniformity. We also manipulated the interior structure of the node relationships by designing data sets that contained clusters, that is, sets of nodes that are strongly interconnected. By varying the degree to which these clusters were ldquomaskedrdquo by extraneous edges we were able to measure observerspsila sensitivity to the existence of clusters and how they revealed them in the network diagram. Based on these measurements we found that observers are able to recover cluster structure, that the distance between clusters is inversely related to the strength of the clustering, and that users exhibit the tendency to use edges to visually delineate perceptual groups. These results demonstrate the role of perceptual organization in representing graph data and provide concrete recommendations for graph layout algorithms.
Keywords: Algorithms;Computer Graphics;Computer Simulation;Index Terms&amp;#8212;Information Storage and Retrieval;Models, Biological;Network layout visualization;Neural Networks (Computer);Pattern Recognition, Automated;User-Computer Interface;Visual Perception;data visualisation;edge crossings;edge-lengths uniformity;graph layout;graph theory;network layout visualization;perceptual organization;perceptual organization;user studies;user-generated graph layouts;visual representations;
Author: van Ham, F.; Rogowitz, B.

Year: 2008
Title: Interactive Visual Analysis of Set-Typed Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658148
Abstract: While it is quite typical to deal with attributes of different data types in the visualization of heterogeneous and multivariate datasets, most existing techniques still focus on the most usual data types such as numerical attributes or strings. In this paper we present a new approach to the interactive visual exploration and analysis of data that contains attributes which are of set type. A set-typed attribute of a data item - like one cell in a table - has a list of nGt=0 elements as its value. We present the setpsilaopsilagram as a new visualization approach to represent data of set type and to enable interactive visual exploration and analysis. We also demonstrate how this approach is capable to help in dealing with datasets that have a larger number of dimensions (more than a dozen or more), especially also in the context of categorical data. To illustrate the effectiveness of our approach, we present the interactive visual analysis of a CRM dataset with data from a questionnaire on the education and shopping habits of about 90000 people.
Keywords: Algorithms;CRM dataset;Categorical Data Visualization;Computer Graphics;Computer Simulation;Database Management Systems;Databases, Factual;Focus+Context Visualization;Index Terms&amp;#8212;Information Storage and Retrieval;Interactive Visual Analysis;Interactive Visualization;Models, Theoretical;Multidimensional Multivariate Data Visualization;Multiple Coordinated Views;User-Computer Interface;categorical data;data analysis;data analysis;data visualisation;data visualization;heterogeneous datasets;interactive visual analysis;interactive visual exploration;multivariate datasets;numerical attributes;numerical strings;set-typed data;
Author: Freiler, W.; Matkovic, K.; Hauser, H.

Year: 2008
Title: Spatially Ordered Treemaps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658149
Abstract: Existing treemap layout algorithms suffer to some extent from poor or inconsistent mappings between data order and visual ordering in their representation, reducing their cognitive plausibility. While attempts have been made to quantify this mismatch, and algorithms proposed to minimize inconsistency, solutions provided tend to concentrate on one-dimensional ordering. We propose extensions to the existing squarified layout algorithm that exploit the two-dimensional arrangement of treemap nodes more effectively. Our proposed spatial squarified layout algorithm provides a more consistent arrangement of nodes while maintaining low aspect ratios. It is suitable for the arrangement of data with a geographic component and can be used to create tessellated cartograms for geovisualization. Locational consistency is measured and visualized and a number of layout algorithms are compared. CIELab color space and displacement vector overlays are used to assess and emphasize the spatial layout of treemap nodes. A case study involving locations of tagged photographs in the Flickr database is described.
Keywords: CIELab;Cartograms;Flickr database;Geographic information;Geovisualization;Index Terms&amp;#8212;Tree structures;Treemaps;data order;data visualisation;geovisualization;locational consistency;spatially ordered treemaps;tessellated cartograms;tree data structures;visual ordering;
Author: Wood, J.; Dykes, J.

Year: 2008
Title: Visualizing Incomplete and Partially Ranked Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658150
Abstract: Ranking data, which result from m raters ranking n items, are difficult to visualize due to their discrete algebraic structure, and the computational difficulties associated with them when n is large. This problem becomes worse when raters provide tied rankings or not all items are ranked. We develop an approach for the visualization of ranking data for large n which is intuitive, easy to use, and computationally efficient. The approach overcomes the structural and computational difficulties by utilizing a natural measure of dissimilarity for raters, and projecting the raters into a low dimensional vector space where they are viewed. The visualization techniques are demonstrated using voting data, jokes, and movie preferences.
Keywords: Index Terms&amp;#8212;Partial rankings;data ranking;data visualisation;discrete algebraic structure;incomplete data visualization;incomplete rankings;multidimensional scaling;partially ranked data visualization;vector space;vectors;
Author: Kidwell, P.; Lebanon, G.; Cleveland, W.S.

Year: 2008
Title: Texture-based Transfer Functions for Direct Volume Rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658151
Abstract: Visualization of volumetric data faces the difficult task of finding effective parameters for the transfer functions. Those parameters can determine the effectiveness and accuracy of the visualization. Frequently, volumetric data includes multiple structures and features that need to be differentiated. However, if those features have the same intensity and gradient values, existing transfer functions are limited at effectively illustrating those similar features with different rendering properties. We introduce texture-based transfer functions for direct volume rendering. In our approach, the voxelpsilas resulting opacity and color are based on local textural properties rather than individual intensity values. For example, if the intensity values of the vessels are similar to those on the boundary of the lungs, our texture-based transfer function will analyze the textural properties in those regions and color them differently even though they have the same intensity values in the volume. The use of texture-based transfer functions has several benefits. First, structures and features with the same intensity and gradient values can be automatically visualized with different rendering properties. Second, segmentation or prior knowledge of the specific features within the volume is not required for classifying these features differently. Third, textural metrics can be combined and/or maximized to capture and better differentiate similar structures. We demonstrate our texture-based transfer function for direct volume rendering with synthetic and real-world medical data to show the strength of our technique.
Keywords: Index Terms&amp;#8212;data variability;data visualisation;direct volume rendering;feature classification;feature extraction;gradient methods;gradient value;image classification;image colour analysis;image texture;medical imaging;rendering (computer graphics);statistical analysis;texture-based transfer function;transfer functions;visualization;volume rendering;volumetric data face visualization;
Author: Caban, J.J.; Rheingans, P.

Year: 2008
Title: Volume MLS Ray Casting
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658152
Abstract: The method of Moving Least Squares (MLS) is a popular framework for reconstructing continuous functions from scattered data due to its rich mathematical properties and well-understood theoretical foundations. This paper applies MLS to volume rendering, providing a unified mathematical framework for ray casting of scalar data stored over regular as well as irregular grids. We use the MLS reconstruction to render smooth isosurfaces and to compute accurate derivatives for high-quality shading effects. We also present a novel, adaptive preintegration scheme to improve the efficiency of the ray casting algorithm by reducing the overall number of function evaluations, and an efficient implementation of our framework exploiting modern graphics hardware. The resulting system enables high-quality volume integration and shaded isosurface rendering for regular and irregular volume data.
Keywords: Adaptive Integration;Algorithms;Diagnostic Imaging;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;Moving Least Squares Reconstruction;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Unstructured Grids;Volume Visualization;adaptive preintegration scheme;continuous functions;data visualisation;function evaluations;high-quality shading effects;high-quality volume integration;irregular grids;least squares approximations;modern graphics hardware;moving least squares;ray tracing;rendering (computer graphics);shaded isosurface;volume MLS ray casting;
Author: Ledergerber, C.; Guennebaud, G.; Meyer, M.; Bacher, M.; Pfister, H.

Year: 2008
Title: Size-based Transfer Functions: A New Volume Exploration Technique
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658153
Abstract: The visualization of complex 3D images remains a challenge, a fact that is magnified by the difficulty to classify or segment volume data. In this paper, we introduce size-based transfer functions, which map the local scale of features to color and opacity. Features in a data set with similar or identical scalar values can be classified based on their relative size. We achieve this with the use of scale fields, which are 3D fields that represent the relative size of the local feature at each voxel. We present a mechanism for obtaining these scale fields at interactive rates, through a continuous scale-space analysis and a set of detection filters. Through a number of examples, we show that size-based transfer functions can improve classification and enhance volume rendering techniques, such as maximum intensity projection. The ability to classify objects based on local size at interactive rates proves to be a powerful method for complex data exploration.
Keywords: 3D fields;Algorithms;Diagnostic Imaging;GPU Techniques;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;Interactive Visualization;Pattern Recognition, Automated;Reproducibility of Results;Scale Space;Sensitivity and Specificity;Transfer Functions;Volume Rendering;complex 3D images;complex data exploration;data visualisation;detection filters;image classification;image representation;image segmentation;interactive rates;maximum intensity projection;opacity;rendering (computer graphics);size-based transfer functions;transfer functions;transfer functions;volume exploration technique;
Author: Correa, C.; Kwan-Liu Ma

Year: 2008
Title: Direct Volume Editing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658154
Abstract: In this work we present basic methodology for interactive volume editing on GPUs, and we demonstrate the use of these methods to achieve a number of different effects. We present fast techniques to modify the appearance and structure of volumetric scalar fields given on Cartesian grids. Similar to 2D circular brushes as used in surface painting we present 3D spherical brushes for intuitive coloring of particular structures in such fields. This paint metaphor is extended to allow the user to change the data itself, and the use of this functionality for interactive structure isolation, hole filling, and artefact removal is demonstrated. Building on previous work in the field we introduce high-resolution selection volumes, which can be seen as a resolution-based focus+context metaphor. By utilizing such volumes we present a novel approach to interactive volume editing at sub-voxel accuracy. Finally, we introduce a fast technique to paste textures onto iso-surfaces in a 3D scalar field. Since the texture resolution is independent of the volume resolution, this technique allows structure-aligned textures containing appearance properties or textual information to be used for volume augmentation and annotation.
Keywords: 3D spherical brushes;Algorithms;Cartesian grids;Diagnostic Imaging;GPU;GPU;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface;Volume editing;annotations;artefact removal;carving;colour graphics;direct volume editing;hole filling;image colour analysis;image resolution;image texture;interactive structure isolation;interactive volume editing;paint metaphor;painting;rendering (computer graphics);surface painting;texture resolution;volume annotation;volume augmentation;volume resolution;
Author: Burger, K.; Kruger, J.; Westermann, R.

Year: 2008
Title: Smoke Surfaces: An Interactive Flow Visualization Technique Inspired by Real-World Flow Experiments
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658155
Abstract: Smoke rendering is a standard technique for flow visualization. Most approaches are based on a volumetric, particle based, or image based representation of the smoke. This paper introduces an alternative representation of smoke structures: as semi-transparent streak surfaces. In order to make streak surface integration fast enough for interactive applications, we avoid expensive adaptive retriangulations by coupling the opacity of the triangles to their shapes. This way, the surface shows a smoke-like look even in rather turbulent areas. Furthermore, we show modifications of the approach to mimic smoke nozzles, wool tufts, and time surfaces. The technique is applied to a number of test data sets.
Keywords: Index Terms&amp;#8212;Unsteady flow visualization;computational fluid dynamics;data visualisation;flow visualisation;interactive flow visualization;interactive systems;rendering (computer graphics);semitransparent streak surface;smoke;smoke rendering;smoke visualization.;streak surfaces;
Author: von Funck, W.; Weinkauf, T.; Theisel, H.; Seidel, H.-P.

Year: 2008
Title: Generation of Accurate Integral Surfaces in Time-Dependent Vector Fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658156
Abstract: We present a novel approach for the direct computation of integral surfaces in time-dependent vector fields. As opposed to previous work, which we analyze in detail, our approach is based on a separation of integral surface computation into two stages: surface approximation and generation of a graphical representation. This allows us to overcome several limitations of existing techniques. We first describe an algorithm for surface integration that approximates a series of time lines using iterative refinement and computes a skeleton of the integral surface. In a second step, we generate a well-conditioned triangulation. Our approach allows a highly accurate treatment of very large time-varying vector fields in an efficient, streaming fashion. We examine the properties of the presented methods on several example datasets and perform a numerical study of its correctness and accuracy. Finally, we investigate some visualization aspects of integral surfaces.
Keywords: 3D vector field visualization;Index Terms&amp;#8212;data visualisation;flow visualization;graphical representation;integral surfaces;iterative refinement;surface approximation;surface extraction;time-dependent vector fields;time-varying and time-series visualization;
Author: Garth, C.; Krishnan, H.; Tricoche, X.; Bobach, T.; Joy, K.I.

Year: 2008
Title: Visualizing Particle/Flow Structure Interactions in the Small Bronchial Tubes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658157
Abstract: Particle deposition in the small bronchial tubes (generations six through twelve) is strongly influenced by the vortex-dominated secondary flows that are induced by axial curvature of the tubes. In this paper, we employ particle destination maps in conjunction with two-dimensional, finite-time Lyapunov exponent maps to illustrate how the trajectories of finite-mass particles are influenced by the presence of vortices. We consider two three-generation bronchial tube models: a planar, asymmetric geometry and a non-planar, asymmetric geometry. Our visualizations demonstrate that these techniques, coupled with judiciously seeded particle trajectories, are effective tools for studying particle/flow structure interactions.
Keywords: Bronchi;Computer Graphics;Computer Simulation;FTLE;Humans;Index Terms&amp;#8212;Models, Biological;Particulate Matter;Pulmonary Ventilation;Rheology;User-Computer Interface;bronchial tube;bronchial tubes;data visualisation;finite-time Lyapunov exponent maps;flow visualisation;medical computing;particle deposition;particle destination maps;particle trajectory;particle/flow structure interaction visualization;visualization;vortex-dominated secondary flows;vortices;
Author: Soni, B.; Thompson, D.; Machiraju, R.

Year: 2008
Title: Interactive Visualization and Analysis of Transitional Flow
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658158
Abstract: A stand-alone visualization application has been developed by a multi-disciplinary, collaborative team with the sole purpose of creating an interactive exploration environment allowing turbulent flow researchers to experiment and validate hypotheses using visualization. This system has specific optimizations made in data management, caching computations, and visualization allowing for the interactive exploration of datasets on the order of 1TB in size. Using this application, the user (co-author Calo) is able to interactively visualize and analyze all regions of a transitional flow volume, including the laminar, transitional and fully turbulent regions. The underlying goal of the visualizations produced from these transitional flow simulations is to localize turbulent spots in the laminar region of the boundary layer, determine under which conditions they form, and follow their evolution. The initiation of turbulent spots, which ultimately lead to full turbulence, was located via a proposed feature detection condition and verified by experimental results. The conditions under which these turbulent spots form and coalesce are validated and presented.
Keywords: Applications of Visualization;Flow Visualization;Index Terms&amp;#8212;Transitional Flow;Turbulence;boundary layers;cache storage;caching computation;computational fluid dynamics;data management;data visualisation;feature detection;flow simulation;flow simulation;flow visualisation;interactive systems;interactive visualization;laminar flow;laminar flow;transitional flow analysis;turbulence;turbulent flow;
Author: Johnson, G.P.; Calo, V.M.; Gaither, K.P.

Year: 2008
Title: Continuous Scatterplots
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658159
Abstract: Scatterplots are well established means of visualizing discrete data values with two data variables as a collection of discrete points. We aim at generalizing the concept of scatterplots to the visualization of spatially continuous input data by a continuous and dense plot. An example of a continuous input field is data defined on an n-D spatial grid with respective interpolation or reconstruction of in-between values. We propose a rigorous, accurate, and generic mathematical model of continuous scatterplots that considers an arbitrary density defined on an input field on an n-D domain and that maps this density to m-D scatterplots. Special cases are derived from this generic model and discussed in detail: scatterplots where the n-D spatial domain and the m-D data attribute domain have identical dimension, 1-D scatterplots as a way to define continuous histograms, and 2-D scatterplots of data on 3-D spatial grids. We show how continuous histograms are related to traditional discrete histograms and to the histograms of isosurface statistics. Based on the mathematical model of continuous scatterplots, respective visualization algorithms are derived, in particular for 2-D scatterplots of data from 3-D tetrahedral grids. For several visualization tasks, we show the applicability of continuous scatterplots. Since continuous scatterplots do not only sample data at grid points but interpolate data values within cells, a dense and complete visualization of the data set is achieved that scales well with increasing data set size. Especially for irregular grids with varying cell size, improved results are obtained when compared to conventional scatterplots. Therefore, continuous scatterplots are a suitable extension of a statistics visualization technique to be applied to typical data from scientific computation.
Keywords: 3D tetrahedral grid;Index Terms&amp;#8212;Scatterplot;computational geometry;continuous frequency plot;continuous histogram;continuous scatterplot;data attribute domain;data variable;data visualisation;dense plot;discrete data value visualization;discrete point;generic mathematical model;histogram;interpolation;interpolation;interpolation;isosurface statistical histogram;spatial grid domain;statistical analysis;
Author: Bachthaler, S.; Weiskopf, D.

Year: 2008
Title: Extensions of Parallel Coordinates for Interactive Exploration of Large Multi-Timepoint Data Sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658160
Abstract: Parallel coordinate plots (PCPs) are commonly used in information visualization to provide insight into multi-variate data. These plots help to spot correlations between variables. PCPs have been successfully applied to unstructured datasets up to a few millions of points. In this paper, we present techniques to enhance the usability of PCPs for the exploration of large, multi-timepoint volumetric data sets, containing tens of millions of points per timestep. The main difficulties that arise when applying PCPs to large numbers of data points are visual clutter and slow performance, making interactive exploration infeasible. Moreover, the spatial context of the volumetric data is usually lost. We describe techniques for preprocessing using data quantization and compression, and for fast GPU-based rendering of PCPs using joint density distributions for each pair of consecutive variables, resulting in a smooth, continuous visualization. Also, fast brushing techniques are proposed for interactive data selection in multiple linked views, including a 3D spatial volume view. These techniques have been successfully applied to three large data sets: Hurricane Isabel (Vis'04 contest), the ionization front instability data set (Vis'08 design contest), and data from a large-eddy simulation of cumulus clouds. With these data, we show how PCPs can be extended to successfully visualize and interactively explore multi-timepoint volumetric datasets with an order of magnitude more data points.
Keywords: GPU-based rendering;Hurricane Isabel;Index Terms&amp;#8212;Parallel coordinate plots;cumulus clouds;data compression;data compression;data quantization;data visualisation;information visualization;ionization front instability data set;joint density distributions;large-eddy simulation;linked related views.;multi-field;multitimepoint volumetric data sets;parallel coordinate plots;rendering (computer graphics);statistical distributions;time-varying;
Author: Blaas, J.; Botha, C.P.; Post, F.H.

Year: 2008
Title: Vectorized Radviz and Its Application to Multiple Cluster Datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658161
Abstract: Radviz is a radial visualization with dimensions assigned to points called dimensional anchors (DAs) placed on the circumference of a circle. Records are assigned locations within the circle as a function of its relative attraction to each of the DAs. The DAs can be moved either interactively or algorithmically to reveal different meaningful patterns in the dataset. In this paper we describe Vectorized Radviz (VRV) which extends the number of dimensions through data flattening. We show how VRV increases the power of Radviz through these extra dimensions by enhancing the flexibility in the layout of the DAs. We apply VRV to the problem of analyzing the results of multiple clusterings of the same data set, called multiple cluster sets or cluster ensembles. We show how features of VRV help discern patterns across the multiple cluster sets. We use the Iris data set to explain VRV and a newt gene microarray data set used in studying limb regeneration to show its utility. We then discuss further applications of VRV.
Keywords: Cluster Ensembles;Clustering;Flattening Datasets;Index Terms&amp;#8212;Multiple Clustering;Radviz;Vectorized Radviz;Visualization;circle circumference;computational geometry;data cluster ensemble;data flattening;data visualisation;dimensional anchor;multiple cluster dataset;pattern clustering;vectorized radviz radial visualization;
Author: Sharko, J.; Grinstein, G.; Marx, K.A.

Year: 2008
Title: Effective Visualization of Short Routes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658162
Abstract: In this work we develop a new alternative to conventional maps for visualization of relatively short paths as they are frequently encountered in hotels, resorts or museums. Our approach is based on a warped rendering of a 3D model of the environment such that the visualized path appears to be straight even though it may contain several junctions. This has the advantage that the beholder of the image gains a realistic impression of the surroundings along the way which makes it easy to retrace the route in practice. We give an intuitive method for generation of such images and present results from user studies undertaken to evaluate the benefit of the warped images for orientation in unknown environments.
Keywords: 3D model;Index Terms&amp;#8212;Maps;Route visualization;Space deformation;cartography;data visualisation;map depiction;realistic image;realistic images;rendering (computer graphics);short route visualization;solid modelling;warped rendering;
Author: Degener, P.; Schnabel, R.; Schwartz, C.; Klein, R.

Year: 2008
Title: Brushing of Attribute Clouds for the Visualization of Multivariate Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658163
Abstract: The visualization and exploration of multivariate data is still a challenging task. Methods either try to visualize all variables simultaneously at each position using glyph-based approaches or use linked views for the interaction between attribute space and physical domain such as brushing of scatterplots. Most visualizations of the attribute space are either difficult to understand or suffer from visual clutter. We propose a transformation of the high-dimensional data in attribute space to 2D that results in a point cloud, called attribute cloud, such that points with similar multivariate attributes are located close to each other. The transformation is based on ideas from multivariate density estimation and manifold learning. The resulting attribute cloud is an easy to understand visualization of multivariate data in two dimensions. We explain several techniques to incorporate additional information into the attribute cloud, that help the user get a better understanding of multivariate data. Using different examples from fluid dynamics and climate simulation, we show how brushing can be used to explore the attribute cloud and find interesting structures in physical space.
Keywords: Index Terms&amp;#8212;Multivariate data;brushing;data transformation;data visualisation;high-dimensional data;linked views.;manifold learning;manifold learning;multivariate data visualization;multivariate density estimation;visual clutter;
Author: Janicke, H.; Bottinger, M.; Scheuermann, G.

Year: 2008
Title: Visualizing Temporal Patterns in Large Multivariate Data using Modified Globbing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658164
Abstract: Extracting and visualizing temporal patterns in large scientific data is an open problem in visualization research. First, there are few proven methods to flexibly and concisely define general temporal patterns for visualization. Second, with large time-dependent data sets, as typical with todaypsilas large-scale simulations, scalable and general solutions for handling the data are still not widely available. In this work, we have developed a textual pattern matching approach for specifying and identifying general temporal patterns. Besides defining the formalism of the language, we also provide a working implementation with sufficient efficiency and scalability to handle large data sets. Using recent large-scale simulation data from multiple application domains, we demonstrate that our visualization approach is one of the first to empower a concept driven exploration of large-scale time-varying multivariate data.
Keywords: Index Terms&amp;#8212;Multivariate visualization;Time-varying;Uncertainty;data visualisation;large multivariate data visualization;large scientific data;large time-dependent data set;pattern matching;temporal pattern extraction;temporal pattern visualization;textual pattern matching;
Author: Glatter, M.; Jian Huang; Ahern, S.; Daniel, J.; Aidong Lu

Year: 2008
Title: Interactive Comparison of Scalar Fields Based on Largest Contours with Applications to Flow Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658165
Abstract: Understanding fluid flow data, especially vortices, is still a challenging task. Sophisticated visualization tools help to gain insight. In this paper, we present a novel approach for the interactive comparison of scalar fields using isosurfaces, and its application to fluid flow datasets. Features in two scalar fields are defined by largest contour segmentation after topological simplification. These features are matched using a volumetric similarity measure based on spatial overlap of individual features. The relationships defined by this similarity measure are ranked and presented in a thumbnail gallery of feature pairs and a graph representation showing all relationships between individual contours. Additionally, linked views of the contour trees are provided to ease navigation. The main render view shows the selected features overlapping each other. Thus, by displaying individual features and their relationships in a structured fashion, we enable exploratory visualization of correlations between similar structures in two scalar fields. We demonstrate the utility of our approach by applying it to a number of complex fluid flow datasets, where the emphasis is put on the comparison of vortex related scalar quantities.
Keywords: Index Terms&amp;#8212;Scalar topology;comparative visualization;complex fluid flow datasets;computer graphics;contour segmentation;contour tree;contour trees;edge detection;flow visualisation;flow visualization;flow visualization;largest contours;scalar fields;topological simplification;volumetric similarity measure;
Author: Schneider, D.; Wiebel, A.; Carr, H.; Hlawitschka, M.; Scheuermann, G.

Year: 2008
Title: Surface Extraction from Multi-field Particle Volume Data Using Multi-dimensional Cluster Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658166
Abstract: Data sets resulting from physical simulations typically contain a multitude of physical variables. It is, therefore, desirable that visualization methods take into account the entire multi-field volume data rather than concentrating on one variable. We present a visualization approach based on surface extraction from multi-field particle volume data. The surfaces segment the data with respect to the underlying multi-variate function. Decisions on segmentation properties are based on the analysis of the multi-dimensional feature space. The feature space exploration is performed by an automated multi-dimensional hierarchical clustering method, whose resulting density clusters are shown in the form of density level sets in a 3D star coordinate layout. In the star coordinate layout, the user can select clusters of interest. A selected cluster in feature space corresponds to a segmenting surface in object space. Based on the segmentation property induced by the cluster membership, we extract a surface from the volume data. Our driving applications are smoothed particle hydrodynamics (SPH) simulations, where each particle carries multiple properties. The data sets are given in the form of unstructured point-based volume data. We directly extract our surfaces from such data without prior resampling or grid generation. The surface extraction computes individual points on the surface, which is supported by an efficient neighborhood computation. The extracted surface points are rendered using point-based rendering operations. Our approach combines methods in scientific visualization for object-space operations with methods in information visualization for feature-space operations.
Keywords: 3D star coordinate layout;Index Terms&amp;#8212;Multi-field and multi-variate visualization;astronomy computing;astrophysical simulation;automated multidimensional hierarchical clustering method;data visualisation;feature extraction;information visualization;isosurfaces and surface extraction;multidimensional cluster visualization;multidimensional feature space exploration;multifield particle volume data visualization;multivariate function;object-space operation;particle simulations.;pattern clustering;point-based rendering;point-based visualization;rendering (computer graphics);scientific visualization;smoothed particle hydrodynamic simulation;star coordinates;surface extraction;surface segmentation;visualization in astrophysics;
Author: Linsen, L.; Van Long, T.; Rosenthal, P.; Rosswog, S.

Year: 2008
Title: Sinus Endoscopy - Application of Advanced GPU Volume Rendering for Virtual Endoscopy
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658167
Abstract: For difficult cases in endoscopic sinus surgery, a careful planning of the intervention is necessary. Due to the reduced field of view during the intervention, the surgeons have less information about the surrounding structures in the working area compared to open surgery. Virtual endoscopy enables the visualization of the operating field and additional information, such as risk structures (e.g., optical nerve and skull base) and target structures to be removed (e.g., mucosal swelling). The Sinus Endoscopy system provides the functional range of a virtual endoscopic system with special focus on a realistic representation. Furthermore, by using direct volume rendering, we avoid time-consuming segmentation steps for the use of individual patient datasets. However, the image quality of the endoscopic view can be adjusted in a way that a standard computer with a modern standard graphics card achieves interactive frame rates with low CPU utilization. Thereby, characteristics of the endoscopic view are systematically used for the optimization of the volume rendering speed. The system design was based on a careful analysis of the endoscopic sinus surgery and the resulting needs for computer support. As a small standalone application it can be instantly used for surgical planning and patient education. First results of a clinical evaluation with ENT surgeons were employed to fine-tune the user interface, in particular to reduce the number of controls by using appropriate default values wherever possible. The system was used for preoperative planning in 102 cases, provides useful information for intervention planning (e.g., anatomic variations of the Rec. Frontalis), and closely resembles the intraoperative situation.
Keywords: Algorithms;ENT surgeons;Endoscopy;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;Paranasal Sinuses;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Surgery, Computer-Assisted;Tomography, X-Ray Computed;advanced GPU volume rendering;data visualisation;endoscopes;endoscopic sinus surgery;graphical processing unit;image quality;individual patient datasets;medical image processing;medical visualization;operationplanning;rendering (computer graphics);risk structures;sinus endoscopy system;sinus surgery;surgery;virtual endoscopic system;virtual endoscopy;virtual reality;volume rendering;
Author: Kruger, A.; Kubisch, C.; Strauss, G.; Preim, B.

Year: 2008
Title: Glyph-Based SPECT Visualization for the Diagnosis of Coronary Artery Disease
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658168
Abstract: Myocardial perfusion imaging with single photon emission computed tomography (SPECT) is an established method for the detection and evaluation of coronary artery disease (CAD). State-of-the-art SPECT scanners yield a large number of regional parameters of the left-ventricular myocardium (e.g., blood supply at rest and during stress, wall thickness, and wall thickening during heart contraction) that all need to be assessed by the physician. Today, the individual parameters of this multivariate data set are displayed as stacks of 2D slices, bull's eye plots, or, more recently, surfaces in 3D, which depict the left-ventricular wall. In all these visualizations, the data sets are displayed side-by-side rather than in an integrated manner, such that the multivariate data have to be examined sequentially and need to be fused mentally. This is time consuming and error-prone. In this paper we present an interactive 3D glyph visualization, which enables an effective integrated visualization of the multivariate data. Results from semiotic theory are used to optimize the mapping of different variables to glyph properties. This facilitates an improved perception of important information and thus an accelerated diagnosis. The 3D glyphs are linked to the established 2D views, which permit a more detailed inspection, and to relevant meta-information such as known stenoses of coronary vessels supplying the myocardial region. Our method has demonstrated its potential for clinical routine use in real application scenarios assessed by nuclear physicians.
Keywords: 3D glyph visualization;Algorithms;Artificial Intelligence;Computer Graphics;Coronary Artery Disease;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;Multivariate visualization;Pattern Recognition, Automated;Reproducibility of Results;SPECT;Sensitivity and Specificity;Tomography, Emission-Computed, Single-Photon;User-Computer Interface;Ventricular Dysfunction, Left;cardiology;coronary artery disease;coronary vessels stenoses;data visualisation;diseases;glyph techniques;glyph-based SPECT visualization;left-ventricular myocardium;medical image processing;multivariate data set;myocardial perfusion imaging;myocardial perfusion imaging;single photon emission computed tomography;single photon emission computed tomography;
Author: Meyer-Spradow, J.; Stegger, L.; Doring, C.; Ropinski, T.; Hinrichs, K.

Year: 2008
Title: Interactive Volume Exploration for Feature Detection and Quantification in Industrial CT Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658169
Abstract: This paper presents a novel method for interactive exploration of industrial CT volumes such as cast metal parts, with the goal of interactively detecting, classifying, and quantifying features using a visualization-driven approach. The standard approach for defect detection builds on region growing, which requires manually tuning parameters such as target ranges for density and size, variance, as well as the specification of seed points. If the results are not satisfactory, region growing must be performed again with different parameters. In contrast, our method allows interactive exploration of the parameter space, completely separated from region growing in an unattended pre-processing stage. The pre-computed feature volume tracks a feature size curve for each voxel over time, which is identified with the main region growing parameter such as variance. A novel 3D transfer function domain over (density, feature.size, time) allows for interactive exploration of feature classes. Features and feature size curves can also be explored individually, which helps with transfer function specification and allows coloring individual features and disabling features resulting from CT artifacts. Based on the classification obtained through exploration, the classified features can be quantified immediately.
Keywords: 3D transfer function;Algorithms;Computer Graphics;Equipment Failure Analysis;Imaging, Three-Dimensional;Index Terms&amp;#8212;Industry;Materials Testing;Multi-Dimensional Transfer Functions;Non-Destructive Testing;Pattern Recognition, Automated;Region Growing;Tomography, X-Ray Computed;User-Computer Interface;Volume Rendering;cast metal part;computerised tomography;data visualisation;defect detection;engineering graphics;feature classification;feature detection;feature extraction;flaw detection;image classification;inspection;interactive industrial CT volume exploration;nondestructive testing;production engineering computing;region growing;rendering (computer graphics);visualization-driven approach;volume rendering;
Author: Hadwiger, M.; Laura, F.; Rezk-Salama, C.; Hollt, T.; Geier, G.; Pabel, T.

Year: 2008
Title: Interactive Blood Damage Analysis for Ventricular Assist Devices
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658170
Abstract: Ventricular Assist Devices (VADs) support the heart in its vital task of maintaining circulation in the human body when the heart alone is not able to maintain a sufficient flow rate due to illness or degenerative diseases. However, the engineering of these devices is a highly demanding task. Advanced modeling methods and computer simulations allow the investigation of the fluid flow inside such a device and in particular of potential blood damage. In this paper we present a set of visualization methods which have been designed to specifically support the analysis of a tensor-based blood damage prediction model. This model is based on the tracing of particles through the VAD, for each of which the cumulative blood damage can be computed. The model's tensor output approximates a single blood cell's deformation in the flow field. The tensor and derived scalar data are subsequently visualized using techniques based on icons, particle visualization, and function plotting. All these techniques are accessible through a Virtual Reality-based user interface, which features not only stereoscopic rendering but also natural interaction with the complex three-dimensional data. To illustrate the effectiveness of these visualization methods, we present the results of an analysis session that was performed by domain experts for a specific data set for the MicroMed DeBakey VAD.
Keywords: Computer Graphics;Computer Simulation;Equipment Design;Equipment Failure Analysis;Erythrocytes;Heart-Assist Devices;Hemolysis;Humans;Index Terms&amp;#8212;Models, Cardiovascular;Tensor visualization;User-Computer Interface;blood cell deformation;blood damage;blood vessels;cardiovascular system;cellular biophysics;data visualisation;degenerative disease;fluid flow;function plotting;illness;interactive blood damage analysis;medical computing;orthotics;particle tracing;particle visualization;scalar data visualization method;tensor-based blood damage prediction model;tensors;time-dependent data;user interfaces;ventricular assist device;ventricular assist device;virtual reality;virtual reality;virtual reality-based user interface;
Author: Hentschel, B.; Tedjo, I.; Probst, M.; Wolter, M.; Behr, M.; Bischof, C.; Kuhlen, T.

Year: 2008
Title: Box Spline Reconstruction On The Face-Centered Cubic Lattice
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658171
Abstract: We introduce and analyze an efficient reconstruction algorithm for FCC-sampled data. The reconstruction is based on the 6-direction box spline that is naturally associated with the FCC lattice and shares the continuity and approximation order of the triquadratic B-spline. We observe less aliasing for generic level sets and derive special techniques to attain the higher evaluation efficiency promised by the lower degree and smaller stencil-size of the C1 6-direction box spline over the triquadratic B-spline.
Keywords: 6-direction box spline reconstruction algorithm;Face-Centered Cubic lattice;Index Terms&amp;#8212;approximation theory;box spline;computational geometry;data visualisation;face-centered cubic lattice;face-centered cubic sampled data;image reconstruction;image sampling;splines (mathematics);triquadratic B-spline approximation order;volumetric data reconstruction;volumetric data visualization;
Author: Minho Kim; Entezari, A.; Peters, J.

Year: 2008
Title: Smooth Surface Extraction from Unstructured Point-based Volume Data Using PDEs
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658172
Abstract: Smooth surface extraction using partial differential equations (PDEs) is a well-known and widely used technique for visualizing volume data. Existing approaches operate on gridded data and mainly on regular structured grids. When considering unstructured point-based volume data where sample points do not form regular patterns nor are they connected in any form, one would typically resample the data over a grid prior to applying the known PDE-based methods. We propose an approach that directly extracts smooth surfaces from unstructured point-based volume data without prior resampling or mesh generation. When operating on unstructured data one needs to quickly derive neighborhood information. The respective information is retrieved by partitioning the 3D domain into cells using a fed-tree and operating on its cells. We exploit neighborhood information to estimate gradients and mean curvature at every sample point using a four-dimensional least-squares fitting approach. Gradients and mean curvature are required for applying the chosen PDE-based method that combines hyperbolic advection to an isovalue of a given scalar field and mean curvature flow. Since we are using an explicit time-integration scheme, time steps and neighbor locations are bounded to ensure convergence of the process. To avoid small global time steps, one can use asynchronous local integration. We extract a smooth surface by successively fitting a smooth auxiliary function to the data set. This auxiliary function is initialized as a signed distance function. For each sample and for every time step we compute the respective gradient, the mean curvature, and a stable time step. With these informations the auxiliary function is manipulated using an explicit Euler time integration. The process successively continues with the next sample point in time. If the norm of the auxiliary function gradient in a sample exceeds a given threshold at some time, the auxiliary function is reinitialized to a signed dista--nce function. After convergence of the evolvution, the resulting smooth surface is obtained by extracting the zero isosurface from the auxiliary function using direct isosurface extraction from unstructured point-based volume data and rendering the extracted surface using point-based rendering methods.
Keywords: Algorithms;Artificial Intelligence;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;PDE;PDEs;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;auxiliary function;convergence;convergence of numerical methods;data visualisation;explicit Euler time integration;feature extraction;four-dimensional least-squares fitting;gradient estimation;gradient methods;least squares approximations;level sets;mean curvature;partial differential equation;partial differential equations;point-based rendering;point-based visualization;regular structured grid;rendering (computer graphics);scalar field;signed distance function;smooth surface extraction;surface extraction;surface fitting;unstructured point-based volume data visualization;
Author: Rosenthal, P.; Linsen, L.

Year: 2008
Title: Particle-based Sampling and Meshing of Surfaces in Multimaterial Volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658173
Abstract: Methods that faithfully and robustly capture the geometry of complex material interfaces in labeled volume data are important for generating realistic and accurate visualizations and simulations of real-world objects. The generation of such multimaterial models from measured data poses two unique challenges: first, the surfaces must be well-sampled with regular, efficient tessellations that are consistent across material boundaries; and second, the resulting meshes must respect the nonmanifold geometry of the multimaterial interfaces. This paper proposes a strategy for sampling and meshing multimaterial volumes using dynamic particle systems, including a novel, differentiable representation of the material junctions that allows the particle system to explicitly sample corners, edges, and surfaces of material intersections. The distributions of particles are controlled by fundamental sampling constraints, allowing Delaunay-based meshing algorithms to reliably extract watertight meshes of consistently high-quality.
Keywords: Delaunay-based meshing algorithms;Index Terms&amp;#8212;Sampling;computational geometry;data visualisation;labeled volume data;material intersections;mathematics computing;mesh generation;meshing;multimaterial volumes;nonmanifold geometry;particle-based sampling;sampling methods;visualizations;
Author: Meyer, M.; Whitaker, R.; Kirby, R.M.; Ledergerber, C.; Pfister, H.

Year: 2008
Title: Importance-Driven Time-Varying Data Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658174
Abstract: The ability to identify and present the most essential aspects of time-varying data is critically important in many areas of science and engineering. This paper introduces an importance-driven approach to time-varying volume data visualization for enhancing that ability. By conducting a block-wise analysis of the data in the joint feature-temporal space, we derive an importance curve for each data block based on the formulation of conditional entropy from information theory. Each curve characterizes the local temporal behavior of the respective block, and clustering the importance curves of all the volume blocks effectively classifies the underlying data. Based on different temporal trends exhibited by importance curves and their clustering results, we suggest several interesting and effective visualization techniques to reveal the important aspects of time-varying data.
Keywords: Index Terms&amp;#8212;Time-varying data;block-wise analysis;clustering;conditional entropy;conditional entropy;data visualisation;entropy;feature-temporal space;highlighting;importance-driven time-varying volume data visualization;information theory;joint feature-temporal space;pattern classification;pattern clustering;transfer function.;
Author: Chaoli Wang; Hongfeng Yu; Kwan-Liu Ma

Year: 2008
Title: Visualizing Multiwavelength Astrophysical Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658175
Abstract: With recent advances in the measurement technology for allsky astrophysical imaging, our view of the sky is no longer limited to the tiny visible spectral range over the 2D Celestial sphere. We now can access a third dimension corresponding to a broad electromagnetic spectrum with a wide range of allsky surveys; these surveys span frequency bands including long long wavelength radio, microwaves, very short X-rays, and gamma rays. These advances motivate us to study and examine multiwavelength visualization techniques to maximize our capabilities to visualize and exploit these informative image data sets. In this work, we begin with the processing of the data themselves, uniformizing the representations and units of raw data obtained from varied detector sources. Then we apply tools to map, convert, color-code, and format the multiwavelength data in forms useful for applications. We explore different visual representations for displaying the data, including such methods as textured image stacks, the horseshoe representation, and GPU-based volume visualization. A family of visual tools and analysis methods are introduced to explore the data, including interactive data mapping on the graphics processing unit (GPU), the mini-map explorer, and GPU-based interactive feature analysis.
Keywords: 2D celestial sphere;Astrophysical visualization;GPU-based interactive feature analysis;GPU-based volume visualization;Index Terms&amp;#8212;allsky astrophysical imaging;astronomical image processing;astronomy;broad electromagnetic spectrum;data processing;data visualisation;graphics processing unit;horseshoe representation;mini-map explorer;multiwavelength astrophysical data visualization;multiwavelength data;multiwavelength visualization techniques;textured image stacks;
Author: Hongwei Li; Chi-Wing Fu; Hanson, A.

Year: 2008
Title: Visiting the G&#x0F6;del Universe
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658176
Abstract: Visualization of general relativity illustrates aspects of Einstein's insights into the curved nature of space and time to the expert as well as the layperson. One of the most interesting models which came up with Einstein's theory was developed by Kurt Godel in 1949. The Godel universe is a valid solution of Einstein's field equations, making it a possible physical description of our universe. It offers remarkable features like the existence of an optical horizon beyond which time travel is possible. Although we know that our universe is not a Godel universe, it is interesting to visualize physical aspects of a world model resulting from a theory which is highly confirmed in scientific history. Standard techniques to adopt an egocentric point of view in a relativistic world model have shortcomings with respect to the time needed to render an image as well as difficulties in applying a direct illumination model. In this paper we want to face both issues to reduce the gap between common visualization standards and relativistic visualization. We will introduce two techniques to speed up recalculation of images by means of preprocessing and lookup tables and to increase image quality through a special optimization applicable to the Godel universe. The first technique allows the physicist to understand the different effects of general relativity faster and better by generating images from existing datasets interactively. By using the intrinsic symmetries of Godel's spacetime which are expressed by the Killing vector field, we are able to reduce the necessary calculations to simple cases using the second technique. This even makes it feasible to account for a direct illumination model during the rendering process. Although the presented methods are applied to Godel's universe, they can also be extended to other manifolds, for example light propagation in moving dielectric media. Therefore, other areas of research can benefit from these generic improvements.
Keywords: Einstein field equations;G&#x0F6;del universe;General relativity;Godel universe;Index Terms&amp;#8212;data visualisation;general relativity;general relativity;image quality;nonlinear ray tracing;physics computing;relativistic visualization;relativistic world model;rendering (computer graphics);rendering process;space-time configurations;time travel.;
Author: Grave, F.; Buser, M.

Year: 2008
Title: The Seismic Analyzer: Interpreting and Illustrating 2D Seismic Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658177
Abstract: We present a toolbox for quickly interpreting and illustrating 2D slices of seismic volumetric reflection data. Searching for oil and gas involves creating a structural overview of seismic reflection data to identify hydrocarbon reservoirs. We improve the search of seismic structures by precalculating the horizon structures of the seismic data prior to interpretation. We improve the annotation of seismic structures by applying novel illustrative rendering algorithms tailored to seismic data, such as deformed texturing and line and texture transfer functions. The illustrative rendering results in multi-attribute and scale invariant visualizations where features are represented clearly in both highly zoomed in and zoomed out views. Thumbnail views in combination with interactive appearance control allows for a quick overview of the data before detailed interpretation takes place. These techniques help reduce the work of seismic illustrators and interpreters.
Keywords: 2D seismic data;Illustrative rendering;Index Terms&amp;#8212;Seismic attributes;Seismic interpretation;Top-down interpretation;data visualisation;hydrocarbon reservoirs;oil technology;rendering algorithms;seismic analyzer;seismic illustrators;seismic interpreters;seismic structures;seismic volumetric reflection data;seismology;texture transfer functions;
Author: Patel, D.; Giertsen, C.; Thurmond, J.; Gjelberg, J.; Grller, E.

Year: 2008
Title: Hypothesis Generation in Climate Research with Interactive Visual Data Exploration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658178
Abstract: One of the most prominent topics in climate research is the investigation, detection, and allocation of climate change. In this paper, we aim at identifying regions in the atmosphere (e.g., certain height layers) which can act as sensitive and robust indicators for climate change. We demonstrate how interactive visual data exploration of large amounts of multi-variate and time-dependent climate data enables the steered generation of promising hypotheses for subsequent statistical evaluation. The use of new visualization and interaction technology-in the context of a coordinated multiple views framework-allows not only to identify these promising hypotheses, but also to efficiently narrow down parameters that are required in the process of computational data analysis. Two datasets, namely an ECHAM5 climate model run and the ERA-40 reanalysis incorporating observational data, are investigated. Higher-order information such as linear trends or signal-to-noise ratio is derived and interactively explored in order to detect and explore those regions which react most sensitively to climate change. As one conclusion from this study, we identify an excellent potential for usefully generalizing our approach to other, similar application cases, as well.
Keywords: ECHAM5 climate model;ERA-40 reanalysis;Index Terms&amp;#8212;climate change;climate research;climatology;computational data analysis;data analysis;geophysics computing;hypothesis generation;interactive visual data exploration;interactive visual exploration and analysis;interactive visual hypothesis generation;subsequent statistical evaluation;visualization for climate research.;
Author: Kehrer, J.; Ladstadter, F.; Muigg, P.; Doleisch, H.; Steiner, A.; Hauser, H.

Year: 2008
Title: Novel interaction techniques for neurosurgical planning and stereotactic navigation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658179
Abstract: Neurosurgical planning and image guided neurosurgery require the visualization of multimodal data obtained from various functional and structural image modalities, such as magnetic resonance imaging (MRI), computed tomography (CT), functional MRI, Single photon emission computed tomography (SPECT) and so on. In the case of epilepsy neurosurgery for example, these images are used to identify brain regions to guide intracranial electrode implantation and resection. Generally, such data is visualized using 2D slices and in some cases using a 3D volume rendering along with the functional imaging results. Visualizing the activation region effectively by still preserving sufficient surrounding brain regions for context is exceedingly important to neurologists and surgeons. We present novel interaction techniques for visualization of multimodal data to facilitate improved exploration and planning for neurosurgery. We extended the line widget from VTK to allow surgeons to control the shape of the region of the brain that they can visually crop away during exploration and surgery. We allow simple spherical, cubical, ellipsoidal and cylindrical (probe aligned cuts) for exploration purposes. In addition we integrate the cropping tool with the image-guided navigation system used for epilepsy neurosurgery. We are currently investigating the use of these new tools in surgical planning and based on further feedback from our neurosurgeons we will integrate them into the setup used for image-guided neurosurgery.
Keywords: 3D volume rendering;Computer Graphics;Computer Simulation;Humans;Imaging, Three-Dimensional;Index Terms&amp;#8212;Irregular cropping;Models, Neurological;Multimodal visualization;Stereotaxic Techniques;Surgery, Computer-Assisted;User interaction;User-Computer Interface;data visualisation;functional MRI;image guided neurosurgery;image-guided neurosurgery;magnetic resonance imaging;medical computing;multimodal data visualization;neurosurgeons;neurosurgical planning;rendering (computer graphics);single photon emission computed tomography;stereotactic navigation;structural image modalities;surgery;
Author: Joshi, A.; Scheinost, D.; Vives, K.; Spencer, D.; Staib, L.; Papademetris, X.

Year: 2008
Title: Visualization of Myocardial Perfusion Derived from Coronary Anatomy
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658180
Abstract: Visually assessing the effect of the coronary artery anatomy on the perfusion of the heart muscle in patients with coronary artery disease remains a challenging task. We explore the feasibility of visualizing this effect on perfusion using a numerical approach. We perform a computational simulation of the way blood is perfused throughout the myocardium purely based on information from a three-dimensional anatomical tomographic scan. The results are subsequently visualized using both three-dimensional visualizations and bullpsilas eye plots, partially inspired by approaches currently common in medical practice. Our approach results in a comprehensive visualization of the coronary anatomy that compares well to visualizations commonly used for other scanning technologies. We demonstrate techniques giving detailed insight in blood supply, coronary territories and feeding coronary arteries of a selected region. We demonstrate the advantages of our approach through visualizations that show information which commonly cannot be directly observed in scanning data, such as a separate visualization of the supply from each coronary artery. We thus show that the results of a computational simulation can be effectively visualized and facilitate visually correlating these results to for example perfusion data.
Keywords: 3D anatomical tomographic scan;Blood Flow Velocity;Cardiac visualization;Computer Graphics;Computer Simulation;Coronary Artery Disease;Coronary Circulation;Coronary Vessels;Humans;Index Terms&amp;#8212;Models, Cardiovascular;User-Computer Interface;blood;blood supply;cardiology;coronary anatomy;coronary artery anatomy;coronary artery disease;coronary artery territories;data visualisation;diseases;heart muscle;medical diagnostic computing;myocardial perfusion;myocardial perfusion visualization;
Author: Termeer, M.; Bescos, J.O.; Breeuwer, M.; Vilanova, A.; Gerritsen, F.; Groller, M.E.; Nagel, E.

Year: 2008
Title: Effective visualization of complex vascular structures using a non-parametric vessel detection method
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658181
Abstract: The effective visualization of vascular structures is critical for diagnosis, surgical planning as well as treatment evaluation. In recent work, we have developed an algorithm for vessel detection that examines the intensity profile around each voxel in an angiographic image and determines the likelihood that any given voxel belongs to a vessel; we term this the "vesselness coefficient" of the voxel. Our results show that our algorithm works particularly well for visualizing branch points in vessels. Compared to standard Hessian based techniques, which are fine-tuned to identify long cylindrical structures, our technique identifies branches and connections with other vessels. Using our computed vesselness coefficient, we explore a set of techniques for visualizing vasculature. Visualizing vessels is particularly challenging because not only is their position in space important for clinicians but it is also important to be able to resolve their spatial relationship. We applied visualization techniques that provide shape cues as well as depth cues to allow the viewer to differentiate between vessels that are closer from those that are farther. We use our computed vesselness coefficient to effectively visualize vasculature in both clinical neurovascular x-ray computed tomography based angiography images, as well as images from three different animal studies. We conducted a formal user evaluation of our visualization techniques with the help of radiologists, surgeons, and other expert users. Results indicate that experts preferred distance color blending and tone shading for conveying depth over standard visualization techniques.
Keywords: Algorithms;Angiography;Artificial Intelligence;Evaluation of visualization techniques;Hessian based techniques;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Vessel identification;Vessel visualization;angiographic image;angiography images;clinical neurovascular x-ray computed tomography;complex vascular structures visualization;computer vision;computerised tomography;cylindrical structures;data visualisation;medical image processing;nonparametric vessel detection method;surgical planning;vessel detection;
Author: Joshi, A.; Xiaoning Qian; Dione, D.; Bulsara, K.; Breuer, C.; Sinusas, A.; Papademetris, X.

Year: 2008
Title: Visualization of Cellular and Microvascular Relationships
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658182
Abstract: Understanding the structure of microvasculature structures and their relationship to cells in biological tissue is an important and complex problem. Brain microvasculature in particular is known to play an important role in chronic diseases. However, these networks are only visible at the microscopic level and can span large volumes of tissue. Due to recent advances in microscopy, large volumes of data can be imaged at the resolution necessary to reconstruct these structures. Due to the dense and complex nature of microscopy data sets, it is important to limit the amount of information displayed. In this paper, we describe methods for encoding the unique structure of microvascular data, allowing researchers to selectively explore microvascular anatomy. We also identify the queries most useful to researchers studying microvascular and cellular relationships. By associating cellular structures with our microvascular framework, we allow researchers to explore interesting anatomical relationships in dense and complex data sets.
Keywords: Algorithms;Blood Vessels;Cell Physiological Phenomena;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Index Terms&amp;#8212;Microcirculation;Microscopy;Models, Biological;Reproducibility of Results;Sensitivity and Specificity;biological tissue;biology computing;cells;cellular biophysics;cellular structures;chronic diseases;complex data;data visualisation;fibers;microscopy;microvascular anatomy;microvasculature structures;vascular;
Author: Mayerich, D.M.; Abbott, L.; Keyser, J.

Year: 2008
Title: A Practical Approach to Morse-Smale Complex Computation: Scalability and Generality
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658183
Abstract: The Morse-Smale (MS) complex has proven to be a useful tool in extracting and visualizing features from scalar-valued data. However, efficient computation of the MS complex for large scale data remains a challenging problem. We describe a new algorithm and easily extensible framework for computing MS complexes for large scale data of any dimension where scalar values are given at the vertices of a closure-finite and weak topology (CW) complex, therefore enabling computation on a wide variety of meshes such as regular grids, simplicial meshes, and adaptive multiresolution (AMR) meshes. A new divide-and-conquer strategy allows for memory-efficient computation of the MS complex and simplification on-the-fly to control the size of the output. In addition to being able to handle various data formats, the framework supports implementation-specific optimizations, for example, for regular data. We present the complete characterization of critical point cancellations in all dimensions. This technique enables the topology based analysis of large data on off-the-shelf computers. In particular we demonstrate the first full computation of the MS complex for a 1 billion/1024<sup>3</sup> node grid on a laptop computer with 2 Gb memory.
Keywords: Index Terms&amp;#8212;Morse-Smale complex;Morse-Smale complex computation;Topology-based analysis;critical point cancellations;data visualisation;divide and conquer methods;divide-and-conquer strategy;large scale data.;scalar-valued data;weak topology complex;
Author: Gyulassy, A.; Bremer, P.-T.; Hamann, B.; Pascucci, V.

Year: 2008
Title: Invariant Crease Lines for Topological and Structural Analysis of Tensor Fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658184
Abstract: We introduce a versatile framework for characterizing and extracting salient structures in three-dimensional symmetric second-order tensor fields. The key insight is that degenerate lines in tensor fields, as defined by the standard topological approach, are exactly crease (ridge and valley) lines of a particular tensor invariant called mode. This reformulation allows us to apply well-studied approaches from scientific visualization or computer vision to the extraction of topological lines in tensor fields. More generally, this main result suggests that other tensor invariants, such as anisotropy measures like fractional anisotropy (FA), can be used in the same framework in lieu of mode to identify important structural properties in tensor fields. Our implementation addresses the specific challenge posed by the non-linearity of the considered scalar measures and by the smoothness requirement of the crease manifold computation. We use a combination of smooth reconstruction kernels and adaptive refinement strategy that automatically adjust the resolution of the analysis to the spatial variation of the considered quantities. Together, these improvements allow for the robust application of existing ridge line extraction algorithms in the tensor context of our problem. Results are proposed for a diffusion tensor MRI dataset, and for a benchmark stress tensor field used in engineering research.
Keywords: Index Terms&amp;#8212;Tensor &amp;#64257;adaptive refinement strategy;crease extraction;data visualisation;elds;fractional anisotropy;ridge line extraction algorithms;ridge lines;smooth reconstruction kernels;structural analysis;structural analysis;tensor invariants;three-dimensional symmetric second-order tensor fields;topological analysis;topology;
Author: Tricoche, X.; Kindlmann, G.; Westin, C.-F.

Year: 2008
Title: Estimating Crossing Fibers: A Tensor Decomposition Approach
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658185
Abstract: Diffusion weighted magnetic resonance imaging is a unique tool for non-invasive investigation of major nerve fiber tracts. Since the popular diffusion tensor (DT-MRI) model is limited to voxels with a single fiber direction, a number of high angular resolution techniques have been proposed to provide information about more diverse fiber distributions. Two such approaches are Q-Ball imaging and spherical deconvolution, which produce orientation distribution functions (ODFs) on the sphere. For analysis and visualization, the maxima of these functions have been used as principal directions, even though the results are known to be biased in case of crossing fiber tracts. In this paper, we present a more reliable technique for extracting discrete orientations from continuous ODFs, which is based on decomposing their higher-order tensor representation into an isotropic component, several rank-1 terms, and a small residual. Comparing to ground truth in synthetic data shows that the novel method reduces bias and reliably reconstructs crossing fibers which are not resolved as individual maxima in the ODF We present results on both Q-Ball and spherical deconvolution data and demonstrate that the estimated directions allow for plausible fiber tracking in a real data set.
Keywords: Algorithms;Artificial Intelligence;Brain;DT-MRI;DW-MRI;Diffusion Magnetic Resonance Imaging;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Index Terms&amp;#8212;Nerve Fibers, Myelinated;Pattern Recognition, Automated;Q-Ball;Q-Ball imaging;Sensitivity and Specificity;biomedical MRI;crossing fiber estimation;data analysis;data analysis;data visualisation;data visualization;deconvolution;diffusion weighted magnetic resonance imaging;diverse fiber distribution;fiber tracking;high angular image resolution technique;higher-order tensor;image representation;image resolution;medical image processing;nerve fiber tract;neurophysiology;orientation distribution function;sphere;spherical deconvolution;spherical deconvolution;tensor decomposition approach;tensor decomposition.;tensor representation;tensors;voxel;
Author: Schultz, T.; Seidel, H.-P.

Year: 2008
Title: Geodesic Distance-weighted Shape Vector Image Diffusion
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658186
Abstract: This paper presents a novel and efficient surface matching and visualization framework through the geodesic distance-weighted shape vector image diffusion. Based on conformal geometry, our approach can uniquely map a 3D surface to a canonical rectangular domain and encode the shape characteristics (e.g., mean curvatures and conformal factors) of the surface in the 2D domain to construct a geodesic distance-weighted shape vector image, where the distances between sampling pixels are not uniform but the actual geodesic distances on the manifold. Through the novel geodesic distance-weighted shape vector image diffusion presented in this paper, we can create a multiscale diffusion space, in which the cross-scale extrema can be detected as the robust geometric features for the matching and registration of surfaces. Therefore, statistical analysis and visualization of surface properties across subjects become readily available. The experiments on scanned surface models show that our method is very robust for feature extraction and surface matching even under noise and resolution change. We have also applied the framework on the real 3D human neocortical surfaces, and demonstrated the excellent performance of our approach in statistical analysis and integrated visualization of the multimodality volumetric data over the shape vector image.
Keywords: 3D surface matching;Algorithms;Artificial Intelligence;Brain;Diffusion Magnetic Resonance Imaging;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Index Terms&amp;#8212;Multiscale Diffusion;Nerve Fibers, Myelinated;Pattern Recognition, Automated;Sensitivity and Specificity;Shape Vector Image;Surface Matching;Visualization;canonical rectangular domain;conformal geometry;data visualisation;differential geometry;encoding;feature detection;feature extraction;feature extraction;geodesic distance-weighted shape vector image diffusion;image matching;image registration;image sampling;image sampling;multiscale diffusion space;solid modelling;statistical analysis;statistical analysis;surface fitting;surface registration;surface visualization;
Author: Jing Hua; Zhaoqiang Lai; Ming Dong; Xianfeng Gu; Hong Qin

Year: 2008
Title: Edge Groups: An Approach to Understanding the Mesh Quality of Marching Methods
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658187
Abstract: Marching cubes is the most popular isosurface extraction algorithm due to its simplicity, efficiency and robustness. It has been widely studied, improved, and extended. While much early work was concerned with efficiency and correctness issues, lately there has been a push to improve the quality of marching cubes meshes so that they can be used in computational codes. In this work we present a new classification of MC cases that we call edge groups, which helps elucidate the issues that impact the triangle quality of the meshes that the method generates. This formulation allows a more systematic way to bound the triangle quality, and is general enough to extend to other polyhedral cell shapes used in other polygonization algorithms. Using this analysis, we also discuss ways to improve the quality of the resulting triangle mesh, including some that require only minor modifications of the original algorithm.
Keywords: Index Terms&amp;#8212;Isosurface extraction;Marching Cubes;computational geometry;isosurface extraction algorithm;marching cubes;marching methods mesh quality;mesh generation;polygonization algorithms;polyhedral cell shapes;triangle mesh;
Author: Dietrich, C.A.; Scheidegger, C.; Comba, J.L.D.; Nedel, L.; Silva, C.T.

Year: 2008
Title: Revisiting Histograms and Isosurface Statistics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658188
Abstract: Recent results have shown a link between geometric properties of isosurfaces and statistical properties of the underlying sampled data. However, this has two defects: not all of the properties described converge to the same solution, and the statistics computed are not always invariant under isosurface-preserving transformations. We apply Federer's Coarea Formula from geometric measure theory to explain these discrepancies. We describe an improved substitute for histograms based on weighting with the inverse gradient magnitude, develop a statistical model that is invariant under isosurface-preserving transformations, and argue that this provides a consistent method for algorithm evaluation across multiple datasets based on histogram equalization. We use our corrected formulation to reevaluate recent results on average isosurface complexity, and show evidence that noise is one cause of the discrepancy between the expected figure and the observed one.
Keywords: Coarea Formula;Federer Coarea Formula;Histograms;Index Terms&amp;#8212;Isosurfaces;data visualisation;histogram equalization;isosurface statistics;isosurface-preserving transformations;statistical analysis;statistical model;
Author: Scheidegger, C.E.; Schreiner, J.M.; Duffy, B.; Carr, H.; Silva, C.T.

Year: 2008
Title: Visibility-driven Mesh Analysis and Visualization through Graph Cuts
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658189
Abstract: In this paper we present an algorithm that operates on a triangular mesh and classifies each face of a triangle as either inside or outside. We present three example applications of this core algorithm: normal orientation, inside removal, and layer-based visualization. The distinguishing feature of our algorithm is its robustness even if a difficult input model that includes holes, coplanar triangles, intersecting triangles, and lost connectivity is given. Our algorithm works with the original triangles of the input model and uses sampling to construct a visibility graph that is then segmented using graph cut.
Keywords: Graph Cut;Index Terms&amp;#8212;Inside Removal;Interior/Exterior Classification;Layer Classification;Normal Orientation;computational geometry;computational geometry;data visualisation;data visualization;graph cut;graph theory;mesh generation;sampling method;sampling methods;visibility-driven triangular mesh analysis;
Author: Zhou, K.; Zhang, E.; Bittner, J.; Wonka, P.

Year: 2008
Title: Text Scaffolds for Effective Surface Labeling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658190
Abstract: In this paper we introduce a technique for applying textual labels to 3D surfaces. An effective labeling must balance the conflicting goals of conveying the shape of the surface while being legible from a range of viewing directions. Shape can be conveyed by placing the text as a texture directly on the surface, providing shape cues, meaningful landmarks and minimally obstructing the rest of the model. But rendering such surface text is problematic both in regions of high curvature, where text would be warped, and in highly occluded regions, where it would be hidden. Our approach achieves both labeling goals by applying surface labels to a psilatext scaffoldpsila, a surface explicitly constructed to hold the labels. Text scaffolds conform to the underlying surface whenever possible, but can also float above problem regions, allowing them to be smooth while still conveying the overall shape. This paper provides methods for constructing scaffolds from a variety of input sources, including meshes, constructive solid geometry, and scalar fields. These sources are first mapped into a distance transform, which is then filtered and used to construct a new mesh on which labels are either manually or automatically placed. In the latter case, annotated regions of the input surface are associated with proximal regions on the new mesh, and labels placed using cartographic principles.
Keywords: 3D surfaces;Index Terms&amp;#8212;annotation;computational cartography;constructive solid geometry;proximal regions;rendering (computer graphics);solid modelling;surface labeling;surface labeling;surface text rendering;text authoring;text scaffolds;textual labels;
Author: Cipriano, G.; Gleicher, M.

Year: 2008
Title: Relation-Aware Volume Exploration Pipeline
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658191
Abstract: Volume exploration is an important issue in scientific visualization. Research on volume exploration has been focused on revealing hidden structures in volumetric data. While the information of individual structures or features is useful in practice, spatial relations between structures are also important in many applications and can provide further insights into the data. In this paper, we systematically study the extraction, representation,exploration, and visualization of spatial relations in volumetric data and propose a novel relation-aware visualization pipeline for volume exploration. In our pipeline, various relations in the volume are first defined and measured using region connection calculus (RCC) and then represented using a graph interface called relation graph. With RCC and the relation graph, relation query and interactive exploration can be conducted in a comprehensive and intuitive way. The visualization process is further assisted with relation-revealing viewpoint selection and color and opacity enhancement. We also introduce a quality assessment scheme which evaluates the perception of spatial relations in the rendered images. Experiments on various datasets demonstrate the practical use of our system in exploratory visualization.
Keywords: Exploratory Visualization;Index Terms&amp;#8212;Relation-Based Visualization;Visualization Pipeline.;data visualisation;graph interface;graph theory;region connection calculus;relation graph;relation-aware volume exploration pipeline;rendered images;rendering (computer graphics);scientific visualization;volumetric data;
Author: Ming-Yuen Chan; Huamin Qu; Ka-Kei Chung; Wai-Ho Mak; Yingcai Wu

Year: 2008
Title: VisComplete: Automating Suggestions for Visualization Pipelines
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658192
Abstract: Building visualization and analysis pipelines is a large hurdle in the adoption of visualization and workflow systems by domain scientists. In this paper, we propose techniques to help users construct pipelines by consensus-automatically suggesting completions based on a database of previously created pipelines. In particular, we compute correspondences between existing pipeline subgraphs from the database, and use these to predict sets of likely pipeline additions to a given partial pipeline. By presenting these predictions in a carefully designed interface, users can create visualizations and other data products more efficiently because they can augment their normal work patterns with the suggested completions. We present an implementation of our technique in a publicly-available, open-source scientific workflow system and demonstrate efficiency gains in real-world situations.
Keywords: Auto Completion;Index Terms&amp;#8212;Scientific Visualization;Scientific Workflows;analysis pipelines;data visualisation;graph theory;open-source scientific workflow system;pipeline subgraphs;visualization pipelines;
Author: Koop, D.; Scheidegger, C.E.; Callahan, S.P.; Freire, J.; Silva, C.T.

Year: 2008
Title: Interactive Visual Steering - Rapid Visual Prototyping of a Common Rail Injection System
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658193
Abstract: Interactive steering with visualization has been a common goal of the visualization research community for twenty years, but it is rarely ever realized in practice. In this paper we describe a successful realization of a tightly coupled steering loop, integrating new simulation technology and interactive visual analysis in a prototyping environment for automotive industry system design. Due to increasing pressure on car manufacturers to meet new emission regulations, to improve efficiency, and to reduce noise, both simulation and visualization are pushed to their limits. Automotive system components, such as the powertrain system or the injection system have an increasing number of parameters, and new design approaches are required. It is no longer possible to optimize such a system solely based on experience or forward optimization. By coupling interactive visualization with the simulation back-end (computational steering), it is now possible to quickly prototype a new system, starting from a non-optimized initial prototype and the corresponding simulation model. The prototyping continues through the refinement of the simulation model, of the simulation parameters and through trial-and-error attempts to an optimized solution. The ability to early see the first results from a multidimensional simulation space - thousands of simulations are run for a multidimensional variety of input parameters - and to quickly go back into the simulation and request more runs in particular parameter regions of interest significantly improves the prototyping process and provides a deeper understanding of the system behavior. The excellent results which we achieved for the common rail injection system strongly suggest that our approach has a great potential of being generalized to other, similar scenarios.
Keywords: Index Terms&amp;#8212;automotive engineering;automotive industry system design;common rail injection system;common rail injection system;coupled steering loop;data visualisation;design engineering;engineering graphics;interactive computational steering;interactive systems;interactive visual analysis;interactive visual analysis;interactive visual steering;mechanical engineering computing;rapid prototyping (industrial);rapid visual prototyping;simulation;
Author: Matkovic, K.; Gracanin, D.; Jelovic, M.; Hauser, H.

Year: 2008
Title: AD-Frustum: Adaptive Frustum Tracing for Interactive Sound Propagation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658194
Abstract: We present an interactive algorithm to compute sound propagation paths for transmission, specular reflection and edge diffraction in complex scenes. Our formulation uses an adaptive frustum representation that is automatically sub-divided to accurately compute intersections with the scene primitives. We describe a simple and fast algorithm to approximate the visible surface for each frustum and generate new frusta based on specular reflection and edge diffraction. Our approach is applicable to all triangulated models and we demonstrate its performance on architectural and outdoor models with tens or hundreds of thousands of triangles and moving objects. In practice, our algorithm can perform geometric sound propagation in complex scenes at 4-20 frames per second on a multi-core PC.
Keywords: Index Terms&amp;#8212;Sound propagation;adaptive frustum tracing;auralization;data visualisation;edge diffraction;interactive sound propagation;interactive system;interactive systems;ray tracing;rendering (computer graphics);scene primitives;specular reflection;
Author: Chandak, A.; Lauterbach, C.; Taylor, M.; Ren, Z.; Manocha, D.

Year: 2008
Title: Query-Driven Visualization of Time-Varying Adaptive Mesh Refinement Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658195
Abstract: The visualization and analysis of AMR-based simulations is integral to the process of obtaining new insight in scientific research. We present a new method for performing query-driven visualization and analysis on AMR data, with specific emphasis on time-varying AMR data. Our work introduces a new method that directly addresses the dynamic spatial and temporal properties of AMR grids that challenge many existing visualization techniques. Further, we present the first implementation of query-driven visualization on the GPU that uses a GPU-based indexing structure to both answer queries and efficiently utilize GPU memory. We apply our method to two different science domains to demonstrate its broad applicability.
Keywords: AMR;GPU-based indexing structure;Index Terms&amp;#8212;Multitemporal Visualization;Query-Driven Visualization;data visualisation;multitemporal visualization;query processing;query-driven visualization;time-varying adaptive mesh refinement data;visualization techniques;
Author: Gosink, L.J.; Anderson, J.C.; Bethel, E.W.; Joy, K.I.

Year: 2008
Title: A Comparison of the Perceptual Benefits of Linear Perspective and Physically-Based Illumination for Display of Dense 3D Streamtubes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658196
Abstract: Large datasets typically contain coarse features comprised of finer sub-features. Even if the shapes of the small structures are evident in a 3D display, the aggregate shapes they suggest may not be easily inferred. From previous studies in shape perception, the evidence has not been clear whether physically-based illumination confers any advantage over local illumination for understanding scenes that arise in visualization of large data sets that contain features at two distinct scales. In this paper we show that physically-based illumination can improve the perception for some static scenes of complex 3D geometry from flow fields. We perform human-subjects experiments to quantify the effect of physically-based illumination on participant performance for two tasks: selecting the closer of two streamtubes from a field of tubes, and identifying the shape of the domain of a flow field over different densities of tubes. We find that physically-based illumination influences participant performance as strongly as perspective projection, suggesting that physically-based illumination is indeed a strong cue to the layout of complex scenes. We also find that increasing the density of tubes for the shape identification task improved participant performance under physically-based illumination but not under the traditional hardware-accelerated illumination model.
Keywords: 3D shape perception;DT-MRI;Index Terms&amp;#8212;complex 3D geometry;computer vision;data visualisation;dense 3D streamtubes;flow visualisation;flow visualization;global illumination;large data sets visualization;linear perspective;local illumination;multi-scale visualization;physically-based illumination;physically-based illumination;streamtubes;user study;volume completion;white matter tractography;
Author: Weigle, C.; Banks, D.

Year: 2008
Title: Focus+Context Visualization with Distortion Minimization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658197
Abstract: The need to examine and manipulate large surface models is commonly found in many science, engineering, and medical applications. On a desktop monitor, however, seeing the whole model in detail is not possible. In this paper, we present a new, interactive Focus+Context method for visualizing large surface models. Our method, based on an energy optimization model, allows the user to magnify an area of interest to see it in detail while deforming the rest of the area without perceivable distortion. The rest of the surface area is essentially shrunk to use as little of the screen space as possible in order to keep the entire model displayed on screen. We demonstrate the efficacy and robustness of our method with a variety of models.
Keywords: Focus+Context visualization;Index Terms&amp;#8212;bounding space;data visualisation;distortion;distortion minimization;energy optimization model;interactive focus-context visualization;large surface model visualization;magnification;minimisation;solid modelling;surface fitting;
Author: Yu-Shuen Wang; Tong-Yee Lee; Chiew-Lan Tai

Year: 2008
Title: Color Design for Illustrative Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658198
Abstract: Professional designers and artists are quite cognizant of the rules that guide the design of effective color palettes, from both aesthetic and attention-guiding points of view. In the field of visualization, however, the use of systematic rules embracing these aspects has received less attention. The situation is further complicated by the fact that visualization often uses semi-transparencies to reveal occluded objects, in which case the resulting color mixing effects add additional constraints to the choice of the color palette. Color design forms a crucial part in visual aesthetics. Thus, the consideration of these issues can be of great value in the emerging field of illustrative visualization. We describe a knowledge-based system that captures established color design rules into a comprehensive interactive framework, aimed to aid users in the selection of colors for scene objects and incorporating individual preferences, importance functions, and overall scene composition. Our framework also offers new knowledge and solutions for the mixing, ordering and choice of colors in the rendering of semi-transparent layers and surfaces. All design rules are evaluated via user studies, for which we extend the method of conjoint analysis to task-based testing scenarios. Our framework's use of principles rooted in color design with application for the illustration of features in pre-classified data distinguishes it from existing systems which target the exploration of continuous-range density data via perceptual color maps.
Keywords: Color design;Index Terms&amp;#8212;color design;colour graphics;conjoint analysis;data visualisation;effective color palettes;illustrative visualization;illustrative visualization;knowledge based systems;knowledge-based system;occluded objects;perceptual color maps;rendering (computer graphics);scene composition;semi-transparent layer rendering;transparency;user study evaluation;visual aesthetics;volume rendering;
Author: Lujin Wang; Giesen, J.; McDonnell, K.T.; Zolliker, P.; Mueller, K.

Year: 2008
Title: An Efficient Naturalness-Preserving Image-Recoloring Method for Dichromats
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658199
Abstract: We present an efficient and automatic image-recoloring technique for dichromats that highlights important visual details that would otherwise be unnoticed by these individuals. While previous techniques approach this problem by potentially changing all colors of the original image, causing their results to look unnatural to color vision deficients, our approach preserves, as much as possible, the image's original colors. Our approach is about three orders of magnitude faster than previous ones. The results of a paired-comparison evaluation carried out with fourteen color-vision deficients (CVDs) indicated the preference of our technique over the state-of-the-art automatic recoloring technique for dichromats. When considering information visualization examples, the subjects tend to prefer our results over the original images. An extension of our technique that exaggerates color contrast tends to be preferred when CVDs compared pairs of scientific visualization images. These results provide valuable information for guiding the design of visualizations for color-vision deficients.
Keywords: CVD;Color-contrast enhancement;Color-vision deficiency;Index Terms&amp;#8212;Information and Scientific Visualization;Recoloring algorithms;automatic image-recoloring technique;color-contrast enhancement;color-vision deficients;colour graphics;colour vision;data visualisation;dichromats;image colour analysis;image enhancement;information visualization;naturalness-preserving image-recoloring method;scientific visualization;
Author: Kuhn, G.R.; Oliveira, M.M.; Fernandes, L.

Year: 2008
Title: Effects of Video Placement and Spatial Context Presentation on Path Reconstruction Tasks with Contextualized Videos
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658200
Abstract: Many interesting and promising prototypes for visualizing video data have been proposed, including those that combine videos with their spatial context (contextualized videos). However, relatively little work has investigated the fundamental design factors behind these prototypes in order to provide general design guidance. Focusing on real-time video data visualization, we evaluated two important design factors - video placement method and spatial context presentation method - through a user study. In addition, we evaluated the effect of spatial knowledge of the environment. Participantspsila performance was measured through path reconstruction tasks, where the participants followed a target through simulated surveillance videos and marked the target paths on the environment model. We found that embedding videos inside the model enabled realtime strategies and led to faster performance. With the help of contextualized videos, participants not familiar with the real environment achieved similar task performance to participants that worked in that environment. We discuss design implications and provide general design recommendations for traffic and security surveillance system interfaces.
Keywords: Index Terms&amp;#8212;contextualized videos;contextualized videos;data visualisation;design factors;path reconstruction;path reconstruction tasks;real-time video data visualization;security surveillance system interface;simulated surveillance videos;spatial context;spatial context presentation;tracking;user study;video placement;video placement;video signal processing;video surveillance;
Author: Yi Wang; Bowman, D.; Krum, D.; Coalho, E.; Smith-Jackson, T.; Bailey, D.; Peck, S.; Anand, S.; Kennedy, T.; Abdrazakov, Y.

Year: 2008
Title: Back matter
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4658201
Abstract: Back matter from Vis/InfoVis 2008
Keywords: Index Terms&amp;#8212;
Author: null

Year: 2007
Title: Visual Analysis of Network Traffic for Resource Planning, Interactive Monitoring, and Interpretation of Security Threats
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376129
Abstract: The Internet has become a wild place: malicious code is spread on personal computers across the world, deploying botnets ready to attack the network infrastructure. The vast number of security incidents and other anomalies overwhelms attempts at manual analysis, especially when monitoring service provider backbone links. We present an approach to interactive visualization with a case study indicating that interactive visualization can be applied to gain more insight into these large data sets. We superimpose a hierarchy on IP address space, and study the suitability of Treemap variants for each hierarchy level. Because viewing the whole IP hierarchy at once is not practical for most tasks, we evaluate layout stability when eliding large parts of the hierarchy, while maintaining the visibility and ordering of the data of interest.
Keywords: IP address space;IP networks;Information visualization;Internet;Internet;Treemap;data visualisation;interactive monitoring;interactive visualization;network infrastructure;network monitoring;network security;network traffic;personal computers;resource planning;security of data;security threats interpretation;telecommunication network planning;telecommunication security;telecommunication traffic;treemap;
Author: Mansmann, F.; Keim, D.A.; North, S.C.; Rexroad, B.; Sheleheda, D.

Year: 2007
Title: AdaptiviTree: Adaptive Tree Visualization for Tournament-Style Brackets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376130
Abstract: Online pick'em games, such as the recent NCAA college basketball March Madness tournament, form a large and rapidly growing industry. In these games, players make predictions on a tournament bracket that defines which competitors play each other and how they proceed toward a single champion. Throughout the course of the tournament, players monitor the brackets to track progress and to compare predictions made by multiple players. This is often a complex sense making task. The classic bracket visualization was designed for use on paper and utilizes an incrementally additive system in which the winner of each match-up is rewritten in the next round as the tournament progresses. Unfortunately, this representation requires a significant amount of space and makes it relatively difficult to get a quick overview of the tournament state since competitors take arbitrary paths through the static bracket. In this paper, we present AdaptiviTree, a novel visualization that adaptively deforms the representation of the tree and uses its shape to convey outcome information. AdaptiviTree not only provides a more compact and understandable representation, but also allows overlays that display predictions as well as other statistics. We describe results from a lab study we conducted to explore the efficacy of AdaptiviTree, as well as from a deployment of the system in a recent real-world sports tournament.
Keywords: AdaptiviTree visualization;Online fantasy sports;adaptive tree visualization;adaptive tree visualization.;bracket;computer games;data visualisation;human factors;online fantasy games;picks;prediction display;sport;statistics;tournament;tournament-style brackets;tree data structures;
Author: Tan, D.S.; Smith, G.; Bongshin Lee; Robertson, G.G.

Year: 2007
Title: ManyEyes: a Site for Visualization at Internet Scale
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376131
Abstract: We describe the design and deployment of Many Eyes, a public Web site where users may upload data, create interactive visualizations, and carry on discussions. The goal of the site is to support collaboration around visualizations at a large scale by fostering a social style of data analysis in which visualizations not only serve as a discovery tool for individuals but also as a medium to spur discussion among users. To support this goal, the site includes novel mechanisms for end-user creation of visualizations and asynchronous collaboration around those visualizations. In addition to describing these technologies, we provide a preliminary report on the activity of our users.
Keywords: Communication;Communication-Minded Visualization.;Computer Graphics;Cooperative Behavior;Information Dissemination;Information Storage and Retrieval;Internet;Internet scale;Many Eyes;Social Data Analysis;Social Software;Software;Software Design;User-Computer Interface;Visualization;Web sites;World Wide Web;data analysis;data analysis;data visualisation;data visualization;public Web site;
Author: Viegas, F.B.; Wattenberg, M.; van Ham, F.; Kriss, J.; McKeon, M.

Year: 2007
Title: Scented Widgets: Improving Navigation Cues with Embedded Visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376132
Abstract: This paper presents scented widgets, graphical user interface controls enhanced with embedded visualizations that facilitate navigation in information spaces. We describe design guidelines for adding visual cues to common user interface widgets such as radio buttons, sliders, and combo boxes and contribute a general software framework for applying scented widgets within applications with minimal modifications to existing source code. We provide a number of example applications and describe a controlled experiment which finds that users exploring unfamiliar data make up to twice as many unique discoveries using widgets imbued with social navigation data. However, these differences equalize as familiarity with the data increases.
Keywords: Information visualization;data visualisation;design guidelines;embedded visualizations;graphical user interface controls;graphical user interfaces;information foraging;information spaces navigation;navigation cues;scented widgets;social data analysis;social navigation;user interface toolkits;visual cues;
Author: Willett, W.; Heer, J.; Agrawala, M.

Year: 2007
Title: Show Me: Automatic Presentation for Visual Analysis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376133
Abstract: This paper describes Show Me, an integrated set of user interface commands and defaults that incorporate automatic presentation into a commercial visual analysis system called Tableau. A key aspect of Tableau is VizQL, a language for specifying views, which is used by Show Me to extend automatic presentation to the generation of tables of views (commonly called small multiple displays). A key research issue for the commercial application of automatic presentation is the user experience, which must support the flow of visual analysis. User experience has not been the focus of previous research on automatic presentation. The Show Me user experience includes the automatic selection of mark types, a command to add a single field to a view, and a pair of commands to build views for multiple fields. Although the use of these defaults and commands is optional, user interface logs indicate that Show Me is used by commercial users.
Keywords: Automatic presentation;Computer Graphics;Expert Systems;Information Storage and Retrieval;Programming Languages;Software;Software Design;User-Computer Interface;algebraic specification;algebraic specification language;automatic presentation;best practices;data analysis;data analysis;data visualisation;data visualization;data visualization;graphic design;graphic design;small multiple display;small multiples.;specification languages;user interface;user interfaces;visual analysis;visual analysis system;
Author: Mackinlay, J.D.; Hanrahan, P.; Stolte, C.

Year: 2007
Title: Casual Information Visualization: Depictions of Data in Everyday Life
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376134
Abstract: Information visualization has often focused on providing deep insight for expert user populations and on techniques for amplifying cognition through complicated interactive visual models. This paper proposes a new subdomain for infovis research that complements the focus on analytic tasks and expert use. Instead of work-related and analytically driven infovis, we propose casual information visualization (or casual infovis) as a complement to more traditional infovis domains. Traditional infovis systems, techniques, and methods do not easily lend themselves to the broad range of user populations, from expert to novices, or from work tasks to more everyday situations. We propose definitions, perspectives, and research directions for further investigations of this emerging subfield. These perspectives build from ambient information visualization (Skog et al., 2003), social visualization, and also from artistic work that visualizes information (Viegas and Wattenberg, 2007). We seek to provide a perspective on infovis that integrates these research agendas under a coherent vocabulary and framework for design. We enumerate the following contributions. First, we demonstrate how blurry the boundary of infovis is by examining systems that exhibit many of the putative properties of infovis systems, but perhaps would not be considered so. Second, we explore the notion of insight and how, instead of a monolithic definition of insight, there may be multiple types, each with particular characteristics. Third, we discuss design challenges for systems intended for casual audiences. Finally we conclude with challenges for system evaluation in this emerging subfield.
Keywords: Activities of Daily Living;Casual information visualization;Computer Graphics;Database Management Systems;Databases, Factual;Information Storage and Retrieval;User-Computer Interface;ambient infovis;ambient infovis;casual audiences;casual information visualization;casual infovis;cognition;data visualisation;design;editorial;evaluation.;interactive visual model;social infovis;social infovis;system evaluation;
Author: Pousman, Z.; Stasko, J.T.; Mateas, M.

Year: 2007
Title: Geographically Weighted Visualization: Interactive Graphics for Scale-Varying Exploratory Analysis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376135
Abstract: We introduce a series of geographically weighted (GW) interactive graphics, or geowigs, and use them to explore spatial relationships at a range of scales. We visually encode information about geographic and statistical proximity and variation in novel ways through <i>gw-choropleth maps</i>, multivariate <i>gw-boxplots, gw-shading</i> and <i>scalograms</i>. The new graphic types reveal information about GW statistics at several scales concurrently. We impement these views in prototype software containing dynamic links and GW interactions that encourage exploration and refine them to consider directional geographies. An informal evaluation uses interactive GW techniques to consider Guerry's dataset of 'moral statistics', casting doubt on correlations originally proposed through visual analysis, revealing new local anomalies and suggesting multivariate geographic relationships. Few attempts at visually synthesising geography with multivariate statistical values at multiple scales have been reported. The <i>geowigs </i>proposed here provide informative representations of multivariate local variation, particularly when combined with interactions that coordinate views and result in <i>gw-shading</i>. We argue that they are widely applicable to area and point-based geographic data and provide a set of methods to support visual analysis using GW statistics through which the effects of geography can be explored at multiple scales.
Keywords: Geographical weighting;coordinated views;data visualisation;directional;exploratory data analysis;geographic information systems;geographically weighted visualization;geowigs;interaction;interactive graphics;interactive systems;multivariate;multivariate local variation;multivariate statistical value;scale;scale-varying exploratory analysis;statistical analysis;
Author: Dykes, J.; Brunsdon, C.

Year: 2007
Title: Visualizing the History of Living Spaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376136
Abstract: The technology available to building designers now makes it possible to monitor buildings on a very large scale. Video cameras and motion sensors are commonplace in practically every office space, and are slowly making their way into living spaces. The application of such technologies, in particular video cameras, while improving security, also violates privacy. On the other hand, motion sensors, while being privacy-conscious, typically do not provide enough information for a human operator to maintain the same degree of awareness about the space that can be achieved by using video cameras. We propose a novel approach in which we use a large number of simple motion sensors and a small set of video cameras to monitor a large office space. In our system we deployed 215 motion sensors and six video cameras to monitor the 3,000-square-meter office space occupied by 80 people for a period of about one year. The main problem in operating such systems is finding a way to present this highly multidimensional data, which includes both spatial and temporal components, to a human operator to allow browsing and searching recorded data in an efficient and intuitive way. In this paper we present our experiences and the solutions that we have developed in the course of our work on the system. We consider this work to be the first step in helping designers and managers of building systems gain access to information about occupants' behavior in the context of an entire building in a way that is only minimally intrusive to the occupants' privacy.
Keywords: Sensor networks;building designer;data visualisation;data visualisation;human factors;image motion analysis;image sensors;living space;motion sensor;spatio-temporal visualization.;spatiotemporal phenomena;surveillance;timeline;user interfaces;user interfaces;video camera;video cameras;
Author: Ivanov, Y.A.; Wren, C.R.; Sorokin, A.; Kaur, I.

Year: 2007
Title: Legible Cities: Focus-Dependent Multi-Resolution Visualization of Urban Relationships
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376137
Abstract: Numerous systems have been developed to display large collections of data for urban contexts; however, most have focused on layering of single dimensions of data and manual calculations to understand relationships within the urban environment. Furthermore, these systems often limit the user's perspectives on the data, thereby diminishing the user's spatial understanding of the viewing region. In this paper, we introduce a highly interactive urban visualization tool that provides intuitive understanding of the urban data. Our system utilizes an aggregation method that combines buildings and city blocks into legible clusters, thus providing continuous levels of abstraction while preserving the user's mental model of the city. In conjunction with a 3D view of the urban model, a separate but integrated information visualization view displays multiple disparate dimensions of the urban data, allowing the user to understand the urban environment both spatially and cognitively in one glance. For our evaluation, expert users from various backgrounds viewed a real city model with census data and confirmed that our system allowed them to gain more intuitive and deeper understanding of the urban model from different perspectives and levels of abstraction than existing commercial urban visualization systems.
Keywords: data visualisation;focus-dependent multiresolution visualization;information visualization;information visualization view displays;interactive systems;interactive urban visualization tool;multi-resolution;town and country planning;urban model 3D view;urban models;urban relationships;
Author: Remco Chang; Wessel, G.; Kosara, R.; Sauda, E.; Ribarsky, W.

Year: 2007
Title: Interactive Visual Exploration of a Large Spatio-temporal Dataset: Reflections on a Geovisualization Mashup.
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376138
Abstract: Exploratory visual analysis is useful for the preliminary investigation of large structured, multifaceted spatio-temporal datasets. This process requires the selection and aggregation of records by time, space and attribute, the ability to transform data and the flexibility to apply appropriate visual encodings and interactions. We propose an approach inspired by geographical 'mashups' in which freely-available functionality and data are loosely but flexibly combined using de facto exchange standards. Our case study combines MySQL, PHP and the LandSerf GIS to allow Google Earth to be used for visual synthesis and interaction with encodings described in KML. This approach is applied to the exploration of a log of 1.42 million requests made of a mobile directory service. Novel combinations of interaction and visual encoding are developed including spatial 'tag clouds', 'tag maps', 'data dials' and multi-scale density surfaces. Four aspects of the approach are informally evaluated: the visual encodings employed, their success in the visual exploration of the dataset, the specific tools used and the 'mashup' approach. Preliminary findings will be beneficial to others considering using mashups for visualization. The specific techniques developed may be more widely applied to offer insights into the structure of multifarious spatio-temporal data of the type explored here.
Keywords: Google Earth;KML;LandSerf GIS;Large dataset visualization;MySQL;PHP;SQL;applications of infovis.;data dials;data visualisation;de facto exchange standards;geographic information systems;geographic visualization;geographical mashups;geovisualization mashup;interactive visual exploration;mobile directory service;multi-scale density surfaces;multiresolution visualization;spatial tag clouds;spatio-temporal dataset;spatiotemporal phenomena;tag maps;text and document visualization;visual encodings;
Author: Wood, J.; Dykes, J.; Slingsby, A.; Clarke, K.

Year: 2007
Title: Hotmap: Looking at Geographic Attention
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376139
Abstract: Understanding how people use online maps allows data acquisition teams to concentrate their efforts on the portions of the map that are most seen by users. Online maps represent vast databases, and so it is insufficient to simply look at a list of the most-accessed URLs. Hotmap takes advantage of the design of a mapping system's imagery pyramid to superpose a heatmap of the log files over the original maps. Users' behavior within the system can be observed and interpreted. This paper discusses the imagery acquisition task that motivated Hotmap, and presents several examples of information that Hotmap makes visible. We discuss the design choices behind Hotmap, including logarithmic color schemes; low-saturation background images; and tuning images to explore both infrequently-viewed and frequently-viewed spaces.
Keywords: GIS;GIS;Geographical visualization;Hotmap;URL;data acquisition;data acquisition;data visualisation;geographic attention;geographic information systems;geographic visualization;heatmap;imagery acquisition;interactive systems;logarithmic color scheme;low-saturation background image;mapping system imagery pyramid;online interactive mapping system;online mapping systems;server log analysis;social navigation;tuning image;
Author: Fisher, D.

Year: 2007
Title: VisLink: Revealing Relationships Amongst Visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376140
Abstract: We present VisLink, a method by which visualizations and the relationships between them can be interactively explored. VisLink readily generalizes to support multiple visualizations, empowers inter-representational queries, and enables the reuse of the spatial variables, thus supporting efficient information encoding and providing for powerful visualization bridging. Our approach uses multiple 2D layouts, drawing each one in its own plane. These planes can then be placed and re-positioned in 3D space: side by side, in parallel, or in chosen placements that provide favoured views. Relationships, connections, and patterns between visualizations can be revealed and explored using a variety of interaction techniques including spreading activation and search filters.
Keywords: 3D visualization;Graph visualization;VisLink;data visualisation;data visualizations;edge aggregation.;hierarchies;information encoding;inter-representational query;node-link diagrams;query formulation;search filters;spreading activation;structural comparison;
Author: Collins, C.; Carpendale, S.

Year: 2007
Title: Visualization of Heterogeneous Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376141
Abstract: Both the resource description framework (RDF), used in the semantic web, and Maya Viz u-forms represent data as a graph of objects connected by labeled edges. Existing systems for flexible visualization of this kind of data require manual specification of the possible visualization roles for each data attribute. When the schema is large and unfamiliar, this requirement inhibits exploratory visualization by requiring a costly up-front data integration step. To eliminate this step, we propose an automatic technique for mapping data attributes to visualization attributes. We formulate this as a schema matching problem, finding appropriate paths in the data model for each required visualization attribute in a visualization template.
Keywords: Data integration;Maya Viz u-forms;RDF;attribute inference;data attributes mapping;data integration;data integrity;data visualisation;data visualization;resource description framework;schema matching problem;semantic Web;
Author: Cammarano, M.; Xin Dong; Bryan Chan; Klingner, J.; Talbot, J.; Halevy, A.; Hanrahan, P.

Year: 2007
Title: Sequential Document Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376142
Abstract: Documents and other categorical valued time series are often characterized by the frequencies of short range sequential patterns such as n-grams. This representation converts sequential data of varying lengths to high dimensional histogram vectors which are easily modeled by standard statistical models. Unfortunately, the histogram representation ignores most of the medium and long range sequential dependencies making it unsuitable for visualizing sequential data. We present a novel framework for sequential visualization of discrete categorical time series based on the idea of local statistical modeling. The framework embeds categorical time series as smooth curves in the multinomial simplex summarizing the progression of sequential trends. We discuss several visualization techniques based on the above framework and demonstrate their usefulness for document visualization.
Keywords: Algorithms;Artificial Intelligence;Computer Graphics;Database Management Systems;Databases, Factual;Document visualization;Documentation;Information Storage and Retrieval;Pattern Recognition, Automated;User-Computer Interface;data visualisation;discrete categorical time series;document handling;histogram vectors;local fitting.;multi-resolution analysis;multinomial simplex summarization;sequential document visualization;statistical analysis;statistical models;time series;
Author: Yi Mao; Dillon, J.V.; Lebanon, G.

Year: 2007
Title: A Taxonomy of Clutter Reduction for Information Visualisation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376143
Abstract: Information visualisation is about gaining insight into data through a visual representation. This data is often multivariate and increasingly, the datasets are very large. To help us explore all this data, numerous visualisation applications, both commercial and research prototypes, have been designed using a variety of techniques and algorithms. Whether they are dedicated to geo-spatial data or skewed hierarchical data, most of the visualisations need to adopt strategies for dealing with overcrowded displays, brought about by too much data to fit in too small a display space. This paper analyses a large number of these clutter reduction methods, classifying them both in terms of how they deal with clutter reduction and more importantly, in terms of the benefits and losses. The aim of the resulting taxonomy is to act as a guide to match techniques to problems where different criteria may have different importance, and more importantly as a means to critique and hence develop existing and new techniques.
Keywords: Clutter reduction;clutter reduction method;data classification;data structures;data visualisation;information visualisation;information visualisation;large datasets;large datasets;multivariate data;occlusion;pattern classification;taxonomy.;visual representation;
Author: Ellis, G.; Dix, A.

Year: 2007
Title: Toward a Deeper Understanding of the Role of Interaction in Information Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376144
Abstract: Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction.
Keywords: Information visualization;Infovis community;Infovis interaction techniques;Infovis systems;data visualisation;human computer interaction;information visualization;interaction;interaction techniques;taxonomy;taxonomy;visual analytics;
Author: Ji Soo Yi; Youn ah Kang; Stasko, J.T.; Jacko, J.A.

Year: 2007
Title: Interactive Tree Comparison for Co-located Collaborative Information Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376145
Abstract: In many domains, increased collaboration has lead to more innovation by fostering the sharing of knowledge, skills, and ideas. Shared analysis of information visualizations does not only lead to increased information processing power, but team members can also share, negotiate, and discuss their views and interpretations on a dataset and contribute unique perspectives on a given problem. Designing technologies to support collaboration around information visualizations poses special challenges and relatively few systems have been designed. We focus on supporting small groups collaborating around information visualizations in a co-located setting, using a shared interactive tabletop display. We introduce an analysis of challenges and requirements for the design of co-located collaborative information visualization systems. We then present a new system that facilitates hierarchical data comparison tasks for this type of collaborative work. Our system supports multi-user input, shared and individual views on the hierarchical data visualization, flexible use of representations, and flexible workspace organization to facilitate group work around visualizations.
Keywords: Information visualization;co-located work;collaboration;colocated collaborative information visualization;data visualisation;groupware;hierarchical data comparison;interactive tree comparison;shared interactive tabletop display;
Author: Isenberg, P.; Carpendale, S.

Year: 2007
Title: Animated Transitions in Statistical Data Graphics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376146
Abstract: In this paper we investigate the effectiveness of animated transitions between common statistical data graphics such as bar charts, pie charts, and scatter plots. We extend theoretical models of data graphics to include such transitions, introducing a taxonomy of transition types. We then propose design principles for creating effective transitions and illustrate the application of these principles in <i>DynaVis</i>, a visualization system featuring animated data graphics. Two controlled experiments were conducted to assess the efficacy of various transition types, finding that animated transitions can significantly improve graphical perception.
Keywords: DynaVis;Statistical data graphics;animated transitions;animation;bar charts;computer animation;data visualisation;design;experiment;graphical perception;information visualization;pie charts;scatter plots;statistical analysis;statistical data graphics;transitions;visualization system;
Author: Heer, J.; Robertson, G.G.

Year: 2007
Title: Browsing Zoomable Treemaps: Structure-Aware Multi-Scale Navigation Techniques
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376147
Abstract: Treemaps provide an interesting solution for representing hierarchical data. However, most studies have mainly focused on layout algorithms and paid limited attention to the interaction with treemaps. This makes it difficult to explore large data sets and to get access to details, especially to those related to the leaves of the trees. We propose the notion of zoomable treemaps (ZTMs), an hybridization between treemaps and zoomable user interfaces that facilitates the navigation in large hierarchical data sets. By providing a consistent set of interaction techniques, ZTMs make it possible for users to browse through very large data sets (e.g., 700,000 nodes dispatched amongst 13 levels). These techniques use the structure of the displayed data to guide the interaction and provide a way to improve interactive navigation in treemaps.
Keywords: Information visualization;data structures;data visualisation;hierarchical data represention;interactive navigation;multi-scale interaction;navigation;structure-aware multiscale navigation;structure-aware navigation;user interfaces;zoomable treemap browsing;zoomable treemaps;zoomable treemaps.;zoomable user interfaces;
Author: Blanch, R.; Lecolinet, E.

Year: 2007
Title: Visualizing Causal Semantics Using Animations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376148
Abstract: Michotte's theory of ampliation suggests that causal relationships are perceived by objects animated under appropriate spatiotemporal conditions. We extend the theory of ampliation and propose that the immediate perception of complex causal relations is also dependent on a set of structural and temporal rules. We designed animated representations, based on Michotte's rules, for showing complex causal relationships or causal semantics. In this paper we describe a set of animations for showing semantics such as causal amplification, causal strength, causal dampening, and causal multiplicity. In a two part study we compared the effectiveness of both the static and animated representations. The first study (N=44) asked participants to recall passages that were previously displayed using both types of representations. Participants were 8% more accurate in recalling causal semantics when they were presented using animations instead of static graphs. In the second study (N=112) we evaluated the intuitiveness of the representations. Our results showed that while users were as accurate with the static graphs as with the animations, they were 9% faster in matching the correct causal statements in the animated condition. Overall our results show that animated diagrams that are designed based on perceptual rules such as those proposed by Michotte have the potential to facilitate comprehension of complex causal relations.
Keywords: Causality;Michotte rules;animated graphs;animation;behavioural sciences computing;causal amplification;causal dampening;causal multiplicity;causal semantics visualization;causal strength;complex causal relations;computer animation;data visualisation;graph semantics.;perception;semantics;static graphs;visualization;visualizing cause and effect;
Author: Kadaba, N.R.; Irani, P.P.; Leboe, J.

Year: 2007
Title: Spatialization Design: Comparing Points and Landscapes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376149
Abstract: Spatializations represent non-spatial data using a spatial layout similar to a map. We present an experiment comparing different visual representations of spatialized data, to determine which representations are best for a non-trivial search and point estimation task. Primarily, we compare point-based displays to 2D and 3D information landscapes. We also compare a colour (hue) scale to a grey (lightness) scale. For the task we studied, point-based spatializations were far superior to landscapes, and 2D landscapes were superior to 3D landscapes. Little or no benefit was found for redundantly encoding data using colour or greyscale combined with landscape height. 3D landscapes with no colour scale (height-only) were particularly slow and inaccurate. A colour scale was found to be better than a greyscale for all display types, but a greyscale was helpful compared to height-only. These results suggest that point-based spatializations should be chosen over landscape representations, at least for tasks involving only point data itself rather than derived information about the data space.
Keywords: 2D;3D;Colour;Greyscale;Information Landscape;Numerosity;Points;Spatialization;Surface;User Study;colour graphics;colour scale;data visualisation;grey scale;information landscapes;non-spatial data;non-trivial search;point estimation task;point-based displays;spatial layout;spatialization design;spatialized data;visual representations;
Author: Tory, M.; Sprague, D.W.; Fuqu Wu; Wing Yan So; Munzner, T.

Year: 2007
Title: Weaving Versus Blending: a quantitative assessment of the information carrying capacities of two alternative methods for conveying multivariate data with color.
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376150
Abstract: In many applications, it is important to understand the individual values of, and relationships between, multiple related scalar variables defined across a common domain. Several approaches have been proposed for representing data in these situations. In this paper we focus on strategies for the visualization of multivariate data that rely on color mixing. In particular, through a series of controlled observer experiments, we seek to establish a fundamental understanding of the information-carrying capacities of two alternative methods for encoding multivariate information using color: color blending and color weaving. We begin with a baseline experiment in which we assess participants' abilities to accurately read numerical data encoded in six different basic color scales defined in the L*a*b* color space. We then assess participants' abilities to read combinations of 2, 3, 4 and 6 different data values represented in a common region of the domain, encoded using either color blending or color weaving. In color blending a single mixed color is formed via linear combination of the individual values in L*a*b* space, and in color weaving the original individual colors are displayed side-by-side in a high frequency texture that fills the region. A third experiment was conducted to clarify some of the trends regarding the color contrast and its effect on the magnitude of the error that was observed in the second experiment. The results indicate that when the component colors are represented side-by-side in a high frequency texture, most participants' abilities to infer the values of individual components are significantly improved, relative to when the colors are blended. Participants' performance was significantly better with color weaving particularly when more than 2 colors were used, and even when the individual colors subtended only 3 minutes of visual angle in the texture. However, the information-carrying capacity of the color weaving approach has its limits. --We found that participants' abilities to accurately interpret each of the individual components in a high frequency color texture typically falls off as the number of components increases from 4 to 6. We found no significant advantages, in either color blending or color weaving, to using color scales based on component hues thatare more widely separated in the L*a*b* color space. Furthermore, we found some indications that extra difficulties may arise when opponent hues are employed.
Keywords: Color;Color;Computer Graphics;Computer Simulation;Database Management Systems;Databases, Factual;Information Storage and Retrieval;Models, Theoretical;Multivariate Analysis;User-Computer Interface;color blending;color blending.;color mixing;color weaving;color weaving;data visualisation;encoding;image colour analysis;image texture;image texture;information carrying capacity;multivariate data visualization;perception;quantitative assessment;visualization;
Author: Hagh-Shenas, H.; Sunghee Kim; Interrante, V.; Healey, C.

Year: 2007
Title: Overview Use in Multiple Visual Information Resolution Interfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376151
Abstract: In interfaces that provide multiple visual information resolutions (VIR), low-VIR overviews typically sacrifice visual details for display capacity, with the assumption that users can select regions of interest to examine at higher VI Rs. Designers can create low VIRs based on multi-level structure inherent in the data, but have little guidance with single-level data. To better guide design tradeoff between display capacity and visual target perceivability, we looked at overview use in two multiple-VIR interfaces with high-VIR displays either embedded within, or separate from, the overviews. We studied two visual requirements for effective overview and found that participants would reliably use the low-VIR overviews only when the visual targets were simple and had small visual spans. Otherwise, at least 20% chose to use the high-VIR view exclusively. Surprisingly, neither of the multiple-VIR interfaces provided performance benefits when compared to using the high-VIR view alone. However, we did observe benefits in providing side-by-side comparisons for target matching. We conjecture that the high cognitive load of multiple-VIR interface interactions, whether real or perceived, is a more considerable barrier to their effective use than was previously considered.
Keywords: Multiple resolutions;data visualisation;display capacity;graphical user interfaces;multi-level structure;multiple visual information resolution interfaces;overview use;target matching;user study.;visual target perceivability;visual targets;
Author: Lam, H.; Munzner, T.; Kincaid, R.

Year: 2007
Title: Visualizing Changes of Hierarchical Data using Treemaps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376152
Abstract: While the treemap is a popular method for visualizing hierarchical data, it is often difficult for users to track layout and attribute changes when the data evolve over time. When viewing the treemaps side by side or back and forth, there exist several problems that can prevent viewers from performing effective comparisons. Those problems include abrupt layout changes, a lack of prominent visual patterns to represent layouts, and a lack of direct contrast to highlight differences. In this paper, we present strategies to visualize changes of hierarchical data using treemaps. A new treemap layout algorithm is presented to reduce abrupt layout changes and produce consistent visual patterns. Techniques are proposed to effectively visualize the difference and contrast between two treemap snapshots in terms of the map items' colors, sizes, and positions. Experimental data show that our algorithm can achieve a good balance in maintaining a treemap's stability, continuity, readability, and average aspect ratio. A software tool is created to compare treemaps and generate the visualizations. User studies show that the users can better understand the changes in the hierarchy and layout, and more quickly notice the color and size differences using our method.
Keywords: Treemap;data visualisation;hierarchical data visualization;software tool;tree comparison;tree data structures;treemap layout algorithm;treemap layout algorithm.;treemap snapshots;visual patterns;visualize changes;
Author: Ying Tu; Han-Wei Shen

Year: 2007
Title: Exploring Multiple Trees through DAG Representations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376153
Abstract: We present a directed acyclic graph visualisation designed to allow interaction with a set of multiple classification trees, specifically to find overlaps and differences between groups of trees and individual trees. The work is motivated by the need to find a representation for multiple trees that has the space-saving property of a general graph representation and the intuitive parent-child direction cues present in individual representation of trees. Using example taxonomic data sets, we describe augmentations to the common barycenter DAG layout method that reveal shared sets of child nodes between common parents in a clearer manner. Other interactions such as displaying the multiple ancestor paths of a node when it occurs in several trees, and revealing intersecting sibling sets within the context of a single DAG representation are also discussed.
Keywords: DAG representations;DAG visualisation;Directed Acyclic Graph.;Multiple trees;data visualisation;directed acyclic graph;directed graphs;merging;merging;multiple classification trees;multiple trees;pattern classification;trees (mathematics);
Author: Graham, M.; Kennedy, J.

Year: 2007
Title: NodeTrix: a Hybrid Visualization of Social Networks
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376154
Abstract: The need to visualize large social networks is growing as hardware capabilities make analyzing large networks feasible and many new data sets become available. Unfortunately, the visualizations in existing systems do not satisfactorily resolve the basic dilemma of being readable both for the global structure of the network and also for detailed analysis of local communities. To address this problem, we present NodeTrix, a hybrid representation for networks that combines the advantages of two traditional representations: node-link diagrams are used to show the global structure of a network, while arbitrary portions of the network can be shown as adjacency matrices to better support the analysis of communities. A key contribution is a set of interaction techniques. These allow analysts to create a NodeTrix visualization by dragging selections to and from node-link and matrix forms, and to flexibly manipulate the NodeTrix representation to explore the dataset and create meaningful summary visualizations of their findings. Finally, we present a case study applying NodeTrix to the analysis of the InfoVis 2004 coauthorship dataset to illustrate the capabilities of NodeTrix as both an exploration tool and an effective means of communicating results.
Keywords: Aggregation;Algorithms;Computer Graphics;Computer Simulation;Hybrid visualization;InfoVis 2004 coauthorship dataset;Interaction.;Matrix visualization;Models, Theoretical;Network visualization;NodeTrix visualization;Social Support;User-Computer Interface;adjacency matrices;data structures;data visualisation;dragging selections;hardware capabilities;hybrid representation;interaction techniques;matrix algebra;social networks hybrid visualization;social sciences computing;
Author: Henry, N.; Fekete, J.-D.; McGuffin, M.J.

Year: 2007
Title: Multi-Level Graph Layout on the GPU
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376155
Abstract: This paper presents a new algorithm for force directed graph layout on the GPU. The algorithm, whose goal is to compute layouts accurately and quickly, has two contributions. The first contribution is proposing a general multi-level scheme, which is based on spectral partitioning. The second contribution is computing the layout on the GPU. Since the GPU requires a data parallel programming model, the challenge is devising a mapping of a naturally unstructured graph into a well-partitioned structured one. This is done by computing a balanced partitioning of a general graph. This algorithm provides a general multi-level scheme, which has the potential to be used not only for computation on the GPU, but also on emerging multi-core architectures. The algorithm manages to compute high quality layouts of large graphs in a fraction of the time required by existing algorithms of similar quality. An application for visualization of the topologies of ISP (Internet service provider) networks is presented.
Keywords: GPU;Graph layout;Internet service provider;computer graphics;data parallel programming model;directed graph layout;general multi-level scheme;graph partitioning;graph partitioning.;graph theory;multi-core architectures;multi-level graph layout;naturally unstructured graph;parallel programming;spectral partitioning;
Author: Frishman, Y.; Tal, A.

Year: 2007
Title: Illustrative Deformation for Data Exploration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376157
Abstract: Much of the visualization research has focused on improving the rendering quality and speed, and enhancing the perceptibility of features in the data. Recently, significant emphasis has been placed on focus+context (F+C) techniques (e.g., fisheye views and magnification lens) for data exploration in addition to viewing transformation and hierarchical navigation. However, most of the existing data exploration techniques rely on the manipulation of viewing attributes of the rendering system or optical attributes of the data objects, with users being passive viewers. In this paper, we propose a more active approach to data exploration, which attempts to mimic how we would explore data if we were able to hold it and interact with it in our hands. This involves allowing the users to physically or actively manipulate the geometry of a data object. While this approach has been traditionally used in applications, such as surgical simulation, where the original geometry of the data objects is well understood by the users, there are several challenges when this approach is generalized for applications, such as flow and information visualization, where there is no common perception as to the normal or natural geometry of a data object. We introduce a taxonomy and a set of transformations especially for illustrative deformation of general data exploration. We present combined geometric or optical illustration operators for focus+context visualization, and examine the best means for preventing the deformed context from being misperceived. We demonstrated the feasibility of this generalization with examples of flow, information and video visualization.
Keywords: Volume deformation;computational geometry;data exploration;data manipulation;data object geometry;data rendering quality;data visualisation;focus+context techniques;focus+context visualization;information visualization;interaction techniques;interaction techniques;interactive systems;rendering (computer graphics);
Author: Correa, C.D.; Silver, D.; Min Chen

Year: 2007
Title: An Effective Illustrative Visualization Framework Based on Photic Extremum Lines (PELs)
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376158
Abstract: Conveying shape using feature lines is an important visualization tool in visual computing. The existing feature lines (e.g., ridges, valleys, silhouettes, suggestive contours, etc.) are solely determined by local geometry properties (e.g., normals and curvatures) as well as the view position. This paper is strongly inspired by the observation in human vision and perception that a sudden change in the luminance plays a critical role to faithfully represent and recover the 3D information. In particular, we adopt the edge detection techniques in image processing for 3D shape visualization and present photic extremum lines (PELs) which emphasize significant variations of illumination over 3D surfaces. Comparing with the existing feature lines, PELs are more flexible and offer users more freedom to achieve desirable visualization effects. In addition, the user can easily control the shape visualization by changing the light position, the number of light sources, and choosing various light models. We compare PELs with the existing approaches and demonstrate that PEL is a flexible and effective tool to illustrate 3D surface and volume for visual computing.
Keywords: 3D shape visualization;Algorithms;Anatomy, Artistic;Computer Graphics;Computer Simulation;Image Interpretation, Computer-Assisted;Lighting;Medical Illustration;Models, Anatomic;Surface and volume illustration;User-Computer Interface;computational geometry;data visualisation;digital geometry processing.;edge detection;edge detection;feature lines;illumination;illustrative visualization framework;image processing;photic extremum lines;photic extremum lines (PELs);ridges and valleys;silhouettes;suggestive contours;
Author: Xuexiang Xie; Ying He; Feng Tian; Hock-Soon Sean; Xianfeng Gu; Hong Qin

Year: 2007
Title: Semantic Layers for Illustrative Volume Rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376159
Abstract: Direct volume rendering techniques map volumetric attributes (e.g., density, gradient magnitude, etc.) to visual styles. Commonly this mapping is specified by a transfer function. The specification of transfer functions is a complex task and requires expert knowledge about the underlying rendering technique. In the case of multiple volumetric attributes and multiple visual styles the specification of the multi-dimensional transfer function becomes more challenging and non-intuitive. We present a novel methodology for the specification of a mapping from several volumetric attributes to multiple illustrative visual styles. We introduce semantic layers that allow a domain expert to specify the mapping in the natural language of the domain. A semantic layer defines the mapping of volumetric attributes to one visual style. Volumetric attributes and visual styles are represented as fuzzy sets. The mapping is specified by rules that are evaluated with fuzzy logic arithmetics. The user specifies the fuzzy sets and the rules without special knowledge about the underlying rendering technique. Semantic layers allow for a linguistic specification of the mapping from attributes to visual styles replacing the traditional transfer function specification.
Keywords: Algorithms;Anatomy, Artistic;Computer Graphics;Focus+Context Techniques;Fuzzy Logic;Illustrative Visualization;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Medical Illustration;Models, Anatomic;Semantics;User-Computer Interface;Volume Visualization;data visualisation;formal specification;formal specification;fuzzy logic;fuzzy logic arithmetic;fuzzy set;fuzzy set theory;illustrative volume rendering;natural language;rendering (computer graphics);semantic layer;transfer function;transfer functions;visual style;
Author: Rautek, P.; Bruckner, S.; Eduard Groller, M.

Year: 2007
Title: Enhancing Depth-Perception with Flexible Volumetric Halos
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376160
Abstract: Volumetric data commonly has high depth complexity which makes it difficult to judge spatial relationships accurately. There are many different ways to enhance depth perception, such as shading, contours, and shadows. Artists and illustrators frequently employ halos for this purpose. In this technique, regions surrounding the edges of certain structures are darkened or brightened which makes it easier to judge occlusion. Based on this concept, we present a flexible method for enhancing and highlighting structures of interest using GPU-based direct volume rendering. Our approach uses an interactively defined halo transfer function to classify structures of interest based on data value, direction, and position. A feature-preserving spreading algorithm is applied to distribute seed values to neighboring locations, generating a controllably smooth field of halo intensities. These halo intensities are then mapped to colors and opacities using a halo profile function. Our method can be used to annotate features at interactive frame rates.
Keywords: Algorithms;Anatomy, Artistic;Computer Graphics;Computer Simulation;Depth Perception;GPU-based direct volume rendering;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Medical Illustration;Models, Anatomic;User-Computer Interface;Volume rendering;computational complexity;computer graphic equipment;data visualisation;depth complexity;depth-perception enhancement;feature-preserving spreading algorithm;flexible volumetric halos;halos;illustrative visualization;illustrative visualization;interactive systems;interactively defined halo transfer function;pattern classification;rendering (computer graphics);structure classification;transfer functions;
Author: Bruckner, S.; Groller, M.E.

Year: 2007
Title: Registration Techniques for Using Imperfect and Partially Calibrated Devices in Planar Multi-Projector Displays
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376161
Abstract: Today's PCs incorporate multiple CPUs and GPUs and are easily arranged in clusters for high-performance, interactive graphics. We present an approach based on hierarchical, screen-space tiles to parallelizing rendering with level of detail. Adapt tiles, render tiles, and machine tiles are associated with CPUs, GPUs, and PCs, respectively, to efficiently parallelize the workload with good resource utilization. Adaptive tile sizes provide load balancing while our level of detail system allows total and independent management of the load on CPUs and GPUs. We demonstrate our approach on parallel configurations consisting of both single PCs and a cluster of PCs.
Keywords: Geometric calibration;adapt tiles;hierarchical tiles;interactive graphics;load balancing;machine tiles;parallel age;parallel processing;photometric calibration;render tiles;rendering (computer graphics);resource allocation;resource utilization;screen-space tiles;tile-based level;tiled displays;
Author: Niski, K.; Cohen, J.D.

Year: 2007
Title: A Unified Paradigm For Scalable Multi-Projector Displays
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376162
Abstract: We present a general framework for the modeling and optimization of scalable multi-projector displays. Based on this framework, we derive algorithms that can robustly optimize the visual quality of an arbitrary combination of projectors without manual adjustment. When the projectors are tiled, we show that our framework automatically produces blending maps that outperform state-of-the-art projector blending methods. When all the projectors are superimposed, the framework can produce high-resolution images beyond the Nyquist resolution limits of component projectors. When a combination of tiled and superimposed projectors are deployed, the same framework harnesses the best features of both tiled and superimposed multi-projector projection paradigms. The framework creates for the first time a new unified paradigm that is agnostic to a particular configuration of projectors yet robustly optimizes for the brightness, contrast, and resolution of that configuration. In addition, we demonstrate that our algorithms support high resolution video at real-time interactive frame rates achieved on commodity graphics platforms. This work allows for inexpensive, compelling, flexible, and robust large scale visualization systems to be built and deployed very efficiently.
Keywords: Multi-projector displays;Nyquist resolution;automatic geometric alignment;blending;computer displays;data visualisation;graphics platform;high-resolution images;image resolution;large format displays;optimisation;optimization;photometric correction;projector blending method;real-time interactive frame;scalable multiprojector display;stitching;super-resolution;superimposed multiprojector projection paradigm;superimposed projection.;tiled displays;tiled projection paradigm;unified paradigm;visualization system;
Author: Damera-Venkata, N.; Chang, N.L.; DiCarlo, J.M.

Year: 2007
Title: Registration Techniques for Using Imperfect and Par tially Calibrated Devices in Planar Multi-Projector Displays
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376163
Abstract: Multi-projector displays today are automatically registered, both geometrically and photometrically, using cameras. Existing registration techniques assume pre-calibrated projectors and cameras that are devoid of imperfections such as lens distortion. In practice, however, these devices are usually imperfect and uncalibrated. Registration of each of these devices is often more challenging than the multi-projector display registration itself. To make tiled projection-based displays accessible to a layman user we should allow the use of uncalibrated inexpensive devices that are prone to imperfections. In this paper, we make two important advances in this direction. First, we present a new geometric registration technique that can achieve geometric alignment in the presence of severe projector lens distortion using a relatively inexpensive low-resolution camera. This is achieved via a closed-form model that relates the projectors to cameras, in planar multi-projector displays, using rational Bezier patches. This enables us to geometrically calibrate a 3000 times 2500 resolution planar multi-projector display made of 3 times 3 array of nine severely distorted projectors using a low resolution (640 times 480) VGA camera. Second, we present a photometric self-calibration technique for a projector-camera pair. This allows us to photometrically calibrate the same display made of nine projectors using a photometrically uncalibrated camera. To the best of our knowledge, this is the first work that allows geometrically imperfect projectors and photometrically uncalibrated cameras in calibrating multi-projector displays.
Keywords: Geometric calibration;cameras;closed-form model;computational geometry;display devices;geometric registration technique;image registration;image resolution;imagery registration;low-resolution camera;optical projectors;partially calibrated devices;photometric calibration;planar multiprojector displays;rational Bezier patches;tiled displays;
Author: Bhasker, E.; Juang, R.; Majumder, A.

Year: 2007
Title: Time Dependent Processing in a Parallel Pipeline Architecture
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376164
Abstract: Pipeline architectures provide a versatile and efficient mechanism for constructing visualizations, and they have been implemented in numerous libraries and applications over the past two decades. In addition to allowing developers and users to freely combine algorithms, visualization pipelines have proven to work well when streaming data and scale well on parallel distributed- memory computers. However, current pipeline visualization frameworks have a critical flaw: they are unable to manage time varying data. As data flows through the pipeline, each algorithm has access to only a single snapshot in time of the data. This prevents the implementation of algorithms that do any temporal processing such as particle tracing; plotting over time; or interpolation, fitting, or smoothing of time series data. As data acquisition technology improves, as simulation time-integration techniques become more complex, and as simulations save less frequently and regularly, the ability to analyze the time-behavior of data becomes more important. This paper describes a modification to the traditional pipeline architecture that allows it to accommodate temporal algorithms. Furthermore, the architecture allows temporal algorithms to be used in conjunction with algorithms expecting a single time snapshot, thus simplifying software design and allowing adoption into existing pipeline frameworks. Our architecture also continues to work well in parallel distributed-memory environments. We demonstrate our architecture by modifying the popular VTK framework and exposing the functionality to the ParaView application. We use this framework to apply time-dependent algorithms on large data with a parallel cluster computer and thereby exercise a functionality that previously did not exist.
Keywords: data acquisition;data acquisition technology;data streaming;data visualisation;data-parallel visualization pipeline;parallel architectures;parallel cluster computer;parallel distributed-memory computers;parallel distributed-memory environments;parallel pipeline architecture;temporal processing;time dependent processing;time varying data;time-varying data;visualization pipelines;
Author: Biddiscombe, J.; Geveci, B.; Martin, K.; Moreland, K.; Thompson, D.

Year: 2007
Title: Multifield
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376165
Abstract: Modern unsteady (multi-)field visualizations require an effective reduction of the data to be displayed. From a huge amount of information the most informative parts have to be extracted. Instead of the fuzzy application dependent notion of feature, a new approach based on information theoretic concepts is introduced in this paper to detect important regions. This is accomplished by extending the concept of local statistical complexity from finite state cellular automata to discretized (multi-)fields. Thus, informative parts of the data can be highlighted in an application-independent, purely mathematical sense. The new measure can be applied to unsteady multifields on regular grids in any application domain. The ability to detect and visualize important parts is demonstrated using diffusion, flow, and weather simulations.
Keywords: Cluster Analysis;Cluster detection analysis;Computer Graphics;Computer Simulation;Gases;Imaging, Three-Dimensional;Models, Chemical;Models, Molecular;Molecular Conformation;Phase Transition;User-Computer Interface;data visualisation;evolution graph view;finite state cellular automata;finite state machines;fuzzy application dependent notion;glyph visualization;information theoretic concept;information theory;local statistical complexity;molecular dynamics visualization;multifield visualization;out-of-core techniques;statistical analysis;time-dependent scattered data;
Author: Janicke, H.; Wiebel, A.; Scheuermann, G.; Kollmann, W.

Year: 2007
Title: Interactive Visual Analysis of Perfusion Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376166
Abstract: Perfusion data are dynamic medical image data which characterize the regional blood flow in human tissue. These data bear a great potential in medical diagnosis, since diseases can be better distinguished and detected at an earlier stage compared to static image data. The wide-spread use of perfusion data is hampered by the lack of efficient evaluation methods. For each voxel, a time-intensity curve characterizes the enhancement of a contrast agent. Parameters derived from these curves characterize the perfusion and have to be integrated for diagnosis. The diagnostic evaluation of this multi-field data is challenging and time-consuming due to its complexity. For the visual analysis of such datasets, feature-based approaches allow to reduce the amount of data and direct the user to suspicious areas. We present an interactive visual analysis approach for the evaluation of perfusion data. For this purpose, we integrate statistical methods and interactive feature specification. Correlation analysis and Principal Component Analysis (PCA) are applied for dimension reduction and to achieve a better understanding of the inter-parameter relations. Multiple, linked views facilitate the definition of features by brushing multiple dimensions. The specification result is linked to all views establishing a focus+context style of visualization in 3D. We discuss our approach with respect to clinical datasets from the three major application areas: ischemic stroke diagnosis, breast tumor diagnosis, as well as the diagnosis of the coronary heart disease (CHD). It turns out that the significance of perfusion parameters strongly depends on the individual patient, scanning parameters, and data pre-processing.
Keywords: Blood Flow Velocity;Blood Vessels;Computer Graphics;Computer Simulation;Databases, Factual;Humans;Integrating InfoVis/SciVis;Models, Cardiovascular;Multi-field Visualization;PCA;Rheology;Time-varying Volume Data;User-Computer Interface;Visual Data Mining;contrast agent enhancement;coronary heart disease;correlation analysis;correlation methods;diagnostic evaluation;dynamic medical image data;evaluation methods;feature-based approaches;human tissue;interactive visual analysis;medical diagnosis;medical image processing;perfusion data evaluation;principal component analysis;principal component analysis;regional blood flow;statistical methods;
Author: Oeltze, S.; Doleisch, H.; Hauser, H.; Muigg, P.; Preim, B.

Year: 2007
Title: Variable Interactions in Query-Driven Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376167
Abstract: Our ability to generate ever-larger, increasingly-complex data, has established the need for scalable methods that identify, and provide insight into, important variable trends and interactions. Query-driven methods are among the small subset of techniques that are able to address both large and highly complex datasets. This paper presents a new method that increases the utility of query-driven techniques by visually conveying statistical information about the trends that exist between variables in a query. In this method, correlation fields, created between pairs of variables, are used with the cumulative distribution functions of variables expressed in a users query. This integrated use of cumulative distribution functions and correlation fields visually reveals, with respect to the solution space of the query, statistically important interactions between any three variables, and allows for trends between these variables to be readily identified. We demonstrate our method by analyzing interactions between variables in two flame-front simulations.
Keywords: Multivariate Data;Query-Driven Visualization;correlation field;cumulative distribution function;data visualisation;query processing;query-driven visualization;statistical analysis;statistical information;
Author: Gosink, L.J.; Anderson, J.C.; Wes Bethel, E.; Joy, K.I.

Year: 2007
Title: Visual Analysis of the Air Pollution Problem in Hong Kong
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376168
Abstract: We present a comprehensive system for weather data visualization. Weather data are multivariate and contain vector fields formed by wind speed and direction. Several well-established visualization techniques such as parallel coordinates and polar systems are integrated into our system. We also develop various novel methods, including circular pixel bar charts embedded into polar systems, enhanced parallel coordinates with S-shape axis, and weighted complete graphs. Our system was used to analyze the air pollution problem in Hong Kong and some interesting patterns have been found.
Keywords: Air Pollutants;Air Pollution;Computer Simulation;Environmental Monitoring;Hong Kong;Hong Kong;Imaging, Three-Dimensional;Models, Theoretical;S-shape axis;User-Computer Interface;Weather data visualization;air pollution;air pollution;air pollution problem;circular pixel bar charts;data visualisation;enhanced parallel coordinates;graph theory;meteorology;parallel coordinates;polar system;polar systems;visual analytics.;weather data visualization;weighted complete graphs;
Author: Huamin Qu; Wing-Yi Chan; Anbang Xu; Kai-Lun Chung; Kai-Hon Lau; Ping Guo

Year: 2007
Title: Topological Landscapes: A Terrain Metaphor for Scientific Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376169
Abstract: Scientific visualization and illustration tools are designed to help people understand the structure and complexity of scientific data with images that are as informative and intuitive as possible. In this context the use of metaphors plays an important role since they make complex information easily accessible by using commonly known concepts. In this paper we propose a new metaphor, called "topological landscapes," which facilitates understanding the topological structure of scalar functions. The basic idea is to construct a terrain with the same topology as a given dataset and to display the terrain as an easily understood representation of the actual input data. In this projection from an n-dimensional scalar function to a two-dimensional (2D) model we preserve function values of critical points, the persistence (function span) of topological features, and one possible additional metric property (in our examples volume). By displaying this topologically equivalent landscape together with the original data we harness the natural human proficiency in understanding terrain topography and make complex topological information easily accessible.
Keywords: Contour Tree;Feature Detection (primary keyword);SOAR;Terrain;Topology;User Interfaces;Visual Analytics;data visualisation;feature detection;illustration tools;scientific data visualization;software tools;terrain metaphor;terrain topography;topological landscapes;user interfaces;user interfaces;visual analytics;
Author: Weber, G.H.; Bremer, P.-T.; Pascucci, V.

Year: 2007
Title: IStar: A Raster Representation for Scalable Image and Volume Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376170
Abstract: Topology has been an important tool for analyzing scalar data and flow fields in visualization. In this work, we analyze the topology of multivariate image and volume data sets with discontinuities in order to create an efficient, raster-based representation we call IStar. Specifically, the topology information is used to create a dual structure that contains nodes and connectivity information for every segmentable region in the original data set. This graph structure, along with a sampled representation of the segmented data set, is embedded into a standard raster image which can then be substantially downsampled and compressed. During rendering, the raster image is upsampled and the dual graph is used to reconstruct the original function. Unlike traditional raster approaches, our representation can preserve sharp discontinuities at any level of magnification, much like scalable vector graphics. However, because our representation is raster-based, it is well suited to the real-time rendering pipeline. We demonstrate this by reconstructing our data sets on graphics hardware at real-time rates.
Keywords: Compression;IStar;Image Representation;Multi-field Visualization;Topology;dual graph;graph structure;graphics hardware;image representation;image segmentation;multivariate image;raster representation;real-time rates;real-time rendering;rendering (computer graphics);scalable image representation;segmented data set;topology;topology information;volume data;
Author: Kniss, J.; Hunt, W.; Potter, K.; Sen, P.

Year: 2007
Title: Topologically Clean Distance Fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376171
Abstract: Analysis of the results obtained from material simulations is important in the physical sciences. Our research was motivated by the need to investigate the properties of a simulated porous solid as it is hit by a projectile. This paper describes two techniques for the generation of distance fields containing a minimal number of topological features, and we use them to identify features of the material. We focus on distance fields defined on a volumetric domain considering the distance to a given surface embedded within the domain. Topological features of the field are characterized by its critical points. Our first method begins with a distance field that is computed using a standard approach, and simplifies this field using ideas from Morse theory. We present a procedure for identifying and extracting a feature set through analysis of the MS complex, and apply it to find the invariants in the clean distance field. Our second method proceeds by advancing a front, beginning at the surface, and locally controlling the creation of new critical points. We demonstrate the value of topologically clean distance fields for the analysis of filament structures in porous solids. Our methods produce a curved skeleton representation of the filaments that helps material scientists to perform a detailed qualitative and quantitative analysis of pores, and hence infer important material properties. Furthermore, we provide a set of criteria for finding the "difference" between two skeletal structures, and use this to examine how the structure of the porous solid changes over several timesteps in the simulation of the particle impact.
Keywords: MS complex;Morse theory;Morse theory;Morse-Smale complex;computational geometry;critical point;curve fitting;curved skeleton representation;distance field;filament structures;material science;porous solid;porous solids;simulated porous solid;topological simplification;topologically clean distance fields;topology;volumetric domain;wavefront;
Author: Gyulassy, A.G.; Duchaineau, M.A.; Vijay Natarajan; Pascucci, V.; Bringa, E.M.; Higginbotham, A.; Hamann, B.

Year: 2007
Title: Efficient Computation of Morse-Smale Complexes for Three-dimensional Scalar Functions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376172
Abstract: The Morse-Smale complex is an efficient representation of the gradient behavior of a scalar function, and critical points paired by the complex identify topological features and their importance. We present an algorithm that constructs the Morse-Smale complex in a series of sweeps through the data, identifying various components of the complex in a consistent manner. All components of the complex, both geometric and topological, are computed, providing a complete decomposition of the domain. Efficiency is maintained by representing the geometry of the complex in terms of point sets.
Keywords: 3D scalar fields;Morse theory;Morse-Smale complex;Morse-Smale complexes;computational geometry;computational topology;data structures;data visualisation;feature detection;geometry;gradient behavior representation;multiresolution;simplification;three-dimensional scalar function;topological data structure;topology;topology-based visualization;
Author: Gyulassy, A.; Natarajan, V.; Pascucci, V.; Hamann, B.

Year: 2007
Title: Similarity-Guided Streamline Placement with Error Evaluation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376173
Abstract: Most streamline generation algorithms either provide a particular density of streamlines across the domain or explicitly detect features, such as critical points, and follow customized rules to emphasize those features. However, the former generally includes many redundant streamlines, and the latter requires Boolean decisions on which points are features (and may thus suffer from robustness problems for real-world data). We take a new approach to adaptive streamline placement for steady vector fields in 2D and 3D. We define a metric for local similarity among streamlines and use this metric to grow streamlines from a dense set of candidate seed points. The metric considers not only Euclidean distance, but also a simple statistical measure of shape and directional similarity. Without explicit feature detection, our method produces streamlines that naturally accentuate regions of geometric interest. In conjunction with this method, we also propose a quantitative error metric for evaluating a streamline representation based on how well it preserves the information from the original vector field. This error metric reconstructs a vector field from points on the streamline representation and computes a difference of the reconstruction from the original vector field.
Keywords: Adaptive streamlines;Boolean decision;Euclidean distance;data visualisation;error evaluation;error statistics;flow;flow visualisation;quantitative error metric;shape matching;shape matching;similarity-guided streamline placement;streamline representation;vector field reconstruction;
Author: Yuan Chen; Cohen, J.D.; Krolik, J.H.

Year: 2007
Title: Efficient Visualization of Lagrangian Coherent Structures by Filtered AMR Ridge Extraction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376174
Abstract: This paper presents a method for filtered ridge extraction based on adaptive mesh refinement. It is applicable in situations where the underlying scalar field can be refined during ridge extraction. This requirement is met by the concept of Lagrangian coherent structures which is based on trajectories started at arbitrary sampling grids that are independent of the underlying vector field. The Lagrangian coherent structures are extracted as ridges in finite Lyapunov exponent fields computed from these grids of trajectories. The method is applied to several variants of finite Lyapunov exponents, one of which is newly introduced. High computation time due to the high number of required trajectories is a main drawback when computing Lyapunov exponents of 3-dimensional vector fields. The presented method allows a substantial speed-up by avoiding the seeding of trajectories in regions where no ridges are present or do not satisfy the prescribed filter criteria such as a minimum finite Lyapunov exponent.
Keywords: Lagrangian coherent structure visualization;Lyapunov methods;adaptive mesh refinement;arbitrary sampling grids;coherent structures;computational fluid dynamics;feature extraction;filtered AMR ridge extraction;filtering theory;finite Lyapunov exponent fields;flow visualisation;flow visualization;mesh generation;ridge extraction;unsteady vector fields;vector field topology;vector fields;
Author: Sadlo, F.; Peikert, R.

Year: 2007
Title: Efficient Computation and Visualization of Coherent Structures in Fluid Flow Applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376175
Abstract: The recently introduced notion of Finite-Time Lyapunov Exponent to characterize Coherent Lagrangian Structures provides a powerful framework for the visualization and analysis of complex technical flows. Its definition is simple and intuitive, and it has a deep theoretical foundation. While the application of this approach seems straightforward in theory, the associated computational cost is essentially prohibitive. Due to the Lagrangian nature of this technique, a huge number of particle paths must be computed to fill the space-time flow domain. In this paper, we propose a novel scheme for the adaptive computation of FTLE fields in two and three dimensions that significantly reduces the number of required particle paths. Furthermore, for three-dimensional flows, we show on several examples that meaningful results can be obtained by restricting the analysis to a well-chosen plane intersecting the flow domain. Finally, we examine some of the visualization aspects of FTLE-based methods and introduce several new variations that help in the analysis of specific aspects of a flow.
Keywords: 3D vector field visualization;Lagrangian structure;Lyapunov methods;coherent structure;computational fluid dynamics;data visualisation;data visualization;feature detection;finite-time Lyapunov exponent;flow visualisation;flow visualization;fluid flow visualization;space-time flow domain;
Author: Garth, C.; Gerhardt, F.; Tricoche, X.; Hagen, H.

Year: 2007
Title: Texture-based feature tracking for effective time-varying data visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376176
Abstract: Analyzing, visualizing, and illustrating changes within time-varying volumetric data is challenging due to the dynamic changes occurring between timesteps. The changes and variations in computational fluid dynamic volumes and atmospheric 3D datasets do not follow any particular transformation. Features within the data move at different speeds and directions making the tracking and visualization of these features a difficult task. We introduce a texture-based feature tracking technique to overcome some of the current limitations found in the illustration and visualization of dynamic changes within time-varying volumetric data. Our texture-based technique tracks various features individually and then uses the tracked objects to better visualize structural changes. We show the effectiveness of our texture-based tracking technique with both synthetic and real world time-varying data. Furthermore, we highlight the specific visualization, annotation, registration, and feature isolation benefits of our technique. For instance, we show how our texture-based tracking can lead to insightful visualizations of time-varying data. Such visualizations, more than traditional visualization techniques, can assist domain scientists to explore and understand dynamic changes.
Keywords: Feature tracking;data visualisation;effective time-varying data visualization;feature extraction;flow visualization;image registration;image texture;texture-based analysis;texture-based feature tracking;time-varying data;tracking;visualization;
Author: Caban, J.J.; Joshi, A.; Rheingans, P.

Year: 2007
Title: Interactive Visualization of Volumetric White Matter Connectivity in DT-MRI Using a Parallel-Hardware Hamilton-Jacobi Solver
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376177
Abstract: In this paper we present a method to compute and visualize volumetric white matter connectivity in diffusion tensor magnetic resonance imaging (DT-MRI) using a Hamilton-Jacobi (H-J) solver on the GPU (graphics processing unit). Paths through the volume are assigned costs that are lower if they are consistent with the preferred diffusion directions. The proposed method finds a set of voxels in the DTI volume that contain paths between two regions whose costs are within a threshold of the optimal path. The result is a volumetric optimal path analysis, which is driven by clinical and scientific questions relating to the connectivity between various known anatomical regions of the brain. To solve the minimal path problem quickly, we introduce a novel numerical algorithm for solving H-J equations, which we call the fast iterative method (FIM). This algorithm is well-adapted to parallel architectures, and we present a GPU-based implementation, which runs roughly 50-100 times faster than traditional CPU-based solvers for anisotropic H-J equations. The proposed system allows users to freely change the endpoints of interesting pathways and to visualize the optimal volumetric path between them at an interactive rate. We demonstrate the proposed method on some synthetic and real DT-MRI datasets and compare the performance with existing methods.
Keywords: Algorithms;Brain;Computer Graphics;Computer Simulation;DT-MRI;Diffusion Magnetic Resonance Imaging;Diffusion tensor visualization;Equipment Design;Equipment Failure Analysis;FIM;GPU;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Models, Biological;Models, Statistical;Nerve Fibers, Myelinated;Neural Pathways;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface;biodiffusion;biology computing;biomedical MRI;brain;brain;data visualisation;diffusion tensor magnetic resonance imaging;fast iterative method;graphics hardware;graphics processing unit;interactive visualization;interactivity.;iterative methods;neurophysiology;numerical algorithm;parallel-hardware Hamilton-Jacobi solver;tensors;volumetric optimal path analysis;volumetric white matter connectivity;
Author: Won-Ki Jeong; Fletcher, P.T.; Ran Tao; Whitaker, R.T.

Year: 2007
Title: Visualizing Whole-Brain DTI Tractography with GPU-based Tuboids and LoD Management
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376178
Abstract: Diffusion tensor imaging (DTI) of the human brain, coupled with tractography techniques, enable the extraction of large- collections of three-dimensional tract pathways per subject. These pathways and pathway bundles represent the connectivity between different brain regions and are critical for the understanding of brain related diseases. A flexible and efficient GPU-based rendering technique for DTI tractography data is presented that addresses common performance bottlenecks and image-quality issues, allowing interactive render rates to be achieved on commodity hardware. An occlusion query-based pathway LoD management system for streamlines/streamtubes/tuboids is introduced that optimizes input geometry, vertex processing, and fragment processing loads, and helps reduce overdraw. The tuboid, a fully-shaded streamtube impostor constructed entirely on the GPU from streamline vertices, is also introduced. Unlike full streamtubes and other impostor constructs, tuboids require little to no preprocessing or extra space over the original streamline data. The supported fragment processing levels of detail range from texture-based draft shading to full raycast normal computation, Phong shading, environment mapping, and curvature-correct text labeling. The presented text labeling technique for tuboids provides adaptive, aesthetically pleasing labels that appear attached to the surface of the tubes. Furthermore, an occlusion query aggregating and scheduling scheme for tuboids is described that reduces the query overhead. Results for a tractography dataset are presented, and demonstrate that LoD-managed tuboids offer benefits over traditional streamtubes both in performance and appearance.
Keywords: Algorithms;Brain;Computer Graphics;Computer Simulation;Diffusion Magnetic Resonance Imaging;GPU-based rendering technique;GPU-based tuboid;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Models, Biological;Models, Statistical;Nerve Fibers, Myelinated;Neural Pathways;Numerical Analysis, Computer-Assisted;Phong shading;Reproducibility of Results;Sensitivity and Specificity;Tuboids;User-Computer Interface;biomedical MRI;brain;computer graphic equipment;curvature-correct text labeling;data visualisation;diffusion tensor imaging;diseases;diseases;environment mapping;fragment processing load;fully-shaded streamtube impostor;human brain;input geometry;interactive gpu-centric rendering;level-of-detail management;medical image processing;neuronal pathways.;occlusion query-based pathway;optimisation;raycast normal computation;rendering (computer graphics);scheduling scheme;streamtubes;texture-based draft shading;tractography technique;vertex processing;
Author: Petrovic, V.; Fallon, J.; Kuester, F.

Year: 2007
Title: Topological Visualization of Brain Diffusion MRI Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376179
Abstract: Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.
Keywords: Algorithms;Brain;Computer Graphics;Computer Simulation;Diffusion Magnetic Resonance Imaging;Diffusion tensor;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Models, Biological;Models, Statistical;Nerve Fibers, Myelinated;Neural Pathways;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface;biodiffusion;biomedical MRI;brain;brain diffusion MRI data visualization;data visualisation;feature extraction;feature extraction;generic tensor fields;medical image processing;probabilistic fiber tracking;probabilistic fiber tracking method;probability;tensor topology;topological visualization;tracking;uncertainty visualization.;
Author: Schultz, T.; Theisel, H.; Seidel, H.-P.

Year: 2007
Title: Stochastic DT-MRI Connectivity Mapping on the GPU
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376180
Abstract: We present a method for stochastic fiber tract mapping from diffusion tensor MRI (DT-MRI) implemented on graphics hardware. From the simulated fibers we compute a connectivity map that gives an indication of the probability that two points in the dataset are connected by a neuronal fiber path. A Bayesian formulation of the fiber model is given and it is shown that the inversion method can be used to construct plausible connectivity. An implementation of this fiber model on the graphics processing unit (GPU) is presented. Since the fiber paths can be stochastically generated independently of one another, the algorithm is highly parallelizable. This allows us to exploit the data-parallel nature of the GPU fragment processors. We also present a framework for the connectivity computation on the GPU. Our implementation allows the user to interactively select regions of interest and observe the evolving connectivity results during computation. Results are presented from the stochastic generation of over 250,000 fiber steps per iteration at interactive frame rates on consumer-grade graphics hardware.
Keywords: Algorithms;Bayes methods;Bayesian formulation;Brain;Computer Graphics;Computer Simulation;Diffusion Magnetic Resonance Imaging;GPU;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Models, Biological;Models, Neurological;Models, Statistical;Nerve Fibers, Myelinated;Neural Pathways;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Stochastic Processes;User-Computer Interface;biodiffusion;biomedical MRI;brain;brain;computer graphic equipment;data visualisation;data visualization;diffusion tensor;diffusion tensor;graphics hardware;graphics processing unit;inversion method;magnetic resonance imaging;magnetic resonance imaging;medical image processing;neuronal fiber path;neurophysiology;parallel algorithm;probability;probability;stochastic DT-MRI connectivity mapping;stochastic fiber tract mapping;stochastic processes;stochastic tractography;tensors;
Author: McGraw, T.; Nadar, M.

Year: 2007
Title: Efficient Surface Reconstruction using Generalized Coulomb Potentials
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376181
Abstract: We propose a novel, geometrically adaptive method for surface reconstruction from noisy and sparse point clouds, without orientation information. The method employs a fast convection algorithm to attract the evolving surface towards the data points. The force field in which the surface is convected is based on generalized Coulomb potentials evaluated on an adaptive grid (i.e., an octree) using a fast, hierarchical algorithm. Formulating reconstruction as a convection problem in a velocity field generated by Coulomb potentials offers a number of advantages. Unlike methods which compute the distance from the data set to the implicit surface, which are sensitive to noise due to the very reliance on the distance transform, our method is highly resilient to shot noise since global, generalized Coulomb potentials can be used to disregard the presence of outliers due to noise. Coulomb potentials represent long-range interactions that consider all data points at once, and thus they convey global information which is crucial in the fitting process. Both the spatial and temporal complexities of our spatially-adaptive method are proportional to the size of the reconstructed object, which makes our method compare favorably with respect to previous approaches in terms of speed and flexibility. Experiments with sparse as well as noisy data sets show that the method is capable of delivering crisp and detailed yet smooth surfaces.
Keywords: Generalized Coulomb potentials;Implicit surfaces;Octrees;Polygonization;Surface reconstruction;adaptive grid;computational geometry;distance transform;electric potential;fast convection algorithm;generalized Coulomb potentials;geometrically adaptive method;noisy point clouds;octree;octrees;sparse point clouds;surface fitting;surface reconstruction;
Author: Jalba, A.C.; Roerdink, J.B.T.

Year: 2007
Title: Surface Extraction from Multi-Material Components for Metrology using Dual Energy CT
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376182
Abstract: This paper describes a novel method for creating surface models of multi-material components using dual energy computed tomography (DECT). The application scenario is metrology and dimensional measurement in industrial high resolution 3D X-ray computed tomography (3DCT). Based on the dual source / dual exposure technology this method employs 3DCT scans of a high precision micro-focus and a high energy macro-focus X-ray source. The presented work makes use of the advantages of dual X-ray exposure technology in order to facilitate dimensional measurements of multi-material components with high density material within low density material. We propose a workflow which uses image fusion and local surface extraction techniques: a prefiltering step reduces noise inherent in the data. For image fusion the datasets have to be registered. In the fusion step the benefits of both scans are combined. The structure of the specimen is taken from the low precision, blurry, high energy dataset while the sharp edges are adopted and fused into the resulting image from the high precision, crisp, low energy dataset. In the final step a reliable surface model is extracted from the fused dataset using a local adaptive technique. The major contribution of this paper is the development of a specific workflow for dimensional measurements of multi-material industrial components, which takes two X-ray CT datasets with complementary strengths and weaknesses into account. The performance of the workflow is discussed using a test specimen as well as two real world industrial parts. As result, a significant improvement in overall measurement precision, surface geometry and mean deviation to reference measurement compared to single exposure scans was facilitated.
Keywords: Absorptiometry, Photon;Algorithms;DECT image fusion;Dual Energy CT;Equipment Failure Analysis;Imaging, Three-Dimensional;Materials Testing;Pattern Recognition, Automated;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Subtraction Technique;Surface Properties;Tomography, X-Ray Computed;computerised tomography;data visualisation;dimensional measurement;dual X-ray exposure technology;dual energy computed tomography;image fusion;image fusion;image registration;image resolution;local surface extraction;measurement;medical image processing;metrology;metrology;multimaterial component;surface extraction;surface fitting;surface geometry;variance comparison.;
Author: Heinzl, C.; Kastner, J.; Groller, E.

Year: 2007
Title: Construction of Simplified Boundary Surfaces from Serial-sectioned Metal Micrographs
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376183
Abstract: We present a method for extracting boundary surfaces from segmented cross-section image data. We use a constrained Potts model to interpolate an arbitrary number of region boundaries between segmented images. This produces a segmented volume from which we extract a triangulated boundary surface using well-known marching tetrahedra methods. This surface contains staircase-like artifacts and an abundance of unnecessary triangles. We describe an approach that addresses these problems with a voxel-accurate simplification algorithm that reduces surface complexity by an order of magnitude. Our boundary interpolation and simplification methods are novel contributions to the study of surface extraction from segmented cross-sections. We have applied our method to construct polycrystal grain boundary surfaces from micrographs of a sample of the metal tantalum.
Keywords: Life Sciences and Engineering;Polygonal meshes;Surface extraction;Visualization in Physical Sciences;boundary interpolation methods;computational complexity;computational geometry;constrained Potts model;data visualisation;feature extraction;grain boundaries;image segmentation;interpolation;marching tetrahedra methods;materials testing;mesh generation;physics computing;polycrystal grain boundary surface construction;segmented cross-section image data;serial-sectioned metal micrographs;simplified boundary surface construction;surface complexity;surface structure;tantalum;triangulated boundary surface extraction;voxel-accurate simplification algorithm;
Author: Dillard, S.E.; Bingert, J.F.; Thoma, D.; Hamann, B.

Year: 2007
Title: Random-Accessible Compressed Triangle Meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376184
Abstract: With the exponential growth in size of geometric data, it is becoming increasingly important to make effective use of multilevel caches, limited disk storage, and bandwidth. As a result, recent work in the visualization community has focused either on designing sequential access compression schemes or on producing cache-coherent layouts of (uncompressed) meshes for random access. Unfortunately combining these two strategies is challenging as they fundamentally assume conflicting modes of data access. In this paper, we propose a novel order-preserving compression method that supports transparent random access to compressed triangle meshes. Our decompression method selectively fetches from disk, decodes, and caches in memory requested parts of a mesh. We also provide a general mesh access API for seamless mesh traversal and incidence queries. While the method imposes no particular mesh layout, it is especially suitable for cache-oblivious layouts, which minimize the number of decompression I/O requests and provide high cache utilization during access to decompressed, in-memory portions of the mesh. Moreover, the transparency of our scheme enables improved performance without the need for application code changes. We achieve compression rates on the order of 20:1 and significantly improved I/O performance due to reduced data transfer. To demonstrate the benefits of our method, we implement two common applications as benchmarks. By using cache-oblivious layouts for the input models, we observe 2-6 times overall speedup compared to using uncompressed meshes.
Keywords: API;I/O request;Mesh compression;application program interfaces;cache storage;cache-coherent layout;cache-coherent layouts;cache-oblivious layout;computational geometry;data transfer;disk storage;external memory algorithms;mesh data structures;mesh generation;multilevel cache;novel order-preserving compression method;random access;random-accessible compressed triangle mesh;sequential access compression scheme;
Author: Sung-Eui Yoon; Lindstrom, P.

Year: 2007
Title: LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376185
Abstract: Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.
Keywords: Algorithms;Anatomy, Cross-Sectional;Artificial Intelligence;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;LiveSync deformed viewing sphere;Models, Anatomic;Navigation;Reproducibility of Results;Sensitivity and Specificity;Surgery, Computer-Assisted;User-Computer Interface;data visualisation;interaction;interactive systems;interactive volume rendering;knowledge based systems;knowledge-based navigation;linked views;medical image;medical image processing;medical visualization;rendering (computer graphics);viewpoint selection.;visualization method;
Author: Kohlmann, P.; Bruckner, S.; Eduard Groller, M.; Kanitsar, A.

Year: 2007
Title: Navigating in a Shape Space of Registered Models
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376186
Abstract: New product development involves people with different backgrounds. Designers, engineers, and consumers all have different design criteria, and these criteria interact. Early concepts evolve in this kind of collaborative context, and there is a need for dynamic visualization of the interaction between design shape and other shape-related design criteria. In this paper, a morphable model is defined from simplified representations of suitably chosen real cars, providing a continuous shape space to navigate, manipulate and visualize. Physical properties and consumer-provided scores for the real cars (such as 'weight' and 'sportiness') are estimated for new designs across the shape space. This coupling allows one to manipulate the shape directly while reviewing the impact on estimated criteria, or conversely, to manipulate the criterial values of the current design to produce a new shape with more desirable attributes.
Keywords: CAD;Morphable model;barycentric coordinates;continuous shape space;data visualisation;design criteria;design space.;dynamic visualization;product development;product development;registered models;shape space;shape-related design criteria;
Author: Smith, R.C.; Pawlicki, R.; Kokai, I.R.; Finger, J.; Vetter, T.

Year: 2007
Title: Querying and Creating Visualizations by Analogy
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376187
Abstract: While there have been advances in visualization systems, particularly in multi-view visualizations and visual exploration, the process of building visualizations remains a major bottleneck in data exploration. We show that provenance metadata collected during the creation of pipelines can be reused to suggest similar content in related visualizations and guide semi-automated changes. We introduce the idea of query-by-example in the context of an ensemble of visualizations, and the use of analogies as first-class operations in a system to guide scalable interactions. We describe an implementation of these techniques in VisTrails, a publicly-available, open-source system.
Keywords: VisTrails;analogy;data exploration;data visualisation;meta data;multiview visualizations;open-source system;pipeline processing;pipelines;provenance metadata;public domain software;query processing;query-by-example;query-by-example;visual exploration;visualization systems;visualization systems;
Author: Scheidegger, C.E.; Vo, H.T.; Koop, D.; Freire, J.; Silva, C.T.

Year: 2007
Title: Contextualized Videos: Combining Videos with Environment Models to Support Situational Understanding
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376188
Abstract: Multiple spatially-related videos are increasingly used in security, communication, and other applications. Since it can be difficult to understand the spatial relationships between multiple videos in complex environments (e.g. to predict a person's path through a building), some visualization techniques, such as video texture projection, have been used to aid spatial understanding. In this paper, we identify and begin to characterize an overall class of visualization techniques that combine video with 3D spatial context. This set of techniques, which we call contextualized videos, forms a design palette which must be well understood so that designers can select and use appropriate techniques that address the requirements of particular spatial video tasks. In this paper, we first identify user tasks in video surveillance that are likely to benefit from contextualized videos and discuss the video, model, and navigation related dimensions of the contextualized video design space. We then describe our contextualized video testbed which allows us to explore this design space and compose various video visualizations for evaluation. Finally, we describe the results of our process to identify promising design patterns through user selection of visualization features from the design space, followed by user interviews.
Keywords: 3D spatial context;Computer Graphics;Environment;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Theoretical;Orientation;User-Computer Interface;Video Recording;complex environments;contextualized videos;data visualisation;design space;multiple spatially-related videos;situational awareness;spatial relationships;testbed design and evaluation.;video signal processing;video surveillance;video texture projection;videos;virtual environment models;
Author: Yi Wang; Krum, D.M.; Coelho, E.M.; Bowman, D.A.

Year: 2007
Title: Lattice-Based Volumetric Global Illumination
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376189
Abstract: We describe a novel volumetric global illumination framework based on the face-centered cubic (FCC) lattice. An FCC lattice has important advantages over a Cartesian lattice. It has higher packing density in the frequency domain, which translates to better sampling efficiency. Furthermore, it has the maximal possible kissing number (equivalent to the number of nearest neighbors of each site), which provides optimal 3D angular discretization among all lattices. We employ a new two-pass (illumination and rendering) global illumination scheme on an FCC lattice. This scheme exploits the angular discretization to greatly simplify the computation in multiple scattering and to minimize illumination information storage. The GPU has been utilized to further accelerate the rendering stage. We demonstrate our new framework with participating media and volume rendering with multiple scattering, where both are significantly faster than traditional techniques with comparable quality.
Keywords: FCC lattice;GPU.;Volume visualization;angular discretization;data visualisation;face-centered cubic lattice;lattice;lattice-based volumetric global illumination;lighting;multiple scattering;multiple scattering;packing density;participating media;physics computing;rendering;rendering (computer graphics);sampling;volume rendering;
Author: Feng Qiu; Fang Xu; Zhe Fan; Neophytos, N.; Kaufman, A.; Mueller, K.

Year: 2007
Title: A Flexible Multi-Volume Shader Framework for Arbitrarily Intersecting Multi-Resolution Datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376190
Abstract: We present a powerful framework for 3D-texture-based rendering of multiple arbitrarily intersecting volumetric datasets. Each volume is represented by a multi-resolution octree-based structure and we use out-of-core techniques to support extremely large volumes. Users define a set of convex polyhedral volume lenses, which may be associated with one or more volumetric datasets. The volumes or the lenses can be interactively moved around while the region inside each lens is rendered using interactively defined multi-volume shaders. Our rendering pipeline splits each lens into multiple convex regions such that each region is homogenous and contains a fixed number of volumes. Each such region is further split by the brick boundaries of the associated octree representations. The resulting puzzle of lens fragments is sorted in front-to-back or back-to-front order using a combination of a view-dependent octree traversal and a GPU-based depth peeling technique. Our current implementation uses slice-based volume rendering and allows interactive roaming through multiple intersecting multi-gigabyte volumes.
Keywords: 3D-texture-based rendering;GPU-based depth peeling technique;Multi-volume visualization;constructive solid geometry;convex polyhedral volume lenses;display algorithms;flexible multivolume shader framework;intersecting multiresolution datasets;multiple intersecting multi-gigabyte volumes;multiresolution octree-based structure;octrees;out-of-core techniques;rendering (computer graphics);shading;slice-based volume rendering;view-dependent octree traversal;volumetric datasets;
Author: Plate, J.; Holtkaemper, T.; Froehlich, B.

Year: 2007
Title: Scalable Hybrid Unstructured and Structured Grid Raycasting
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376191
Abstract: This paper presents a scalable framework for real-time raycasting of large unstructured volumes that employs a hybrid bricking approach. It adaptively combines original unstructured bricks in important (focus) regions, with structured bricks that are resampled on demand in less important (context) regions. The basis of this focus+context approach is interactive specification of a scalar degree of interest (DOI) function. Thus, rendering always considers two volumes simultaneously: a scalar data volume, and the current DOI volume. The crucial problem of visibility sorting is solved by raycasting individual bricks and compositing in visibility order from front to back. In order to minimize visual errors at the grid boundary, it is always rendered accurately, even for resampled bricks. A variety of different rendering modes can be combined, including contour enhancement. A very important property of our approach is that it supports a variety of cell types natively, i.e., it is not constrained to tetrahedral grids, even when interpolation within cells is used. Moreover, our framework can handle multi-variate data, e.g., multiple scalar channels such as temperature or pressure, as well as time-dependent data. The combination of unstructured and structured bricks with different quality characteristics such as the type of interpolation or resampling resolution in conjunction with custom texture memory management yields a very scalable system.
Keywords: Focus+Context Techniques;Hardware-Assisted Volume Rendering;Volume Rendering of Unstructured Grids;focus-context technique;grid raycasting;hardware-assisted volume rendering;hybrid bricking approach;interactive specification;ray tracing;rendering (computer graphics);visibility sorting;
Author: Muigg, P.; Hadwiger, M.; Doleisch, H.; Hauser, H.

Year: 2007
Title: Transform Coding for Hardware-accelerated Volume Rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376192
Abstract: Hardware-accelerated volume rendering using the GPU is now the standard approach for real-time volume rendering, although limited graphics memory can present a problem when rendering large volume data sets. Volumetric compression in which the decompression is coupled to rendering has been shown to be an effective solution to this problem; however, most existing techniques were developed in the context of software volume rendering, and all but the simplest approaches are prohibitive in a real-time hardware-accelerated volume rendering context. In this paper we present a novel block-based transform coding scheme designed specifically with real-time volume rendering in mind, such that the decompression is fast without sacrificing compression quality. This is made possible by consolidating the inverse transform with dequantization in such a way as to allow most of the reprojection to be precomputed. Furthermore, we take advantage of the freedom afforded by offline compression in order to optimize the encoding as much as possible while hiding this complexity from the decoder. In this context we develop a new block classification scheme which allows us to preserve perceptually important features in the compression. The result of this work is an asymmetric transform coding scheme that allows very large volumes to be compressed and then decompressed in real-time while rendering on the GPU.
Keywords: Compressed Volume Rendering;GPU;Hardware-accelerated Volume Rendering;Transform Coding;Volume Compression;compression quality;computer graphic equipment;data compression;decompression;dequantization;graphics memory;hardware-accelerated volume rendering;inverse transform;large volume data sets;real-time systems;real-time volume rendering;rendering (computer graphics);software volume rendering;transform coding;transform coding;volumetric compression;
Author: Fout, N.; Kwan-Liu Ma

Year: 2007
Title: Molecular Surface Abstraction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376193
Abstract: In this paper we introduce a visualization technique that provides an abstracted view of the shape and spatio-physico-chemical properties of complex molecules. Unlike existing molecular viewing methods, our approach suppresses small details to facilitate rapid comprehension, yet marks the location of significant features so they remain visible. Our approach uses a combination of filters and mesh restructuring to generate a simplified representation that conveys the overall shape and spatio-physico-chemical properties (e.g. electrostatic charge). Surface markings are then used in the place of important removed details, as well as to supply additional information. These simplified representations are amenable to display using stylized rendering algorithms to further enhance comprehension. Our initial experience suggests that our approach is particularly useful in browsing collections of large molecules and in readily making comparisons between them.
Keywords: Algorithms;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Chemical;Models, Molecular;Molecular Conformation;Surface Properties;biochemistry;biology computing;cartographic labeling;chemistry computing;data visualisation;electrostatic charge;mesh restructuring;molecular biophysics;molecular configurations;molecular surface abstraction;molecular surfaces;molecular visualization;protein;proteins;rendering (computer graphics);spatio-physico-chemical property;structural biology;stylized rendering algorithm;surface marking;surfaces;textures;visualization technique;
Author: Cipriano, G.; Gleicher, M.

Year: 2007
Title: Two-Level Approach to Efficient Visualization of Protein Dynamics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376194
Abstract: Proteins are highly flexible and large amplitude deformations of their structure, also called slow dynamics, are often decisive to their function. We present a two-level rendering approach that enables visualization of slow dynamics of large protein assemblies. Our approach is aligned with a hierarchical model of large scale molecules. Instead of constantly updating positions of large amounts of atoms, we update the position and rotation of residues, i.e., higher level building blocks of a protein. Residues are represented by one vertex only indicating its position and additional information defining the rotation. The atoms in the residues are generated on-the-fly on the GPU, exploiting the new graphics hardware geometry shader capabilities. Moreover, we represent the atoms by billboards instead of tessellated spheres. Our representation is then significantly faster and pixel precise. We demonstrate the usefulness of our new approach in the context of our collaborative bioinformatics project.
Keywords: Algorithms;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Chemical;Models, Molecular;Molecular visualization;Protein Conformation;Protein Folding;Proteins;Surface Properties;biology computing;collaborative bioinformatics project;data visualisation;graphics hardware geometry shader capability;graphics processor unit;groupware;hardware acceleration;protein dynamics;protein dynamics.;proteins;rendering (computer graphics);slow dynamics visualization;two-level rendering approach;
Author: Lampe, O.D.; Viola, I.; Reuter, N.; Hauser, H.

Year: 2007
Title: Visual Verification and Analysis of Cluster Detection for Molecular Dynamics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376195
Abstract: A current research topic in molecular thermodynamics is the condensation of vapor to liquid and the investigation of this process at the molecular level. Condensation is found in many physical phenomena, e.g. the formation of atmospheric clouds or the processes inside steam turbines, where a detailed knowledge of the dynamics of condensation processes will help to optimize energy efficiency and avoid problems with droplets of macroscopic size. The key properties of these processes are the nucleation rate and the critical cluster size. For the calculation of these properties it is essential to make use of a meaningful definition of molecular clusters, which currently is a not completely resolved issue. In this paper a framework capable of interactively visualizing molecular datasets of such nucleation simulations is presented, with an emphasis on the detected molecular clusters. To check the quality of the results of the cluster detection, our framework introduces the concept of flow groups to highlight potential cluster evolution over time which is not detected by the employed algorithm. To confirm the findings of the visual analysis, we coupled the rendering view with a schematic view of the clusters' evolution. This allows to rapidly assess the quality of the molecular cluster detection algorithm and to identify locations in the simulation data in space as well as in time where the cluster detection fails. Thus, thermodynamics researchers can eliminate weaknesses in their cluster detection algorithms. Several examples for the effective and efficient usage of our tool are presented.
Keywords: Algorithms;Cluster Analysis;Cluster detection analysis;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Chemical;Models, Molecular;Molecular Conformation;Surface Properties;condensation processes;energy efficiency;evolution graph view;glyph visualization;molecular cluster detection algorithm;molecular datasets;molecular dynamics method;molecular dynamics visualization;molecular thermodynamics;nucleation;nucleation simulations;out-of-core techniques;potential cluster evolution;steam turbines;time-dependent scattered data;vapor-liquid condensation;visual verification;
Author: Grottel, S.; Reina, G.; Vrabec, J.; Ertl, T.

Year: 2007
Title: CoViCAD: Comprehensive Visualization of Coronary Artery Disease
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376196
Abstract: We present novel, comprehensive visualization techniques for the diagnosis of patients with coronary artery disease using segmented cardiac MRI data. We extent an accepted medical visualization technique called the bull's eye plot by removing discontinuities, preserving the volumetric nature of the left ventricular wall and adding anatomical context. The resulting volumetric bull's eye plot can be used for the assessment of transmurality. We link these visualizations to a 3D view that presents viability information in a detailed anatomical context. We combine multiple MRI scans (whole heart anatomical data, late enhancement data) and multiple segmentations (polygonal heart model, late enhancement contours, coronary artery tree). By selectively combining different rendering techniques we obtain comprehensive yet intuitive visualizations of the various data sources.
Keywords: Algorithms;Cardiac MRI;CoViCAD;Computer Graphics;Computer Simulation;Coronary Artery Disease;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Magnetic Resonance Angiography;Models, Cardiovascular;Software;User-Computer Interface;biomedical MRI;bull's eye plot.;bulls eye plot;cardiology;coronary artery disease;coronary artery tree;data visualisation;image segmentation;late enhancement;late enhancement contours;late enhancement data;medical image processing;medical visualization;patient diagnosis;polygonal heart model;segmented cardiac MRI data;viability;visualization;whole heart anatomical data;
Author: Termeer, M.; Bescos, J.O.; Breeuwer, M.; Vilanova, A.; Gerritsen, F.; Groller, M.E.

Year: 2007
Title: Visualizing Large-Scale Uncertainty in Astrophysical Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376197
Abstract: Visualization of uncertainty or error in astrophysical data is seldom available in simulations of astronomical phenomena, and yet almost all rendered attributes possess some degree of uncertainty due to observational error. Uncertainties associated with spatial location typically vary significantly with scale and thus introduce further complexity in the interpretation of a given visualization. This paper introduces effective techniques for visualizing uncertainty in large-scale virtual astrophysical environments. Building upon our previous transparently scalable visualization architecture, we develop tools that enhance the perception and comprehension of uncertainty across wide scale ranges. Our methods include a unified color-coding scheme for representing log-scale distances and percentage errors, an ellipsoid model to represent positional uncertainty, an ellipsoid envelope model to expose trajectory uncertainty, and a magic-glass design supporting the selection of ranges of log-scale distance and uncertainty parameters, as well as an overview mode and a scalable WIM tool for exposing the magnitudes of spatial context and uncertainty.
Keywords: Uncertainty visualization;astronomy computing;astronomy.;data visualisation;interstellar data;large spatial scale;large-scale virtual astrophysical environment;log-scale distance;magic-glass design;rendering (computer graphics);trajectory uncertainty;uncertainty visualization;unified color-coding scheme;
Author: Hongwei Li; Chi-Wing Fu; Yinggang Li; Hanson, A.J.

Year: 2007
Title: Uncertainty Visualization in Medical Volume Rendering Using Probabilistic Animation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376198
Abstract: Direct volume rendering has proved to be an effective visualization method for medical data sets and has reached wide-spread clinical use. The diagnostic exploration, in essence, corresponds to a tissue classification task, which is often complex and time-consuming. Moreover, a major problem is the lack of information on the uncertainty of the classification, which can have dramatic consequences for the diagnosis. In this paper this problem is addressed by proposing animation methods to convey uncertainty in the rendering. The foundation is a probabilistic Transfer Function model which allows for direct user interaction with the classification. The rendering is animated by sampling the probability domain over time, which results in varying appearance for uncertain regions. A particularly promising application of this technique is a "sensitivity lens" applied to focus regions in the data set. The methods have been evaluated by radiologists in a study simulating the clinical task of stenosis assessment, in which the animation technique is shown to outperform traditional rendering in terms of assessment accuracy.
Keywords: Algorithms;Anatomy, Artistic;Computer Graphics;Computer Simulation;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Medical Illustration;Models, Anatomic;Models, Statistical;Reproducibility of Results;Sensitivity and Specificity;Uncertainty;Video Recording;biological tissues;computer animation;data visualisation;diagnostic medical imaging;direct user interaction;direct volume rendering;image classification;medical data sets;medical image processing;medical visualization;medical volume rendering;probabilistic animation;probabilistic transfer function model;probability;probability;rendering (computer graphics);tissue classification task;transfer function;uncertainty handling;uncertainty visualization;volume rendering;
Author: Lundstrom, C.; Ljung, P.; Persson, A.; Ynnerman, A.

Year: 2007
Title: Grid With a View: Optimal Texturing for Perception of Layered Surface Shape
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376199
Abstract: We present the results of two controlled studies comparing layered surface visualizations under various texture conditions. The task was to estimate surface normals, measured by accuracy of a hand-set surface normal probe. A single surface visualization was compared with the two-surfaces case under conditions of no texture and with projected grid textures. Variations in relative texture spacing on top and bottom surfaces were compared, as well as opacity of the top surface. Significant improvements are found for the textured cases over non-textured surfaces. Either larger or thinner top-surface textures, and lower top surface opacities are shown to give less bottom surface error. Top surface error appears to be highly resilient to changes in texture. Given the results we also present an example of how appropriate textures might be useful in volume visualization.
Keywords: Perception;data visualisation;grid computing;image texture;layered surface shape perception;layered surface visualizations;layered surfaces.;optimal texturing;optimal visualization;projected grid textures;relative texture spacing;texturing;
Author: Bair, A.; House, D.

Year: 2007
Title: Conjoint Analysis to Measure the Perceived Quality in Volume Rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376200
Abstract: Visualization algorithms can have a large number of parameters, making the space of possible rendering results rather high-dimensional. Only a systematic analysis of the perceived quality can truly reveal the optimal setting for each such parameter. However, an exhaustive search in which all possible parameter permutations are presented to each user within a study group would be infeasible to conduct. Additional complications may result from possible parameter co-dependencies. Here, we will introduce an efficient user study design and analysis strategy that is geared to cope with this problem. The user feedback is fast and easy to obtain and does not require exhaustive parameter testing. To enable such a framework we have modified a preference measuring methodology, conjoint analysis, that originated in psychology and is now also widely used in market research. We demonstrate our framework by a study that measures the perceived quality in volume rendering within the context of large parameter spaces.
Keywords: Algorithms;Computer Graphics;Conjoint Analysis;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Parameterized Algorithms;Quality Control;Reproducibility of Results;Sensitivity and Specificity;Visual Perception;Volume Visualization;conjoint analysis;data visualisation;market research;perceived quality;rendering (computer graphics);user feedback;visualization algorithms;volume rendering;
Author: Giesen, J.; Mueller, K.; Schuberth, E.; Lujin Wang; Zolliker, P.

Year: 2007
Title: Interactive sound rendering in complex and dynamic scenes using frustum tracing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376201
Abstract: We present a new approach for real-time sound rendering in complex, virtual scenes with dynamic sources and objects. Our approach combines the efficiency of interactive ray tracing with the accuracy of tracing a volumetric representation. We use a four-sided convex frustum and perform clipping and intersection tests using ray packet tracing. A simple and efficient formulation is used to compute secondary frusta and perform hierarchical traversal. We demonstrate the performance of our algorithm in an interactive system for complex environments and architectural models with tens or hundreds of thousands of triangles. Our algorithm can perform real-time simulation and rendering on a high-end PC.
Keywords: Acoustic propagation;Ray tracing;acoustic signal processing;complex-dynamic scene;frustum tracing;interactive sound rendering;interactive system;interactive systems;ray packet tracing;ray tracing;rendering (computer graphics);virtual scene;
Author: Lauterbach, C.; Chandak, A.; Manocha, D.

Year: 2007
Title: Listener-based Analysis of Surface Importance for Acoustic Metrics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376202
Abstract: Acoustic quality in room acoustics is measured by well defined quantities, like definition, which can be derived from simulated impulse response filters or measured values. These take into account the intensity and phase shift of multiple reflections due to a wave front emanating from a sound source. Definition (D<sub>50</sub>) and clarity (C<sub>50</sub>) for example correspond to the fraction of the energy received in total to the energy received in the first 50 ms at a certain listener position. Unfortunately, the impulse response measured at a single point does not provide any information about the direction of reflections, and about the reflection surfaces which contribute to this measure. For the visualization of room acoustics, however, this information is very useful since it allows to discover regions with high contribution and provides insight into the influence of all reflecting surfaces to the quality measure. We use the phonon tracing method to calculate the contribution of the reflection surfaces to the impulse response for different listener positions. This data is used to compute importance values for the geometry taking a certain acoustic metric into account. To get a visual insight into the directional aspect, we map the importance to the reflecting surfaces of the geometry. This visualization indicates which parts of the surfaces need to be changed to enhance the chosen acoustic quality measure. We apply our method to the acoustic improvement of a lecture hall by means of enhancing the overall speech comprehensibility (clarity) and evaluate the results using glyphs to visualize the clarity (C<sub>50</sub>) values at listener positions throughout the room.
Keywords: Acoustic Metric;Applications of Visualization;Phonon Tracing;Room Acoustics;Sound analytics;acoustic metrics;acoustic quality measure;architectural acoustics;data visualisation;impulse response;listener-based analysis;phonon tracing;room acoustics visualization;speech clarity;speech comprehensibility;transient response;
Author: Michel, F.; Deines, E.; Hering-Bertram, M.; Garth, C.; Hagen, H.

Year: 2007
Title: Shadow-Driven 4D Haptic Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376203
Abstract: Just as we can work with two-dimensional floor plans to communicate 3D architectural design, we can exploit reduced- dimension shadows to manipulate the higher-dimensional objects generating the shadows. In particular, by taking advantage of physically reactive 3D shadow-space controllers, we can transform the task of interacting with 4D objects to a new level of physical reality. We begin with a teaching tool that uses 2D knot diagrams to manipulate the geometry of 3D mathematical knots via their projections; our unique 2D haptic interface allows the user to become familiar with sketching, editing, exploration, and manipulation of 3D knots rendered as projected images on a 2D shadow space. By combining graphics and collision-sensing haptics, we can enhance the 2D shadow-driven editing protocol to successfully leverage 2D pen-and-paper or blackboard skills. Building on the reduced-dimension 2D editing tool for manipulating 3D shapes, we develop the natural analogy to produce a reduced-dimension 3D tool for manipulating 4D shapes. By physically modeling the correct properties of 4D surfaces, their bending forces, and their collisions in the 3D haptic controller interface, we can support full-featured physical exploration of 4D mathematical objects in a manner that is otherwise far beyond the experience accessible to human beings. As far as we are aware, this paper reports the first interactive system with force-feedback that provides "4D haptic visualization" permitting the user to model and interact with 4D cloth-like objects.
Keywords: 2D haptic interface;2D knot diagrams;2D pen-and-paper;2D shadow-driven editing protocol;3D architectural design;3D mathematical knots;4D haptic visualization;4D shapes;blackboard skills;collision-sensing haptics;data visualisation;force feedback;force feedback;haptic interfaces;haptics;higher-dimensional objects;knot theory;natural analogy;reactive 3D shadow-space controllers;reduced- dimension shadows;rendering (computer graphics);two-dimensional floor plans;visualization;
Author: Hui Zhang; Hanson, A.J.

Year: 2007
Title: High-Quality Multimodal Volume Rendering for Preoperative Planning of Neurosurgical Interventions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376204
Abstract: Surgical approaches tailored to an individual patient's anatomy and pathology have become standard in neurosurgery. Precise preoperative planning of these procedures, however, is necessary to achieve an optimal therapeutic effect. Therefore, multiple radiological imaging modalities are used prior to surgery to delineate the patient's anatomy, neurological function, and metabolic processes. Developing a three-dimensional perception of the surgical approach, however, is traditionally still done by mentally fusing multiple modalities. Concurrent 3D visualization of these datasets can, therefore, improve the planning process significantly. In this paper we introduce an application for planning of individual neurosurgical approaches with high-quality interactive multimodal volume rendering. The application consists of three main modules which allow to (1) plan the optimal skin incision and opening of the skull tailored to the underlying pathology; (2) visualize superficial brain anatomy, function and metabolism; and (3) plan the patient-specific approach for surgery of deep-seated lesions. The visualization is based on direct multi-volume raycasting on graphics hardware, where multiple volumes from different modalities can be displayed concurrently at interactive frame rates. Graphics memory limitations are avoided by performing raycasting on bricked volumes. For preprocessing tasks such as registration or segmentation, the visualization modules are integrated into a larger framework, thus supporting the entire workflow of preoperative planning.
Keywords: Algorithms;Computer Graphics;Computer Simulation;Hardware Assisted Raycasting;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Models, Anatomic;Models, Neurological;Multimodal Volume Rendering;Neurosurgery;Preoperative Care;Reproducibility of Results;Sensitivity and Specificity;Surgery Planning;Surgery, Computer-Assisted;User-Computer Interface;computer vision;concurrent 3D visualization;data visualisation;graphics hardware;high-quality multimodal volume rendering;medical computing;multi-volume raycasting;neurosurgical interventions preoperative planning;optimal skin incision;radiological imaging;rendering (computer graphics);surgery;
Author: Beyer, J.; Hadwiger, M.; Wolfsberger, S.; Buhler, K.

Year: 2007
Title: Topology, Accuracy, and Quality of Isosurface Meshes Using Dynamic Particles
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376205
Abstract: This paper describes a method for constructing isosurface triangulations of sampled, volumetric, three-dimensional scalar fields. The resulting meshes consist of triangles that are of consistently high quality, making them well suited for accurate interpolation of scalar and vector-valued quantities, as required for numerous applications in visualization and numerical simulation. The proposed method does not rely on a local construction or adjustment of triangles as is done, for instance, in advancing wavefront or adaptive refinement methods. Instead, a system of dynamic particles optimally samples an implicit function such that the particles' relative positions can produce a topologically correct Delaunay triangulation. Thus, the proposed method relies on a global placement of triangle vertices. The main contributions of the paper are the integration of dynamic particles systems with surface sampling theory and PDE-based methods for controlling the local variability of particle densities, as well as detailing a practical method that accommodates Delaunay sampling requirements to generate sparse sets of points for the production of high-quality tessellations.
Keywords: Delaunay triangulation;Delaunay triangulation.;Isosurface extraction;dynamic particle;isosurface triangulation;mesh generation;partial differential equation;partial differential equations;particle systems;surface sampling theory;
Author: Meyer, M.; Kirby, R.M.; Whitaker, R.

Year: 2007
Title: Visualization of Cosmological Particle-Based Datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376206
Abstract: We describe our visualization process for a particle-based simulation of the formation of the first stars and their impact on cosmic history. The dataset consists of several hundred time-steps of point simulation data, with each time-step containing approximately two million point particles. For each time-step, we interpolate the point data onto a regular grid using a method taken from the radiance estimate of photon mapping [21]. We import the resulting regular grid representation into ParaView [24], with which we extract isosurfaces across multiple variables. Our images provide insights into the evolution of the early universe, tracing the cosmic transition from an initially homogeneous state to one of increasing complexity. Specifically, our visualizations capture the build-up of regions of ionized gas around the first stars, their evolution, and their complex interactions with the surrounding matter. These observations will guide the upcoming James Webb Space Telescope, the key astronomy mission of the next decade.
Keywords: Astronomy;Cosmology.;Interpolation;Isosurface;ParaView;astronomical image processing;astronomy mission;cosmic history;cosmic transition tracing;cosmological particle-based dataset visualization;cosmology;data visualisation;early universe evolution;first stars formation;grid representation;isosurface extraction;particle-based simulation;photon mapping;point simulation data interpolation;star formation;stellar evolution;
Author: Navratil, P.A.; Johnson, J.L.; Bromm, V.

Year: 2007
Title: Segmentation of Three-dimensional Retinal Image Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376207
Abstract: We have combined methods from volume visualization and data analysis to support better diagnosis and treatment of human retinal diseases. Many diseases can be identified by abnormalities in the thicknesses of various retinal layers captured using optical coherence tomography (OCT). We used a support vector machine (SVM) to perform semi-automatic segmentation of retinal layers for subsequent analysis including a comparison of layer thicknesses to known healthy parameters. We have extended and generalized an older SVM approach to support better performance in a clinical setting through performance enhancements and graceful handling of inherent noise in OCT data by considering statistical characteristics at multiple levels of resolution. The addition of the multi-resolution hierarchy extends the SVM to have "global awareness". A feature, such as a retinal layer, can therefore be modeled within the SVM as a combination of statistical characteristics across all levels; thus capturing high- and low-frequency information. We have compared our semi-automatically generated segmentations to manually segmented layers for verification purposes. Our main goals were to provide a tool that could (i) be used in a clinical setting; (ii) operate on noisy OCT data; and (iii) isolate individual or multiple retinal layers in both healthy and disease cases that contain structural deformities.
Keywords: Algorithms;Artificial Intelligence;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Pattern Recognition, Automated;Retina;Retinoscopy;data analysis;data visualisation;human retinal diseases;image analysis;image processing.;image segmentation;medical image processing;optical coherence tomography;optical coherence tomography;optical tomography;retinal;retinal layers;segmentation;semiautomatic segmentation;support vector machine;support vector machine;support vector machines;three-dimensional retinal image data segmentation;volume visualization;volume visualization;
Author: Fuller, A.R.; Zawadzki, R.J.; Choi, S.; Wiley, D.F.; Werner, J.S.; Hamann, B.

Year: 2007
Title: Interactive Isosurface Ray Tracing of Time-Varying Tetrahedral Volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376208
Abstract: We describe a system for interactively rendering isosurfaces of tetrahedral finite-element scalar fields using coherent ray tracing techniques on the CPU. By employing state-of-the art methods in polygonal ray tracing, namely aggressive packet/frustum traversal of a bounding volume hierarchy, we can accommodate large and time-varying unstructured data. In conjunction with this efficiency structure, we introduce a novel technique for intersecting ray packets with tetrahedral primitives. Ray tracing is flexible, allowing for dynamic changes in isovalue and time step, visualization of multiple isosurfaces, shadows, and depth-peeling transparency effects. The resulting system offers the intuitive simplicity of isosurfacing, guaranteed-correct visual results, and ultimately a scalable, dynamic and consistently interactive solution for visualizing unstructured volumes.
Keywords: Isosurfaces;Ray Tracing;Scalar Fields;Tetrahedra;Time-varying data.;Unstructured meshes;aggressive packet/frustum traversal;interactive isosurface ray tracing;polygonal ray tracing;ray tracing;rendering;rendering (computer graphics);tetrahedral finite-element scalar fields;time-varying tetrahedral volumes;
Author: Wald, I.; Friedrich, H.; Knoll, A.; Hansen, C.D.

Year: 2007
Title: Generalized Streak Lines: Analysis and Visualization of Boundary Induced Vortices
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376209
Abstract: We present a method to extract and visualize vortices that originate from bounding walls of three-dimensional time- dependent flows. These vortices can be detected using their footprint on the boundary, which consists of critical points in the wall shear stress vector field. In order to follow these critical points and detect their transformations, affected regions of the surface are parameterized. Thus, an existing singularity tracking algorithm devised for planar settings can be applied. The trajectories of the singularities are used as a basis for seeding particles. This leads to a new type of streak line visualization, in which particles are released from a moving source. These generalized streak lines visualize the particles that are ejected from the wall. We demonstrate the usefulness of our method on several transient fluid flow datasets from computational fluid dynamics simulations.
Keywords: Skin friction;boundary induced vortex;computational fluid dynamics;computational fluid dynamics;confined flow;data visualisation;data visualisation;flow visualisation;flow visualization;generalized streak line;shear flow;shear flow visualisation;singularity tracking;singularity tracking algorithm;streak line;time-dependent vector fields.;vortex;vortices;
Author: Wiebel, A.; Tricoche, X.; Schneider, D.; Janicke, H.; Scheuermann, G.

Year: 2007
Title: Moment Invariants for the Analysis of 2D Flow Fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376210
Abstract: We present a novel approach for analyzing two-dimensional (2D) flow field data based on the idea of invariant moments. Moment invariants have traditionally been used in computer vision applications, and we have adapted them for the purpose of interactive exploration of flow field data. The new class of moment invariants we have developed allows us to extract and visualize 2D flow patterns, invariant under translation, scaling, and rotation. With our approach one can study arbitrary flow patterns by searching a given 2D flow data set for any type of pattern as specified by a user. Further, our approach supports the computation of moments at multiple scales, facilitating fast pattern extraction and recognition. This can be done for critical point classification, but also for patterns with greater complexity. This multi-scale moment representation is also valuable for the comparative visualization of flow field data. The specific novel contributions of the work presented are the mathematical derivation of the new class of moment invariants, their analysis regarding critical point features, the efficient computation of a novel feature space representation, and based upon this the development of a fast pattern recognition algorithm for complex flow structures.
Keywords: 2D flow field;2D flow pattern extraction;2D flow pattern visualisation;Feature Detection;Flow Visualization;Image Processing;Pattern Recognition;complex flow structures;computer vision application;critical point classification;data structures;data visualisation;feature extraction;feature space representation;flow field data visualization;moment invariants;multiscale moment representation;pattern classification;pattern recognition;
Author: Schlemmer, M.; Heringer, M.; Morr, F.; Hotz, I.; Bertram, M.-H.; Garth, C.; Kollmann, W.; Hamann, B.; Hagen, H.

Year: 2007
Title: Virtual Rheoscopic Fluids for Flow Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376211
Abstract: Physics-based flow visualization techniques seek to mimic laboratory flow visualization methods with virtual analogues. In this work we describe the rendering of a virtual rheoscopic fluid to produce images with results strikingly similar to laboratory experiments with real-world rheoscopic fluids using products such as Kalliroscope. These fluid additives consist of microscopic, anisotropic particles which, when suspended in the flow, align with both the flow velocity and the local shear to produce high-quality depictions of complex flow structures. Our virtual rheoscopic fluid is produced by defining a closed-form formula for the orientation of shear layers in the flow and using this orientation to volume render the flow as a material with anisotropic reflectance and transparency. Examples are presented for natural convection, thermocapillary convection, and Taylor-Couette flow simulations. The latter agree well with photographs of experimental results of Taylor-Couette flows from the literature.
Keywords: Flow visualization;Taylor-Couette flow simulations;anisotropic particles;complex flow structures;flow velocity;flow visualisation;flow visualization techniques;mechanical engineering computing;natural convection;rendering (computer graphics);rheoscopic fluids.;shear layers orientation;thermocapillary convection;virtual analogues;virtual rheoscopic fluid rendering;virtual rheoscopic fluids;
Author: Barth, W.L.; Burns, C.A.

Year: 2007
Title: Cores of Swirling Particle Motion in Unsteady Flows
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4376212
Abstract: In nature and in flow experiments particles form patterns of swirling motion in certain locations. Existing approaches identify these structures by considering the behavior of stream lines. However, in unsteady flows particle motion is described by path lines which generally gives different swirling patterns than stream lines. We introduce a novel mathematical characterization of swirling motion cores in unsteady flows by generalizing the approach of Sujudi/Haimes to path lines. The cores of swirling particle motion are lines sweeping over time, i.e., surfaces in the space-time domain. They occur at locations where three derived 4D vectors become coplanar. To extract them, we show how to re-formulate the problem using the parallel vectors operator. We apply our method to a number of unsteady flow fields.
Keywords: computational fluid dynamics;feature extraction;flow instability;flow visualisation;mathematical characterization;parallel vector operator;particle motion;space-time domain;swirling flow;swirling particle motion;unsteady flow visualization;unsteady flow visualization;
Author: Weinkauf, T.; Sahner, J.; Theisel, H.; Hege, H.-C.

Year: 2006
Title: Vis/InfoVis 2006 pre-pages
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015415
Abstract: These pre-pages to the issue contain a table of contents, a list of supporting organizations, a message from the Editor-in-Chief, the preface, committee and reviewer listings, 2005 visualization awards, and the keynote and capstone addressess for Vis and InfoVis.
Keywords: Awards and Prizes;Data Display;History, 21st Century;Portraits as Topic;Societies, Scientific;United States;
Author: null

Year: 2006
Title: ASK-GraphView: A Large Scale Graph Visualization System
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015416
Abstract: We describe ASK-GraphView, a node-link-based graph visualization system that allows clustering and interactive navigation of large graphs, ranging in size up to 16 million edges. The system uses a scalable architecture and a series of increasingly sophisticated clustering algorithms to construct a hierarchy on an arbitrary, weighted undirected input graph. By lowering the interactivity requirements we can scale to substantially bigger graphs. The user is allowed to navigate this hierarchy in a top down manner by interactively expanding individual clusters. ASK-GraphView also provides facilities for filtering and coloring, annotation and cluster labeling
Keywords: ASK-GraphView;Graph Clustering.;Graph Visualization;Information Visualization;cluster labeling;data visualisation;graph clustering;graph theory;interactive navigation;large scale graph visualization system;node-link-based graph visualization system;pattern clustering;weighted undirected input graph;
Author: Abello, J.; van Ham, F.; Krishnan, N.

Year: 2006
Title: MatrixExplorer: a Dual-Representation System to Explore Social Networks
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015417
Abstract: MatrixExplorer is a network visualization system that uses two representations: node-link diagrams and matrices. Its design comes from a list of requirements formalized after several interviews and a participatory design session conducted with social science researchers. Although matrices are commonly used in social networks analysis, very few systems support the matrix-based representations to visualize and analyze networks. MatrixExplorer provides several novel features to support the exploration of social networks with a matrix-based representation, in addition to the standard interactive filtering and clustering functions. It provides tools to reorder (layout) matrices, to annotate and compare findings across different layouts and find consensus among several clusterings. MatrixExplorer also supports node-link diagram views which are familiar to most users and remain a convenient way to publish or communicate exploration results. Matrix and node-link representations are kept synchronized at all stages of the exploration process
Keywords: Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Information Storage and Retrieval;MatrixExplorer;Models, Biological;Population Dynamics;Social Behavior;Social Support;Software;User-Computer Interface;clustering functions;consensus.;data visualisation;diagrams;dual-representation system;exploratory process;graph theory;interactive clustering;interactive filtering;matrix algebra;matrix ordering;matrix-based representations;matrix-based representations;network visualization system;node-link diagrams;node-link diagrams;pattern clustering;social networks;social networks visualization;social sciences computing;
Author: Henry, N.; Fekete, J.-D.

Year: 2006
Title: Visual Analysis of Multivariate State Transition Graphs
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015418
Abstract: We present a new approach for the visual analysis of state transition graphs. We deal with multivariate graphs where a number of attributes are associated with every node. Our method provides an interactive attribute-based clustering facility. Clustering results in metric, hierarchical and relational data, represented in a single visualization. To visualize hierarchically structured quantitative data, we introduce a novel technique: the bar tree. We combine this with a node-link diagram to visualize the hierarchy and an arc diagram to visualize relational data. Our method enables the user to gain significant insight into large state transition graphs containing tens of thousands of nodes. We illustrate the effectiveness of our approach by applying it to a real-world use case. The graph we consider models the behavior of an industrial wafer stepper and contains 55 043 nodes and 289 443 edges
Keywords: Graph visualization;arc diagram;bar tree;data visualisation;diagrams;finite state machines.;hierarchically structured quantitative data visualization;industrial wafer stepper;interactive attribute-based clustering facility;interactive clustering;multivariate state transition graphs;multivariate visualization;node-link diagram;pattern clustering;relational data;state spaces;transition systems;tree data structures;trees (mathematics);visual analysis;
Author: Pretorius, A.J.; Van Wijkk, J.J.

Year: 2006
Title: Balancing Systematic and Flexible Exploration of Social Networks
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015419
Abstract: Social network analysis (SNA) has emerged as a powerful method for understanding the importance of relationships in networks. However, interactive exploration of networks is currently challenging because: (1) it is difficult to find patterns and comprehend the structure of networks with many nodes and links, and (2) current systems are often a medley of statistical methods and overwhelming visual output which leaves many analysts uncertain about how to explore in an orderly manner. This results in exploration that is largely opportunistic. Our contributions are techniques to help structural analysts understand social networks more effectively. We present SocialAction, a system that uses attribute ranking and coordinated views to help users systematically examine numerous SNA measures. Users can (1) flexibly iterate through visualizations of measures to gain an overview, filter nodes, and find outliers, (2) aggregate networks using link structure, find cohesive subgroups, and focus on communities of interest, and (3) untangle networks by viewing different link types separately, or find patterns across different link types using a matrix overview. For each operation, a stable node layout is maintained in the network visualization so users can make comparisons. SocialAction offers analysts a strategy beyond opportunism, as it provides systematic, yet flexible, techniques for exploring social networks
Keywords: Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Information Storage and Retrieval;Models, Biological;Population Dynamics;Social Behavior;Social Support;Social networks;SocialAction;Software;User-Computer Interface;attribute ranking;attribute ranking;coordinated views;data analysis;data analysis;data visualisation;exploratory data analysis;graph theory;graphical user interfaces;interactive graph visualization;matrix algebra;matrix overview;network visualization;social network analysis;social sciences computing;statistical methods;
Author: Perer, A.; Shneiderman, B.

Year: 2006
Title: Multi-Scale Banking to 45 Degrees
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015420
Abstract: In his text Visualizing Data, William Cleveland demonstrates how the aspect ratio of a line chart can affect an analyst's perception of trends in the data. Cleveland proposes an optimization technique for computing the aspect ratio such that the average absolute orientation of line segments in the chart is equal to 45 degrees. This technique, called banking to 45deg, is designed to maximize the discriminability of the orientations of the line segments in the chart. In this paper, we revisit this classic result and describe two new extensions. First, we propose alternate optimization criteria designed to further improve the visual perception of line segment orientations. Second, we develop multi-scale banking, a technique that combines spectral analysis with banking to 45deg. Our technique automatically identifies trends at various frequency scales and then generates a banked chart for each of these scales. We demonstrate the utility of our techniques in a range of visualization tools and analysis examples
Keywords: Information visualization;aspect ratio;banking to 45 degrees;computational geometry;data visualisation;graphical perception;human factors;line chart;line charts;line segments;multiscale banking;optimisation;optimization technique;sparklines;spectral analysis;spectral analysis;time-series;visual perception;visual perception;visualization tools;
Author: Heer, J.; Agrawala, M.

Year: 2006
Title: Measuring Data Abstraction Quality in Multiresolution Visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015421
Abstract: Data abstraction techniques are widely used in multiresolution visualization systems to reduce visual clutter and facilitate analysis from overview to detail. However, analysts are usually unaware of how well the abstracted data represent the original dataset, which can impact the reliability of results gleaned from the abstractions. In this paper, we define two data abstraction quality measures for computing the degree to which the abstraction conveys the original dataset: the histogram difference measure and the nearest neighbor measure. They have been integrated within XmdvTool, a public-domain multiresolution visualization system for multivariate data analysis that supports sampling as well as clustering to simplify data. Several interactive operations are provided, including adjusting the data abstraction level, changing selected regions, and setting the acceptable data abstraction quality level. Conducting these operations, analysts can select an optimal data abstraction level. Also, analysts can compare different abstraction methods using the measures to see how well relative data density and outliers are maintained, and then select an abstraction method that meets the requirement of their analytic tasks
Keywords: Clustering;Metrics;Multiresolution Visualization Authors 1:;Sampling;XmdvTool;data abstraction quality measures;data analysis;data clustering;data structures;data visualisation;histogram difference measure;multivariate data analysis;nearest neighbor measure;pattern clustering;public-domain multiresolution visualization system;sampling methods;very large databases;
Author: Qingguang Cui; Ward, M.; Rundensteiner, E.; Jing Yang

Year: 2006
Title: Enabling Automatic Clutter Reduction in Parallel Coordinate Plots
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015422
Abstract: We have previously shown that random sampling is an effective clutter reduction technique and that a sampling lens can facilitate focus+context viewing of particular regions. This demands an efficient method of estimating the overlap or occlusion of large numbers of intersecting lines in order to automatically adjust the sampling rate within the lens. This paper proposes several ways for measuring occlusion in parallel coordinate plots. An empirical study into the accuracy and efficiency of the occlusion measures show that a probabilistic approach combined with a 'binning' technique is very fast and yet approaches the accuracy of the more expensive 'true' complete measurement
Keywords: Sampling;automatic clutter reduction;binning technique;clutter;data visualisation;density reduction;hidden feature removal;information visualisation;lens;occlusion;occlusion;overplotting;parallel coordinate plots;parallel coordinates.;probabilistic approach;probability;random sampling;random sampling;sampling methods;
Author: Ellis, G.; Dix, A.

Year: 2006
Title: Topographic Visualization of Prefix Propagation in the Internet
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015423
Abstract: We propose a new metaphor for the visualization of prefixes propagation in the Internet. Such a metaphor is based on the concept of topographic map and allows to put in evidence the relative importance of the Internet Service Providers (ISPs) involved in the routing of the prefix. Based on the new metaphor we propose an algorithm for computing layouts and experiment with such algorithm on a test suite taken from the real Internet. The paper extends the visualization approach of the BGPlay service, which is an Internet routing monitoring tool widely used by ISP operators
Keywords: BGPlay service;Graph Drawing;ISP;Interdomain Routing;Internet;Internet Service Providers;Internet Visualization;Internet routing monitoring tool;Spring Embedder;data visualisation;graph drawing;graph theory;prefix propagation;telecommunication network routing;topographic map;topographic visualization;
Author: Cortese, P.F.; Di Battista, G.; Moneta, A.; Patrignani, M.; Pizzonia, M.

Year: 2006
Title: Network Visualization by Semantic Substrates
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015424
Abstract: Networks have remained a challenge for information visualization designers because of the complex issues of node and link layout coupled with the rich set of tasks that users present. This paper offers a strategy based on two principles: (1) layouts are based on user-defined semantic substrates, which are non-overlapping regions in which node placement is based on node attributes, (2) users interactively adjust sliders to control link visibility to limit clutter and thus ensure comprehensibility of source and destination. Scalability is further facilitated by user control of which nodes are visible. We illustrate our semantic substrates approach as implemented in NVSS 1.0 with legal precedent data for up to 1122 court cases in three regions with 7645 legal citations
Keywords: NVSS 1.0;Network visualization;data visualisation;graphical user interfaces;graphical user interfaces;graphical user interfaces;information visualization;information visualization designers;legal citations;legal precedent data;network visualization;semantic substrate;user-defined semantic substrates;
Author: Shneiderman, B.; Aris, A.

Year: 2006
Title: Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015425
Abstract: A compound graph is a frequently encountered type of data set. Relations are given between items, and a hierarchy is defined on the items as well. We present a new method for visualizing such compound graphs. Our approach is based on visually bundling the adjacency edges, i.e., non-hierarchical edges, together. We realize this as follows. We assume that the hierarchy is shown via a standard tree visualization method. Next, we bend each adjacency edge, modeled as a B-spline curve, toward the polyline defined by the path via the inclusion edges from one node to another. This hierarchical bundling reduces visual clutter and also visualizes implicit adjacency edges between parent nodes that are the result of explicit adjacency edges between their respective child nodes. Furthermore, hierarchical edge bundling is a generic method which can be used in conjunction with existing tree visualization techniques. We illustrate our technique by providing example visualizations and discuss the results based on an informal evaluation provided by potential users of such visualizations
Keywords: B-spline curve;Network visualization;adjacency relation visualization;compound graph;curve fitting;curves;data visualisation;edge aggregation;edge bundling;edge concentration;graph visualization;hierarchical data;hierarchical edge bundles;hierarchies;node-link diagrams;splines (mathematics);tree data structures;tree visualization;tree visualization method;treemaps.;trees (mathematics);visual clutter;
Author: Holten, D.

Year: 2006
Title: Visualization of Geo-spatial Point Sets via Global Shape Transformation and Local Pixel Placement
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015426
Abstract: In many applications, data is collected and indexed by geo-spatial location. Discovering interesting patterns through visualization is an important way of gaining insight about such data. A previously proposed approach is to apply local placement functions such as PixelMaps that transform the input data set into a solution set that preserves certain constraints while making interesting patterns more obvious and avoid data loss from overplotting. In experience, this family of spatial transformations can reveal fine structures in large point sets, but it is sometimes difficult to relate those structures to basic geographic features such as cities and regional boundaries. Recent information visualization research has addressed other types of transformation functions that make spatially-transformed maps with recognizable shapes. These types of spatial-transformation are called global shape functions. In particular, cartogram-based map distortion has been studied. On the other hand, cartogram-based distortion does not handle point sets readily. In this study, we present a framework that allows the user to specify a global shape function and a local placement function. We combine cartogram-based layout (global shape) with PixelMaps (local placement), obtaining some of the benefits of each toward improved exploration of dense geo-spatial data sets
Keywords: Cartogram;Geo-spatial Data;Pixel Placement;PixelMaps;Shape Transformation;cartogram-based map distortion;cartography;data visualisation;geo-spatial point set visualization;global shape functions;information visualization;local pixel placement;shape transformation;spatially-transformed maps;
Author: Panse, C.; Sips, M.; Keim, D.; North, S.

Year: 2006
Title: Worldmapper: The World as You've Never Seen it Before
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015427
Abstract: This paper describes the Worldmapper project, which makes use of novel visualization techniques to represent a broad variety of social and economic data about the countries of the world. The goal of the project is to use the map projections known as cartograms to depict comparisons and relations between different territories, and its execution raises many interesting design challenges that were not all apparent at the outset. We discuss the approaches taken towards these challenges, some of which may have considerably broad application. We conclude by commenting on the positive initial response to the Worldmapper images published on the Web, which we believe is due, at least in part, to the particular effectiveness of the cartogram as a tool for communicating quantitative geographic data
Keywords: Cartogram.;Computer Graphics;Data Visualization;Geographic Visualization;Internet;Social Visualization;Web;Worldmapper;Worldmapper project;cartogram;cartography;computer graphics;data visualisation;geographic data visualization technique;geographic information systems;map projection;socio-economic data representation;socio-economic effects;
Author: Dorling, D.; Barford, A.; Newman, M.

Year: 2006
Title: Spatial Analysis of News Sources
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015428
Abstract: People in different places talk about different things. This interest distribution is reflected by the newspaper articles circulated in a particular area. We use data from our large-scale newspaper analysis system (Lydia) to make entity datamaps, a spatial visualization of the interest in a given named entity. Our goal is to identify entities which display regional biases. We develop a model of estimating the frequency of reference of an entity in any given city from the reference frequency centered in surrounding cities, and techniques for evaluating the spatial significance of this distribution
Keywords: GIS;GIS;Geographic Visualization;Information analytics;Internet;Lydia large-scale newspaper analysis system;Newspapers;Spidering;Text and Document Visualization;WWW data visualization;Web data visualization;data visualisation;document visualization;entity datamap;geographic data visualization;geographic information systems;information analytics;information resources;news sources;regional bias display;spatial analysis;spatial visualization;text analysis;text visualization;
Author: Mehler, A.; Yunfan Bao; Xin Li; Yue Wang; Skiena, S.

Year: 2006
Title: Dynamic Map Labeling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015429
Abstract: We address the problem of filtering, selecting and placing labels on a dynamic map, which is characterized by continuous zooming and panning capabilities. This consists of two interrelated issues. The first is to avoid label popping and other artifacts that cause confusion and interrupt navigation, and the second is to label at interactive speed. In most formulations the static map labeling problem is NP-hard, and a fast approximation might have O(n log n) complexity. Even this is too slow during interaction, when the number of labels shown can be several orders of magnitude less than the number in the map. In this paper we introduce a set of desiderata for "consistent" dynamic map labeling, which has qualities desirable for navigation. We develop a new framework for dynamic labeling that achieves the desiderata and allows for fast interactive display by moving all of the selection and placement decisions into the preprocessing phase. This framework is general enough to accommodate a variety of selection and placement algorithms. It does not appear possible to achieve our desiderata using previous frameworks. Prior to this paper, there were no formal models of dynamic maps or of dynamic labels; our paper introduces both. We formulate a general optimization problem for dynamic map labeling and give a solution to a simple version of the problem. The simple version is based on label priorities and a versatile and intuitive class of dynamic label placements we call "invariant point placements". Despite these restrictions, our approach gives a useful and practical solution. Our implementation is incorporated into the G-Vis system which is a full-detail dynamic map of the continental USA. This demo is available through any browser
Keywords: G-Vis system;GIS;GIS;HCI;HCI;Map labeling;Web browser;cartography;computational cartography;computational cartography;computational complexity;continental USA full-detail dynamic map;data visualisation;dynamic map labeling;dynamic maps;geographic information systems;human computer interaction;human-computer interface;human-computer interface;interactive display;label consistency;label consistency;label filtering;label filtering;label placement;label placement;label popping;label selection;label selection;optimisation;optimization problem;preprocessing.;realtime;user interfaces;
Author: Been, K.; Daiches, E.; Chee Yap

Year: 2006
Title: Visualization of Barrier Tree Sequences
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015430
Abstract: Dynamical models that explain the formation of spatial structures of RNA molecules have reached a complexity that requires novel visualization methods that help to analyze the validity of these models. We focus on the visualization of so-called folding landscapes of a growing RNA molecule. Folding landscapes describe the energy of a molecule as a function of its spatial configuration; thus they are huge and high dimensional. Their most salient features, however, are encapsulated by their so-called barrier tree that reflects the local minima and their connecting saddle points. For each length of the growing RNA chain there exists a folding landscape. We visualize the sequence of folding landscapes by an animation of the corresponding barrier trees. To generate the animation, we adapt the foresight layout with tolerance algorithm for general dynamic graph layout problems. Since it is very general, we give a detailed description of each phase: constructing a supergraph for the trees, layout of that supergraph using a modified DOT algorithm, and presentation techniques for the final animation
Keywords: Base Sequence;Computer Graphics;Computer Simulation;Graph drawing;Models, Chemical;Models, Molecular;Molecular Sequence Data;Nucleic Acid Conformation;RNA;RNA folding;RNA folding landscape visualization;RNA molecule spatial structures;Sequence Analysis, RNA;User-Computer Interface;barrier tree;barrier tree animation;barrier tree sequence visualization;biology computing;computer animation;data visualisation;dynamic graph;dynamic supergraph layout problem;energy landscape;fitness landscape;graph drawing;macromolecules;molecular biophysics;organic compounds;sequences;tolerance algorithm;trees (mathematics);
Author: Heine, C.; Scheuermann, G.; Flamm, C.; Hofacker, I.L.; Stadler, P.F.

Year: 2006
Title: Visualizing Business Data with Generalized Treemaps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015431
Abstract: Business data is often presented using simple business graphics. These familiar visualizations are effective for providing overviews, but fall short for the presentation of large amounts of detailed information. Treemaps can provide such detail, but are often not easy to understand. We present how standard treemap algorithms can be adapted such that the results mimic familiar business graphics. Specifically, we present the use of different layout algorithms per level, a number of variations of the squarified algorithm, the use of variable borders, and the use of non-rectangular shapes. The combined use of these leads to histograms, pie charts and a variety of other styles
Keywords: Information visualization;business data processing;business data visualization;business graphics;business graphics;business graphics;data models;data visualisation;generalized treemap algorithm;hierarchical data;hierarchical data visualization;histogram;layout algorithm;pie chart;squarified algorithm;tree data structures;treemap;
Author: Vliegen, R.; van Wijk, J.J.; van der Linden, E.-J.

Year: 2006
Title: FacetMap: A Scalable Search and Browse Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015432
Abstract: The dominant paradigm for searching and browsing large data stores is text-based: presenting a scrollable list of search results in response to textual search term input. While this works well for the Web, there is opportunity for improvement in the domain of personal information stores, which tend to have more heterogeneous data and richer metadata. In this paper, we introduce FacetMap, an interactive, query-driven visualization, generalizable to a wide range of metadata-rich data stores. FacetMap uses a visual metaphor for both input (selection of metadata facets as filters) and output. Results of a user study provide insight into tradeoffs between FacetMap's graphical approach and the traditional text-oriented approach
Keywords: Algorithms;Computer Graphics;Database Management Systems;Databases, Factual;FacetMap graphical approach;FacetMap interactive query-driven visualization;Graphical visualization;Information Storage and Retrieval;Internet;Natural Language Processing;Programming Languages;Software;User-Computer Interface;Web;browse visualization;data store text-based browsing;data store text-based searching;data visualisation;faceted metadata;faceted metadata-rich data stores;graphical visualization;interactive information retrieval;interactive information retrieval;interactive systems;meta data;personal information systems;query processing;search visualization;visual metaphor;
Author: Smith, G.; Czerwinski, M.; Meyers, B.Robbins.; Robertson, G.; Tan, D.S.

Year: 2006
Title: Visual Exploration of Complex Time-Varying Graphs
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015433
Abstract: Quasi-trees, namely graphs with tree-like structure, appear in many application domains, including bioinformatics and computer networks. Our new SPF approach exploits the structure of these graphs with a two-level approach to drawing, where the graph is decomposed into a tree of biconnected components. The low-level biconnected components are drawn with a force-directed approach that uses a spanning tree skeleton as a starting point for the layout. The higher-level structure of the graph is a true tree with meta-nodes of variable size that contain each biconnected component. That tree is drawn with a new area-aware variant of a tree drawing algorithm that handles high-degree nodes gracefully, at the cost of allowing edge-node overlaps. SPF performs an order of magnitude faster than the best previous approaches, while producing drawings of commensurate or improved quality
Keywords: Graph and network visualization;biconnected components;bioinformatics;computational geometry;computer network;data visualisation;financial data visualization;force-directed approach;graph layout;graph visualization;hierarchy visualization;network visualization;quasitree drawing algorithm;spanning tree skeleton;time series data;tree-like graph structure;trees (mathematics);
Author: Kumar, G.; Garland, M.

Year: 2006
Title: Smashing Peacocks Further: Drawing Quasi-Trees from Biconnected Components
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015434
Abstract: We extend the popular force-directed approach to network (or graph) layout to allow separation constraints, which enforce a minimum horizontal or vertical separation between selected pairs of nodes. This simple class of linear constraints is expressive enough to satisfy a wide variety of application-specific layout requirements, including: layout of directed graphs to better show flow; layout with non-overlapping node labels; and layout of graphs with grouped nodes (called clusters). In the stress majorization force-directed layout process, separation constraints can be treated as a quadratic programming problem. We give an incremental algorithm based on gradient projection for efficiently solving this problem. The algorithm is considerably faster than using generic constraint optimization techniques and is comparable in speed to unconstrained stress majorization. We demonstrate the utility of our technique with sample data from a number of practical applications including gene-activation networks, terrorist networks and visualization of high-dimensional data
Keywords: Graph and Network Visualization;Quasi-Tree;application-specific layout requirements;computational geometry;constraint optimization technique;data visualisation;directed graph layout;directed graphs;gene-activation network;gradient projection;grouped node graph layout;high-dimensional data visualization;incremental algorithm;network layout;nonoverlapping node label layout;quadratic programming;quadratic programming problem;separation constraint graph layout;stress majorization force-directed layout approach;terrorist network;
Author: Archambault, D.; Munzner, T.; Auber, D.

Year: 2006
Title: IPSep-CoLa: An Incremental Procedure for Separation Constraint Layout of Graphs
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015435
Abstract: Existing information-visualization techniques that target small screens are usually limited to exploring a few hundred items. In this article we present a scatterplot tool for personal digital assistants that allows the handling of many thousands of items. The application's scalability is achieved by incorporating two alternative interaction techniques: a geometric-semantic zoom that provides smooth transition between overview and detail, and a fisheye distortion that displays the focus and context regions of the scatterplot in a single view. A user study with 24 participants was conducted to compare the usability and efficiency of both techniques when searching a book database containing 7500 items. The study was run on a pen-driven Wacom board simulating a PDA interface. While the results showed no significant difference in task-completion times, a clear majority of 20 users preferred the fisheye view over the zoom interaction. In addition, other dependent variables such as user satisfaction and subjective rating of orientation and navigation support revealed a preference for the fisheye distortion. These findings partly contradict related research and indicate that, when using a small screen, users place higher value on the ability to preserve navigational context than they do on the ease of use of a simplistic, metaphor-based interaction style
Keywords: Graph drawing;PDA interface simulation;book database;constraints;data visualisation;fisheye distortion;force directed algorithms;geometric-semantic zoom;human computer interaction;information-visualization technique;layout;multidimensional scaling.;notebook computers;pen-driven Wacom board;personal digital assistant;scatterplot tool;stress majorization;user interaction technique;user interfaces;
Author: Dwyer, T.; Koren, Y.; Marriott, K.

Year: 2006
Title: User Interaction with Scatterplots on Small Screens - A Comparative Evaluation of Geometric-Semantic Zoom and Fisheye Distortion
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015436
Abstract: Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays
Keywords: PDA;Small screen;data visualisation;embedded bar matrix;embedded time-series graph;fisheye;focus+context.;geospatially-referenced multidimensional time-series data;high-resolution display;information visualization perceptual scalability;large screen displays;large tiled display;scatter plot;space-time-attribute visualization;spatial grouping;zoom;
Author: Buering, T.; Gerken, J.; Reiterer, H.

Year: 2006
Title: The Perceptual Scalability of Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015437
Abstract: Larger, higher resolution displays can be used to increase the scalability of information visualizations. But just how much can scalability increase using larger displays before hitting human perceptual or cognitive limits? Are the same visualization techniques that are good on a single monitor also the techniques that are best when they are scaled up using large, high-resolution displays? To answer these questions we performed a controlled experiment on user performance time, accuracy, and subjective workload when scaling up data quantity with different space-time-attribute visualizations using a large, tiled display. Twelve college students used small multiples, embedded bar matrices, and embedded time-series graphs either on a 2 megapixel (Mp) display or with data scaled up using a 32 Mp tiled display. Participants performed various overview and detail tasks on geospatially-referenced multidimensional time-series data. Results showed that current designs are perceptually scalable because they result in a decrease in task completion time when normalized per number of data attributes along with no decrease in accuracy. It appears that, for the visualizations selected for this study, the relative comparison between designs is generally consistent between display sizes. However, results also suggest that encoding is more important on a smaller display while spatial grouping is more important on a larger display. Some suggestions for designers are provided based on our experience designing visualizations for large displays.
Keywords: Computer Graphics;Data Display;Female;Humans;Information Storage and Retrieval;Information visualization;Male;Psychomotor Performance;Reaction Time;User-Computer Interface;Visual Perception;empirical evaluation;large displays;
Author: Yost, B.; North, C.

Year: 2006
Title: Complex Logarithmic Views for Small Details in Large Contexts
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015438
Abstract: Commonly known detail in context techniques for the two-dimensional Euclidean space enlarge details and shrink their context using mapping functions that introduce geometrical compression. This makes it difficult or even impossible to recognize shapes for large differences in magnification factors. In this paper we propose to use the complex logarithm and the complex root functions to show very small details even in very large contexts. These mappings are conformal, which means they only locally rotate and scale, thus keeping shapes intact and recognizable. They allow showing details that are orders of magnitude smaller than their surroundings in combination with their context in one seamless visualization. We address the utilization of this universal technique for the interaction with complex two-dimensional data considering the exploration of large graphs and other examples
Keywords: Detail in context;Euclidean space;analytic functions;complex logarithm;complex logarithmic view;complex root function;computational geometry;conformal mapping;conformal mapping function;conformal mappings;data visualisation;data visualization;geometrical compression;graph theory;interaction.;
Author: Bottger, J.; Balzer, M.; Deussen, O.

Year: 2006
Title: Software Design Patterns for Information Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015439
Abstract: Despite a diversity of software architectures supporting information visualization, it is often difficult to identify, evaluate, and re-apply the design solutions implemented within such frameworks. One popular and effective approach for addressing such difficulties is to capture successful solutions in design patterns, abstract descriptions of interacting software components that can be customized to solve design problems within a particular context. Based upon a review of existing frameworks and our own experiences building visualization software, we present a series of design patterns for the domain of information visualization. We discuss the structure, context of use, and interrelations of patterns spanning data representation, graphics, and interaction. By representing design knowledge in a reusable form, these patterns can be used to facilitate software design, implementation, and evaluation, and improve developer education and communication
Keywords: Algorithms;Computer Graphics;Database Management Systems;Databases, Factual;Design patterns;Information Storage and Retrieval;Software;Software Design;User-Computer Interface;data visualisation;information visualization;information visualization;object-oriented programming;object-oriented programming;pattern spanning data representation;software architecture;software architecture;software design pattern;software engineering;
Author: Heer, J.; Maneesh Agrawala

Year: 2006
Title: A Pipeline for Computer Aided Polyp Detection
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015440
Abstract: We present a novel pipeline for computer-aided detection (CAD) of colonic polyps by integrating texture and shape analysis with volume rendering and conformal colon flattening. Using our automatic method, the 3D polyp detection problem is converted into a 2D pattern recognition problem. The colon surface is first segmented and extracted from the CT data set of the patient's abdomen, which is then mapped to a 2D rectangle using conformal mapping. This flattened image is rendered using a direct volume rendering technique with a translucent electronic biopsy transfer function. The polyps are detected by a 2D clustering method on the flattened image. The false positives are further reduced by analyzing the volumetric shape and texture features. Compared with shape based methods, our method is much more efficient without the need of computing curvature and other shape parameters for the whole colon surface. The final detection results are stored in the 2D image, which can be easily incorporated into a virtual colonoscopy (VC) system to highlight the polyp locations. The extracted colon surface mesh can be used to accelerate the volumetric ray casting algorithm used to generate the VC endoscopic view. The proposed automatic CAD pipeline is incorporated into an interactive VC system, with a goal of helping radiologists detect polyps faster and with higher accuracy
Keywords: 2D clustering method;2D pattern recognition problem;Algorithms;Artificial Intelligence;Cluster Analysis;Colonic Polyps;Colonography, Computed Tomographic;Computer Aided Detection;Computer Graphics;Humans;Imaging, Three-Dimensional;Information Storage and Retrieval;Pattern Recognition, Automated;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Texture Analysis;User-Computer Interface;Virtual Colonoscopy;Volume Rendering;computer aided polyp detection;computerised tomography;conformal colon flattening;conformal mapping;conformal mapping;feature extraction;image texture;image texture;interactive virtual colonoscopy system;medical image processing;pattern clustering;rendering (computer graphics);shape analysis;translucent electronic biopsy transfer function;virtual reality;volume rendering;volumetric ray casting algorithm;volumetric texture feature;
Author: Hong, W.; Qiu, F.; Kaufman, A.

Year: 2006
Title: Full Body Virtual Autopsies using a State-of-the-art Volume Rendering Pipeline
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015441
Abstract: This paper presents a procedure for virtual autopsies based on interactive 3D visualizations of large scale, high resolution data from CT-scans of human cadavers. The procedure is described using examples from forensic medicine and the added value and future potential of virtual autopsies is shown from a medical and forensic perspective. Based on the technical demands of the procedure state-of-the-art volume rendering techniques are applied and refined to enable real-time, full body virtual autopsies involving gigabyte sized data on standard GPUs. The techniques applied include transfer function based data reduction using level-of-detail selection and multi-resolution rendering techniques. The paper also describes a data management component for large, out-of-core data sets and an extension to the GPU-based raycaster for efficient dual TF rendering. Detailed benchmarks of the pipeline are presented using data sets from forensic cases
Keywords: Algorithms;Autopsy;CT-scan;Cadaver;Computer Graphics;Forensics;GPU-based raycaster;Humans;Imaging, Three-Dimensional;Information Storage and Retrieval;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Tomography, X-Ray Computed;User-Computer Interface;Whole Body Imaging;autopsies;computerised tomography;data management component;data reduction;data visualisation;forensic medicine;full body virtual autopsy;image resolution;interactive 3D visualization;large scale data.;medical image processing;medical visualization;multiresolution rendering technique;rendering (computer graphics);transfer function;virtual reality;volume rendering;volume rendering pipeline;
Author: Ljung, P.; Winskog, C.; Persson, A.; Lundstrom, C.; Ynnerman, A.

Year: 2006
Title: Real-Time Illustration of Vascular Structures
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015442
Abstract: We present real-time vascular visualization methods, which extend on illustrative rendering techniques to particularly accentuate spatial depth and to improve the perceptive separation of important vascular properties such as branching level and supply area. The resulting visualization can and has already been used for direct projection on a patient's organ in the operation theater where the varying absorption and reflection characteristics of the surface limit the use of color. The important contributions of our work are a GPU-based hatching algorithm for complex tubular structures that emphasizes shape and depth as well as GPU-accelerated shadow-like depth indicators, which enable reliable comparisons of depth distances in a static monoscopic 3D visualization. In addition, we verify the expressiveness of our illustration methods in a large, quantitative study with 160 subjects
Keywords: Adolescent;Adult;Algorithms;Brain;Computer Graphics;Computer Simulation;Computer Systems;Female;GPU-accelerated shadow-like depth indicator;GPU-based hatching algorithm;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Magnetic Resonance Imaging;Male;Medical Illustration;Microcirculation;Middle Aged;Models, Anatomic;Models, Cardiovascular;Reproducibility of Results;Sensitivity and Specificity;Tomography, X-Ray Computed;User-Computer Interface;Vessel visualization;blood vessels;data visualisation;evaluation;functional realism;illustrative rendering;real-time vascular visualization method;rendering (computer graphics);rendering technique;spatial perception;static monoscopic 3D visualization;tubular structure;vascular structure;
Author: Ritter, F.; Hansen, C.; Dicken, V.; Konrad, O.; Preim, B.; Peitgen, H.-O.

Year: 2006
Title: Lines of Curvature for Polyp Detection in Virtual Colonoscopy
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015443
Abstract: Computer-aided diagnosis (CAD) is a helpful addition to laborious visual inspection for preselection of suspected colonic polyps in virtual colonoscopy. Most of the previous work on automatic polyp detection makes use of indicators based on the scalar curvature of the colon wall and can result in many false-positive detections. Our work tries to reduce the number of false-positive detections in the preselection of polyp candidates. Polyp surface shape can be characterized and visualized using lines of curvature. In this paper, we describe techniques for generating and rendering lines of curvature on surfaces and we show that these lines can be used as part of a polyp detection approach. We have adapted existing approaches on explicit triangular surface meshes, and developed a new algorithm on implicit surfaces embedded in 3D volume data. The visualization of shaded colonic surfaces can be enhanced by rendering the derived lines of curvature on these surfaces. Features strongly correlated with true-positive detections were calculated on lines of curvature and used for the polyp candidate selection. We studied the performance of these features on 5 data sets that included 331 pre-detected candidates, of which 50 sites were true polyps. The winding angle had a significant discriminating power for true-positive detections, which was demonstrated by a Wilcoxon rank sum test with p&lt;0.001. The median winding angle and inter-quartile range (IQR) for true polyps were 7.817 and 6.770-9.288 compared to 2.954 and 1.995-3.749 for false-positive detections
Keywords: 3D volume data;Algorithms;Artificial Intelligence;Cluster Analysis;Colonic Polyps;Colonography, Computed Tomographic;Computer Graphics;Humans;Imaging, Three-Dimensional;Information Storage and Retrieval;Medical visualization;Pattern Recognition, Automated;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;User-Computer Interface;colonic polyp detection;computational geometry;computer-aided diagnosis;curvature line;data visualisation;data visualization;false-positive detection;feature detection;feature extraction;implicit surface.;line of curvature;medical image processing;mesh generation;polyp detection;rendering (computer graphics);rendering technique;triangular surface meshes;virtual colonoscopy;virtual colonoscopy;virtual reality;
Author: Zhao, L.; Botha, C.P.; Bescos, J.O.; Truyen, R.; Vos, F.M.; Post, F.H.

Year: 2006
Title: Outlier-Preserving Focus+Context Visualization in Parallel Coordinates
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015444
Abstract: Focus+context visualization integrates a visually accentuated representation of selected data items in focus (more details, more opacity, etc.) with a visually deemphasized representation of the rest of the data, i.e., the context. The role of context visualization is to provide an overview of the data for improved user orientation and improved navigation. A good overview comprises the representation of both outliers and trends. Up to now, however, context visualization not really treated outliers sufficiently. In this paper we present a new approach to focus+context visualization in parallel coordinates which is truthful to outliers in the sense that small-scale features are detected before visualization and then treated specially during context visualization. Generally, we present a solution which enables context visualization at several levels of abstraction, both for the representation of outliers and trends. We introduce outlier detection and context generation to parallel coordinates on the basis of a binned data representation. This leads to an output-oriented visualization approach which means that only those parts of the visualization process are executed which actually affect the final rendering. Accordingly, the performance of this solution is much more dependent on the visualization size than on the data size which makes it especially interesting for large datasets. Previous approaches are outperformed, the new solution was successfully applied to datasets with up to 3 million data records and up to 50 dimensions
Keywords: Parallel coordinates;context visualization;data abstraction;data representation;data structures;data visualisation;feature extraction;focus visualization;focus+context visualization;large data visualization.;outlier detection;outliers & trends;output-oriented visualization approach;parallel coordinate;rendering (computer graphics);rendering technique;small-scale feature detection;
Author: Novotny, M.; Hauser, H.

Year: 2006
Title: Composite Rectilinear Deformation for Stretch and Squish Navigation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015445
Abstract: We present the first scalable algorithm that supports the composition of successive rectilinear deformations. Earlier systems that provided stretch and squish navigation could only handle small datasets. More recent work featuring rubber sheet navigation for large datasets has focused on rendering and on application-specific issues. However, no algorithm has yet been presented for carrying out such navigation methods; our paper addresses this problem. For maximum flexibility with large datasets, a stretch and squish navigation algorithm should allow for millions of potentially deformable regions. However, typical usage only changes the extents of a small subset k of these n regions at a time. The challenge is to avoid computations that are linear in n, because a single deformation can affect the absolute screen-space location of every deformable region. We provide an O(klogn) algorithm that supports any application that can lay out a dataset on a generic grid, and show an implementation that allows navigation of trees and gene sequences with millions of items in sub-millisecond time
Keywords: Focus+Context;composite rectilinear deformation;data visualisation;information visualization;information visualization;navigation.;real time rendering;real-time rendering;rendering (computer graphics);rubber sheet navigation;screen-space location;squish navigation;stretch navigation;
Author: Slack, J.; Munzner, T.

Year: 2006
Title: Multi-variate, Time Varying, and Comparative Visualization with Contextual Cues
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015446
Abstract: Time-varying, multi-variate, and comparative data sets are not easily visualized due to the amount of data that is presented to the user at once. By combining several volumes together with different operators into one visualized volume, the user is able to compare values from different data sets in space over time, run, or field without having to mentally switch between different renderings of individual data sets. In this paper, we propose using a volume shader where the user is given the ability to easily select and operate on many data volumes to create comparison relationships. The user specifies an expression with set and numerical operations and her data to see relationships between data fields. Furthermore, we render the contextual information of the volume shader by converting it to a volume tree. We visualize the different levels and nodes of the volume tree so that the user can see the results of suboperations. This gives the user a deeper understanding of the final visualization, by seeing how the parts of the whole are operationally constructed
Keywords: comparative;contextual information;data visualisation;data visualization;focus + context;multi-variate;multivariate time-varying comparative visualization;numerical operation;rendering (computer graphics);rendering technique;time-varying;volume shader;volume tree;
Author: Woodring, J.; Han-Wei Shen

Year: 2006
Title: Multifield-Graphs: An Approach to Visualizing Correlations in Multifield Scalar Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015447
Abstract: We present an approach to visualizing correlations in 3D multifield scalar data. The core of our approach is the computation of correlation fields, which are scalar fields containing the local correlations of subsets of the multiple fields. While the visualization of the correlation fields can be done using standard 3D volume visualization techniques, their huge number makes selection and handling a challenge. We introduce the multifield-graph to give an overview of which multiple fields correlate and to show the strength of their correlation. This information guides the selection of informative correlation fields for visualization. We use our approach to visually analyze a number of real and synthetic multifield datasets
Keywords: 3D multifield scalar data;3D volume visualization technique;Visualization;correlation;correlation field;data visualisation;data visualization;multifield;multifield-graph method;rendering (computer graphics);
Author: Sauber, N.; Theisel, H.; Seidel, H.-P.

Year: 2006
Title: Saliency-guided Enhancement for Volume Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015448
Abstract: Recent research in visual saliency has established a computational measure of perceptual importance. In this paper we present a visual-saliency-based operator to enhance selected regions of a volume. We show how we use such an operator on a user-specified saliency field to compute an emphasis field. We further discuss how the emphasis field can be integrated into the visualization pipeline through its modifications of regional luminance and chrominance. Finally, we validate our work using an eye-tracking-based user study and show that our new saliency enhancement operator is more effective at eliciting viewer attention than the traditional Gaussian enhancement operator
Keywords: Algorithms;Attention;Computer Graphics;Eye Movements;Fixation, Ocular;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Saliency;User-Computer Interface;data visualisation;non-photorealistic rendering;perceptual enhancement;rendering (computer graphics);saliency-guided enhancement;visual attention;visual-saliency-based operator;volume rendering;volume rendering;volume visualization;
Author: Kim, Y.; Varshney, A.

Year: 2006
Title: Importance-Driven Focus of Attention
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015449
Abstract: This paper introduces a concept for automatic focusing on features within a volumetric data set. The user selects a focus, i.e., object of interest, from a set of pre-defined features. Our system automatically determines the most expressive view on this feature. A characteristic viewpoint is estimated by a novel information-theoretic framework which is based on the mutual information measure. Viewpoints change smoothly by switching the focus from one feature to another one. This mechanism is controlled by changes in the importance distribution among features in the volume. The highest importance is assigned to the feature in focus. Apart from viewpoint selection, the focusing mechanism also steers visual emphasis by assigning a visually more prominent representation. To allow a clear view on features that are normally occluded by other parts of the volume, the focusing for example incorporates cut-away views
Keywords: Algorithms;Attention;Computer Graphics;Eye Movements;Fixation, Ocular;Humans;Illustrative visualization;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;User-Computer Interface;automatic feature focusing;characteristic viewpoint estimation;characteristic viewpoint estimation;cut-away view incorporation;data visualisation;data visualisation;expressive feature view;focus+context techniques;focusing;importance distribution;importance-driven attention focus;information-theoretic framework;interacting with volumetric datasets;mutual information measure;visual emphasis;volume visualization;volumetric data set;
Author: Viola, I.; Feixas, M.; Sbert, M.; Groller, M.E.

Year: 2006
Title: ClearView: An Interactive Context Preserving Hotspot Visualization Technique
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015450
Abstract: Volume rendered imagery often includes a barrage of 3D information like shape, appearance and topology of complex structures, and it thus quickly overwhelms the user. In particular, when focusing on a specific region a user cannot observe the relationship between various structures unless he has a mental picture of the entire data. In this paper we present ClearView, a GPU-based, interactive framework for texture-based volume ray-casting that allows users which do not have the visualization skills for this mental exercise to quickly obtain a picture of the data in a very intuitive and user-friendly way. ClearView is designed to enable the user to focus on particular areas in the data while preserving context information without visual clutter. ClearView does not require additional feature volumes as it derives any features in the data from image information only. A simple point-and-click interface enables the user to interactively highlight structures in the data. ClearView provides an easy to use interface to complex volumetric data as it only uses transparency in combination with a few specific shaders to convey focus and context information
Keywords: Algorithms;ClearView;Computer Graphics;Computer Simulation;GPU rendering;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Anatomic;Software;Terms????Focus & Context;User-Computer Interface;complex volumetric data;context information focus;data visualisation;focusing;image information;image resolution;interactive context preserving hotspot visualization technique;mental exercise;point-and-click interface;rendering (computer graphics);texture-based volume ray-casting;user interfaces;visual clutter;volume raycasting;
Author: Kruger, J.; Schneider, J.; Westermann, R.

Year: 2006
Title: Visualization Tools for Vorticity Transport Analysis in Incompressible Flow
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015451
Abstract: Vortices are undesirable in many applications while indispensable in others. It is therefore of common interest to understand their mechanisms of creation. This paper aims at analyzing the transport of vorticity inside incompressible flow. The analysis is based on the vorticity equation and is performed along pathlines which are typically started in upstream direction from vortex regions. Different methods for the quantitative and explorative analysis of vorticity transport are presented and applied to CFD simulations of water turbines. Simulation quality is accounted for by including the errors of meshing and convergence into analysis and visualization. The obtained results are discussed and interpretations with respect to engineering questions are given
Keywords: CFD simulations;Flow visualization;computational fluid dynamics;computational fluid dynamics;convergence;data visualisation;explorative analysis;flow visualisation;incompressible flow;linked views.;meshing errors;quantitative analysis;simulation quality;turbines;unsteady flow;upstream direction;visualization tools;vortex regions;vortices;vorticity equation;vorticity transport;vorticity transport analysis;water turbines;
Author: Sadlo, F.; Peikert, R.; Sick, M.

Year: 2006
Title: Vortex Visualization for Practical Engineering Applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015452
Abstract: In order to understand complex vortical flows in large data sets, we must be able to detect and visualize vortices in an automated fashion. In this paper, we present a feature-based vortex detection and visualization technique that is appropriate for large computational fluid dynamics data sets computed on unstructured meshes. In particular, we focus on the application of this technique to visualization of the flow over a serrated wing and the flow field around a spinning missile with dithering canards. We have developed a core line extraction technique based on the observation that vortex cores coincide with local extrema in certain scalar fields. We also have developed a novel technique to handle complex vortex topology that is based on k-means clustering. These techniques facilitate visualization of vortices in simulation data that may not be optimally resolved or sampled. Results are included that highlight the strengths and weaknesses of our approach. We conclude by describing how our approach can be improved to enhance robustness and expand its range of applicability
Keywords: Vortex detection;complex vortical flows;computational fluid dynamics;core line extraction technique;data visualisation;external flows;feature extraction;feature mining;feature-based vortex detection;flow visualisation;k-means clustering;large computational fluid dynamics;mesh generation;missile flow field;missiles;pattern clustering;practical engineering applications;scalar fields;serrated wing;simulation data sets;unstructured meshes;vortex visualization;vortex visualization technique;vortices;
Author: Jankun-Kelly, M.; Ming Jiang; Thompson, D.; Machiraju, R.

Year: 2006
Title: An Advanced Evenly-Spaced Streamline Placement Algorithm
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015453
Abstract: This paper presents an advanced evenly-spaced streamline placement algorithm for fast, high-quality, and robust layout of flow lines. A fourth-order Runge-Kutta integrator with adaptive step size and error control is employed for rapid accurate streamline advection. Cubic Hermite polynomial interpolation with large sample-spacing is adopted to create fewer evenly-spaced samples along each streamline to reduce the amount of distance checking. We propose two methods to enhance placement quality. Double queues are used to prioritize topological seeding and to favor long streamlines to minimize discontinuities. Adaptive distance control based on the local flow variance is explored to reduce cavities. Furthermore, we propose a universal, effective, fast, and robust loop detection strategy to address closed and spiraling streamlines. Our algorithm is an order-of-magnitude faster than Jobard and Lefer's algorithm with better placement quality and over 5 times faster than Mebarki et al.'s algorithm with comparable placement quality, but with a more robust solution to loop detection
Keywords: Flow visualization;Runge-Kutta methods;adaptive distance control;adaptive step size;advanced evenly-spaced streamline placement algorithm;closed streamlines.;computational fluid dynamics;cubic Hermite polynomial interpolation;data visualisation;distance checking;double queues;error control;evenly-spaced streamlines;flow line layout;flow visualisation;fourth-order Runge-Kutta integrator;interpolation;local flow variance;placement quality;rapid accurate streamline advection;robust loop detection strategy;sample-spacing;seeding strategy;streamline placement;topological seeding;
Author: Zhanping Liu; Moorhead, R.; Groner, J.

Year: 2006
Title: Fine-grained Visualization Pipelines and Lazy Functional Languages
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015454
Abstract: The pipeline model in visualization has evolved from a conceptual model of data processing into a widely used architecture for implementing visualization systems. In the process, a number of capabilities have been introduced, including streaming of data in chunks, distributed pipelines, and demand-driven processing. Visualization systems have invariably built on stateful programming technologies, and these capabilities have had to be implemented explicitly within the lower layers of a complex hierarchy of services. The good news for developers is that applications built on top of this hierarchy can access these capabilities without concern for how they are implemented. The bad news is that by freezing capabilities into low-level services expressive power and flexibility is lost. In this paper we express visualization systems in a programming language that more naturally supports this kind of processing model. Lazy functional languages support fine-grained demand-driven processing, a natural form of streaming, and pipeline-like function composition for assembling applications. The technology thus appears well suited to visualization applications. Using surface extraction algorithms as illustrative examples, and the lazy functional language Haskell, we argue the benefits of clear and concise expression combined with fine-grained, demand-driven computation. Just as visualization provides insight into data, functional abstraction provides new insight into visualization
Keywords: Haskell;Pipeline model;computer graphic equipment;data visualisation;demand-driven processing;fine-grained visualization pipelines;functional abstraction;functional languages;functional programming;functional programming.;laziness;lazy functional languages;pipeline processing;pipeline-like function composition;programming language;streaming form;surface extraction algorithms;
Author: Duke, D.; Wallace, M.; Borgo, R.; Runciman, C.

Year: 2006
Title: A Novel Visualization Model for Web Search Results
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015455
Abstract: This paper presents an interactive visualization system, named WebSearchViz, for visualizing the Web search results and facilitating users' navigation and exploration. The metaphor in our model is the solar system with its planets and asteroids revolving around the sun. Location, color, movement, and spatial distance of objects in the visual space are used to represent the semantic relationships between a query and relevant Web pages. Especially, the movement of objects and their speeds add a new dimension to the visual space, illustrating the degree of relevance among a query and Web search results in the context of users' subjects of interest. By interacting with the visual space, users are able to observe the semantic relevance between a query and a resulting Web page with respect to their subjects of interest, context information, or concern. Users' subjects of interest can be dynamically changed, redefined, added, or deleted from the visual space
Keywords: Algorithms;Computer Graphics;Database Management Systems;Databases, Factual;Information Storage and Retrieval;Internet;Natural Language Processing;Programming Languages;Software;User-Computer Interface;Visualization model;Web pages;Web search results;WebSearchViz;data visualisation;interactive systems;interactive visualization system;movement;online front-ends;query processing;search engines;semantic relationships;solar system;solar system;speed;user exploration;user navigation;visual space;
Author: Nguyen, T.N.; Zhang, J.

Year: 2006
Title: A Trajectory-Preserving Synchronization Method for Collaborative Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015456
Abstract: In the past decade, a lot of research work has been conducted to support collaborative visualization among remote users over the networks, allowing them to visualize and manipulate shared data for problem solving. There are many applications of collaborative visualization, such as oceanography, meteorology and medical science. To facilitate user interaction, a critical system requirement for collaborative visualization is to ensure that remote users would perceive a synchronized view of the shared data. Failing this requirement, the user's ability in performing the desirable collaborative tasks would be affected. In this paper, we propose a synchronization method to support collaborative visualization. It considers how interaction with dynamic objects is perceived by application participants under the existence of network latency, and remedies the motion trajectory of the dynamic objects. It also handles the false positive and false negative collision detection problems. The new method is particularly well designed for handling content changes due to unpredictable user interventions or object collisions. We demonstrate the effectiveness of our method through a number of experiments
Keywords: Collaborative visualization;application participants;collaborative visualization;content change handling;data visualisation;distributed synchronization.;dynamic object interaction;false negative collision detection problems;false positive collision detection problems;groupware;motion control;motion synchronization;motion trajectory-preserving synchronization method;network latency;network latency;position control;synchronisation;unpredictable user interventions;
Author: Li, L.W.F.; Li, F.W.B.; Lau, R.W.H.

Year: 2006
Title: Concurrent Visualization in a Production Supercomputing Environment
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015457
Abstract: We describe a concurrent visualization pipeline designed for operation in a production supercomputing environment. The facility was initially developed on the NASA Ames "Columbia" supercomputer for a massively parallel forecast model (GEOS4). During the 2005 Atlantic hurricane season, GEOS4 was run 4 times a day under tight time constraints so that its output could be included in an ensemble prediction that was made available to forecasters at the National Hurricane Center. Given this time-critical context, we designed a configurable concurrent pipeline to visualize multiple global fields without significantly affecting the runtime model performance or reliability. We use MPEG compression of the accruing images to facilitate live low-bandwidth distribution of multiple visualization streams to remote sites. We also describe the use of our concurrent visualization framework with a global ocean circulation model, which provides a 864-fold increase in the temporal resolution of practically achievable animations. In both the atmospheric and oceanic circulation models, the application scientists gained new insights into their model dynamics, due to the high temporal resolution animations attainable
Keywords: Atlantic hurricane season;ECCO;GEOS4;GEOS4 global climate model;MPEG compression;NASA Ames Columbia supercomputer;National Hurricane Center;Supercomputing;atmospheric circulation models;computer animation;concurrent visualization;concurrent visualization pipeline;data compression;data visualisation;ensemble prediction;geophysics computing;global ocean circulation model;high temporal resolution visualization;hurricane visualization;image coding;image resolution;interactive visual computing;low-bandwidth distribution;multiple visualization streams;ocean modeling.;parallel forecast model;parallel machines;pipeline processing;production supercomputing environment;remote sites;rendering (computer graphics);runtime model performance;storms;temporal resolution animations;time-critical context;time-varying data;weather forecasting;
Author: Ellsworth, D.; Green, B.; Henze, C.; Moran, P.; Sandstrom, T.

Year: 2006
Title: Scalable WIM: Effective Exploration in Large-scale Astrophysical Environments
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015458
Abstract: Navigating through large-scale virtual environments such as simulations of the astrophysical Universe is difficult. The huge spatial range of astronomical models and the dominance of empty space make it hard for users to travel across cosmological scales effectively, and the problem of wayfinding further impedes the user's ability to acquire reliable spatial knowledge of astronomical contexts. We introduce a new technique called the scalable world-in-miniature (WIM) map as a unifying interface to facilitate travel and wayfinding in a virtual environment spanning gigantic spatial scales: power-law spatial seating enables rapid and accurate transitions among widely separated regions; logarithmically mapped miniature spaces offer a global overview mode when the full context is too large; 3D landmarks represented in the WIM are enhanced by scale, positional, and directional cues to augment spatial context awareness; a series of navigation models are incorporated into the scalable WIM to improve the performance of travel tasks posed by the unique characteristics of virtual cosmic exploration. The scalable WIM user interface supports an improved physical navigation experience and assists pragmatic cognitive understanding of a visualization context that incorporates the features of large-scale astronomy
Keywords: 3D landmarks;Astrophysical visualization;astronomical contexts;astronomy computing;cosmological scales;cosmology;data visualisation;global overview mode;interaction techniques;large-scale astrophysical environments;large-scale exploration;physical navigation;power-law spatial seating;pragmatic cognitive understanding;scalable WIM;scalable world-in-miniature map;spatial context awareness;spatial knowledge range;travel task performance;user interface;user interfaces;virtual cosmic exploration;world-in-miniature (WIM);
Author: Yinggang Li; Chi-Wing Fu; Hanson, A.

Year: 2006
Title: Using Visual Cues of Contact to Improve Interactive Manipulation of Virtual Objects in Industrial Assembly/Maintenance Simulations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015459
Abstract: This paper describes a set of visual cues of contact designed to improve the interactive manipulation of virtual objects in industrial assembly/maintenance simulations. These visual cues display information of proximity, contact and effort between virtual objects when the user manipulates a part inside a digital mock-up. The set of visual cues encloses the apparition of glyphs (arrow, disk, or sphere) when the manipulated object is close or in contact with another part of the virtual environment. Light sources can also be added at the level of contact points. A filtering technique is proposed to decrease the number of glyphs displayed at the same time. Various effects - such as change in color, change in size, and deformation of shape - can be applied to the glyphs as a function of proximity with other objects or amplitude of the contact forces. A preliminary evaluation was conducted to gather the subjective preference of a group of participants during the simulation of an automotive assembly operation. The collected questionnaires showed that participants globally appreciated our visual cues of contact. The changes in color appeared to be preferred concerning the display of distances and proximity information. Size changes and deformation effects appeared to be preferred in terms of perception of contact forces between the parts. Last, light sources were selected to focus the attention of the user on the contact areas
Keywords: assembling;assembly/maintenance simulation;automotive assembly operation;collected questionnaires;contact;data visualisation;data visualisation;deformation effects;digital mock-up;digital simulation;filtering technique;force;glyph;glyph apparition;industrial assembly simulations;industry maintenance simulations;interactive manipulation;light;proximity;proximity information;virtual objects;virtual prototyping;virtual prototyping;virtual prototyping;virtual reality;virtual reality environment;visual contact cues;visual cues;
Author: Sreng, J.; Lecuyer, A.; Megard, C.; Andriot, C.

Year: 2006
Title: High-Level User Interfaces for Transfer Function Design with Semantics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015460
Abstract: Many sophisticated techniques for the visualization of volumetric data such as medical data have been published. While existing techniques are mature from a technical point of view, managing the complexity of visual parameters is still difficult for nonexpert users. To this end, this paper presents new ideas to facilitate the specification of optical properties for direct volume rendering. We introduce an additional level of abstraction for parametric models of transfer functions. The proposed framework allows visualization experts to design high-level transfer function models which can intuitively be used by non-expert users. The results are user interfaces which provide semantic information for specialized visualization problems. The proposed method is based on principal component analysis as well as on concepts borrowed from computer animation
Keywords: Algorithms;Brain;Computer Graphics;Gaussian distribution;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Semantics;User-Computer Interface;Volume rendering;computer animation;computer animation;data visualisation;data visualization;direct volume rendering;graphical user interfaces;high-level user interface;medical computing;optical property;parametric model;principal component analysis;principal component analysis;rendering (computer graphics);semantic information;semantic models.;transfer function design;transfer function design;transfer functions;
Author: Salama, C.R.; Keller, M.; Kohlmann, P.

Year: 2006
Title: LOD Map - A Visual Interface for Navigating Multiresolution Volume Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015461
Abstract: In multiresolution volume visualization, a visual representation of level-of-detail (LOD) quality is important for us to examine, compare, and validate different LOD selection algorithms. While traditional methods rely on ultimate images for quality measurement, we introduce the LOD map - an alternative representation of LOD quality and a visual interface for navigating multiresolution data exploration. Our measure for LOD quality is based on the formulation of entropy from information theory. The measure takes into account the distortion and contribution of multiresolution data blocks. A LOD map is generated through the mapping of key LOD ingredients to a treemap representation. The ordered treemap layout is used for relative stable update of the LOD map when the view or LOD changes. This visual interface not only indicates the quality of LODs in an intuitive way, but also provides immediate suggestions for possible LOD improvement through visually-striking features. It also allows us to compare different views and perform rendering budget control. A set of interactive techniques is proposed to make the LOD adjustment a simple and easy task. We demonstrate the effectiveness and efficiency of our approach on large scientific and medical data sets
Keywords: Algorithms;Computer Graphics;Diagnostic Imaging;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;LOD map;LOD map;Models, Anatomic;User-Computer Interface;Visible Human Projects;data visualisation;entropy measure;graphical user interfaces;image resolution;information theory;knowledge representation;large volume visualization Author 1:;level-of-detail quality;medical data set;multiresolution rendering;multiresolution volume visualization;navigation;perceptual reasoning;rendering (computer graphics);treemap representation;trees (mathematics);visual interface;visual representation;
Author: Wang, C.; Shen, H.-W.

Year: 2006
Title: Analyzing Complex FTMS Simulations: a Case Study in High-Level Visualization of Ion Motions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015462
Abstract: Current practice in particle visualization renders particle position data directly onto the screen as points or glyphs. Using a camera placed at a fixed position, particle motions can be visualized by rendering trajectories or by animations. Applying such direct techniques to large, time dependent particle data sets often results in cluttered images in which the dynamic properties of the underlying system are difficult to interpret. In this case study we take an alternative approach to the visualization of ion motions. Instead of rendering ion position data directly, we first extract meaningful motion information from the ion position data and then map this information onto geometric primitives. Our goal is to produce high-level visualizations that reflect the physicists' way of thinking about ion dynamics. Parameterized geometric icons are defined to encode motion information of clusters of related ions. In addition, a parameterized camera control mechanism is used to analyze relative instead of only absolute ion motions. We apply the techniques to simulations of Fourier transform mass spectrometry (FTMS) experiments. The data produced by such simulations can amount to 5.10<sup>4</sup> ions and 10<sup>5</sup> timesteps. This paper discusses the requirements, design and informal evaluation of the implemented system
Keywords: FTMS simulation;Fourier transform mass spectrometry;Fourier transform spectrometers;Fourier transforms;Particle visualization;computer animation;data visualisation;dynamic property;motion;motion features;parameterized camera control mechanism;particle visualization;physics computing;rendering (computer graphics);rendering ion motion;trapped ions;
Author: Burakiewicz, W.; van Liere, R.

Year: 2006
Title: Detection and Visualization of Defects in 3D Unstructured Models of Nematic Liquid Crystals
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015463
Abstract: A method for the semi-automatic detection and visualization of defects in models of nematic liquid crystals (NLCs) is introduced; this method is suitable for unstructured models, a previously unsolved problem. The detected defects - also known as disclinations - are regions were the alignment of the liquid crystal rapidly changes over space; these defects play a large role in the physical behavior of the NLC substrate. Defect detection is based upon a measure of total angular change of crystal orientation (the director) over a node neighborhood via the use of a nearest neighbor path. Visualizations based upon the detection algorithm clearly identify complete defect regions as opposed to incomplete visual descriptions provided by cutting-plane and isosurface approaches. The introduced techniques are currently in use by scientists studying the dynamics of defect change
Keywords: 3D unstructured model;data visualisation;defects;disclination;feature extraction;feature extraction;mesh generation;nematic liquid crystal;nematic liquid crystals;nematic liquid crystals;physics computing;scientific visualization;scientific visualization;semi-automatic defect detection;unstructured grid;
Author: Ketan Mehta; Jankun-Kelly, T.J.

Year: 2006
Title: Understanding the Structure of the Turbulent Mixing Layer in Hydrodynamic Instabilities
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015464
Abstract: When a heavy fluid is placed above a light fluid, tiny vertical perturbations in the interface create a characteristic structure of rising bubbles and falling spikes known as Rayleigh-Taylor instability. Rayleigh-Taylor instabilities have received much attention over the past half-century because of their importance in understanding many natural and man-made phenomena, ranging from the rate of formation of heavy elements in supernovae to the design of capsules for Inertial Confinement Fusion. We present a new approach to analyze Rayleigh-Taylor instabilities in which we extract a hierarchical segmentation of the mixing envelope surface to identify bubbles and analyze analogous segmentations of fields on the original interface plane. We compute meaningful statistical information that reveals the evolution of topological features and corroborates the observations made by scientists. We also use geometric tracking to follow the evolution of single bubbles and highlight merge/split events leading to the formation of the large and complex structures characteristic of the later stages. In particular we (i) Provide a formal definition of a bubble; (ii) Segment the envelope surface to identify bubbles; (iii) Provide a multi-scale analysis technique to produce statistical measures of bubble growth; (iv) Correlate bubble measurements with analysis of fields on the interface plane; (v) Track the evolution of individual bubbles over time. Our approach is based on the rigorous mathematical foundations of Morse theory and can be applied to a more general class of applications
Keywords: Morse theory;Morse theory;Rayleigh-Taylor instability;Rayleigh-Taylor instability;bubble growth;bubbles;computational fluid dynamics;falling spikes;geometric tracking;geometry;heavy fluid;hydrodynamic instabilities;hydrodynamics;light fluid;multi-resolution;multiscale analysis technique;original interface plane;rising bubbles;segmentations;statistical measures;tiny vertical perturbations;topological features;topology;topology;turbulence;turbulent mixing layer;
Author: Laney, D.; Bremer, P.-T.; Mascarenhas, A.; Miller, P.; Pascucci, V.

Year: 2006
Title: Hub-based Simulation and Graphics Hardware Accelerated Visualization for Nanotechnology Applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015465
Abstract: The Network for computational nanotechnology (NCN) has developed a science gateway at nanoHUB.org for nanotechnology education and research. Remote users can browse through online seminars and courses, and launch sophisticated nanotechnology simulation tools, all within their Web browser. Simulations are supported by a middleware that can route complex jobs to grid supercomputing resources. But what is truly unique about the middleware is the way that it uses hardware accelerated graphics to support both problem setup and result visualization. This paper describes the design and integration of a remote visualization framework into the nanoHUB for interactive visual analytics of nanotechnology simulations. Our services flexibly handle a variety of nanoscience simulations, render them utilizing graphics hardware acceleration in a scalable manner, and deliver them seamlessly through the middleware to the user. Rendering is done only on-demand, as needed, so each graphics hardware unit can simultaneously support many user sessions. Additionally, a novel node distribution scheme further improves our system's scalability. Our approach is not only efficient but also cost-effective. Only half-dozen render nodes are anticipated to support hundreds of active tool sessions on the nanoHUB. Moreover, this architecture and visual analytics environment provides capabilities that can serve many areas of scientific simulation and analysis beyond nanotechnology with its ability to interactively analyze and visualize multivariate scalar and vector fields
Keywords: Computer Graphics;Computer Simulation;Computers;Hub-based simulation;Internet;Models, Theoretical;Nanostructures;Nanotechnology;Signal Processing, Computer-Assisted;User-Computer Interface;Web browser;computational nanotechnology application;computer graphic equipment;data visualisation;flow visualisation;flow visualization;graphics hardware;graphics hardware accelerated visualization;grid supercomputing resources;mesh generation;middleware;middleware;nanotechnology;nanotechnology simulation.;online front-ends;physics computing;remote visualization;rendering (computer graphics);science gateway;volume visualization;
Author: Qiao, W.; McLennan, M.; Kennell, R.; Ebert, D.S.; Klimeck, G.

Year: 2006
Title: Feature Aligned Volume Manipulation for Illustration and Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015466
Abstract: In this paper we describe a GPU-based technique for creating illustrative visualization through interactive manipulation of volumetric models. It is partly inspired by medical illustrations, where it is common to depict cuts and deformation in order to provide a better understanding of anatomical and biological structures or surgical processes, and partly motivated by the need for a real-time solution that supports the specification and visualization of such illustrative manipulation. We propose two new feature aligned techniques, namely surface alignment and segment alignment, and compare them with the axis-aligned techniques which were reported in previous work on volume manipulation. We also present a mechanism for defining features using texture volumes, and methods for computing correct normals for the deformed volume in respect to different alignments. We describe a GPU-based implementation to achieve real-time performance of the techniques and a collection of manipulation operators including peelers, retractors, pliers and dilators which are adaptations of the metaphors and tools used in surgical procedures and medical illustrations. Our approach is directly applicable in medical and biological illustration, and we demonstrate how it works as an interactive tool for focus+context visualization, as well as a generic technique for volume graphics
Keywords: Algorithms;Computer Graphics;Computer Simulation;Computer-Assisted Instruction;GPU computing;GPU-based technique;Humans;Illustrative manipulation;Illustrative visualization;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Medical Illustration;Models, Anatomic;User-Computer Interface;anatomical structure;biological structure;computer graphic equipment;computer-assisted medical illustration;data visualisation;data visualization;feature aligned volume manipulation;medical computing;medical illustration;rendering (computer graphics);segment alignment;surface alignment;surgical procedure;volume deformation;volume graphics;volume rendering;volumetric model;
Author: Correa, C.D.; Silver, D.; Chen, M.

Year: 2006
Title: Exploded Views for Volume Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015467
Abstract: Exploded views are an illustration technique where an object is partitioned into several segments. These segments are displaced to reveal otherwise hidden detail. In this paper we apply the concept of exploded views to volumetric data in order to solve the general problem of occlusion. In many cases an object of interest is occluded by other structures. While transparency or cutaways can be used to reveal a focus object, these techniques remove parts of the context information. Exploded views, on the other hand, do not suffer from this drawback. Our approach employs a force-based model: the volume is divided into a part configuration controlled by a number of forces and constraints. The focus object exerts an explosion force causing the parts to arrange according to the given constraints. We show that this novel and flexible approach allows for a wide variety of explosion-based visualizations including view-dependent explosions. Furthermore, we present a high-quality GPU-based volume ray casting algorithm for exploded views which allows rendering and interaction at several frames per second
Keywords: Algorithms;Anatomy, Cross-Sectional;Computer Graphics;Computer Simulation;Computer-Assisted Instruction;GPU-based volume ray casting algorithm;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Anatomic;User-Computer Interface;context information;data visualisation;exploded views;exploded views;force-based model;hidden feature removal;illustrative visualization;occlusion;rendering (computer graphics);view-dependent explosion;volume data;volume rendering;
Author: Bruckner, S.; Groller, M.E.

Year: 2006
Title: Caricaturistic Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015468
Abstract: Caricatures are pieces of art depicting persons or sociological conditions in a non-veridical way. In both cases caricatures are referring to a reference model. The deviations from the reference model are the characteristic features of the depicted subject. Good caricatures exaggerate the characteristics of a subject in order to accent them. The concept of caricaturistic visualization is based on the caricature metaphor. The aim of caricaturistic visualization is an illustrative depiction of characteristics of a given dataset by exaggerating deviations from the reference model. We present the general concept of caricaturistic visualization as well as a variety of examples. We investigate different visual representations for the depiction of caricatures. Further, we present the caricature matrix, a technique to make differences between datasets easily identifiable
Keywords: Computer Graphics;Face;Facial Expression;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Subtraction Technique;User-Computer Interface;art;art;caricaturistic visualization;characteristic feature;data visualisation;exploded views;face recognition;feature extraction;illustrative visualization;reference model;visual representation;volume rendering;
Author: Rautek, P.; Viola, I.; Groller, M.E.

Year: 2006
Title: Visual Signatures in Video Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015469
Abstract: Video visualization is a computation process that extracts meaningful information from original video data sets and conveys the extracted information to users in appropriate visual representations. This paper presents a broad treatment of the subject, following a typical research pipeline involving concept formulation, system development, a path-finding user study, and a field trial with real application data. In particular, we have conducted a fundamental study on the visualization of motion events in videos. We have, for the first time, deployed flow visualization techniques in video visualization. We have compared the effectiveness of different abstract visual representations of videos. We have conducted a user study to examine whether users are able to learn to recognize visual signatures of motions, and to assist in the evaluation of different visualization techniques. We have applied our understanding and the developed techniques to a set of application video clips. Our study has demonstrated that video visualization is both technically feasible and cost-effective. It has provided the first set of evidence confirming that ordinary users can be accustomed to the visual features depicted in video visualizations, and can learn to recognize visual signatures of a variety of motion events
Keywords: Algorithms;Computer Graphics;Female;GPU rendering.;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Male;Movement;Pattern Recognition, Visual;Task Performance and Analysis;User-Computer Interface;Video Recording;Video visualization;feature extraction;flow visualisation;flow visualization;flow visualization technique;human factors;human factors;motion estimation;optical flow;user study;video clips;video processing;video retrieval;video signal processing;video visualization;visual signature representation;visual signatures;volume visualization;
Author: Chen, M.; Hashim, R.R.; Botchen, R.P.; Weiskopf, D.; Ertl, T.; Thornton, I.M.

Year: 2006
Title: Asynchronous Distributed Calibration for Scalable and Reconfigurable Multi-Projector Displays
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015470
Abstract: Centralized techniques have been used until now when automatically calibrating (both geometrically and photometrically) large high-resolution displays created by tiling multiple projectors in a 2D array. A centralized server managed all the projectors and also the camera(s) used to calibrate the display. In this paper, we propose an asynchronous distributed calibration methodology via a display unit called the plug-and-play projector (PPP). The PPP consists of a projector, camera, computation and communication unit, thus creating a self-sufficient module that enables an asynchronous distributed architecture for multi-projector displays. We present a single-program-multiple-data (SPMD) calibration algorithm that runs on each PPP and achieves a truly scalable and reconfigurable display without any input from the user. It instruments novel capabilities like adding/removing PPPs from the display dynamically, detecting faults, and reshaping the display to a reasonable rectangular shape to react to the addition/removal/faults. To the best of our knowledge, this is the first attempt to realize a completely asynchronous and distributed calibration architecture and methodology for multi-projector displays
Keywords: Multi-projector displays;asynchronous distributed calibration;calibration;camera;cameras;centralized technique;client-server systems;computer displays;distributed algorithms;distributed algorithms.;geometric and color calibration;high-resolution displays;plug-and-play projector;projector-camera systems;reconfigurable multiprojector displays;single-program-multiple-data calibration algorithm;
Author: Bhasker, E.S.; Sinha, P.; Majumder, A.

Year: 2006
Title: Dynamic View Selection for Time-Varying Volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015471
Abstract: Animation is an effective way to show how time-varying phenomena evolve over time. A key issue of generating a good animation is to select ideal views through which the user can perceive the maximum amount of information from the time-varying dataset. In this paper, we first propose an improved view selection method for static data. The method measures the quality of a static view by analyzing the opacity, color and curvature distributions of the corresponding volume rendering images from the given view. Our view selection metric prefers an even opacity distribution with a larger projection area, a larger area of salient features' colors with an even distribution among the salient features, and more perceived curvatures. We use this static view selection method and a dynamic programming approach to select time-varying views. The time-varying view selection maximizes the information perceived from the time-varying dataset based on the constraints that the time-varying view should show smooth changes of direction and near-constant speed. We also introduce a method that allows the user to generate a smooth transition between any two views in a given time step, with the perceived information maximized as well. By combining the static and dynamic view selection methods, the users are able to generate a time-varying view that shows the maximum amount of information from a time-varying data set
Keywords: computer animation;computer animation;curvature distributions;data visualisation;dynamic programming;dynamic programming approach;dynamic view selection;dynamic view selection;image based method;information entropy;opacity distribution;optimization.;rendering (computer graphics);salient feature colors;smooth transition generation;static view selection;static view selection method;time-varying dataset;time-varying view selection;time-varying volumes;volume rendering images;
Author: Guangfeng Ji; Han-Wei Shen

Year: 2006
Title: Enhancing Depth Perception in Translucent Volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015472
Abstract: We present empirical studies that consider the effects of stereopsis and simulated aerial perspective on depth perception in translucent volumes. We consider a purely absorptive lighting model, in which light is not scattered or reflected, but is simply absorbed as it passes through the volume. A purely absorptive lighting model is used, for example, when rendering digitally reconstructed radiographs (DRRs), which are synthetic X-ray images reconstructed from CT volumes. Surgeons make use of DRRs in planning and performing operations, so an improvement of depth perception in DRRs may help diagnosis and surgical planning
Keywords: Algorithms;Computer Graphics;Depth Perception;Humans;Imaging, Three-Dimensional;Photometry;Radiograph;Radiographic Image Enhancement;Radiographic Image Interpretation, Computer-Assisted;Stereo;Stereopsis;Tomography, X-Ray Computed;User-Computer Interface;Volume Rendering;X--ray;absorptive lighting model;aerial perspective;computerised tomography;computerised tomography volumes;depth perception enhancement;diagnostic radiography;digitally reconstructed radiographs;image reconstruction;image reconstruction;medical image processing;rendering (computer graphics);stereopsis effect;surgery;surgical planning;synthetic X-ray images;translucent volumes;visual perception;
Author: Kersten, M.A.; Stewart, A.J.; Troje, N.; Ellis, R.

Year: 2006
Title: Texturing of Layered Surfaces for Optimal Viewing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015473
Abstract: This paper is a contribution to the literature on perceptually optimal visualizations of layered three-dimensional surfaces. Specifically, we develop guidelines for generating texture patterns, which, when tiled on two overlapped surfaces, minimize confusion in depth-discrimination and maximize the ability to localize distinct features. We design a parameterized texture space and explore this texture space using a "human in the loop" experimental approach. Subjects are asked to rate their ability to identify Gaussian bumps on both upper and lower surfaces of noisy terrain fields. Their ratings direct a genetic algorithm, which selectively searches the texture parameter space to find fruitful areas. Data collected from these experiments are analyzed to determine what combinations of parameters work well and to develop texture generation guidelines. Data analysis methods include ANOVA, linear discriminant analysis, decision trees, and parallel coordinates. To confirm the guidelines, we conduct a post-analysis experiment, where subjects rate textures following our guidelines against textures violating the guidelines. Across all subjects, textures following the guidelines consistently produce high rated textures on an absolute scale, and are rated higher than those that did not follow the guidelines
Keywords: Gaussian bumps;data analysis;data analysis methods;data mining;data visualisation;decision trees;decision trees;decision trees;feature extraction;genetic algorithm;genetic algorithm;genetic algorithms;human-in-the-loop;image texture;layered surfaces;layered three-dimensional surface texturing;linear discriminant analysis;linear discriminant analysis;noisy terrain fields;optimal visualization;parallel coordinates;parallel coordinates;parameterized texture space;pattern classification;perception;perceptual optimal visualizations;search problems;surface texture;texture parameter space search;texture pattern generation;
Author: Bair, A.; House, D.H.; Ware, C.

Year: 2006
Title: Subjective Quantification of Perceptual Interactions among some 2D Scientific Visualization Methods
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015474
Abstract: We present an evaluation of a parameterized set of 2D icon-based visualization methods where we quantified how perceptual interactions among visual elements affect effective data exploration. During the experiment, subjects quantified three different design factors for each method: the spatial resolution it could represent, the number of data values it could display at each point, and the degree to which it is visually linear. The class of visualization methods includes Poisson-disk distributed icons where icon size, icon spacing, and icon brightness can be set to a constant or coupled to data values from a 2D scalar field. By only coupling one of those visual components to data, we measured filtering interference for all three design factors. Filtering interference characterizes how different levels of the constant visual elements affect the evaluation of the data-coupled element. Our novel experimental methodology allowed us to generalize this perceptual information, gathered using ad-hoc artificial datasets, onto quantitative rules for visualizing real scientific datasets. This work also provides a framework for evaluating visualizations of multi-valued data that incorporate additional visual cues, such as icon orientation or color
Keywords: 2D icon-based visualization methods;2D scientific visualization methods;2D visualization methods;Perception models;Poisson distribution;Poisson-disk distributed icons;ad-hoc artificial datasets;data visualisation;filtering interference;graphical user interfaces;icon brightness;icon size;icon spacing;multivalued data visualization;perceptual interactions;perceptual interactions;scientific dataset visualization;spatial resolution;visual design.;visual elements;visual perception;visualization evaluation;
Author: Acevedo, D.; Laidlaw, D.

Year: 2006
Title: Occlusion-Free Animation of Driving Routes for Car Navigation Systems
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015475
Abstract: This paper presents a method for occlusion-free animation of geographical landmarks, and its application to a new type of car navigation system in which driving routes of interest are always visible. This is achieved by animating a nonperspective image where geographical landmarks such as mountain tops and roads are rendered as if they are seen from different viewpoints. The technical contribution of this paper lies in formulating the nonperspective terrain navigation as an inverse problem of continuously deforming a 3D terrain surface from the 2D screen arrangement of its associated geographical landmarks. The present approach provides a perceptually reasonable compromise between the navigation clarity and visual realism where the corresponding nonperspective view is fully augmented by assigning appropriate textures and shading effects to the terrain surface according to its geometry. An eye tracking experiment is conducted to prove that the present approach actually exhibits visually-pleasing navigation frames while users can clearly recognize the shape of the driving route without occlusion, together with the spatial configuration of geographical landmarks in its neighborhood
Keywords: 2D screen arrangement;3D terrain surface;car navigation systems;car navigation systems;computer animation;continuously deforming inverse problem;driver information systems;navigation;nonperspective image;nonperspective projection;nonperspective terrain navigation;occlusion-free animation;occlusion-free driving routes animation;occlusion-free geographical landmark animation;solid modelling;temporal coherence;visual perception;visually-pleasing navigation frames;
Author: Takahashi, S.; Yoshida, K.; Shimada, K.; Nishita, T.

Year: 2006
Title: Interactive Visualization of Intercluster Galaxy Structures in the Horologium-Reticulum Supercluster
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015476
Abstract: We present GyVe, an interactive visualization tool for understanding structure in sparse three-dimensional (3D) point data. The scientific goal driving the tool's development is to determine the presence of filaments and voids as defined by inferred 3D galaxy positions within the horologium-reticulum supercluster (HRS). GyVe provides visualization techniques tailored to examine structures defined by the intercluster galaxies. Specific techniques include: interactive user control to move between a global overview and local viewpoints, labelled axes and curved drop lines to indicate positions in the astronomical RA-DEC-cz coordinate system, torsional rocking and stereo to enhance 3D perception, and geometrically distinct glyphs to show potential correlation between intercluster galaxies and known clusters. We discuss the rationale for each design decision and review the success of the techniques in accomplishing the scientific goals. In practice, GyVe has been useful for gaining intuition about structures that were difficult to perceive with 2D projection techniques alone. For example, during their initial session with GyVe, our collaborators quickly confirmed scientific conclusions regarding the large-scale structure of the HRS previously obtained over months of study with 2D projections and statistical techniques. Further use of GyVe revealed the spherical shape of voids and showed that a presumed filament was actually two disconnected structures
Keywords: 2D projection techniques;3D galaxy positions;3D perception;GyVe interactive visualization tool;Sparse point visualization;astronomical RA-DEC-cz coordinate system;astronomy;astronomy computing;clusters of galaxies;cosmology;cosmology;data visualisation;geometrical distinct glyphs;horologium-reticulum supercluster;interactive user control;interactive visualization;intercluster galaxy structures;sparse three-dimensional point data;statistical techniques;torsional rocking;
Author: Miller, J.; Quammen, C.; Fleenor, M.

Year: 2006
Title: An Atmospheric Visual Analysis and Exploration System
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015477
Abstract: Meteorological research involves the analysis of multi-field, multi-scale, and multi-source data sets. Unfortunately, traditional atmospheric visualization systems only provide tools to view a limited number of variables and small segments of the data. These tools are often restricted to 2D contour or vector plots or 3D isosurfaces. The meteorologist must mentally synthesize the data from multiple plots to glean the information needed to produce a coherent picture of the weather phenomenon of interest. In order to provide better tools to meteorologists and reduce system limitations, we have designed an integrated atmospheric visual analysis and exploration system for interactive analysis of weather data sets. Our system allows for the integrated visualization of 1D, 2D, and 3D atmospheric data sets in common meteorological grid structures and utilizes a variety of rendering techniques. These tools provide meteorologists with new abilities to analyze their data and answer questions on regions of interest, ranging from physics-based atmospheric rendering to illustrative rendering containing particles and glyphs. In this paper, we discuss the use and performance of our visual analysis for two important meteorological applications. The first application is warm rain formation in small cumulus clouds. In this, our three-dimensional, interactive visualization of modeled drop trajectories within spatially correlated fields from a cloud simulation has provided researchers with new insight. Our second application is improving and validating severe storm models, specifically the weather research and forecasting (WRF) model. This is done through correlative visualization of WRF model and experimental Doppler storm data
Keywords: 2D contour;3D atmospheric data sets;3D isosurfaces;Doppler storm data;astronomy computing;atmospheric techniques;atmospheric visual analysis;cloud simulation;correlative visualization;drop trajectory modeling;exploration system;glyph rendering;grid structures;integrated atmospheric visual analysis;interactive weather data sets analysis;meteorological grid structures;meteorological research;multifield data set analysis;multiscale data set analysis;multisource data sets;physics-based atmospheric rendering;rendering (computer graphics);rendering techniques;small cumulus clouds;spatially correlated fields;storm models;storms;three-dimensional interactive visualization;transfer function;volume rendering;volume visualization;warm rain entrainment process;warm rain formation;weather forecasting;weather forecasting model;weather phenomenon;weather visualization;
Author: Yuyan Song; Jing Ye; Svakhine, N.; Lasher-Trapp, S.; Baldwin, M.; Ebert, D.

Year: 2006
Title: Visualization of Fibrous and Thread-like Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015478
Abstract: Thread-like structures are becoming more common in modern volumetric data sets as our ability to image vascular and neural tissue at higher resolutions improves. The thread-like structures of neurons and micro-vessels pose a unique problem in visualization since they tend to be densely packed in small volumes of tissue. This makes it difficult for an observer to interpret useful patterns from the data or trace individual fibers. In this paper we describe several methods for dealing with large amounts of thread-like data, such as data sets collected using knife-edge scanning microscopy (KESM) and serial block-face scanning electron microscopy (SBF-SEM). These methods allow us to collect volumetric data from embedded samples of whole-brain tissue. The neuronal and microvascular data that we acquire consists of thin, branching structures extending over very large regions. Traditional visualization schemes are not sufficient to make sense of the large, dense, complex structures encountered. In this paper, we address three methods to allow a user to explore a fiber network effectively. We describe interactive techniques for rendering large sets of neurons using self-orienting surfaces implemented on the GPU. We also present techniques for rendering fiber networks in a way that provides useful information about flow and orientation. Third, a global illumination framework is used to create high-quality visualizations that emphasize the underlying fiber structure. Implementation details, performance, and advantages and disadvantages of each approach are discussed
Keywords: Anatomy, Cross-Sectional;Computer Graphics;GPU acceleration;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Microscopy, Electron, Scanning;Nerve Net;Neurons;User-Computer Interface;brain;fiber network;fiber network rendering;fibrous visualization;global illumination;image vascular;interactive techniques;knife-edge scanning microscopy;medical image processing;microvascular data;neural tissue;neuron rendering;neuron visualization;neurophysiology;orientation filtering;rendering (computer graphics);scanning electron microscopy;self-orienting surfaces;serial block-face scanning electron microscopy;thread-like data;thread-like neuron structures;volumetric data sets;whole-brain tissue;
Author: Melek, Z.; Mayerich, D.; Yuksel, C.; Keyser, J.

Year: 2006
Title: Comparative Visualization for Wave-based and Geometric Acoustics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015479
Abstract: We present a comparative visualization of the acoustic simulation results obtained by two different approaches that were combined into a single simulation algorithm. The first method solves the wave equation on a volume grid based on finite elements. The second method, phonon tracing, is a geometric approach that we have previously developed for interactive simulation, visualization and modeling of room acoustics. Geometric approaches of this kind are more efficient than FEM in the high and medium frequency range. For low frequencies they fail to represent diffraction, which on the other hand can be simulated properly by means of FEM. When combining both methods we need to calibrate them properly and estimate in which frequency range they provide comparable results. For this purpose we use an acoustic metric called gain and display the resulting error. Furthermore we visualize interference patterns, since these depend not only on diffraction, but also exhibit phase-dependent amplification and neutralization effects
Keywords: acoustic metric;acoustic simulation;acoustic wave diffraction;acoustic wave interference;architectural acoustics;comparative visualization;comparative visualization;finite element analysis;finite element method;geometric acoustic;geometrical acoustics;interactive simulation;interference pattern visualization;neutralization effects;nite element method;phase-dependent amplification;phonon map;phonon tracing;ray tracing;ray tracing;room acoustic modeling;single simulation algorithm;wave equation;wave equations;wave-based acoustic;
Author: Deines, E.; Bertram, M.; Mohring, J.; Jegorovs, J.; Michel, F.; Hagen, H.; Nielson, G.M.

Year: 2006
Title: Hybrid Visualization for White Matter Tracts using Triangle Strips and Point Sprites
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015480
Abstract: Diffusion tensor imaging is of high value in neurosurgery, providing information about the location of white matter tracts in the human brain. For their reconstruction, streamline techniques commonly referred to as fiber tracking model the underlying fiber structures and have therefore gained interest. To meet the requirements of surgical planning and to overcome the visual limitations of line representations, a new real-time visualization approach of high visual quality is introduced. For this purpose, textured triangle strips and point sprites are combined in a hybrid strategy employing GPU programming. The triangle strips follow the fiber streamlines and are textured to obtain a tube-like appearance. A vertex program is used to orient the triangle strips towards the camera. In order to avoid triangle flipping in case of fiber segments where the viewing and segment direction are parallel, a correct visual representation is achieved in these areas by chains of point sprites. As a result, high quality visualization similar to tubes is provided allowing for interactive multimodal inspection. Overall, the presented approach is faster than existing techniques of similar visualization quality and at the same time allows for real-time rendering of dense bundles encompassing a high number of fibers, which is of high importance for diagnosis and surgical planning
Keywords: Algorithms;Brain;Brain Neoplasms;Computer Graphics;Diffusion Magnetic Resonance Imaging;Diffusion tensor data;GPU programming;Humans;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Nerve Fibers, Myelinated;Neural Pathways;User-Computer Interface;biomedical MRI;brain;camera;data visualisation;diffusion tensor imaging;fiber structures;fiber tracking;fiber tracking model;human brain;hybrid visualization;image reconstruction;image segmentation;image texture;interactive multimodal inspection;medical image processing;neurosurgery;point sprites;real-time dense bundle rendering;real-time visualization approach;streamline techniques;streamline visualization;surgery;surgical planning;triangle strip texture;tube-like appearance;vertex program;visual quality;visual representation;white matter tracts;
Author: Merhof, D.; Sonntag, M.; Enders, F.; Nimsky, C.; Hastreiter, P.; Greiner, G.

Year: 2006
Title: Analyzing Vortex Breakdown Flow Structures by Assignment of Colors to Tensor Invariants
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015481
Abstract: Topological methods are often used to describe flow structures in fluid dynamics and topological flow field analysis usually relies on the invariants of the associated tensor fields. A visual impression of the local properties of tensor fields is often complex and the search of a suitable technique for achieving this is an ongoing topic in visualization. This paper introduces and assesses a method of representing the topological properties of tensor fields and their respective flow patterns with the use of colors. First, a tensor norm is introduced, which preserves the properties of the tensor and assigns the tensor invariants to values of the RGB color space. Secondly, the RGB colors of the tensor invariants are transferred to corresponding hue values as an alternative color representation. The vectorial tensor invariants field is reduced to a scalar hue field and visualization of iso-surfaces of this hue value field allows us to identify locations with equivalent flow topology. Additionally highlighting by the maximum of the eigenvalue difference field reflects the magnitude of the structural change of the flow. The method is applied on a vortex breakdown flow structure inside a cylinder with a rotating lid
Keywords: Flow visualization;Invariants;Tensor field Topology;associated tensor fields;equivalent flow topology;flow patterns;flow visualisation;flow visualization;fluid dynamics;pattern formation;red-green-blue color space;rotating lid;tensor norm;topological flow field analysis;vectorial tensor invariants field;vortex breakdown flow structures;vortices;
Author: Rutten, M.; Chong, M.S.

Year: 2006
Title: Superellipsoid-based, Real Symmetric Traceless Tensor Glyphs Motivated by Nematic Liquid Crystal Alignment Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015482
Abstract: A glyph-based method for visualizing the nematic liquid crystal alignment tensor is introduced. Unlike previous approaches, the glyph is based upon physically-linked metrics, not offsets of the eigenvalues. These metrics, combined with a set of superellipsoid shapes, communicate both the strength of the crystal's uniaxial alignment and the amount of biaxiality. With small modifications, our approach can visualize any real symmetric traceless tensor
Keywords: data visualisation;eigenvalues;eigenvalues and eigenfunctions;nematic liquid crystal alignment tensor visualization;nematic liquid crystals;nematic liquid crystals;physics computing;scientific visualization;superellipsoid-based real symmetric traceless tensor glyphs;symmetric traceless tensor;tensor visualization;tensors;
Author: Jankun-Kelly, T.J.; Mehta, K.

Year: 2006
Title: High-Quality Extraction of Isosurfaces from Regular and Irregular Grids
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015483
Abstract: Isosurfaces are ubiquitous in many fields, including visualization, graphics, and vision. They are often the main computational component of important processing pipelines (e.g., surface reconstruction), and are heavily used in practice. The classical approach to compute isosurfaces is to apply the Marching Cubes algorithm, which although robust and simple to implement, generates surfaces that require additional processing steps to improve triangle quality and mesh size. An important issue is that in some cases, the surfaces generated by Marching Cubes are irreparably damaged, and important details are lost which can not be recovered by subsequent processing. The main motivation of this work is to develop a technique capable of constructing high-quality and high-fidelity isosurfaces. We propose a new advancing front technique that is capable of creating high-quality isosurfaces from regular and irregular volumetric datasets. Our work extends the guidance field framework of Schreiner et al. to implicit surfaces, and improves it in significant ways. In particular, we describe a set of sampling conditions that guarantee that surface features will be captured by the algorithm. We also describe an efficient technique to compute a minimal guidance field, which greatly improves performance. Our experimental results show that our technique can generate high-quality meshes from complex datasets
Keywords: Advancing Front;Algorithms;Computer Graphics;Curvature;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Isosurface Extraction;Marching Cubes algorithm;Reproducibility of Results;Sensitivity and Specificity;computational geometry;data visualisation;feature extraction;high-quality isosurface extraction;image reconstruction;irregular grids;mesh generation;minimal guidance field;regular grids;sampling conditions;surface fitting;surface reconstruction;
Author: Schreiner, J.; Scheiclegger, C.E.; Silva, C.T.

Year: 2006
Title: Mesh Layouts for Block-Based Caches
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015484
Abstract: Current computer architectures employ caching to improve the performance of a wide variety of applications. One of the main characteristics of such cache schemes is the use of block fetching whenever an uncached data element is accessed. To maximize the benefit of the block fetching mechanism, we present novel cache-aware and cache-oblivious layouts of surface and volume meshes that improve the performance of interactive visualization and geometric processing algorithms. Based on a general I/O model, we derive new cache-aware and cache-oblivious metrics that have high correlations with the number of cache misses when accessing a mesh. In addition to guiding the layout process, our metrics can be used to quantify the quality of a layout, e.g. for comparing different layouts of the same mesh and for determining whether a given layout is amenable to significant improvement. We show that layouts of unstructured meshes optimized for our metrics result in improvements over conventional layouts in the performance of visualization applications such as isosurface extraction and view-dependent rendering. Moreover, we improve upon recent cache-oblivious mesh layouts in terms of performance, applicability, and accuracy
Keywords: Mesh and graph layouts;block fetching;block-based caches;cache storage;cache-aware and cache-oblivious layouts;cache-aware layouts;cache-oblivious layouts;computational geometry;computer architectures;data locality.;data visualisation;geometric processing algorithms;interactive systems;interactive visualization;isosurface extraction;mesh generation;mesh layouts;metrics for cache coherence;uncached data element;unstructured meshes;view-dependent rendering;volume meshes;
Author: Sung-Eui Yoon; Lindstrom, P.

Year: 2006
Title: Out-of-Core Remeshing of Large Polygonal Meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015485
Abstract: We propose an out-of-core method for creating semi-regular surface representations from large input surface meshes. Our approach is based on a streaming implementation of the MAPS remesher of Lee et al. Our remeshing procedure consists of two stages. First, a simplification process is used to obtain the base domain. During simplification, we maintain the mapping information between the input and the simplified meshes. The second stage of remeshing uses the mapping information to produce samples of the output semi-regular mesh. The out-of-core operation of our method is enabled by the synchronous streaming of a simplified mesh and the mapping information stored at the original vertices. The synchronicity of two streaming buffers is maintained using a specially designed write strategy for each buffer. Experimental results demonstrate the remeshing performance of the proposed method, as well as other applications that use the created mapping between the simplified and the original surface representations
Keywords: MAPS remesher;Out-of-core algorithm;computational geometry;data compression;large input surface meshes;large polygonal meshes;mesh generation;out-of-core remeshing;semi-regular remeshing;semiregular surface representations;shape compression;shape compression;solid modelling;surface fitting;
Author: Minsu Ahn; Guskov, I.; Seungyong Lee

Year: 2006
Title: Interactive Point-Based Rendering of Higher-Order Tetrahedral Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015486
Abstract: Computational simulations frequently generate solutions defined over very large tetrahedral volume meshes containing many millions of elements. Furthermore, such solutions may often be expressed using non-linear basis functions. Certain solution techniques, such as discontinuous Galerkin methods, may even produce non-conforming meshes. Such data is difficult to visualize interactively, as it is far too large to fit in memory and many common data reduction techniques, such as mesh simplification, cannot be applied to non-conforming meshes. We introduce a point-based visualization system for interactive rendering of large, potentially non-conforming, tetrahedral meshes. We propose methods for adaptively sampling points from non-linear solution data and for decimating points at run time to fit GPU memory limits. Because these are streaming processes, memory consumption is independent of the input size. We also present an order-independent point rendering method that can efficiently render volumes on the order of 20 million tetrahedra at interactive rates
Keywords: Interactive large higher-order tetrahedral volume visualization;adaptively sampling points;computational geometry;computational simulations;data visualisation;higher-order tetrahedral data;interactive point-based rendering;interactive systems;memory consumption;mesh generation;order-independent point rendering method;point-based visualization system;point-based visualization.;rendering (computer graphics);tetrahedral volume meshes;
Author: Yuan Zhou; Garland, M.

Year: 2006
Title: Ambient Occlusion and Edge Cueing for Enhancing Real Time Molecular Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015487
Abstract: The paper presents a set of combined techniques to enhance the real-time visualization of simple or complex molecules (up to order of 10<sup>6</sup> atoms) space fill mode. The proposed approach includes an innovative technique for efficient computation and storage of ambient occlusion terms, a small set of GPU accelerated procedural impostors for space-fill and ball-and-stick rendering, and novel edge-cueing techniques. As a result, the user's understanding of the three-dimensional structure under inspection is strongly increased (even for'still images), while the rendering still occurs in real time
Keywords: 3D shapes;Algorithms;Ambient Occlusion;Biopolymers;Computer Graphics;Computer Simulation;Computer Systems;Cues;GPU accelerated procedural impostors;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Chemical;Models, Molecular;Molecular Conformation;Molecular Visualization;Real Time Rendering;User-Computer Interface;ambient occlusion;ball-and-stick rendering;biological techniques;biology computing;data visualisation;edge cueing;molecular biophysics;molecular configurations;proteins;proteins;real time molecular visualization enhancement;rendering (computer graphics);solid modelling;space-fill rendering;
Author: Tarini, M.; Cignoni, P.; Montani, C.

Year: 2006
Title: Fast and Efficient Compression of Floating-Point Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015488
Abstract: Large scale scientific simulation codes typically run on a cluster of CPUs that write/read time steps to/from a single file system. As data sets are constantly growing in size, this increasingly leads to I/O bottlenecks. When the rate at which data is produced exceeds the available I/O bandwidth, the simulation stalls and the CPUs are idle. Data compression can alleviate this problem by using some CPU cycles to reduce the amount of data needed to be transfered. Most compression schemes, however, are designed to operate offline and seek to maximize compression, not throughput. Furthermore, they often require quantizing floating-point values onto a uniform integer grid, which disqualifies their use in applications where exact values must be retained. We propose a simple scheme for lossless, online compression of floating-point data that transparently integrates into the I/O of many applications. A plug-in scheme for data-dependent prediction makes our scheme applicable to a wide variety of data used in visualization, such as unstructured meshes, point sets, images, and voxel grids. We achieve state-of-the-art compression rates and speeds, the latter in part due to an improved entropy coder. We demonstrate that this significantly accelerates I/O throughput in real simulation runs. Unlike previous schemes, our method also adapts well to variable-precision floating-point and integer data
Keywords: High throughput;I/O bandwidth;data compression;data visualisation;data visualization;data-dependent prediction;fast entropy coding;file compaction for I/O efficiency;floating point arithmetic;large scale simulation and visualization.;lossless compression;mathematics computing;online floating-point data compression;plug-in scheme;predictive coding;range coder;scientific simulation codes;
Author: Lindstrom, P.; Isenburg, M.

Year: 2006
Title: Visualization and Analysis of Large Data Collections: a Case Study Applied to Confocal Microscopy Data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015489
Abstract: In this paper we propose an approach in which interactive visualization and analysis are combined with batch tools for the processing of large data collections. Large and heterogeneous data collections are difficult to analyze and pose specific problems to interactive visualization. Application of the traditional interactive processing and visualization approaches as well as batch processing encounter considerable drawbacks for such large and heterogeneous data collections due to the amount and type of data. Computing resources are not sufficient for interactive exploration of the data and automated analysis has the disadvantage that the user has only limited control and feedback on the analysis process. In our approach, an analysis procedure with features and attributes of interest for the analysis is defined interactively. This procedure is used for offline processing of large collections of data sets. The results of the batch process along with "visual summaries" are used for further analysis. Visualization is not only used for the presentation of the result, but also as a tool to monitor the validity and quality of the operations performed during the batch process. Operations such as feature extraction and attribute calculation of the collected data sets are validated by visual inspection. This approach is illustrated by an extensive case study, in which a collection of confocal microscopy data sets is analyzed
Keywords: Algorithms;Biomedical visualization;Computer Graphics;Database Management Systems;Databases, Factual;Image Enhancement;Image Interpretation, Computer-Assisted;Information Storage and Retrieval;Microscopy, Confocal;Software;User-Computer Interface;attribute calculation;confocal microscopy data;data visualisation;feature extraction;feature extraction;features in volume data sets;interactive systems;interactive visualization;large data collection analysis;large data collection visualization;large data set visualization. Author 1:;medical image processing;microscopic images;microscopy;
Author: de Leeuw, W.; Verschure, P.J.; van Liere, R.

Year: 2006
Title: On Histograms and Isosurface Statistics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015490
Abstract: In this paper, we show that histograms represent spatial function distributions with a nearest neighbour interpolation. We confirm that this results in systematic underrepresentation of transitional features of the data, and provide new insight why this occurs. We further show that isosurface statistics, which use higher quality interpolation, give better representations of the function distribution. We also use our experimentally collected isosurface statistics to resolve some questions as to the formal complexity of isosurfaces
Keywords: Algorithms;Computer Graphics;Computer Simulation;Data Interpretation, Statistical;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Models, Statistical;User-Computer Interface;data visualisation;histograms;histograms;interpolation;isosurface statistics;isosurface statistics;isosurfaces;mathematics computing;nearest neighbour interpolation;spatial function distributions;statistical analysis;surface fitting;
Author: Carr, H.; Duffy, B.; Denby, B.

Year: 2006
Title: Interactive Point-based Isosurface Exploration and High-quality Rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015491
Abstract: We present an efficient point-based isosurface exploration system with high quality rendering. Our system incorporates two point-based isosurface extraction and visualization methods: edge splatting and the edge kernel method. In a volume, two neighboring voxels define an edge. The intersection points between the active edges and the isosurface are used for exact isosurface representation. The point generation is incorporated in the GPU-based hardware-accelerated rendering, thus avoiding any overhead when changing the isovalue in the exploration. We call this method edge splatting. In order to generate high quality isosurface rendering regardless of the volume resolution and the view, we introduce an edge kernel method. The edge kernel upsamples the isosurface by subdividing every active cell of the volume data. Enough sample points are generated to preserve the exact shape of the isosurface defined by the trilinear interpolation of the volume data. By employing these two methods, we can achieve interactive isosurface exploration with high quality rendering
Keywords: Algorithms;Computer Graphics;GPU acceleration.;GPU-based hardware-accelerated rendering;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Isosurface;Numerical Analysis, Computer-Assisted;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;User-Computer Interface;computer graphic equipment;data visualisation;edge detection;edge kernel method;edge splatting;feature extraction;hardware acceleration;high-quality rendering;interactive point-based isosurface exploration system;interactive systems;interpolation;isosurface extraction;point-based isosurface extraction;point-based isosurface visualization;point-based visualization;rendering (computer graphics);surface fitting;trilinear interpolation;
Author: Zhang, H.; Kaufman, A.

Year: 2006
Title: Using Difference Intervals for Time-Varying Isosurface Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015492
Abstract: We present a novel approach to out-of-core time-varying isosurface visualization. We attempt to interactively visualize time-varying datasets which are too large to fit into main memory using a technique which is dramatically different from existing algorithms. Inspired by video encoding techniques, we examine the data differences between time steps to extract isosurface information. We exploit span space extraction techniques to retrieve operations necessary to update isosurface geometry from neighboring time steps. Because only the changes between time steps need to be retrieved from disk, I/O bandwidth requirements are minimized. We apply temporal compression to further reduce disk access and employ a point-based previewing technique that is refined in idle interaction cycles. Our experiments on computational simulation data indicate that this method is an extremely viable solution to large time-varying isosurface visualization. Our work advances the state-of-the-art by enabling all isosurfaces to be represented by a compact set of operations
Keywords: Isosurface;computational geometry;data compression;data visualisation;difference intervals;feature extraction;interactive systems;isosurface geometry;isosurface information extraction;out-of-core;out-of-core time-varying isosurface visualization;point-based previewing technique;point-based rendering;rendering (computer graphics);span space;span space extraction techniques;surface fitting;temporal compression;time-varying;time-varying dataset interactive visualization;video encoding techniques;
Author: Waters, K.W.; Co, C.S.; Joy, K.I.

Year: 2006
Title: Isosurface Extraction and Spatial Filtering using Persistent Octree (POT)
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015493
Abstract: We propose a novel persistent octree (POT) indexing structure for accelerating isosurface extraction and spatial filtering from volumetric data. This data structure efficiently handles a wide range of visualization problems such as the generation of view-dependent isosurfaces, ray tracing, and isocontour slicing for high dimensional data. POT can be viewed as a hybrid data structure between the interval tree and the branch-on-need octree (BONO) in the sense that it achieves the asymptotic bound of the interval tree for identifying the active cells corresponding to an isosurface and is more efficient than BONO for handling spatial queries. We encode a compact octree for each isovalue. Each such octree contains only the corresponding active cells, in such a way that the combined structure has linear space. The inherent hierarchical structure associated with the active cells enables very fast filtering of the active cells based on spatial constraints. We demonstrate the effectiveness of our approach by performing view-dependent isosurfacing on a wide variety of volumetric data sets and 4D isocontour slicing on the time-varying Richtmyer-Meshkov instability dataset
Keywords: 4D isocontour slicing;Algorithms;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Richtmyer-Meshkov instability dataset;User-Computer Interface;branch-on-need octree;data visualisation;database indexing;feature extraction;hybrid data structure;indexing.;isosurface extraction;isosurface extraction;octrees;persistent octree;scientific visualization;spatial data structures;spatial filtering;
Author: Shi, Q.; JaJa, J.

Year: 2006
Title: Scalable Data Servers for Large Multivariate Volume Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015494
Abstract: Volumetric datasets with multiple variables on each voxel over multiple time steps are often complex, especially when considering the exponentially large attribute space formed by the variables in combination with the spatial and temporal dimensions. It is intuitive, practical, and thus often desirable, to interactively select a subset of the data from within that high-dimensional value space for efficient visualization. This approach is straightforward to implement if the dataset is small enough to be stored entirely in-core. However, to handle datasets sized at hundreds of gigabytes and beyond, this simplistic approach becomes infeasible and thus, more sophisticated solutions are needed. In this work, we developed a system that supports efficient visualization of an arbitrary subset, selected by range-queries, of a large multivariate time-varying dataset. By employing specialized data structures and schemes of data distribution, our system can leverage a large number of networked computers as parallel data servers, and guarantees a near optimal load-balance. We demonstrate our system of scalable data servers using two large time-varying simulation datasets
Keywords: Clinical Trials, Phase III as Topic;Data Interpretation, Statistical;Drug Industry;Humans;Parallel and distributed volume visualization;Research Design;data visualisation;file servers;large data set visualization;multi-variate visualization;multivariate time-varying dataset;multivariate volume visualization;parallel data servers;scalable data servers;spatial data structures;spatial data structures;volume visualization.;
Author: Glatter, M.; Mollenhour, C.; Huang, J.; Gao, J.

Year: 2006
Title: Distributed Shared Memory for Roaming Large Volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015495
Abstract: We present a cluster-based volume rendering system for roaming very large volumes. This system allows to move a gigabyte-sized probe inside a total volume of several tens or hundreds of gigabytes in real-time. While the size of the probe is limited by the total amount of texture memory on the cluster, the size of the total data set has no theoretical limit. The cluster is used as a distributed graphics processing unit that both aggregates graphics power and graphics memory. A hardware-accelerated volume renderer runs in parallel on the cluster nodes and the final image compositing is implemented using a pipelined sort-last rendering algorithm. Meanwhile, volume bricking and volume paging allow efficient data caching. On each rendering node, a distributed hierarchical cache system implements a global software-based distributed shared memory on the cluster. In case of a cache miss, this system first checks page residency on the other cluster nodes instead of directly accessing local disks. Using two gigabit Ethernet network interfaces per node, we accelerate data fetching by a factor of 4 compared to directly accessing local disks. The system also implements asynchronous disk access and texture loading, which makes it possible to overlap data loading, volume slicing and rendering for optimal volume roaming
Keywords: Clinical Trials, Phase II as Topic;Clinical Trials, Phase III as Topic;Data Interpretation, Statistical;Humans;Large volumes;Probability;Sample Size;cache storage;cluster-based volume rendering system;data caching;distributed graphics processing;distributed shared memory;distributed shared memory;distributed shared memory systems;gigabit Ethernet network interface;graphics cluster.;graphics hardware;hardware-accelerated volume visualization;hierarchical caching;optimal volume roaming;out-of-core;paged storage;parallel rendering;pipelined sort-last rendering algorithm;rendering (computer graphics);volume roaming;workstation clusters;
Author: Castanie, L.; Mion, C.; Cavin, X.; Levy, B.

Year: 2006
Title: Progressive Volume Rendering of Large Unstructured Grids
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015496
Abstract: We describe a new progressive technique that allows real-time rendering of extremely large tetrahedral meshes. Our approach uses a client-server architecture to incrementally stream portions of the mesh from a server to a client which refines the quality of the approximate rendering until it converges to a full quality rendering. The results of previous steps are re-used in each subsequent refinement, thus leading to an efficient rendering. Our novel approach keeps very little geometry on the client and works by refining a set of rendered images at each step. Our interactive representation of the dataset is efficient, light-weight, and high quality. We present a framework for the exploration of large datasets stored on a remote server with a thin client that is capable of rendering and managing full quality volume visualizations
Keywords: Client-Server;Clinical Trials as Topic;Endpoint Determination;Humans;Large Unstructured Grids;Level-of-Detail;Progressive Rendering;Research Design;Sample Size;Volume Rendering;client-server architecture;client-server systems;grid computing;real-time rendering;remote server;rendering (computer graphics);tetrahedral mesh;unstructured grids;volume rendering;
Author: Callahan, S.P.; Bavoil, L.; Pascucci, V.; Silva, C.T.

Year: 2006
Title: Representing Higher-Order Singularities in Vector Fields on Piecewise Linear Surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015497
Abstract: Accurately representing higher-order singularities of vector fields defined on piecewise linear surfaces is a non-trivial problem. In this work, we introduce a concise yet complete interpolation scheme of vector fields on arbitrary triangulated surfaces. The scheme enables arbitrary singularities to be represented at vertices. The representation can be considered as a facet-based "encoding" of vector fields on piecewise linear surfaces. The vector field is described in polar coordinates over each facet, with a facet edge being chosen as the reference to define the angle. An integer called the period jump is associated to each edge of the triangulation to remove the ambiguity when interpolating the direction of the vector field between two facets that share an edge. To interpolate the vector field, we first linearly interpolate the angle of rotation of the vectors along the edges of the facet graph. Then, we use a variant of Nielson's side-vertex scheme to interpolate the vector field over the entire surface. With our representation, we remove the bound imposed on the complexity of singularities that a vertex can represent by its connectivity. This bound is a limitation generally exists in vertex-based linear schemes. Furthermore, using our data structure, the index of a vertex of a vector field can be combinatorily determined
Keywords: Bayes Theorem;Clinical Trials, Phase II as Topic;GPU;Humans;Nielson side-vertex scheme;Randomized Controlled Trials as Topic;Research Design;Stomach Neoplasms;arbitrary triangulated surface;computational complexity;computational geometry;data visualisation;facet graph;graph theory;higher-order singularities;higher-order singularity representation;interpolation;interpolation scheme;line integral convolution;piecewise linear surfaces;vector field visualization;vector fields;vectors;
Author: Li, W.-C.; Vallet, B.; Ray, N.; Levy, B.

Year: 2006
Title: Techniques for the Visualization of Topological Defect Behavior in Nematic Liquid Crystals
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015498
Abstract: We present visualization tools for analyzing molecular simulations of liquid crystal (LC) behavior. The simulation data consists of terabytes of data describing the position and orientation of every molecule in the simulated system over time. Condensed matter physicists study the evolution of topological defects in these data, and our visualization tools focus on that goal. We first convert the discrete simulation data to a sampled version of a continuous second-order tensor field and then use combinations of visualization methods to simultaneously display combinations of contractions of the tensor data, providing an interactive environment for exploring these complicated data. The system, built using AVS, employs colored cutting planes, colored isosurfaces, and colored integral curves to display fields of tensor contractions including Westin's scalar c<sub>l</sub>, c<sub>p </sub>, and c<sub>s</sub> metrics and the principal eigenvector. Our approach has been in active use in the physics lab for over a year. It correctly displays structures already known; it displays the data in a spatially and temporally smoother way than earlier approaches, avoiding confusing grid effects and facilitating the study of multiple time steps; it extends the use of tools developed for visualizing diffusion tensor data, re-interpreting them in the context of molecular simulations; and it has answered long-standing questions regarding the orientation of molecules around defects and the conformational changes of the defects
Keywords: Case Studies;Clinical Trials as Topic;Data Interpretation, Statistical;Decision Making;Humans;Liquid Crystals;Molecular Modeling;Research Design;Tensor Visualization;continuous second-order tensor field;data visualisation;digital simulation;molecular simulation analyzing;nematic liquid crystals;nematic liquid crystals;physics computing;physics lab;tensors;topological defect behavior;visualization technique;
Author: Slavin, V.A.; Pelcovits, R.A.; Loriot, G.; Callan-Jones, A.; Laidlaw, D.H.

Year: 2006
Title: Diffusion Tensor Visualization with Glyph Packing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015499
Abstract: A common goal of multivariate visualization is to enable data inspection at discrete points, while also illustrating larger-scale continuous structures. In diffusion tensor visualization, glyphs are typically used to meet the first goal, and methods such as texture synthesis or fiber tractography can address the second. We adapt particle systems originally developed for surface modeling and anisotropic mesh generation to enhance the utility of glyph-based tensor visualizations. By carefully distributing glyphs throughout the field (either on a slice, or in the volume) into a dense packing, using potential energy profiles shaped by the local tensor value, we remove undue visual emphasis of the regular sampling grid of the data, and the underlying continuous features become more apparent. The method is demonstrated on a DT-MRI scan of a patient with a brain tumor
Keywords: Bayes Theorem;Clinical Trials as Topic;Diffusion tensor;Dose-Response Relationship, Drug;Humans;Maximum Tolerated Dose;Regression Analysis;anisotropic mesh generation;anisotropic sampling;biomedical MRI;brain;brain tumor;data visualisation;diffusion tensor visualization;fiber tractography;fiber tractography;glyph packing;glyphs;medical image processing;mesh generation;particle systems;patient DT-MRI scan;surface modeling;tensors;tumours;
Author: Kindlmann, G.; and Westin, C.-F.

Year: 2006
Title: Extensions of the Zwart-Powell Box Spline for Volumetric Data Reconstruction on the Cartesian Lattice
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015500
Abstract: In this article we propose a box spline and its variants for reconstructing volumetric data sampled on the Cartesian lattice. In particular we present a tri-variate box spline reconstruction kernel that is superior to tensor product reconstruction schemes in terms of recovering the proper Cartesian spectrum of the underlying function. This box spline produces a C<sup>2</sup> reconstruction that can be considered as a three dimensional extension of the well known Zwart-Powell element in 2D. While its smoothness and approximation power are equivalent to those of the tri-cubic B-spline, we illustrate the superiority of this reconstruction on functions sampled on the Cartesian lattice and contrast it to tensor product B-splines. Our construction is validated through a Fourier domain analysis of the reconstruction behavior of this box spline. Moreover, we present a stable method for evaluation of this box spline by means of a decomposition. Through a convolution, this decomposition reduces the problem to evaluation of a four directional box spline that we previously published in its explicit closed form
Keywords: Cartesian lattice;Clinical Trials, Phase II as Topic;Data Interpretation, Statistical;Fourier analysis;Fourier domain analysis;Humans;Pulmonary Disease, Chronic Obstructive;Research Design;Sample Size;Volumetric data interpolation;Zwart-Powell box spline;box splines;computational geometry;interpolation;reconstruction;sampling methods;splines (mathematics);tricubic B-spline;volumetric data reconstruction;
Author: Entezari, A.; Moller, T.

Year: 2006
Title: A Generic and Scalable Pipeline for GPU Tetrahedral Grid Rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015501
Abstract: Recent advances in algorithms and graphics hardware have opened the possibility to render tetrahedral grids at interactive rates on commodity PCs. This paper extends on this work in that it presents a direct volume rendering method for such grids which supports both current and upcoming graphics hardware architectures, large and deformable grids, as well as different rendering options. At the core of our method is the idea to perform the sampling of tetrahedral elements along the view rays entirely in local barycentric coordinates. Then, sampling requires minimum GPU memory and texture access operations, and it maps efficiently onto a feed-forward pipeline of multiple stages performing computation and geometry construction. We propose to spawn rendered elements from one single vertex. This makes the method amenable to upcoming Direct3D 10 graphics hardware which allows to create geometry on the GPU. By only modifying the algorithm slightly it can be used to render per-pixel iso-surfaces and to perform tetrahedral cell projection. As our method neither requires any pre-processing nor an intermediate grid representation it can efficiently deal with dynamic and large 3D meshes
Keywords: Adolescent;Adolescent Psychology;Child;Child Psychology;Curriculum;Direct volume rendering;GPU tetrahedral grid rendering;Great Britain;Health Services Needs and Demand;Humans;Interdisciplinary Communication;Mental Disorders;Mental Health Services;Psychosocial Deprivation;Teaching;computational geometry;computer graphic equipment;feed-forward pipeline;geometry construction;graphics hardware;grid computing;pipeline processing;programmable graphics hardware;rendering (computer graphics);unstructured grids;
Author: Georgii, J.; Westermann, R.

Year: 2006
Title: A Spectral Analysis of Function Composition and its Implications for Sampling in Direct Volume Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4015502
Abstract: In this paper we investigate the effects of function composition in the form g(f(x)) = h(x) by means of a spectral analysis of h. We decompose the spectral description of h(x) into a scalar product of the spectral description of g(x) and a term that solely depends on f(x) and that is independent of g(x). We then use the method of stationary phase to derive the essential maximum frequency of g(f(x)) bounding the main portion of the energy of its spectrum. This limit is the product of the maximum frequency of g(x) and the maximum derivative of f(x). This leads to a proper sampling of the composition h of the two functions g and f. We apply our theoretical results to a fundamental open problem in volume rendering - the proper sampling of the rendering integral after the application of a transfer function. In particular, we demonstrate how the sampling criterion can be incorporated in adaptive ray integration, visualization with multi-dimensional transfer functions, and pre-integrated volume rendering
Keywords: Adolescent;Child;Child Behavior Disorders;Community Mental Health Services;Comprehensive Health Care;Demography;Family;Female;Fourier analysis;Fourier transform;Great Britain;Humans;Interinstitutional Relations;Male;Parent-Child Relations;Parents;Program Development;Psychology;Questionnaires;Severity of Illness Index;adaptive sampling.;data visualisation;direct volume visualization;multidimensional transfer functions;pre-integrated volume rendering;rendering (computer graphics);sampling method;signal processing;signal sampling;spectral analysis;spectral analysis;transfer function;volume rendering;
Author: Bergner, S.; Moller, T.; Weiskopf, D.; Muraki, D.J.

