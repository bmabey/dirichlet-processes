Year: 2005
Title: Framework for visualizing higher-order basis functions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532776
Abstract: Techniques in numerical simulation such as the finite element method depend on basis functions for approximating the geometry and variation of the solution over discrete regions of a domain. Existing visualization systems can visualize these basis functions if they are linear, or for a small set of simple non-linear bases. However, newer numerical approaches often use basis functions of elevated and mixed order or complex form; hence existing visualization systems cannot directly process them. In this paper we describe an approach that supports automatic, adaptive tessellation of general basis functions using a flexible and extensible software architecture in conjunction with an on demand, edge-based recursive subdivision algorithm. The framework supports the use of functions implemented in external simulation packages, eliminating the need to reimplement the bases within the visualization system. We demonstrate our method on several examples, and have implemented the framework in the open-source visualization system VTK.
Keywords:  computational geometry; data visualisation; edge-based recursive subdivision algorithm; finite element analysis; finite element method; higher-order basis functions; open-source visualization system; software architecture; splines (mathematics);
Author: Schroeder, W.J.; Bertel, F.; Malaterre, M.; Thompson, D.; Pebay, P.P.; O'Barall, R.; Saurabh Tendulkar

Year: 2005
Title: Visualization of white matter tracts with wrapped streamlines
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532777
Abstract:  Diffusion tensor imaging is a magnetic resonance imaging method which has gained increasing importance in neuroscience and especially in neurosurgery. It acquires diffusion properties represented by a symmetric 2nd order tensor for each voxel in the gathered dataset. From the medical point of view, the data is of special interest due lo different diffusion characteristics of varying brain tissue allowing conclusions about the underlying structures such as while matter tracts. An obvious way to visualize this data is to focus on the anisotropic areas using the major eigenvector for tractography and rendering lines for visualization of the simulation results. Our approach extends this technique to avoid line representation since lines lead 10 very complex illustrations and furthermore are mistakable. Instead, we generate surfaces wrapping bundles of lines. Thereby, a more intuitive representation of different tracts is achieved.
Keywords: biological tissues; biomedical MRI; brain; brain tissue; data visualisation; data visualization; diffusion tensor imaging; magnetic resonance imaging method; medical image processing; neurophysiology; tensors;
Author: Enders, F.; Sauber, N.; Merhof, D.; Hastreiter, P.; Nimsky, C.; Stamminger, M.

Year: 2005
Title: Fast and reproducible fiber bundle selection in DTI visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532778
Abstract:  Diffusion tensor imaging (DTI) is an MRI-based technique for quantifying water diffusion in living tissue. In the white matter of the brain, water diffuses more rapidly along the neuronal axons than in the perpendicular direction. By exploiting this phenomenon, DTI can be used to determine trajectories of fiber bundles, or neuronal connections between regions, in the brain. The resulting bundles can be visualized. However, the resulting visualizations can be complex and difficult to interpret. An effective approach is to pre-determine trajectories from a large number of positions throughout the white matter (full brain fiber tracking) and to offer facilities to aid the user in selecting fiber bundles of interest. Two factors are crucial for the use and acceptance of this technique in clinical studies: firstly, the selection of the bundles by brain experts should be interactive, supported by real-time visualization of the trajectories registered with anatomical MRI scans. Secondly, the fiber selections should be reproducible, so that different experts will achieve the same results. In this paper we present a practical technique for the interactive selection of fiber-bundles using multiple convex objects that is an order of magnitude faster than similar techniques published earlier. We also present the results of a clinical study with ten subjects that show that our selection approach is highly reproducible for fractional anisotropy (FA) calculated over the selected fiber bundles.
Keywords: DTI visualization; MRI-based technique; anatomical MRI scans; biomedical MRI; brain; brain; data visualisation; diffusion tensor imaging; fiber bundle selection; fractional anisotropy;
Author: Blaas, J.; Botha, C.P.; Peters, B.; Vos, F.M.; Post, F.H.

Year: 2005
Title: Evaluation of fiber clustering methods for diffusion tensor imaging
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532779
Abstract:  Fiber tracking is a standard approach for the visualization of the results of diffusion tensor imaging (DTI). If fibers are reconstructed and visualized individually through the complete white matter, the display gets easily cluttered making it difficult to get insight in the data. Various clustering techniques have been proposed to automatically obtain bundles that should represent anatomical structures, but it is unclear which clustering methods and parameter settings give the best results. We propose a framework to validate clustering methods for white-matter fibers. Clusters are compared with a manual classification which is used as a ground truth. For the quantitative evaluation of the methods, we developed a new measure to assess the difference between the ground truth and the clusterings. The measure was validated and calibrated by presenting different clusterings to physicians and asking them for their judgement. We found that the values of our new measure for different clusterings match well with the opinions of physicians. Using this framework, we have evaluated different clustering algorithms, including shared nearest neighbor clustering, which has not been used before for this purpose. We found that the use of hierarchical clustering using single-link and a fiber similarity measure based on the mean distance between fibers gave the best results.
Keywords: DTI; biodiffusion; biomedical MRI; brain; data visualisation; diffusion tensor imaging; fiber clustering methods; fiber tracking; manual classification; medical image processing; pattern clustering; physicians; white-matter fibers;
Author: Moberts, B.; Vilanova, A.; van Wijk, J.J.

Year: 2005
Title: The application of GPU particle tracing to diffusion tensor field visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532780
Abstract:  In this paper we introduce GPU particle tracing for the visualization of 3D diffusion tensor fields. For about half a million particles, reconstruction of diffusion directions from the tensor field, time integration and rendering can be done at interactive rates. Different visualization options like oriented particles of diffusion-dependent shape, stream lines or stream tubes facilitate the use of particle tracing for diffusion tensor visualization. The proposed methods provide efficient and intuitive means to show the dynamics in diffusion tensor fields, and they accommodate the exploration of the diffusion properties of biological tissue.
Keywords: 3D diffusion tensor field visualization; GPU particle tracing; biodiffusion; biological tissue; biological tissues; data visualisation; diffusion-dependent shape; medical image processing; rendering; rendering (computer graphics); stream lines; stream tubes;
Author: Kondratieva, P.; Kruger, J.; Westermann, R.

Year: 2005
Title: The value of visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532781
Abstract:  The field of visualization is getting mature. Many problems have been solved, and new directions are sought for. In order to make good choices, an understanding of the purpose and meaning of visualization is needed. Especially, it would be nice if we could assess what a good visualization is. In this paper an attempt is made to determine the value of visualization. A technological viewpoint is adopted, where the value of visualization is measured based on effectiveness and efficiency. An economic model of visualization is presented, and benefits and costs are established. Next, consequences (brand limitations of visualization are discussed (including the use of alternative methods, high initial costs, subjective/less, and the role of interaction), as well as examples of the use of the model for the judgement of existing classes of methods and understanding why they are or are not used in practice. Furthermore, two alternative views on visualization are presented and discussed: viewing visualization as an art or as a scientific discipline. Implications and future directions are identified.
Keywords: data visualisation; visualization economic model; visualization value;
Author: van Wijk, J.J.

Year: 2005
Title: On the optimization of visualizations of complex phenomena
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532782
Abstract:  The problem of perceptually optimizing complex visualizations is a difficult one, involving perceptual as well as aesthetic issues. In our experience, controlled experiments are quite limited in their ability to uncover interrelationships among visualization parameters, and thus may not be the most useful way to develop rules-of-thumb or theory to guide the production of high-quality visualizations. In this paper, we propose a new experimental approach to optimizing visualization quality that integrates some of the strong points of controlled experiments with methods more suited to investigating complex highly-coupled phenomena. We use human-in-the-loop experiments to search through visualization parameter space, generating large databases of rated visualization solutions. This is followed by data mining to extract results such as exemplar visualizations, guidelines for producing visualizations, and hypotheses about strategies leading to strong visualizations. The approach can easily address both perceptual and aesthetic concerns, and can handle complex parameter interactions. We suggest a genetic algorithm as a valuable way of guiding the human-in-the-loop search through visualization parameter space. We describe our methods for using clustering, histogramming, principal component analysis, and neural networks for data mining. The experimental approach is illustrated with a study of the problem of optimal texturing for viewing layered surfaces so that both surfaces are maximally observable.
Keywords: complex phenomena visualizations; data mining; data mining; data visualisation; genetic algorithm; genetic algorithms; histogramming; human-in-the-loop experiments; large databases; neural nets; neural networks; optimization; pattern clustering; principal component analysis; principal component analysis; search problems; very large databases; visualization parameter space;
Author: House, D.; Bair, A.; Ware, C.

Year: 2005
Title: Curve-skeleton applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532783
Abstract:  Curve-skeletons are a 1D subset of the medial surface of a 3D object and are useful for many visualization tasks including virtual navigation, reduced-model formulation, visualization improvement, mesh repair, animation, etc. There are many algorithms in the literature describing extraction methodologies for different applications; however, it is unclear how general and robust they are. In this paper, we provide an overview of many curve-skeleton applications and compile a set of desired properties of such representations. We also give a taxonomy of methods and analyze the advantages and drawbacks of each class of algorithms.
Keywords: 1D subset; 3D object; computational geometry; curve fitting; curve-skeleton applications; data visualisation; image representation; image thinning; medial surface; set theory; solid modelling; visualization tasks;
Author: Cornea, N.D.; Silver, D.; Min, P.

Year: 2005
Title: Sort-middle multi-projector immediate-mode rendering in Chromium
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532784
Abstract:  Traditionally, sort-middle is a technique that has been difficult to attain on clusters because of the tight coupling of geometry and rasterization processes on commodity graphics hardware. In this paper, we describe the implementation of a new sort-middle approach for performing immediate-mode rendering in Chromium. The Chromium Rendering System is used extensively to drive multi-projector displays on PC clusters with inexpensive commodity graphics components. By default, Chromium uses a sort-first approach to distribute rendering work to individual nodes in a PC cluster. While this sort-first approach works effectively in retained-mode rendering, it suffers from various network bottlenecks when rendering in immediate-mode. Current techniques avoid these bottlenecks by sorting vertex data as a pre-processing step and grouping vertices into specific bounding boxes, using Chromium's bounding box extension. These steps may be expensive, especially if the dataset is dynamic. In our approach, we utilize standard programmable graphics hardware and extend standard APIs to achieve a separation in the rendering pipeline. The pre-processing of vertex data or the grouping of vertices into bounding boxes are not required. Additionally, the amount of OpenGL state commands transmitted through the network are reduced. Our results indicate that the approach can attain twice the frame rates as compared to Chromium's sort-first approach when rendering in immediate-mode.
Keywords: API; Chromium Rendering System; OpenGL state commands; PC clusters; application program interfaces; computer graphic equipment; multiprojector displays; pipeline processing; programmable graphics hardware; rendering (computer graphics); rendering pipeline; retained-mode rendering; sort-middle multiprojector immediate-mode rendering; sorting; workstation clusters;
Author: Williams, J.L.; Hiromoto, R.E.

Year: 2005
Title: COTS cluster-based sort-last rendering: performance evaluation and pipelined implementation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532785
Abstract:  Sort-last parallel rendering is an efficient technique to visualize huge datasets on COTS clusters. The dataset is subdivided and distributed across the cluster nodes. For every frame, each node renders a full resolution image of its data using its local GPU, and the images are composited together using a parallel image compositing algorithm. In this paper, we present a performance evaluation of standard sort-last parallel rendering methods and of the different improvements proposed in the literature. This evaluation is based on a detailed analysis of the different hardware and software components. We present a new implementation of sort-last rendering that fully overlaps CPU(s), GPU and network usage all along the algorithm. We present experiments on a 3 years old 32-node PC cluster and on a 1.5 years old 5-node PC cluster, both with Gigabit interconnect, showing volume rendering at respectively 13 and 31 frames per second and polygon rendering at respectively 8 and 17 frames per second on a 1024 x 768 render area, and we show that our implementation outperforms or equals many other implementations and specialized visualization clusters.
Keywords: 32-node PC cluster; 5-node PC cluster; COTS cluster-based sort-last parallel rendering; CPU; GPU; Gigabit interconnect; computer graphic equipment; data visualisation; image processing; image resolution; parallel image compositing algorithm; performance evaluation; pipeline processing; pipelined implementation; polygon rendering; rendering (computer graphics); sorting; volume rendering; workstation clusters;
Author: Cavin, X.; Mion, C.; Filbois, A.

Year: 2005
Title: OpenGL multipipe SDK: a toolkit for scalable parallel rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532786
Abstract:  We describe OpenGL multipipe SDK (MPK), a toolkit for scalable parallel rendering based on OpenGL. MPK provides a uniform application programming interface (API) to manage scalable graphics applications across many different graphics subsystems. MPK-based applications run seamlessly from single-processor, single-pipe desktop systems to large multi-processor, multipipe scalable graphics systems. The application is oblivious of the system configuration, which can be specified through a configuration file at run time. To scale application performance, MPK uses a decomposition system that supports different modes for task partitioning and implements optimized CPU-based composition algorithms. MPK also provides a customizable image composition interface, which can be used to apply post-processing algorithms on raw pixel data obtained from executing sub-tasks on multiple graphics pipes in parallel. This can be used to implement parallel versions of any CPU-based algorithm, not necessarily used for rendering. In this paper, we motivate the need for a scalable graphics API and discuss the architecture of MPK. We present MPK's graphics configuration interface, introduce the notion of compound-based decomposition schemes and describe our implementation. We present some results from our work on a couple of target system architectures and conclude with future directions of research in this area.
Keywords: API; MPK graphics configuration interface; OpenGL multipipe SDK; application program interfaces; application programming interface; compound-based decomposition scheme; computer graphic equipment; image composition interface; multiple graphics pipes; open systems; optimized CPU-based composition algorithms; pipeline processing; post-processing algorithms; rendering (computer graphics); scalable parallel rendering;
Author: Praveen Bhaniramka; Robert, P.C.D.; Eilemann, S.

Year: 2005
Title: A shader-based parallel rendering framework
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532787
Abstract:  Existing parallel or remote rendering solutions rely on communicating pixels, OpenGL commands, scene-graph changes or application-specific data. We propose an intermediate solution based on a set of independent graphics primitives that use hardware shaders to specify their visual appearance. Compared to an OpenGL based approach, it reduces the complexity of the model by eliminating most fixed function parameters while giving access to the latest functionalities of graphics cards. It also suppresses the OpenGL state machine that creates data dependencies making primitive re-scheduling difficult. Using a retained-mode communication protocol transmitting changes between each frame, combined with the possibility to use shaders to implement interactive data processing operations instead of sending final colors and geometry, we are able to optimize the network load. High level information such as bounding volumes is used to setup advanced schemes where primitives are issued in parallel, routed according to their visibility, merged and re-ordered when received for rendering. Different optimization algorithms can be efficiently implemented, saving network bandwidth or reducing texture switches for instance. We present performance results based on two VTK applications, a parallel iso-surface extraction and a parallel volume renderer. We compare our approach with Chromium. Results show that our approach leads to significantly better performance and scalability, while offering easy access to hardware accelerated rendering algorithms.
Keywords: Chromium; OpenGL; VTK applications; computer graphic equipment; graphics cards; hardware accelerated rendering algorithms; hardware shaders; optimization algorithms; parallel iso-surface extraction; parallel volume renderer; protocols; rendering (computer graphics); shader-based parallel rendering framework; workstation clusters;
Author: Allard, J.; Raffin, B.

Year: 2005
Title: VisTrails: enabling interactive multiple-view visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532788
Abstract:  VisTrails is a new system that enables interactive multiple-view visualizations by simplifying the creation and maintenance of visualization pipelines, and by optimizing their execution. It provides a general infrastructure that can be combined with existing visualization systems and libraries. A key component of VisTrails is the visualization trail (vistrail), a formal specification of a pipeline. Unlike existing dataflow-based systems, in VisTrails there is a clear separation between the specification of a pipeline and its execution instances. This separation enables powerful scripting capabilities and provides a scalable mechanism for generating a large number of visualizations. VisTrails also leverages the vistrail specification to identify and avoid redundant operations. This optimization is especially useful while exploring multiple visualizations. When variations of the same pipeline need to be executed, substantial speedups can be obtained by caching the results of overlapping subsequences of the pipelines. In this paper, we describe the design and implementation of VisTrails, and show its effectiveness in different application scenarios.
Keywords: VisTrails; data visualisation; formal specification; formal specification; interactive multiple-view visualizations; optimisation; optimization; pipeline processing; visualization pipelines; visualization trail;
Author: Bavoil, L.; Callahan, S.P.; Crossno, P.J.; Freire, J.; Scheidegger, C.E.; Silva, C.T.; Vo, H.T.

Year: 2005
Title: Build-by-number: rearranging the real world to visualize novel architectural spaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532789
Abstract:  We present build-by-number, a technique for quickly designing architectural structures that can be rendered photorealistically at interactive rates. We combine image-based capturing and rendering with procedural modeling techniques to allow the creation of novel structures in the style of real-world structures. Starting with a simple model recovered from a sparse image set, the model is divided into feature regions, such as doorways, windows, and brick. These feature regions essentially comprise a mapping from model space to image space, and can be recombined to texture a novel model. Procedural rules for the growth and reorganization of the model are automatically derived to allow for very fast editing and design. Further, the redundancies marked by the feature labeling can be used to perform automatic occlusion replacement and color equalization in the finished scene, which is rendered using view-dependent texture mapping on standard graphics hardware. Results using four captured scenes show that a great variety of novel structures can be created very quickly once a captured scene is available, and rendered with a degree of realism comparable to the original scene.
Keywords: architectural CAD; architectural structure design; automatic occlusion replacement; build-by-number technique; data visualisation; feature extraction; hidden feature removal; image colour analysis; image texture; image-based capturing; photorealistic rendering; procedural modeling techniques; real-world structures; realistic images; rendering (computer graphics); sparse image set; standard graphics hardware; view-dependent texture mapping;
Author: Bekins, D.; Aliaga, D.G.

Year: 2005
Title: Phonon tracing for auralization and visualization of sound
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532790
Abstract:  We present a new particle tracing approach for the simulation of mid- and high-frequency sound. Inspired by the photorealism obtained by methods like photon mapping, we develop a similar method for the physical simulation of sound within rooms. For given source and listener positions, our method computes a finite-response filter accounting for the different reflections at various surfaces with frequency-dependent absorption coefficients. Convoluting this filter with an anechoic input signal reproduces a realistic aural impression of the simulated room. We do not consider diffraction effects due to low frequencies, since these can be better computed by finite elements. Our method allows the visualization of a wave front propagation using color-coded blobs traversing the paths of individual phonons.
Keywords: acoustic signal processing; acoustic wave propagation; color-coded blobs; data visualisation; finite-response filter accounting; frequency-dependent absorption coefficients; particle tracing approach; phonon tracing; phonons; photon mapping; ray tracing; realistic aural impression; realistic images; sound auralization; sound visualization; wave front propagation;
Author: Bertram, M.; Deines, E.; Mohring, J.; Jegorovs, J.; Hagen, H.

Year: 2005
Title: The visible radio: process visualization of a software-defined radio
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532791
Abstract:  In this case study, a data-oriented approach is used to visualize a complex digital signal processing pipeline. The pipeline implements a frequency modulated (FM) software-defined radio (SDR). SDR is an emerging technology where portions of the radio hardware, such as filtering and modulation, are replaced by software components. We discuss how an SDR implementation is instrumented to illustrate the processes involved in FM transmission and reception. By using audio-encoded images, we illustrate the processes involved in radio, such as how filters are used to reduce noise, the nature of a carrier wave, and how frequency modulation acts on a signal. The visualization approach used in this work is very effective in demonstrating advanced topics in digital signal processing and is a useful tool for experimenting with the software radio design.
Keywords: audio-encoded images; data visualisation; data-oriented approach; digital signal processing pipeline; frequency modulation; frequency modulation; image coding; process visualization; radio hardware; signal processing; software components; software radio; software-defined radio;
Author: Hall, M.; Betts, A.; Cox, D.; Pointer, D.; Kindratenko, V.

Year: 2005
Title: Query-driven visualization of large data sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532792
Abstract:  We present a practical and general-purpose approach to large and complex visual data analysis where visualization processing, rendering and subsequent human interpretation is constrained to the subset of data deemed interesting by the user. In many scientific data analysis applications, "interesting" data can be defined by compound Boolean range queries of the form (temperature>1000) AND (70<pressure<90). As data sizes grow larger, a central challenge is to answer such queries as efficiently as possible. Prior work in the visualization community has focused on answering range queries for scalar fields within the context of accelerating the search phase of isosurface algorithms. In contrast, our work describes an approach that leverages state-of-the-art indexing technology from the scientific data management community called "bitmap indexing". Our implementation, which we call "DEX" (short for dextrous data explorer), uses bitmap indexing to efficiently answer multivariate, multidimensional data queries to provide input to a visualization pipeline. We present an analysis overview and benchmark results that show bitmap indexing offers significant storage and performance improvements when compared to previous approaches for accelerating the search phase of isosurface algorithms. More importantly, since bitmap indexing supports complex multidimensional, multivariate range queries, it is more generally applicable to scientific data visualization and analysis problems. In addition to benchmark performance and analysis, we apply DEX to a typical scientific visualization problem encountered in combustion simulation data analysis.
Keywords: bitmap indexing; combustion simulation data analysis; data visualisation; database indexing; dextrous data explorer; isosurface algorithms; large data sets; multidimensional data queries; query processing; query-driven visualization; rendering (computer graphics); scientific data management; very large databases; visualization pipeline;
Author: Stockinger, K.; Shalf, J.; Wu, K.; Bethel, E.W.

Year: 2005
Title: Visualization of time-dependent remote adaptive mesh refinement data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532793
Abstract:  Analysis of phenomena that simultaneously occur on different spatial and temporal scales requires adaptive, hierarchical schemes to reduce computational and storage demands. Adaptive mesh refinement (AMR) schemes support both refinement in space that results in a time-dependent grid topology, as well as refinement in time that results in updates at higher rates for refined levels. Visualization of AMR data requires generating data for absent refinement levels at specific time steps. We describe a solution starting from a given set of "key frames" with potentially different grid topologies. The presented work was developed in a project involving several research institutes that collaborate in the field of cosmology and numerical relativity. AMR data results from simulations that are run on dedicated compute machines and is thus stored centrally, whereas the analysis of the data is performed on the local computers of the scientists. We built a distributed solution using remote procedure calls (RPC). To keep the application responsive, we split the bulk data transfer from the RPC response and deliver it asynchronously as a binary stream. The number of network round-trips is minimized by using high level operations. In summary, we provide an application for exploratory visualization of remotely stored AMR data.
Keywords: AMR data visualization; absent refinement levels; adaptive mesh refinement; cosmology; data analysis; data visualisation; grid computing; mesh generation; numerical relativity; remote procedure calls; remote procedure calls; time-dependent grid topology;
Author: Kaehler, R.; Prohaska, S.; Hutanu, A.; Hege, H.-C.

Year: 2005
Title: Distributed data management for large volume visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532794
Abstract:  We propose a distributed data management scheme for large data visualization that emphasizes efficient data sharing and access. To minimize data access time and support users with a variety of local computing capabilities, we introduce an adaptive data selection method based on an "enhanced time-space partitioning" (ETSP) tree that assists with effective visibility culling, as well as multiresolution data selection. By traversing the tree, our data management algorithm can quickly identify the visible regions of data, and, for each region, adaptively choose the lowest resolution satisfying user-specified error tolerances. Only necessary data elements are accessed and sent to the visualization pipeline. To further address the issue of sharing large-scale data among geographically distributed collaborative teams, we have designed an infrastructure for integrating our data management technique with a distributed data storage system provided by logistical networking (LoN). Data sets at different resolutions are generated and uploaded to LoN for wide-area access. We describe a parallel volume rendering system that verifies the effectiveness of our data storage, selection and access scheme.
Keywords: adaptive data selection method; data visualisation; distributed data management; distributed data storage system; distributed databases; enhanced time-space partitioning tree; geographically distributed collaborative teams; information retrieval; information storage; large volume visualization; logistical networking; multiresolution data selection; parallel volume rendering system; rendering (computer graphics); temporal databases; tree data structures; user-specified error tolerances; wide area networks;
Author: Gao, J.; Huang, J.; Johnson, C.R.; Atchley, S.

Year: 2005
Title: A contract based system for large data visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532795
Abstract:  VisIt is a richly featured visualization tool that is used to visualize some of the largest simulations ever run. The scale of these simulations requires that optimizations are incorporated into every operation VisIt performs. But the set of applicable optimizations that VisIt can perform is dependent on the types of operations being done. Complicating the issue, VisIt has a plugin capability that allows new, unforeseen components to be added, making it even harder to determine which optimizations can be applied. We introduce the concept of a contract to the standard data flow network design. This contract enables each component of the data flow network to modify the set of optimizations used. In addition, the contract allows for new components to be accommodated gracefully within VisIt's data flow network system.
Keywords: VisIt data flow network design; contract based system; data flow computing; data visualisation; featured visualization tool; very large databases;
Author: Childs, H.; Brugger, E.; Bonnell, K.; Meredith, J.; Miller, M.; Whitlock, B.; Max, N.

Year: 2005
Title: Interactive rendering of large unstructured grids using dynamic level-of-detail
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532796
Abstract:  We describe a new dynamic level-of-detail (LOD) technique that allows real-time rendering of large tetrahedral meshes. Unlike approaches that require hierarchies of tetrahedra, our approach uses a subset of the faces that compose the mesh. No connectivity is used for these faces so our technique eliminates the need for topological information and hierarchical data structures. By operating on a simple set of triangular faces, our algorithm allows a robust and straightforward graphics hardware (GPU) implementation. Because the subset of faces processed can be constrained to arbitrary size, interactive rendering is possible for a wide range of data sets and hardware configurations.
Keywords: computational geometry; computer graphic equipment; data structures; dynamic level-of-detail; graphics hardware; hierarchical data structures; interactive rendering; interactive systems; large tetrahedral meshes; large unstructured grids; mesh generation; rendering (computer graphics);
Author: Callahan, S.P.; Comba, J.L.D.; Shirley, P.; Silva, C.T.

Year: 2005
Title: Batched multi triangulation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532797
Abstract:  The multi triangulation framework (MT) is a very general approach for managing adaptive resolution in triangle meshes. The key idea is arranging mesh fragments at different resolution in a directed acyclic graph (DAG) which encodes the dependencies between fragments, thereby encompassing a wide class of multiresolution approaches that use hierarchies or DAGs with predefined topology. On current architectures, the classic MT is however unfit for real-time rendering, since DAG traversal costs vastly dominate raw rendering costs. In this paper, we redesign the MT framework in a GPU friendly fashion, moving its granularity from triangles to precomputed optimized triangle patches. The patches can be conveniently tri-stripped and stored in secondary memory to be loaded on demand, ready to be sent to the GPU using preferential paths. In this manner, central memory only contains the DAG structure and CPU workload becomes negligible. The major contributions of this work are: a new out-of-core multiresolution framework, that, just like the MT, encompasses a wide class of multiresolution structures; a robust and elegant way to build a well conditioned MT DAG by introducing the concept of V-partitions, that can encompass various state of the art multiresolution algorithms; an efficient multithreaded rendering engine and a general subsystem for the external memory processing and simplification of huge meshes.
Keywords: V-partition concept; computational geometry; directed acyclic graph; directed graphs; graphical user interfaces; mesh generation; multiresolution algorithms; multithreaded rendering engine; multitriangulation framework; out-of-core multiresolution framework; precomputed optimized triangle patches; real-time rendering; rendering (computer graphics); storage management; triangle meshes;
Author: Cignoni, P.; Ganovelli, F.; Gobbetti, E.; Marton, F.; Ponchio, F.; Scopigno, R.

Year: 2005
Title: View-dependent rendering of multiresolution texture-atlases
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532798
Abstract:  Real-time rendering of massively textured 3D scenes usually involves two major problems: Large numbers of texture switches are a well-known performance bottleneck and the set of simultaneously visible textures is limited by the graphics memory. This paper presents a level-of-detail texturing technique that overcomes both problems. In a preprocessing step, the technique creates a hierarchical data structure for all textures used by scene objects, and it derives texture atlases at different resolutions. At runtime, our texturing technique requires only a small set of these texture atlases, which represent scene textures in an appropriate size depending on the current camera position and screen resolution. Independent of the number and total size of all simultaneously visible textures, the achieved frame rates are similar to that of rendering the scene without any texture switches. Since the approach includes dynamic texture loading, the total size of the textures is only limited by the hard disk capacity. The technique is applicable for any 3D scenes whose scene objects are primarily distributed in a plane, such as in the case of 3D city models or outdoor scenes in computer games. Our approach has been successfully applied to massively textured, large-scale 3D city models.
Keywords: 3D city models; computational geometry; computer games; data structures; dynamic texture loading; hierarchical data structure; image resolution; image texture; level-of-detail texturing technique; multiresolution texture-atlases; real-time rendering; rendering (computer graphics); texture switches; textured 3D scenes; view-dependent rendering;
Author: Buchholz, H.; Dollner, J.

Year: 2005
Title: Exploiting frame-to-frame coherence for accelerating high-quality volume raycasting on graphics hardware
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532799
Abstract:  GPU-based raycasting offers an interesting alternative to conventional slice-based volume rendering due to the inherent flexibility and the high quality of the generated images. Recent advances in graphics hardware allow for the ray traversal and volume sampling to be executed on a per-fragment level completely on the GPU leading to interactive framerates. In this work we present optimization techniques that improve the performance and quality of GPU-based volume raycasting. We apply a hybrid image/object space approach to accelerate the ray traversal in animation sequences that works for both isosurface rendering and semi-transparent volume rendering. An empty-space-leaping technique that exploits the spatial coherence between consecutively rendered images is used to estimate the optimal initial ray sampling point for each image pixel. These can double the rendering performance for typical volumetric data sets without sacrificing image quality. The achieved speed-up allows for further improvements of image quality. We demonstrate an object space antialiasing technique based on selective super-sampling at sharp creases and silhouette edges which also benefits from exploiting frame-to-frame coherence.
Keywords: GPU; animation sequence; antialiasing; computer animation; data visualisation; empty-space-leaping technique; frame-to-frame coherence; graphics hardware; high-quality volume raycasting; image quality; image sampling; image sequences; object space antialiasing technique; optimal initial ray sampling; ray tracing; rendering (computer graphics); selective super-sampling; semitransparent volume rendering; silhouette edge; spatial coherence; volume sampling;
Author: Klein, T.; Strengert, M.; Stegmaier, S.; Ertl, T.

Year: 2005
Title: Streaming meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532800
Abstract:  Recent years have seen an immense increase in the complexity of geometric data sets. Today's gigabyte-sized polygon models can no longer be completely loaded into the main memory of common desktop PCs. Unfortunately, current mesh formats, which were designed years ago when meshes were orders of magnitudes smaller, do not account for this. Using such formats to store large meshes is inefficient and complicates all subsequent processing. We describe a streaming format for polygon meshes that is simple enough to replace current offline mesh formats and is more suitable for representing large data sets. Furthermore, it is an ideal input and output format for I/O-efficient out-of-core algorithms that process meshes in a streaming, possibly pipelined, fashion. This paper chiefly concerns the underlying theory and the practical aspects of creating and working with this new representation. In particular, we describe desirable qualities for streaming meshes and methods for converting meshes from a traditional to a streaming format. A central theme of this paper is the issue of coherent and compatible layouts of the mesh vertices and polygons. We present metrics and diagrams that characterize the coherence of a mesh layout and suggest appropriate strategies for improving its "streamability". To this end, we outline several out-of-core algorithms for reordering meshes with poor coherence, and present results for a menagerie of well known and generally incoherent surface meshes.
Keywords: computational complexity; computational geometry; data compression; data visualisation; geometric data sets; mesh generation; mesh layout coherence; mesh streaming; out-of-core algorithm; polygon mesh format;
Author: Isenburg, M.; Lindstrom, P.

Year: 2005
Title: Stream-processing points
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532801
Abstract:  With the growing size of captured 3D models it has become increasingly important to provide basic efficient processing methods for large unorganized raw surface-sample point data sets. In this paper we introduce a novel stream-based (and out-of-core) point processing framework. The proposed approach processes points in an orderly sequential way by sorting them and sweeping along a spatial dimension. The major advantages of this new concept are: (1) support of extensible and concatenate local operators called stream operators, (2) low main-memory usage and (3) applicability to process very large data sets out-of-core.
Keywords: 3D model; computational geometry; data visualisation; image sampling; out-of-core point processing; raw surface-sample point data set; solid modelling; spatial dimension; stream operator; stream-processing point;
Author: Pajarola, R.

Year: 2005
Title: VolumeExplorer: roaming large volumes to couple visualization and data processing for oil and gas exploration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532802
Abstract:  In this paper, we present a volume roaming system dedicated to oil and gas exploration. Our system combines probe-based volume rendering with data processing and computing. The daily oil production and the estimation of the world proven-reserves directly affect the barrel price and have a strong impact on the economy. Among others, production and correct estimation are linked to the accuracy of the sub-surface model used for predicting oil reservoirs shape and size. Geoscientists build this model from the interpretation of seismic data, i.e. 3D images of the subsurface obtained from geophysical surveys. Our system couples visualization and data processing for the interpretation of seismic data. It is based on volume roaming along with efficient volume paging to manipulate the multi-gigabyte data sets commonly acquired during seismic surveys. Our volume rendering lenses implement high quality pre-integrated volume rendering with accurate lighting. They use a generic multi-modal volume rendering system that blends several volumes in the spirit of the "stencil" paradigm used in 2D painting programs. In addition, our system can interactively display non-polygonal isosurfaces painted with an attribute. Beside the visualization algorithms, automatic extraction of local features of the subsurface model also take full advantage of the volume paging.
Keywords: VolumeExplorer; automatic extraction; computational geometry; data processing; data visualisation; data visualization; feature extraction; gas exploration; image texture; multimodal volume rendering system; natural gas technology; nonpolygonal isosurface; oil exploration; oil technology; paged storage; rendering (computer graphics); seismic data interpretation; volume paging; volume roaming system;
Author: Castanie, L.; Levy, B.; Bosquet, F.

Year: 2005
Title: Reflection nebula visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532803
Abstract:  Stars form in dense clouds of interstellar gas and dust. The residual dust surrounding a young star scatters and diffuses its light, making the star's "cocoon" of dust observable from Earth. The resulting structures, called reflection nebulae, are commonly very colorful in appearance due to wavelength-dependent effects in the scattering and extinction of light. The intricate interplay of scattering and extinction cause the color hues, brightness distributions, and the apparent shapes of such nebulae to vary greatly with viewpoint. We describe an interactive visualization tool for realistically rendering the appearance of arbitrary 3D dust distributions surrounding one or more illuminating stars. Our rendering algorithm is based on the physical models used in astrophysics research. The tool can be used to create virtual fly-throughs of reflection nebulae for interactive desktop visualizations, or to produce scientifically accurate animations for educational purposes, e.g., in planetarium shows. The algorithm is also applicable to investigate on-the-fly the visual effects of physical parameter variations, exploiting visualization technology to help gain a deeper and more intuitive understanding of the complex interaction of light and dust in real astrophysical settings.
Keywords: arbitrary 3D dust distribution; astronomy computing; computer animation; data visualisation; interactive desktop visualization tool; interstellar dust; interstellar gas; light scattering; nebulae; realistic images; realistic rendering; reflection nebula visualization; rendering (computer graphics); virtual reality;
Author: Magnor, M.A.; Hildebrand, K.; Lintu, A.; Hanson, A.J.

Year: 2005
Title: Multimodal exploration of the fourth dimension
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532804
Abstract:  We present a multimodal paradigm for exploring topological surfaces embedded in four dimensions; we exploit haptic methods in particular to overcome the intrinsic limitations of 3D graphics images and 3D physical models. The basic problem is that, just as 2D shadows of 3D curves lose structure where lines cross, 3D graphics projections of smooth 4D topological surfaces are interrupted where one surface intersects another. Furthermore, if one attempts to trace real knotted ropes or a plastic models of self-intersecting surfaces with a fingertip, one inevitably collides with parts of the physical artifact. In this work, we exploit the free motion of a computer-based haptic probe to support a continuous motion that follows the local continuity of the object being explored. For our principal test case of 4D-embedded surfaces projected to 3D, this permits us to follow the full local continuity of the surface as though in fact we were touching an actual 4D object. We exploit additional sensory cues to provide supplementary or redundant information. For example, we can use audio tags to note the relative 4D depth of illusory 3D surface intersections produced by projection from 4D, as well as providing automated refinement of the tactile exploration path to eliminate jitter and snagging, resulting in a much cleaner exploratory motion than a bare uncorrected motion. Visual enhancements provide still further improvement to the feedback: by opening a view-direction-defined cutaway into the interior of the 3D surface projection, we allow the viewer to keep the haptic probe continuously in view as it traverses any touchable part of the object. Finally, we extend the static tactile exploration framework using a dynamic mode that links each stylus motion to a change in orientation that creates at each instant a maximal-area screen projection of a neighborhood of the current point of interest. This minimizes 4D distortion and permits true metric sizes to be deduced locally at any point. All these methods combine to reveal the full richness of the complex spatial relationships of the target shapes, and to overcome many expected perceptual limitations in 4D visualization.
Keywords: 3D graphics image; 3D physical model; 3D surface projection; 4D visualization; 4D-embedded surface; computer-based haptic probe; data visualisation; fourth dimension; haptic interfaces; haptic method; multimodal exploration; solid modelling; topological surface; visual enhancement;
Author: Hanson, A.J.; Zhang, H.

Year: 2005
Title: High performance volume splatting for visualization of neurovascular data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532805
Abstract:  A new technique is presented to increase the performance of volume splatting by using hardware accelerated point sprites. This allows creating screen aligned elliptical splats for high quality volume splatting at very low cost on the GPU. Only one vertex per splat is stored on the graphics card. GPU generated point sprite texture coordinates are used for computing splats and per-fragment 3D-texture coordinates on the fly. Thus, only 6 bytes per splat are stored on the GPU and vertex shader load is 25% in comparison to applying textured quads. For eight predefined viewing directions, depth-sorting of the splats is performed in a pre-processing step where the resulting indices are stored on the GPU. Thereby, there is no data transfer between CPU and GPU during rendering. Post-classificative two dimensional transfer functions with lighting for scalar data and tagged volumes were implemented. Thereby, we focused on the visualization of neurovascular structures, where typically no more than 2% of the voxels contribute to the resulting 3D-representation. A comparison with a 3D-texture-based slicing algorithm showed frame rates up to 11 times higher for the presented approach on current CPUs. The presented technique was evaluated with a broad medical database and its value for highly sparse volume visualization is shown.
Keywords: 3D-representation; 3D-texture-based slicing algorithm; GPU; computer graphic equipment; data visualisation; high performance volume splatting; image reconstruction; image representation; image texture; image texture; medical database; neurophysiology; neurovascular data visualization; neurovascular structure; rendering (computer graphics); sparse volume visualization; transfer function; visual databases; volume rendering;
Author: Vega-Higuera, F.; Hastreiter, P.; Fahlbusch, R.; Greiner, G.

Year: 2005
Title: Teniae coli guided navigation and registration for virtual colonoscopy
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532806
Abstract:  We present a new method for guiding virtual colonoscopic navigation and registration by using teniae coli as anatomical landmarks. As most existing protocols require a patient to be scanned in both supine and prone positions to increase sensitivity in detecting colonic polyps, reference and registration between scans are necessary. However, the conventional centerline approach, generating only the longitudinal distance along the colon, lacks the necessary orientation information to synchronize the virtual navigation cameras in both scanned positions. In this paper we describe a semi-automatic method to detect teniae coli from a colonic surface model reconstructed from CT colonography. Teniae coli are three bands of longitudinal smooth muscle on the surface of the colon. They form a triple helix structure from the appendix to the sigmoid colon and are ideal references for virtual navigation. Our method was applied to 3 patients resulting in 6 data sets (supine and prone scans). The detected teniae coli matched well with our visual inspection. In addition, we demonstrate that polyps visible on both scans can be located and matched more efficiently with the aid of a teniae coli guided navigation implementation.
Keywords: CT colonography; colonic surface model; computerised tomography; data visualisation; image reconstruction; image reconstruction; image registration; image registration; medical image processing; sigmoid colon; teniae coli guided navigation; triple helix structure; virtual colonoscopy; virtual navigation camera; virtual reality; visual inspection;
Author: Huang, A.; Roy, D.; Franaszek, M.; Summers, R.M.

Year: 2005
Title: Statistically quantitative volume visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532807
Abstract:  Visualization users are increasingly in need of techniques for assessing quantitative uncertainty and error in the images produced. Statistical segmentation algorithms compute these quantitative results, yet volume rendering tools typically produce only qualitative imagery via transfer function-based classification. This paper presents a visualization technique that allows users to interactively explore the uncertainty, risk, and probabilistic decision of surface boundaries. Our approach makes it possible to directly visualize the combined "fuzzy" classification results from multiple segmentations by combining these data into a unified probabilistic data space. We represent this unified space, the combination of scalar volumes from numerous segmentations, using a novel graph-based dimensionality reduction scheme. The scheme both dramatically reduces the dataset size and is suitable for efficient, high quality, quantitative visualization. Lastly, we show that the statistical risk arising from overlapping segmentations is a robust measure for visualizing features and assigning optical properties.
Keywords: data visualisation; fuzzy classification; graph-based dimensionality reduction scheme; image classification; image classification; image segmentation; probabilistic decision; qualitative imagery; rendering (computer graphics); statistical analysis; statistical segmentation algorithm; statistically quantitative volume visualization; transfer function; volume rendering tool;
Author: Kniss, J.M.; Van Uitert, R.; Stephens, A.; Li, G.-S.; Tasdizen, T.; Hansen, C.

Year: 2005
Title: Scale-invariant volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532808
Abstract:  As standard volume rendering is based on an integral in physical space (or "coordinate space"), it is inherently dependent on the scaling of this space. Although this dependency is appropriate for the realistic rendering of semitransparent volumetric objects, it has several unpleasant consequences for volume visualization. In order to overcome these disadvantages, a new variant of the volume rendering integral is proposed, which is defined in data space instead of physical space. Apart from achieving scale invariance, this new method supports the rendering of isosurfaces of uniform opacity and color, independently of the local gradient or" the visualized scalar field. Moreover, it reveals certain structures in scalar fields even with constant transfer functions. Furthermore, it can be defined as the limit of infinitely many semitransparent isosurfaces, and is therefore based on an intuitive and at the same time precise definition. In addition to the discussion of these features of scale-invariant volume rendering, efficient adaptations of existing volume rendering algorithms and extensions for silhouette enhancement and local illumination by transmitted light are presented.
Keywords: data visualisation; feature extraction; feature extraction; image enhancement; realistic images; realistic rendering; rendering (computer graphics); scale-invariant volume rendering; semitransparent volumetric object; silhouette enhancement; transfer function; volume visualization;
Author: Kraus, M.

Year: 2005
Title: Rendering tetrahedral meshes with higher-order attenuation functions for digital radiograph reconstruction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532809
Abstract:  This paper presents a novel method for computing simulated x-ray images, or DRRs (digitally reconstructed radiographs), of tetrahedral meshes with higher-order attenuation functions. DRRs are commonly used in computer assisted surgery (CAS), with the attenuation function consisting of a voxelized CT study, which is viewed from different directions. Our application of DRRs is in intra-operative "2D-3D" registration, i.e., finding the pose of the CT dataset given a small number of patient radiographs. We register 2D patient images with a statistical tetrahedral model, which encodes the CT intensity numbers as Bernstein polynomials, and includes knowledge about typical shape variation modes. The unstructured grid is more suitable for applying deformations than a rectilinear grid, and the higher-order polynomials provide a better approximation of the actual density than constant or linear models. The infra-operative environment demands a fast method for creating the DRRs, which we present here. We demonstrate this application through the creation and use of a deformable atlas of human pelvis bones. Compared with other works on rendering unstructured grids, the main contributions of this work are: 1) Simple and perspective-correct interpolation of the thickness of a tetrahedral cell. 2) Simple and perspective-correct interpolation of front and back barycentric coordinates with respect to the cell. 3) Computing line integrals of higher-order functions. 4) Capability of applying shape deformations and variations in the attenuation function without significant performance loss. The method does not depend on for pre-integration, and does not require depth-sorting of the visualized cells. We present imaging and timing results of implementing the algorithm, and discuss the impact of using higher-order functions on the quality of the result and the performance.
Keywords: 2D patient image; 2D-3D registration; Bernstein polynomials; biology computing; computer assisted surgery; diagnostic radiography; digital radiograph reconstruction; higher-order attenuation function; image registration; mesh generation; perspective-correct interpolation; polynomials; rendering (computer graphics); rendering tetrahedral mesh; simulated x-ray images;
Author: Sadowsky, C.; Cohen, J.D.; Taylor, R.H.

Year: 2005
Title: Prefiltered Gaussian reconstruction for high-quality rendering of volumetric data sampled on a body-centered cubic grid
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532810
Abstract:  In this paper a novel high-quality reconstruction scheme is presented. Although our method is mainly proposed to reconstruct volumetric data sampled on an optimal body-centered cubic (BCC) grid, it can be easily adapted lo the conventional regular rectilinear grid as well. The reconstruction process is decomposed into two steps. The first step, which is considered to be a preprocessing, is a discrete Gaussian deconvolution performed only once in the frequency domain. Afterwards, the second step is a spatial-domain convolution with a truncated Gaussian kernel, which is used to interpolate arbitrary samples for ray casting. Since the preprocessing is actually a discrete prefiltering, we call our technique prefiltered Gaussian reconstruction (PGR). It is shown that the impulse response of PGR well approximates the ideal reconstruction kernel. Therefore the quality of PGR is much higher than that of previous reconstruction techniques proposed for optimally sampled data, which are based on linear and cubic box splines adapted to the BCC grid. Concerning the performance, PGR is slower than linear box-spline reconstruction but significantly faster than cubic box-spline reconstruction.
Keywords: Gaussian processes; body-centered cubic grid; crystal structure; cubic box-spline reconstruction; discrete Gaussian deconvolution; high-quality rendering; image reconstruction; linear box-spline reconstruction; physics computing; prefiltered Gaussian reconstruction; rendering (computer graphics); spatial-domain convolution; splines (mathematics); volumetric data;
Author: Csebfalvi, B.

Year: 2005
Title: VolQD: direct volume rendering of multi-million atom quantum dot simulations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532811
Abstract:  In this work we present a hardware-accelerated direct volume rendering system for visualizing multivariate wave functions in semiconducting quantum dot (QD) simulations. The simulation data contains the probability density values of multiple electron orbitals for up to tens of millions of atoms, computed by the NEMO3-D quantum device simulator software run on large-scale cluster architectures. These atoms form two interpenetrating crystalline face centered cubic lattices (FCC), where each FCC cell comprises the eight corners of a cubic cell and six additional face centers. We have developed compact representation techniques for the FCC lattice within PC graphics hardware texture memory, hardware-accelerated linear and cubic reconstruction schemes, and new multi-field rendering techniques utilizing logarithmic scale transfer functions. Our system also enables the user to drill down through the simulation data and execute statistical queries using general-purpose computing on the GPU (GPGPU).
Keywords: NEMO3-D quantum device simulator software; PC graphics hardware texture memory; atomistic simulation; cluster architecture; crystal structure; cubic reconstruction scheme; data visualisation; face centered cubic lattices; general-purpose computing; hardware-accelerated direct volume rendering system; image reconstruction; image texture; logarithmic scale transfer function; multivariate wave function visualiziation; physics computing; programmable graphics hardware; quantum computing; rendering (computer graphics); semiconductor quantum dots; semiconductor quantum dots simulation; statistical queries; transfer functions; wave functions;
Author: Qiao, W.; Ebert, D.S.; Entezari, A.; Korkusinski, M.; Klimeck, G.

Year: 2005
Title: High dynamic range volume visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532812
Abstract:  High resolution volumes require high precision compositing to preserve detailed structures. This is even more desirable for volumes with high dynamic range values. After the high precision intermediate image has been computed, simply rounding up pixel values to regular display scales loses the computed details. In this paper, we present a novel high dynamic range volume visualization method for rendering volume data with both high spatial and intensity resolutions. Our method performs high precision volume rendering followed by dynamic tone mapping to preserve details on regular display devices. By leveraging available high dynamic range image display algorithms, this dynamic tone mapping can be automatically adjusted to enhance selected features for the final display. We also present a novel transfer function design interface with nonlinear magnification of the density range and logarithmic scaling of the color/opacity range to facilitate high dynamic range volume visualization. By leveraging modern commodity graphics hardware and out-of-core acceleration, our system can produce an effective visualization of huge volume data.
Keywords: data visualisation; dynamic range volume visualization; dynamic tone mapping; graphical user interfaces; graphics hardware; image display algorithm; image resolution; image resolution; logarithmic scaling; nonlinear magnification; precision intermediate image; precision volume rendering; regular display device; rendering (computer graphics); transfer function design interface; transfer functions;
Author: Yuan, X.; Nguyen, M.Z.; Chen, B.; Porter, D.H.

Year: 2005
Title: Volume rendering of smoke propagation CFD data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532813
Abstract:  The evacuation of buildings in the event of a fire requires careful planning of ventilation and evacuation routes during early architectural design stages. Different designs are evaluated by simulating smoke propagation using computational fluid dynamics (CFD). Visibility plays a decisive role in finding the nearest fire exit. This paper presents real-time volume rendering of transient smoke propagation conforming to standardized visibility distances. We visualize time dependent smoke particle concentration on unstructured tetrahedral meshes using a direct volume rendering approach. Due to the linear transfer function of the optical model commonly used in fire protection engineering, accurate pre-integration of diffuse color across tetrahedra can be carried out with a single 2D texture lookup. We reduce rounding errors during frame buffer blending by applying randomized dithering if high accuracy frame buffers are unavailable on the target platform. A simple absorption-based lighting model is evaluated in a preprocessing step using the same rendering approach. Back-illuminated exit signs are commonly used to indicate the escape route. As light emitting objects are visible further than reflective objects, the transfer function in front of illuminated exit signs must be adjusted with a deferred rendering pass.
Keywords: 2D texture lookup; CFD data; absorption-based lighting model; architectural design; back-illuminated exit signs; computational fluid dynamics; computational fluid dynamics; data visualisation; evacuation; fire protection engineering; image texture; linear transfer function; randomized dithering; real-time volume rendering; rendering (computer graphics); smoke; smoke propagation; tetrahedral mesh; transfer functions; ventilation; volume rendering;
Author: Staubli, O.; Sigg, C.; Peikert, R.; Gubler, D.; Gross, M.

Year: 2005
Title: Hardware-accelerated simulated radiography
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532815
Abstract:  We present the application of hardware accelerated volume rendering algorithms to the simulation of radiographs as an aid to scientists designing experiments, validating simulation codes, and understanding experimental data. The techniques presented take advantage of 32-bit floating point texture capabilities to obtain solutions to the radiative transport equation for X-rays. The hardware accelerated solutions are accurate enough to enable scientists to explore the experimental design space with greater efficiency than the methods currently in use. An unsorted hexahedron projection algorithm is presented for curvilinear hexahedral meshes that produces simulated radiographs in the absorption-only regime. A sorted tetrahedral projection algorithm is presented that simulates radiographs of emissive materials. We apply the tetrahedral projection algorithm to the simulation of experimental diagnostics for inertial confinement fusion experiments on a laser at the University of Rochester.
Keywords: 32-bit floating point texture; X-rays; X-rays; absorption-only regime; curvilinear hexahedral mesh; emissive materials; hardware-accelerated simulated radiography; hexahedron projection algorithm; image texture; inertial confinement fusion; mesh generation; physics computing; radiative transport equation; radiography; rendering (computer graphics); tetrahedral projection algorithm; volume rendering algorithm;
Author: Laney, D.; Callahan, S.P.; Max, N.; Silva, C.T.; Langer, S.; Frank, R.

Year: 2005
Title: Fast visualization by shear-warp on quadratic super-spline models using wavelet data decompositions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532816
Abstract:  We develop the first approach Tor interactive volume visualization based on a sophisticated rendering method of shear-warp type, wavelet data encoding techniques, and a trivariate spline model, which has been introduced recently. As a first step of our algorithm, we apply standard wavelet expansions to represent and decimate the given gridded three-dimensional data. Based on this data encoding, we give a sophisticated version of the shear-warp based volume rendering method. Our new algorithm visits each voxel only once taking advantage of the particular data organization of octrees. In addition, the hierarchies of the data guide the local (re)construction of the quadratic super-spline models, which we apply as a pure visualization tool. The low total degree of the polynomial pieces allows to numerically approximate the volume rendering integral efficiently. Since the coefficients of the splines are almost immediately available from the given data, Bernstein-Bezier techniques can be fully employed in our algorithms. In this way, we demonstrate that these models can be successfully applied to full volume rendering of hierarchically organized data. Our computational results show that (even when hierarchical approximations are used) the new approach leads to almost artifact-free visualizations of high quality for complicated and noise-contaminated volume data sets, while the computational effort is considerable low, i.e. our current implementation yields 1-2 frames per second for parallel perspective rendering a 2563 volume data set (using simple opacity transfer functions) in a 5122 view-port.
Keywords: artifact-free visualization; data visualisation; interactive volume visualization; octrees; octrees; parallel perspective rendering; quadratic super-spline model; rendering (computer graphics); shear-warp based volume rendering method; splines (mathematics); transfer function; transfer functions; trivariate spline model; wavelet data decomposition; wavelet data encoding; wavelet transforms;
Author: Schlosser, G.; Hesser, J.; Zeilfelder, F.; Rossl, C.; Nurnberger, G.; Seidel, H.-P.; Manner, R.

Year: 2005
Title: Dataset traversal with motion-controlled transfer functions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532817
Abstract:  In this paper, we describe a methodology and implementation for interactive dataset traversal using motion-controlled transfer functions. Dataset traversal here refers lo the process of translating a transfer function along a specific path. In scientific visualization, it is often necessary to manipulate transfer functions in order to visualize datasets more effectively. This manipulation of transfer functions is usually performed globally, i.e., a new transfer function is applied to the entire dataset. Our approach allows one to locally manipulate transfer functions while controling its movement along a traversal path. The method we propose allows the user to select a traversal path within the dataset, based on the shape of the volumetric model and manipulate a transfer function along this path. Examples of dataset traversal include the animation of transfer functions along a pre-defined path, the simulation of flow in vascular structures, and the visualization of convoluted shapes. For example, this type of traversal is often used in medical illustration to highlight flow in blood vessels. We present an interactive implementation of our method using graphics hardware, based on the decomposition of the volume. We show examples of our approach using a variety of volumetric datasets, and we also demonstrate that with our novel decomposition, the rendering process is faster.
Keywords: blood vessels; blood vessels; computer animation; data visualisation; dataset traversal; graphics hardware; haemorheology; image motion analysis; interactive dataset traversal; medical illustration; medical image processing; motion-controlled transfer function; rendering (computer graphics); rendering process; scientific visualization; transfer function animation; transfer functions; vascular structure; visual databases; volumetric datasets; volumetric model;
Author: Correa, C.D.; Silver, D.

Year: 2005
Title: The magic volume lens: an interactive focus+context technique for volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532818
Abstract:  The size and resolution of volume datasets in science and medicine are increasing at a rate much greater than the resolution of the screens used to view them. This limits the amount of data that can be viewed simultaneously, potentially leading to a loss of overall context of the data when the user views or zooms into a particular area of interest. We propose a focus+context framework that uses various standard and advanced magnification lens rendering techniques to magnify the features of interest, while compressing the remaining volume regions without clipping them away completely. Some of these lenses can be interactively configured by the user to specify the desired magnification patterns, while others are feature-adaptive. All our lenses are accelerated on the GPU. They allow the user to interactively manage the available screen area, dedicating more area to the more resolution-important features.
Keywords: hardware-assisted volume rendering; image resolution; image segmentation; interactive focus-context technique; lenses; magic volume lens; rendering (computer graphics); resolution-important feature;
Author: Wang, L.; Zhao, Y.; Mueller, K.; Kaufman, A.

Year: 2005
Title: Effectively visualizing large networks through sampling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532819
Abstract:  We study the problem of visualizing large networks and develop techniques for effectively abstracting a network and reducing the size to a level that can be clearly viewed. Our size reduction techniques are based on sampling, where only a sample instead of the full network is visualized. We propose a randomized notion of "focus" that specifies a part of the network and the degree to which it needs to be magnified. Visualizing a sample allows our method to overcome the scalability issues inherent in visualizing massive networks. We report some characteristics that frequently occur in large networks and the conditions under which they are preserved when sampling from a network. This can be useful in selecting a proper sampling scheme that yields a sample with similar characteristics as the original network. Our method is built on top of a relational database, thus it can be easily and efficiently implemented using any off-the-shelf database software. As a proof of concept, we implement our methods and report some of our experiments over the movie database and the connectivity graph of the Web.
Keywords: Internet; Web; connectiviiy graph; data visualisation; graph theory; image sampling; large networks visualization; movie database; off-the-shelf database software; relational database; relational databases; sampling;
Author: Rafiei, D.

Year: 2005
Title: Opening the black box - data driven visualization of neural networks
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532820
Abstract:  Artificial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well defined criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more efficient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classification task.
Keywords: artificial neural network; backpropagation; black box opening; classification task; data driven visualization; data visualisation; human nervous system; machine learning tool; neural nets; problem solving; problem solving;
Author: Tzeng, F.-Y.; Ma, K.-L.

Year: 2005
Title: Interactive visual analysis and exploration of injection systems simulations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532821
Abstract:  Simulations often generate large amounts of data that require use of SciVis techniques for effective exploration of simulation results. In some cases, like 1D theory of fluid dynamics, conventional SciVis techniques are not very useful. One such example is a simulation of injection systems that is becoming more and more important due to an increasingly restrictive emission regulations. There are many parameters and correlations among them that influence the simulation results. We describe how basic information visualization techniques can help in visualizing, understanding and analyzing this kind of data. The Com Vis tool is developed and used to analyze and explore the data. Com Vis supports multiple linked views and common information visualization displays such as 2D and 3D scatter-plot, histogram, parallel coordinates, pie-chart, etc. A diesel common rail injector with 2/2 way valve is used for a case study. Data sets were generated using a commercially available AVL HYDSIM simulation tool for dynamic analysis of hydraulic and hydro-mechanical systems, with the main application area in the simulation of fuel injection systems.
Keywords: 1D fluid dynamics theory; AVL HYDSIM simulation tool; Com Vis tool; SciVis technique; automobiles; computational fluid dynamics; data visualisation; diesel common rail injector; diesel engines; fuel injection system simulation; fuel systems; hydraulic system analysis; hydro-mechanical system analysis; information visualization display; information visualization technique; interactive systems; interactive visual analysis; interactive visual exploration; restrictive emission regulation;
Author: Matkovic, K.; Jelovic, M.; Juric, J.; Konyha, Z.; Gracanin, D.

Year: 2005
Title: Quality mesh generation for molecular skin surfaces using restricted union of balls
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532822
Abstract: Quality surface meshes for molecular models are desirable in the studies of protein shapes and functionalities. However, there is still no robust software that is capable to generate such meshes with good quality. In this paper, we present a Delaunay-based surface triangulation algorithm generating quality surface meshes for the molecular skin model. We expand the restricted union of balls along the surface and generate an &#949;-sampling of the skin surface incrementally. At the same time, a quality surface mesh is extracted from the Delaunay triangulation of the sample points. The algorithm supports robust and efficient implementation and guarantees the mesh quality and topology as well. Our results facilitate molecular visualization and have made a contribution towards generating quality volumetric tetrahedral meshes for the macromolecules.
Keywords: Delaunay-based surface triangulation algorithm; data visualisation; homeomorphism; macromolecules; macromolecules; mesh generation; molecular skin surface model; molecular visualization; protein shape study; proteins; quality surface mesh generation; quality volumetric tetrahedral mesh generation; restricted union of ball; skin; surface fitting;&epsiv;-sampling;
Author: Cheng, H.-L.; Shi, X.

Year: 2005
Title: Surface reconstruction via contour metamorphosis: an Eulerian approach with Lagrangian particle tracking
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532823
Abstract:  We present a robust method for 3D reconstruction of closed surfaces from sparsely sampled parallel contours. A solution to this problem is especially important for medical segmentation, where manual contouring of 2D imaging scans is still extensively used. Our proposed method is based on a morphing process applied to neighboring contours that sweeps out a 3D surface. Our method is guaranteed to produce closed surfaces that exactly pass through the input contours, regardless of the topology of the reconstruction. Our general approach consecutively morphs between sets of input contours using an Eulerian formulation (i.e. fixed grid) augmented with Lagrangian particles (i.e. interface tracking). This is numerically accomplished by propagating the input contours as 2D level sets with carefully constructed continuous speed functions. Specifically this involves particle advection to estimate distances between the contours, monotonicity constrained spline interpolation to compute continuous speed functions without overshooting, and state-of-the-art numerical techniques for solving the level set equations. We demonstrate the robustness of our method on a variety of medical, topographic and synthetic data sets.
Keywords: 2D imaging scan; 3D closed surface reconstruction; 3D surface sweeping; Eulerian approach; Lagrangian particle tracking; continuous speed functions; data visualisation; image reconstruction; image resolution; image sampling; image segmentation; interface tracking; interpolation; level set equation; medical image processing; medical segmentation; monotonicity constrained spline interpolation; parallel contour metamorphosis; particle advection; splines (mathematics); surface fitting; surface reconstruction;
Author: Nilsson, O.; Breen, D.; Museth, K.

Year: 2005
Title: Reconstructing manifold and non-manifold surfaces from point clouds
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532824
Abstract:  This paper presents a novel approach for surface reconstruction from point clouds. The proposed technique is general in the sense that it naturally handles both manifold and non-manifold surfaces, providing a consistent way for reconstructing closed surfaces as well as surfaces with boundaries. It is also robust in the presence of noise, irregular sampling and surface gaps. Furthermore, it is fast, parallelizable and easy to implement because it is based on simple local operations. In this approach, surface reconstruction consists of three major steps: first, the space containing the point cloud is subdivided, creating a voxel representation. Then, a voxel surface is computed using gap filling and topological thinning operations. Finally, the resulting voxel surface is converted into a polygonal mesh. We demonstrate the effectiveness of our approach by reconstructing polygonal models from range scans of real objects as well as from synthetic data.
Keywords: computational geometry; gap filling; image reconstruction; image representation; image sampling; image thinning; manifold surface reconstruction; mesh generation; nonmanifold surface reconstruction; point cloud; polygonal mesh; polygonal model reconstruction; real object; solid modelling; surface fitting; topological thinning; voxel surface representation;
Author: Wang, J.; Oliveira, M.M.; Kaufman, A.E.

Year: 2005
Title: Marching diamonds for unstructured meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532825
Abstract:  We present a higher-order approach to the extraction of isosurfaces from unstructured meshes. Existing methods use linear interpolation along each mesh edge to find isosurface intersections. In contrast, our method determines intersections by performing barycentric interpolation over diamonds formed by the tetrahedra incident to each edge. Our method produces smoother, more accurate isosurfaces. Additionally, interpolating over diamonds, rather than linearly interpolating edge endpoints. enables us to identify up to two isosurface intersections per edge. This paper details how our new technique extracts isopoints, and presents a simple connection strategy for forming a triangle mesh isosurface.
Keywords: barycentric interpolation; computational geometry; image representation; interpolation; isosurface extraction; isosurface intersection; linear interpolation mesh edge endpoints; marching diamonds; mesh generation; triangle mesh isosurface; unstructured mesh;
Author: Anderson, J.C.; Bennett, J.C.; Joy, K.I.

Year: 2005
Title: Evolutionary morphing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532826
Abstract:  We introduce a technique to visualize the gradual evolutionary change of the shapes of living things as a morph between known three-dimensional shapes. Given geometric computer models of anatomical shapes for some collection of specimens - here the skulls of the some of the extant members of a family of monkeys - an evolutionary tree for the group implies a hypothesis about the way in which the shape changed through time. We use a statistical model which expresses the value of some continuous variable at an internal point in the tree as a weighted average of the values at the leaves. The framework of geometric morphometrics can then be used to define a shape-space, based on the correspondences of landmark points on the surfaces, within which these weighted averages can be realized as actual surfaces. Our software provides tools for performing and visualizing such an analysis in three dimensions. Beginning with laser range scans of crania, we use our landmark editor to interactively place landmark points on the surface. We use these to compute a "tree-morph" that smoothly interpolates the shapes across the tree. Each intermediate shape in the morph is a linear combination of all of the input surfaces. We create a surface model for an intermediate shape by warping all the input meshes towards the correct shape and then blending them together. To do the blending, we compute a weighted average of their associated trivariate distance functions and then extract a surface from the resulting function. We implement this idea using the squared distance function, rather than the usual signed distance function, in a novel way.
Keywords: bone; computational geometry; crania laser range scan; data visualisation; evolution (biological); evolutionary morphing; evolutionary tree; geometric computer model; geometric morphometrics; image morphing; interactive landmark point; interpolation; landmark editor; medical image processing; mesh generation; mesh surface blending; mesh surface warping; monkey skull; palaeontology; signed distance function; smooth shape interpolation; solid modelling; squared distance function; statistical analysis; statistical model; surface extraction; surface merging; surface model; three-dimensional shape visualization; tree-morph; trivariate distance functions; visualization tool; zoology;
Author: Wiley, D.F.; Amenta, N.; Alcantara, D.A.; Ghosh, D.; Kil, Y.J.; Delson, E.; Harcourt-Smith, W.; Rohlf, F.J.; St John, K.; Hamann, B.

Year: 2005
Title: Hardware-accelerated 3D visualization of mass spectrometry data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532827
Abstract:  We present a system for three-dimensional visualization of complex liquid chromatography-mass spectrometry (LCMS) data. Every LCMS data point has three attributes: time, mass, and intensity. Instead of the traditional visualization of two-dimensional subsets of the data, we visualize it as a height field or terrain in 3D. Unlike traditional terrains, LCMS data has non-linear sampling and consists mainly of tall needle-like features. We adapt the level-of-detail techniques of geometry clipmaps for hardware-accelerated rendering of LCMS data. The data is cached in video memory as a set of nested rectilinear grids centered about the view frustum. We introduce a simple compression scheme and dynamically stream data from the CPU to the GPU as the viewpoint moves. Our system allows interactive investigation of complex LCMS data with close to one billion data points at up to 130 frames per second, depending on the view conditions.
Keywords: GPU; LCMS data visualization; chemistry computing; chromatography; complex liquid chromatography-mass spectrometry; compression scheme; computer graphic equipment; data caching; data visualisation; geometry clipmap; hardware-accelerated rendering; interactive hardware-accelerated 3D visualization; interactive systems; level-of-detail technique; mass spectrometry data; mass spectroscopy; nested rectilinear grid set; nonlinear sampling; rendering (computer graphics); tall needle-like feature; traditional terrain; video memory; view frustum;
Author: de Corral, J.; Pfister, H.

Year: 2005
Title: Differential protein expression analysis via liquid-chromatography/mass-spectrometry data visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532828
Abstract:  Differential protein expression analysis is one of the main challenges in proteomics. It denotes the search for proteins, whose encoding genes are differentially expressed under a given experimental setup. An important task in this context is to identify the differentially expressed proteins or, more generally, all proteins present in the sample. One of the most promising and recently widely used approaches for protein identification is to cleave proteins into peptides, separate the peptides using liquid chromatography, and determine the masses of the separated peptides using mass spectrometry. The resulting data needs to be analyzed and matched against protein sequence databases. The analysis step is typically done by searching for intensity peaks in a large number of 2D graphs. We present an interactive visualization tool for the exploration of liquid-chromatography/mass-spectrometry data in a 3D space, which allows for the understanding of the data in its entirety and a detailed analysis of regions of interest. We compute differential expression over the liquid-chromatography/mass-spectrometry domain and embed it visually in our system. Our exploration tool can treat single liquid-chromatography/mass-spectrometry data sets as well as data acquired using multi-dimensional protein identification technology. For efficiency purposes we perform a peak-preserving data resampling and multiresolution hierarchy generation prior to visualization.
Keywords: 2D graph; 3D space data exploration; bioinformatics visualization; biology computing; chemistry computing; chromatography; data visualisation; differential protein expression analysis; gene encoding; genetics; interactive systems; interactive visualization tool; liquid-chromatography data visualization; mass spectroscopy; mass-spectrometry data visualization; multidimensional protein identification technology; multiresolution hierarchy generation; peak-preserving data resampling; peptide; protein sequence database; proteins; proteomics;
Author: Linsen, L.; Locherbach, J.; Berth, M.; Bernhardt, J.; Becher, D.

Year: 2005
Title: The software interface to the 3D-force microscope
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532829
Abstract:  We have developed a real-time experiment-control and data-display system for a novel microscope, the 3D-force microscope (3DFM), which is designed for nanometer-scale and nanoNewton-force biophysical experiments. The 3DFM software suite synthesizes the several data sources from the 3DFM into a coherent view and provides control over data collection and specimen manipulation. Herein, we describe the system architecture designed to handle the several feedback loops and data flows present in the microscope and its control system. We describe the visualization techniques used in the 3DFM software suite, where used, and on which types of data. We present feedback from our scientist-users regarding the usefulness of these techniques, and we also present lessons learned from our successive implementations.
Keywords: 3D-force microscope; 3DFM software suite; data visualisation; data-display system; display devices; haptic interface; haptic interfaces; interactive graphics; magnetic force microscopy; medical computing; multimodal visualization; nanoNewton-force biophysical experiment; nanometer-scale biophysical experiment; optical microscopes; real-time experiment-control; real-time systems; scientific visualization; software interface; virtual reality; virtual world; visualization technique;
Author: Marshburn, D.; Weigle, C.; Wilde, B.G.; Taylor, R.M., II; Desai, K.; Fisher, J.K.; Cribb, J.; O'Brien, E.T.; Superfine, R.

Year: 2005
Title: Opening the can of worms: an exploration tool for vortical flows
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532830
Abstract: Gaining a comprehensive understanding of turbulent flows still poses one of the great challenges in fluid dynamics. A well-established approach to advance this research is the analysis of the vortex structures contained in the flow. In order to be able to perform this analysis efficiently, supporting visualization tools with clearly defined requirements are needed. In this paper, we present a visualization system which matches these requirements to a large extent. The system consists of two components. The first component analyzes the flow by means of a novel combination of vortex core line detection and the &lambda;<sub>2</sub> method. The second component is a vortex browser which allows for an interactive exploration and manipulation of the vortices detected and separated during the first phase. Our system improves the reliability and applicability of existing vortex detection methods and allows for a more efficient study of vortical flows which is demonstrated in an evaluation performed by experts.
Keywords: 3D vector field visualization; computational fluid dynamics; data visualisation; flow visualisation; flow visualization; fluid dynamics; turbulence; turbulent flow; vortex browser; vortex core line detection; vortex structure analysis; vortical flow; vortices;&lambda;2 method;
Author: Stegmaier, S.; Rist, U.; Ertl, T.

Year: 2005
Title: Strategy for seeding 3D streamlines
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532831
Abstract: This paper presents a strategy for seeding streamlines in 3D flow fields. Its main goal is to capture the essential flow patterns and to provide sufficient coverage in the field while reducing clutter. First, critical points of the flow field are extracted to identify regions with important flow patterns that need to be presented. Different seeding templates are then used around the vicinity of the different critical points. Because there is significant variability in the flow pattern even for the same type of critical point, our template can change shape depending on how far the critical point is from transitioning into another type of critical point. To accomplish this, we introduce the &alpha;-&beta; map of 3D critical points. Next, we use Poisson seeding to populate the empty regions. Finally, we filter the streamlines based on their geometric and spatial properties. Altogether, this multi-step strategy reduces clutter and yet captures the important 3D flow features.
Keywords: 3D flow field; Poisson seeding; clutter reduction; computational fluid dynamics; critical point; critical points; data visualisation; flow pattern; flow visualisation; streamline seeding; variable template;
Author: Xiangong Ye; Kao, D.; Pang, A.

Year: 2005
Title: Farthest point seeding for efficient placement of streamlines
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532832
Abstract:  We propose a novel algorithm for placement of streamlines from two-dimensional steady vector or direction fields. Our method consists of placing one streamline at a time by numerical integration starting at the furthest away from all previously placed streamlines. Such a farthest point seeding strategy leads to high quality placements by favoring long streamlines, while retaining uniformity with the increasing density. Our greedy approach generates placements of comparable quality with respect to the optimization approach from Turk and Banks, while being 200 times faster. Simplicity, robustness as well as efficiency is achieved through the use of a Delaunay triangulation to model the streamlines, address proximity queries and determine the biggest voids by exploiting the empty circle property. Our method handles variable density and extends to multiresolution.
Keywords: Delaunay triangulation; computational fluid dynamics; data visualisation; direction field; farthest point seeding strategy; flow visualisation; greedy algorithms; greedy approach; mesh generation; numerical integration; optimisation; optimization; streamlines placement; two-dimensional steady vector; variable density;
Author: Mebarki, A.; Alliez, P.; Devillers, O.

Year: 2005
Title: View selection for volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532833
Abstract:  In a visualization of a three-dimensional dataset, the insights gained are dependent on what is occluded and what is not. Suggestion of interesting viewpoints can improve both the speed and efficiency of data understanding. This paper presents a view selection method designed for volume rendering. It can be used to find informative views for a given scene, or to find a minimal set of representative views which capture the entire scene. It becomes particularly useful when the visualization process is non-interactive - for example, when visualizing large datasets or time-varying sequences. We introduce a viewpoint "goodness" measure based on the formulation of entropy from information theory. The measure takes into account the transfer function, the data distribution and the visibility of the voxels. Combined with viewpoint properties like view-likelihood and view-stability, this technique can be used as a guide, which suggests "interesting" viewpoints for further exploration. Domain knowledge is incorporated into the algorithm via an importance transfer function or volume. This allows users to obtain view selection behaviors tailored to their specific situations. We generate a view space partitioning, and select one representative view for each partition. Together, this set of views encapsulates the "interesting" and distinct views of the data. Viewpoints in this set can be used as starting points for interactive exploration of the data, thus reducing the human effort in visualization. In non-interactive situations, such a set can be used as a representative visualization of the dataset from all directions.
Keywords: data distribution; data visualisation; data visualization; domain knowledge; entropy; entropy formulation; hidden feature removal; information theory; interactive data exploration; occlusion; rendering (computer graphics); transfer function; very large databases; view selection method; view space partitioning; volume rendering; voxel visibility;
Author: Bordoloi, U.D.; Shen, H.-W.

Year: 2005
Title: A feature-driven approach to locating optimal viewpoints for volume visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532834
Abstract:  Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.
Keywords: 3D surface mesh; data visualisation; direct volume rendering; entropy; level-set graph; mesh generation; optimal viewpoint selection; rendering (computer graphics); surface fitting; transfer function; viewpoint entropy; volume visualization;
Author: Takahashi, S.; Fujishiro, I.; Takeshima, Y.; Nishita, T.

Year: 2005
Title: Visualizing intersecting surfaces with nested-surface techniques
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532835
Abstract:  This paper describes the adaptation and evaluation of existing nested-surface visualization techniques for the problem of displaying intersecting surfaces. For this work, we collaborated with a neurosurgeon who is comparing multiple tumor segmentations with the goal of increasing the segmentation accuracy and reliability. A second collaborator, a physicist, aims to validate geometric models of specimens against atomic-force microscope images of actual specimens. These collaborators are interested in comparing both surface shape and inter-surface distances. Many commonly employed techniques for visually comparing multiple surfaces (side-by-side, wireframe, colormaps, uniform translucence) do not simultaneously convey inter-surface distance and the shapes of two or more surfaces. This paper describes a simple geometric partitioning of intersecting surfaces that enables the application of existing nested-surface techniques, such as texture-modulated translucent rendering of exteriors, to a broader range of visualization problems. Three user studies investigate the performance of existing techniques and a new shadow-casting glyph technique. The results of the first user study show that texture glyphs on partitioned, intersecting surfaces can convey inter-surface distance better than directly mapping distance to a red-gray-blue color scale on a single surface. The results of the second study show similar results for conveying local surface orientation. The results of the third user study show that adding cast shadows to texture glyphs can increase the understanding of inter-surface distance in static images, but can be overpowered by the shape cues from a simple rocking motion.
Keywords: data visualisation; geometric partitioning; image texture; intersecting surface visualization; nested-surface visualization; rendering (computer graphics); scientific visualization; shadow-casting glyph technique; surface fitting; texture-modulated translucent rendering; transparent surface;
Author: Weigle, C.; Taylor, R.M., II

Year: 2005
Title: Understanding visualization through spatial ability differences
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532836
Abstract:  Little is known about the cognitive abilities which influence the comprehension of scientific and information visualizations and what properties of the visualization affect comprehension. Our goal in this paper is to understand what makes visualizations difficult. We address this goal by examining the spatial ability differences in a diverse population selected for spatial ability variance. For example, how is, spatial ability related to visualization comprehension? What makes a particular visualization difficult or time intensive for specific groups of subjects? In this paper, we present the results of an experiment designed to answer these questions. Fifty-six subjects were tested on a basic visualization task and given standard paper tests of spatial abilities. An equal number of males and females were recruited in this study in order to increase spatial ability variance. Our results show that high spatial ability is correlated with accuracy on our three-dimensional visualization test, but not with time. High spatial ability subjects also had less difficulty with object complexity and the hidden properties of an object.
Keywords: cognition; cognitive ability; data visualisation; gender difference; gender issues; information visualization; orthogonal projection; scientific visualization; solid modelling; spatial ability variance; standardized testing;
Author: Velez, M.C.; Silver, D.; Tremaine, M.

Year: 2005
Title: Eyegaze analysis of displays with combined 2D and 3D views
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532837
Abstract:  Displays combining both 2D and 3D views have been shown to support higher performance on certain visualization tasks. However, it is not clear how best to arrange a combination of 2D and 3D views spatially in a display. In this study, we analyzed the eyegaze strategies of participants using two arrangements of 2D and 3D views to estimate the relative position of objects in a 3D scene. Our results show that the 3D view was used significantly more often than individual 2D views in both displays, indicating the importance of the 3D view for successful task completion. However, viewing patterns were significantly different between the two displays: transitions through centrally-placed views were always more frequent, and users avoided saccades between views that were far apart. Although the change in viewing strategy did not result in significant performance differences, error analysis indicates that a 3D overview in the center may reduce the number of serious errors compared to a 3D overview placed off to the side.
Keywords: 2D-3D combination display; biomedical imaging; data visualisation; error analysis; eye; eyegaze analysis; graphical user interfaces; view visualization;
Author: Tory, M.; Atkins, M.S.; Kirkpatrick, A.E.; Nicolaou, M.; Yang, G.-Z.

Year: 2005
Title: Visualizing data with motion
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532838
Abstract: This paper describes an experimental study of three perceptual properties of motion: flicker, direction, and velocity. Our goal is to understand how to apply these properties to represent data in a visualization environment. Results from our experiments show that all three properties can encode multiple data values, but that minimum visual differences are needed to ensure rapid and accurate target detection: flicker must be coherent and must have a cycle length of 120 milliseconds or greater, direction must differ by at least 20&deg;, and velocity must differ by at least 0.43&deg; of subtended visual angle. We conclude with an overview of how we are applying our results to real-world data, and then discuss future work we plan to pursue.
Keywords: data visualisation; data visualization; direction property; flicker property; image motion analysis; motion perceptual property; velocity property;
Author: Huber, D.E.; Healey, C.G.

Year: 2005
Title: Topology-driven surface mappings with robust feature alignment
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532840
Abstract:  Topological concepts and techniques have been broadly applied in computer graphics and geometric modeling. However, the homotopy type of a mapping between two surfaces has not been addressed before. In this paper, we present a novel solution to the problem of computing continuous maps with different homotopy types between two arbitrary triangle meshes with the same topology. Inspired by the rich theory of topology as well as the existing body of work on surface mapping, our newly-developed mapping techniques are both fundamental and unique, offering many attractive advantages. First, our method allows the user to change the homotopy type or global structure of the mapping with minimal intervention. Moreover, to locally affect shape correspondence, we articulate a new technique that robustly satisfies hard feature constraints, without the use of heuristics to ensure validity. In addition to acting as a useful tool for computer graphics applications, our method can be used as a rigorous and practical mechanism for the visualization of abstract topological concepts such as homotopy type of surface mappings, homology basis, fundamental domain, and universal covering space. At the core of our algorithm is a procedure for computing the canonical homology basis and using it as a common cut graph for any surface with the same topology. We demonstrate our results by applying our algorithm to shape morphing in this paper.
Keywords: common cut graph; computer graphics; data visualisation; data visualization; feature alignment; feature extraction; geometric modeling; image morphing; mesh generation; shape morphing; surface fitting; topology-driven surface mappings; triangle meshes; universal covering space;
Author: Garner, C.; Jin, M.; Gu, X.; Qin, H.

Year: 2005
Title: Topological structures of 3D tensor fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532841
Abstract:  Tensor topology is useful in providing a simplified and yet detailed representation of a tensor field. Recently the field of 3D tensor topology is advanced by the discovery that degenerate tensors usually form lines in their most basic configurations. These lines form the backbone for further topological analysis. A number of ways for extracting and tracing the degenerate tensor lines have also been proposed. In this paper, we complete the previous work by studying the behavior and extracting the separating surfaces emanating from these degenerate lines. First, we show that analysis of eigenvectors around a 3D degenerate tensor can be reduced to 2D. That is, in most instances, the 3D separating surfaces are just the trajectory of the individual 2D separatrices which includes trisectors and wedges. But the proof is by no means trivial since it is closely related to perturbation theory around a pair of singular slate. Such analysis naturally breaks down at the tangential points where the degenerate lines pass through the plane spanned by the eigenvectors associated with the repeated eigenvalues. Second, we show that the separatrices along a degenerate line may switch types (e.g. trisectors to wedges) exactly at the points where the eigenplane is tangential to the degenerate curve. This property leads to interesting and yet complicated configuration of surfaces around such transition points. Finally, we apply the technique to several common data sets to verify its correctness.
Keywords: 3D separating surfaces; 3D tensor field; computational geometry; curve fitting; curve fitting; eigenvalues; eigenvalues and eigenfunctions; eigenvectors; perturbation theory; surface fitting; tensor topology; tensors;
Author: Zheng, X.; Parlett, B.; Pang, A.

Year: 2005
Title: Extracting higher order critical points and topological simplification of 3D vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532842
Abstract:  This paper presents an approach to extracting and classifying higher order critical points of 3D vector fields. To do so, we place a closed convex surface s around the area of interest. Then we show that the complete 3D classification of a critical point into areas of different flow behavior is equivalent to extracting the topological skeleton of an appropriate 2D vector field on s, if each critical point is equipped with an additional bit of information. Out of this skeleton, we create an icon which replaces the complete topological structure inside s for the visualization. We apply our method to find a simplified visual representation of clusters of critical points, leading to expressive visualizations of topologically complex 3D vector fields.
Keywords: 3D vector field; computational geometry; convex surface; data visualisation; data visualization; flow behavior; surface fitting; topological simplification; vectors;
Author: Weinkauf, T.; Theisel, H.; Shi, K.; Hege, H.-C.; Seidel, H.-P.

Year: 2005
Title: Visualization of the genus of knots
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532843
Abstract:  The genus of a knot or link can be defined via Seifert surfaces. A Seifert surface of a knot or link is an oriented surface whose boundary coincides with that, knot or link. Schematic images of these surfaces are shown in every text book on knot theory, but from these it is hard to understand their shape and structure. In this paper the visualization of such surfaces is discussed. A method is presented to produce different styles of surfaces for knots and links, starting from the so-called braid representation. Also, it is shown how closed oriented surfaces can be generated in which the knot is embedded, such that the knot subdivides the surface into two parts. These closed surfaces provide a direct visualization of the genus of a knot.
Keywords: Seifert surfaces; braid representation; data visualisation; knot visualization; mathematics computing; surface fitting; topology;
Author: van Wijk, J.J.; Cohen, A.M.

Year: 2005
Title: Visualizing the tightening of knots
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532844
Abstract:  The study of physical models for knots has recently received much interest in the mathematics community. In this paper, we consider the ropelength model, which considers knots tied in an idealized rope. This model is interesting in pure mathematics, and has been applied to the study of a variety of problems in the natural sciences as well. Modeling and visualizing the tightening of knots in this idealized rope poses some interesting challenges in computer graphics. In particular, self-contact in a deformable rope model is a difficult problem which cannot be handled by standard techniques. In this paper, we describe a solution based on reformulating the contact problem and using constrained-gradient techniques from nonlinear optimization. The resulting animations reveal new properties of the tightening flow and provide new insights into the geometric structure of tight knots and links.
Keywords: computational geometry; computational geometry; computer animation; computer animation; computer graphics; constrained-gradient technique; data visualisation; deformable rope model; gradient methods; knot visualization; mathematics computing; nonlinear optimization; optimisation; ropelength model;
Author: Cantarella, J.; Piatek, M.; Rawdon, E.

Year: 2005
Title: Visualization in the Einstein Year 2005: a case study on explanatory and illustrative visualization of relativity and astrophysics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532845
Abstract: In this application paper, we report on over fifteen years of experience with relativistic and astrophysical visualization, which has been culminating in a substantial engagement for visualization in the Einstein Year 2005 - the 100<sup>th</sup> anniversary of Einstein's publications on special relativity, the photoelectric effect, and Brownian motion. This paper focuses on explanatory and illustrative visualizations used to communicate aspects of the difficult theories of special and general relativity, their geometric structure, and of the related fields of cosmology and astrophysics. We discuss visualization strategies, motivated by physics education and didactics of mathematics, and describe what kind of visualization methods have proven to be useful for different types of media, such as still images in popular-science magazines, film contributions to TV shows, oral presentations, or interactive museum installations. Although our visualization tools build upon existing methods and implementations, these techniques have been improved by several novel technical contributions like image-based special relativistic rendering on GPUs, an extension of general relativistic ray tracing to manifolds described by multiple charts, GPU-based interactive visualization of gravitational light deflection, as well as planetary terrain rendering. The usefulness and effectiveness of our visualizations are demonstrated by reporting on experiences with, and feedback from, recipients of visualizations and collaborators.
Keywords: Einstein Year 2005; GPU; astronomy computing; astrophysical visualization; computational geometry; computer graphic equipment; cosmology; cosmology; data visualisation; image-based special relativistic rendering; physics computing; physics education; planetary terrain rendering; ray tracing; ray tracing; relativity visualization;
Author: Weiskopf, D.; Borchers, M.; Ertl, T.; Falk, M.; Fechtig, O.; Frank, R.; Grave, F.; King, A.; Kraus, U.; Muller, T.; Nollert, H.-P.; Mendez, I.R.; Ruder, H.; Schafhitzel, T.; Schar, S.; Zahn, C.; Zatloukal, M.

Year: 2005
Title: A handheld flexible display system
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532846
Abstract:  A new close range virtual reality system is introduced that allows intuitive and immersive user interaction with computer generated objects. A projector with a special spherical lens is combined with a flexible, tracked rear projection screen that users hold in their hands. Unlike normal projectors, the spherical lens allows for a 180 degree field of view and nearly infinite depth of focus. This allows the user to move the screen around the environment and use it as a virtual "slice" to examine the interior of 3D volumes. This provides a concrete correspondence between the virtual representation of the 3D volume and how that volume would actually appear if its real counterpart was sliced open. The screen can also be used as a "magic window" to view the mesh of the volume from different angles prior to taking cross sections of it. Real time rendering of the desired 3D volume or mesh is accomplished using current graphics hardware. Additional applications of the system are also discussed.
Keywords: computational geometry; computer displays; computer graphic equipment; display system; graphical user interfaces; graphics hardware; mesh generation; optical projectors; projector; real time rendering; rendering (computer graphics); spherical lens; user interaction; virtual reality; virtual reality system;
Author: Konieczny, J.; Shimizu, C.; Meyer, G.; Colucci, D.

Year: 2005
Title: Profile Flags: a novel metaphor for probing of T2 maps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532847
Abstract: This paper describes a tool for the visualization of T<sub>2</sub> maps of knee cartilage. Given the anatomical scan, and the T<sub>2</sub> map of the cartilage, we combine the information on the shape and the quality of the cartilage in a single image. The Profile Flag is an intuitive 3D glyph for probing and annotating of the underlying data. It comprises a bulletin board pin-like shape with a small flag on top of it. While moving the glyph along the reconstructed surface of an object, the curve data measured along the pin's needle and in its neighborhood are shown on the flag. The application area of the Profile Flag is manifold, enabling the visualization of profile data of dense but in-homogeneous objects. Furthermore, it extracts the essential part of the data without removing or even reducing the context information. By sticking Profile Flags into the investigated structure, one or more significant locations can be annotated by showing the local characteristics of the data at that locations. In this paper we are demonstrating the properties of the tool by visualizing T<sub>2</sub> maps of knee cartilage.
Keywords: Profile Flags; anatomical scan; curve data measurement; curve fitting; data visualisation; knee cartilage; medical computing; orthopaedics; pin needle; profile data visualization; surface fitting; surface reconstruction;T2 map;
Author: Mlejnek, M.; Ermest, P.; Vilanova, A.; van der Rijt, R.; van den Bosch, H.; Gerritsen, F.; Groller, M.E.

Year: 2005
Title: Eyelet particle tracing - steady visualization of unsteady flow
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532848
Abstract:  It is a challenging task to visualize the behavior of time-dependent 3D vector fields. Most of the time an overview of unsteady fields is provided via animations, but, unfortunately, animations provide only transient impressions of momentary flow. In this paper we present two approaches to visualize time varying fields with fixed geometry. Path lines and streak lines represent such a steady visualization of unsteady vector fields, but because of occlusion and visual clutter it is useless to draw them all over the spatial domain. A selection is needed. We show how bundles of streak lines and path lines, running at different times through one point in space, like through an eyelet, yield an insightful visualization of flow structure ("eyelet lines"). To provide a more intuitive and appealing visualization we also explain how to construct a surface from these lines. As second approach, we use a simple measurement of local changes of a field over time to determine regions with strong changes. We visualize these regions with isosurfaces to give an overview of the activity in the dataset. Finally we use the regions as a guide for placing eyelets.
Keywords: 3D vector field; computational fluid dynamics; computational geometry; computational geometry; computer animation; data visualisation; eyelet particle tracing; flow visualisation; flow visualization; hidden feature removal; occlusion; path lines; streak lines; surface fitting; visual clutter;
Author: Wiebel, A.; Scheuermann, G.

Year: 2005
Title: Interpolation and visualization for advected scalar fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532849
Abstract:  Doppler radars are useful facilities for weather forecasting. The data sampled by using Doppler radars are used to measure the distributions and densities of rain drops, snow crystals, hail stones, or even insects in the atmosphere. In this paper, we propose to build up a graphics-based software system for visualizing Doppler radar data. In the system, the reflectivity data gathered by using Doppler radars are post-processed to generate virtual cloud images which reveal the densities of precipitation in the air. An optical flow based method is adopted to compute the velocities of clouds, advected by winds. Therefore, the movement of clouds is depicted. The cloud velocities are also used to interpolate reflectivities for arbitrary time steps. Therefore, the reflectivities at any time can be produced. Our system composes of three stages. At the first stage, the raw radar data are re-sampled and filtered to create a multiple resolution data structure, based on a pyramid structure. At the second stage, a numeric method is employed to compute cloud velocities in the air and to interpolate radar reflectivity data at given time steps. The radar reflectivity data and cloud velocities are displayed at the last stage. The reflectivities are rendered by using splatting methods to produce semi-transparent cloud images. Two kinds of media are created for analyzing the reflectivity data. The first kind media consists of a group of still images of clouds which displays the distribution and density of water in the air. The second type media is a short animation of cloud images to show the formation and movement of the clouds. To show the advection of clouds, the cloud velocities are displayed by using two dimensional images. In these images, the velocities are represented by arrows and superimposed on cloud images. To enhance image quality, gradients and diffusion of the radar data are computed and used in the rendering process. Therefore the cloud structures are better portrayed. In order to achieve interactive visualization, our system is also comprised with a view-dependent visualization module. The radar data at far distance are rendered in lower resolutions, while the data closer to the eye position is rendered in details.
Keywords: Doppler radar; Doppler radars; cloud image animation; computer animation; data visualisation; data visualization; flow visualisation; graphics-based software system; image quality; image resolution; image resolution; interpolation; interpolation; optical flow based method; pyramid structure; rendering (computer graphics); scalar field; virtual cloud images; virtual reality; weather forecasting; weather forecasting;
Author: Shyh-Kuang Ueng; Sheng-Chuan Wang

Year: 2005
Title: Visual analysis and exploration of fluid flow in a cooling jacket
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532850
Abstract:  We present a visual analysis and exploration of fluid flow through a cooling jacket. Engineers invest a large amount of time and serious effort to optimize the flow through this engine component because of its important role in transferring heat away from the engine block. In this study we examine the design goals that engineers apply in order to construct an ideal-as-possible cooling jacket geometry and use a broad range of visualization tools in order to analyze, explore, and present the results. We systematically employ direct, geometric, and texture-based flow visualization techniques as well as automatic feature extraction and interactive feature-based methodology. And we discuss the relative advantages and disadvantages of these approaches as well as the challenges, both technical and perceptual with this application. The result is a feature-rich state-of-the-art flow visualization analysis applied to an important and complex data set from real-world computational fluid dynamics simulations.
Keywords: automatic feature extraction; computational fluid dynamics; computational fluid dynamics simulations; computational geometry; cooling jacket geometry; engine component; engines; feature extraction; flow visualisation; fluid flow exploration; heat transfer; image texture; interactive feature-based methodology; texture-based flow visualization techniques; visual analysis;
Author: Laramee, R.S.; Garth, C.; Doleisch, H.; Schneider, J.; Hauser, H.; Hagen, H.

Year: 2005
Title: Extraction of parallel vector surfaces in 3D time-dependent fields and application to vortex core line tracking
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532851
Abstract:  We introduce an approach to tracking vortex core lines in time-dependent 3D flow fields which are defined by the parallel vectors approach. They build surface structures in the 4D space-time domain. To extract them, we introduce two 4D vector fields which act as feature flow fields, i.e., their integration gives the vortex core structures. As part of this approach, we extract and classify local bifurcations of vortex core lines in space-time. Based on a 4D stream surface integration, we provide an algorithm to extract the complete vortex core structure. We apply our technique to a number of test data sets.
Keywords: 4D space-time domain; 4D vector fields; bifurcation; computational geometry; data visualisation; feature extraction; flow visualisation; parallel vector surface extraction; physics computing; surface fitting; time-dependent 3D flow fields; tracking; vortex core line tracking;
Author: Theisel, H.; Sahner, J.; Weinkauf, T.; Hege, H.-C.; Seidel, H.-P.

Year: 2005
Title: Particle and texture based spatiotemporal visualization of time-dependent vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532852
Abstract:  We propose a hybrid particle and texture based approach for the visualization of time-dependent vector fields. The underlying space-time framework builds a dense vector field representation in a two-step process: 1) particle-based forward integration of trajectories in spacetime for temporal coherence, and 2) texture-based convolution along another set of paths through the spacetime for spatially correlated patterns. Particle density is controlled by stochastically injecting and removing particles, taking into account the divergence of the vector field. Alternatively, a uniform density can be maintained by placing exactly one particle in each cell of a uniform grid, which leads to particle-in-cell forward advection. Moreover, we discuss strategies of previous visualization methods for unsteady flow and show how they address issues of spatiotemporal coherence and dense visual representations. We demonstrate how our framework is capable of realizing several of these strategies. Finally, we present an efficient GPU implementation that facilitates an interactive visualization of unsteady 2D flow on Shader Model 3 compliant graphics hardware.
Keywords: GPU implementation; Shader Model 3; coherence; dense visual representations; flow visualisation; graphics hardware; image texture; particle-in-cell forward advection; spatiotemporal coherence; spatiotemporal phenomena; texture-based convolution; time-dependent vector field representation; unsteady 2D flow visualization;
Author: Weiskopf, D.; Schramm, F.; Erlebacher, G.; Ertl, T.

Year: 2005
Title: Texture-based visualization of uncertainty in flow fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532853
Abstract:  In this paper, we present two novel texture-based techniques to visualize uncertainty in time-dependent 2D flow fields. Both methods use semi-Lagrangian texture advection to show flow direction by streaklines and convey uncertainty by blurring these streaklines. The first approach applies a cross advection perpendicular to the flow direction. The second method employs isotropic diffusion that can be implemented by Gaussian filtering. Both methods are derived from a generic filtering process that is incorporated into the traditional texture advection pipeline. Our visualization methods allow for a continuous change of the density of flow representation by adapting the density of particle injection. All methods can be mapped to efficient GPU implementations. Therefore, the user can interactively control all important characteristics of the system like particle density, error influence, or dye injection to create meaningful illustrations of the underlying uncertainty. Even though there are many sources of uncertainties, we focus on uncertainty that occurs during data acquisition. We demonstrate the usefulness of our methods for the example of real-world fluid flow data measured with the particle image velocimetry (PIV) technique. Furthermore, we compare these techniques with an adapted multi-frequency noise approach.
Keywords: GPU implementations; Gaussian filtering; data acquisition; data acquisition; data visualisation; flow representation; flow visualisation; image texture; isotropic diffusion; multifrequency noise approach; particle image velocimetry; physics computing; semiLagrangian texture advection; texture-based visualization; time-dependent 2D flow fields;
Author: Botchen, R.P.; Weiskopf, D.; Ertl, T.

Year: 2005
Title: Example-based volume illustrations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532854
Abstract:  Scientific illustrations use accepted conventions and methodologies to effectively convey object properties and improve our understanding. We present a method to illustrate volume datasets by emulating example illustrations. As with technical illustrations, our volume illustrations more clearly delineate objects, enrich details, and artistically visualize volume datasets. For both color and scalar 3D volumes, we have developed an automatic color transfer method based on the clustering and similarities in the example illustrations and volume sources. As an extension to 2D Wang tiles, we provide a new, general texture synthesis method for Wang cubes that solves the edge discontinuity problem. We have developed a 2D illustrative slice viewer and a GPU-based direct volume rendering system that uses these non-periodic 3D textures to generate illustrative results similar to the 2D examples. Both applications simulate scientific illustrations to provide more information than the original data and visualize objects more effectively, while only requiring simple user interaction.
Keywords: 2D Wang tiles; 2D illustrative slice viewer; GPU-based direct volume rendering system; Wang cubes; automatic color transfer method; colour graphics; data visualisation; image texture; nonperiodic 3D textures; rendering (computer graphics); scientific illustrations; texture synthesis method; volume datasets illustrations;
Author: Lu, A.; Ebert, D.S.

Year: 2005
Title: Illustrative display of hidden iso-surface structures
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532855
Abstract:  Indirect volume rendering is a widespread method for the display of volume datasets. It is based on the extraction of polygonal iso-surfaces from volumetric data, which are then rendered using conventional rasterization methods. Whereas this rendering approach is fast and relatively easy to implement, it cannot easily provide an understandable display of structures occluded by the directly visible iso-surface. Simple approaches like alpha-blending for transparency when drawing the iso-surface often generate a visually complex output, which is difficult to interpret. Moreover, such methods can significantly increase the computational complexity of the rendering process. In this paper, we therefore propose a new approach for the illustrative indirect rendering of volume data in real-time. This algorithm emphasizes the silhouette of objects represented by the iso-surface. Additionally, shading intensities on objects are reproduced with a monochrome hatching technique. Using a specially designed two-pass rendering process, structures behind the front layer of the iso-surface are automatically extracted with a depth peeling method. The shapes of these hidden structures are also displayed as silhouette outlines. As an additional option, the geometry of explicitly specified inner objects can be displayed with constant translucency. Although these inner objects always remain visible, a specific shading and depth attenuation method is used to convey the depth relationships. We describe the implementation of the algorithm, which exploits the programmability of state-of-the-art graphics processing units (GPUs). The algorithm described in this paper does not require any preprocessing of the input data or a manual definition of inner structures. Since the presented method works on iso-surfaces, which are stored as polygonal datasets, it can also be applied to other types of polygonal models.
Keywords: alpha-blending; computational geometry; data visualisation; depth attenuation method; depth peeling method; graphics processing units; hidden feature removal; hidden iso-surface structures; illustrative display; indirect volume rendering; monochrome hatching technique; object detection; object silhouette; polygonal datasets; rasterization methods; rendering (computer graphics); surface fitting;
Author: Fischer, J.; Bartz, D.; Strasser, W.

Year: 2005
Title: VolumeShop: an interactive system for direct volume illustration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532856
Abstract:  Illustrations play a major role in the education process. Whether used to teach a surgical or radiologic procedure, to illustrate normal or aberrant anatomy, or to explain the functioning of a technical device, illustration significantly impacts learning. Although many specimens are readily available as volumetric data sets, particularly in medicine, illustrations are commonly produced manually as static images in a time-consuming process. Our goal is to create a fully dynamic three-dimensional illustration environment which directly operates on volume data. Single images have the aesthetic appeal of traditional illustrations, but can be interactively altered and explored. In this paper we present methods to realize such a system which combines artistic visual styles and expressive visualization techniques. We introduce a novel concept for direct multi-object volume visualization which allows control of the appearance of inter-penetrating objects via two-dimensional transfer functions. Furthermore, a unifying approach to efficiently integrate many non-photorealistic rendering models is presented. We discuss several illustrative concepts which can be realized by combining cutaways, ghosting, and selective deformation. Finally, we also propose a simple interface to specify objects of interest through three-dimensional volumetric painting. All presented methods are integrated into VolumeShop, an interactive hardware-accelerated application for direct volume illustration.
Keywords: VolumeShop; artistic visual styles; data visualisation; direct multiobject volume visualization; direct volume illustration; education process; interactive hardware-accelerated application; interactive systems; nonphotorealistic rendering models; object detection; rendering (computer graphics); solid modelling; three-dimensional volumetric painting; transfer functions; two-dimensional transfer functions; volumetric data sets;
Author: Bruckner, S.; Groller, M.E.

Year: 2005
Title: Illustration-inspired techniques for visualizing time-varying data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532857
Abstract:  Traditionally, time-varying data has been visualized using snapshots of the individual time steps or an animation of the snapshots shown in a sequential manner. For larger datasets with many time-varying features, animation can be limited in its use, as an observer can only track a limited number of features over the last few frames. Visually inspecting each snapshot is not practical either for a large number of time-steps. We propose new techniques inspired from the illustration literature to convey change over time more effectively in a time-varying dataset. Speedlines are used extensively by cartoonists to convey motion, speed, or change over different panels. Flow ribbons are another technique used by cartoonists to depict motion in a single frame. Strobe silhouettes are used to depict previous positions of an object to convey the previous positions of the object to the user. These illustration-inspired techniques can be used in conjunction with animation to convey change over time.
Keywords: computer animation; computer animation; data visualisation; feature extraction; flow ribbons; illustration-inspired techniques; motion estimation; rendering (computer graphics); strobe silhouettes; time-varying data visualization;
Author: Joshi, A.; Rheingans, P.

Year: 2005
Title: Illustration and photography inspired visualization of flows and volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532858
Abstract:  Understanding and analyzing complex volumetrically varying data is a difficult problem. Many computational visualization techniques have had only limited success in succinctly portraying the structure of three-dimensional turbulent flow. Motivated by both the extensive history and success of illustration and photographic flow visualization techniques, we have developed a new interactive volume rendering and visualization system for flows and volumes that simulates and enhances traditional illustration, experimental advection, and photographic flow visualization techniques. Our system uses a combination of varying focal and contextual illustrative styles, new advanced two-dimensional transfer functions, enhanced Schlieren and shadowgraphy shaders, and novel oriented structure enhancement techniques to allow interactive visualization, exploration, and comparative analysis of scalar, vector, and time-varying volume datasets. Both traditional illustration techniques and photographic flow visualization techniques effectively reduce visual clutter by using compact oriented structure information to convey three-dimensional structures. Therefore, a key to the effectiveness of our system is using one-dimensional (Schlieren and shadowgraphy) and two-dimensional (silhouette) oriented structural information to reduce visual clutter, while still providing enough three-dimensional structural information for the user's visual system to understand complex three-dimensional flow data. By combining these oriented feature visualization techniques with flexible transfer function controls, we can visualize scalar and vector data, allow comparative visualization of flow properties in a succinct, informative manner, and provide continuity for visualizing time-varying datasets.
Keywords: contextual illustrative styles; data visualisation; flow visualisation; interactive systems; interactive volume rendering; photographic flow visualization techniques; photography; rendering (computer graphics); schlieren systems; shadowgraphy shaders; structure enhancement techniques; three-dimensional turbulent flow; time-varying volume datasets; transfer functions; turbulence; two-dimensional transfer functions; visual clutter;
Author: Svakhine, N.A.; Jang, Y.; Ebert, D.; Gaither, K.

Year: 2005
Title: Visualization with stylized line primitives
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532859
Abstract:  Line primitives are a very powerful visual attribute used for scientific visualization and in particular for 3D vector-field visualization. We extend the basic line primitives with additional visual attributes including color, line width, texture and orientation. To implement the visual attributes we represent the stylized line primitives as generalized cylinders. One important contribution of our work is an efficient rendering algorithm for stylized lines, which is hybrid in the sense that it uses both CPU and GPU based rendering. We improve the depth perception with a shadow algorithm. We present several applications for the visualization with stylized lines among which are the visualizations of 3D vector fields and molecular structures.
Keywords: 3D vector-field visualization; computational geometry; data visualisation; depth perception; image texture; molecular structures; rendering (computer graphics); rendering algorithm; scientific visualization; shadow algorithm; stylized line primitives; visual attribute;
Author: Stoll, C.; Gumhold, S.; Seidel, H.-P.

Year: 2005
Title: 2D asymmetric tensor analysis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532770
Abstract:  Analysis of degenerate tensors is a fundamental step in finding the topological structures and separatrices in tensor fields. Previous work in this area have been limited to analyzing symmetric second order tensor fields. In this paper, we extend the topological analysis to 2D general (asymmetric) second order tensor fields. We show that it is not sufficient to define degeneracies based on eigenvalues alone, but one must also include the eigenvectors in the analysis. We also study the behavior of these eigenvectors as they cross from one topological region into another.
Keywords: 2D asymmetric tensor analysis; data visualisation; eigenvalues and eigenfunctions; eigenvectors analysis; tensors; topological structure; topology;
Author: Zheng, X.; Pang, A.

Year: 2005
Title: Exploring 2D tensor fields using stress nets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532771
Abstract:  In this article we describe stress nets, a technique for exploring 2D tensor fields. Our method allows a user to examine simultaneously the tensors' eigenvectors (both major and minor) as well as scalar-valued tensor invariants. By avoiding noise-advection techniques, we are able to display both principal directions of the tensor field as well as the derived scalars without cluttering the display. We present a CPU-only implementation of stress nets as well as a hybrid CPU/GPU approach and discuss the relative strengths and weaknesses of each. Stress nets have been used as part of an investigation into crack propagation. They were used to display the directions of maximum shear in a slab of material under tension as well as the magnitude of the shear forces acting on each point. Our methods allowed users to find new features in the data that were not visible on standard plots of tensor invariants. These features disagree with commonly accepted analytical crack propagation solutions and have sparked renewed investigation. Though developed for a materials mechanics problem, our method applies equally well to any 2D tensor field having unique characteristic directions.
Keywords: 2D tensor field; crack propagation; cracks; data visualisation; hybrid CPU approach; hybrid GPU approach; noise-advection techniques; physics computing; shear forces; stress analysis; stress nets; tensors;
Author: Wilson, A.; Brannon, R.

Year: 2005
Title: Illuminated lines revisited
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1532772
Abstract:  For the rendering of vector and tensor fields, several texture-based volumetric rendering methods were presented in recent years. While they have indisputable merits, the classical vertex-based rendering of integral curves has the advantage of better zooming capabilities as it is not bound to a fixed resolution. It has been shown that lighting can improve spatial perception of lines significantly, especially if lines appear in bundles. Although OpenGL does not directly support lighting of lines, fast rendering of illuminated lines can be achieved by using basic texture mapping. This existing technique is based on a maximum principle which gives a good approximation of specular reflection. Diffuse reflection however is essentially limited to bidirectional lights at infinity. We show how the realism can be further increased by improving diffuse reflection. We present simplified expressions for the Phong/Blinn lighting of infinitesimally thin cylindrical tubes. Based on these, we propose a fast rendering technique with diffuse and specular reflection for orthographic and perspective views and for multiple local and infinite lights. The method requires commonly available programmable vertex and fragment shaders and only two-dimensional lookup textures.
Keywords: data visualisation; graphics hardware; image resolution; image texture; rendering (computer graphics); specular reflection approximation; texture mapping; texture-based volumetric rendering method; vector field visualization; vertex-based rendering;
Author: Mallo, O.; Peikert, R.; Sigg, C.; Sadlo, F.

Year: 2004
Title: The human visual system: how is its design related to the physics of the natural environment?
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372171
Abstract:  Summary form only given. The human visual system is the result of evolution by natural selection and hence its design must incorporate detailed knowledge of the physical properties of the natural environment. This is an obvious statement, but the scientific community has been slow to take it seriously. Only recently has there been an increased effort to directly measure the statistical properties of natural scenes and compare them to the design and performance of the human visual system. This work describes some recent studies of the chromatic and geometrical properties of natural materials and natural images, as well as some perceptual and physiological studies designed to test how those physical properties are related to human perceptual mechanisms.
Keywords: chromatic properties; computational geometry; geometrical properties; human perceptual mechanisms; human visual system; natural environment; natural images; natural scenes; natural scenes; physiological studies; physiology; realistic images; statistical analysis; visual perception;
Author: Geisler, W.S.

Year: 2004
Title: Self-illustrating phenomena
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372172
Abstract:  Summary form only given. A self-illustrating phenomenon is an image which exposes the science behind it. Some famous examples are pictures of iron filings aligned along magnetic lines of force, sand particles collecting at the stationary points of the standing waves of a violin, stress in a mechanical part revealed through birefringence, and particle tracks in a bubble chamber. Such images brilliantly combine experimental design, analysis, and visualization. Quoting J. Tukey, "the general purposes of conducting experiments and analyzing data match, point by point". We argue in this talk that computer tools for visual analysis should normally be conceived of as aids in constructing computational visual experiments; and that the resulting visualizations be consciously designed to help validate or invalidate the hypothesis being tested by the experiment.
Keywords: computational visual experiments; data visualisation; data visualization; image processing; self-illustrating phenomenon; visual analysis;
Author: Hanrahan, P.

Year: 2004
Title: Methods for efficient, high quality volume resampling in the frequency domain
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372173
Abstract:  Resampling is a frequent task in visualization and medical imaging. It occurs whenever images or volumes are magnified, rotated, translated, or warped. Resampling is also an integral procedure in the registration of multimodal datasets, such as CT, PET, and MRI, in the correction of motion artifacts in MRI, and in the alignment of temporal volume sequences in fMRI. It is well known that the quality of the resampling result depends heavily on the quality of the interpolation filter used. However, high-quality filters are rarely employed in practice due to their large spatial extents. We explore a new resampling technique that operates in the frequency-domain where high-quality filtering is feasible. Further, unlike previous methods of this kind, our technique is not limited to integer-ratio scaling factors, but can resample image and volume datasets at any rate. This would usually require the application of slow discrete Fourier transforms (DFT) to return the data to the spatial domain. We studied two methods that successfully avoid these delays: the chirp-z transform and the FFTW package. We also outline techniques to avoid the ringing artifacts that may occur with frequency-domain filtering. Thus, our method can achieve high-quality interpolation at speeds that are usually associated with spatial filters of far lower quality.
Keywords: DFT; MRI; biomedical MRI; chirp-z transform; data visualisation; data visualization; discrete Fourier transforms; discrete Fourier transforms; frequency-domain filtering; image enhancement; image registration; image representation; image sampling; image sequences; integer-ratio scaling factors; interpolation; interpolation filter; medical imaging; multimodal datasets; spatial filters; spatial filters; spatiotemporal phenomena; temporal volume sequences; visual databases; volume resampling;
Author: Li, A.; Mueller, K.; Ernst, T.

Year: 2004
Title: Linear and cubic box splines for the body centered cubic lattice
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372174
Abstract:  We derive piecewise linear and piecewise cubic box spline reconstruction filters for data sampled on the body centered cubic (BCC) lattice. We analytically derive a time domain representation of these reconstruction filters and using the Fourier slice-projection theorem we derive their frequency responses. The quality of these filters, when used in reconstructing BCC sampled volumetric data, is discussed and is demonstrated with a raycaster. Moreover, to demonstrate the superiority of the BCC sampling, the resulting reconstructions are compared with those produced from similar filters applied to data sampled on the Cartesian lattice.
Keywords: Cartesian lattice; Fourier slice-projection theorem; Fourier transforms; body centered cubic lattice; computational geometry; filtering theory; image reconstruction; image representation; image sampling; interpolation; lattice theory; optimal regular sampling; piecewise cubic box spline reconstruction filters; splines (mathematics);
Author: Entezari, A.; Dyer, R.; Moller, T.

Year: 2004
Title: Light weight space leaping using ray coherence
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372175
Abstract:  We present a space leaping technique for accelerating volume rendering with very low space and run-time complexity. Our technique exploits the ray coherence during ray casting by using the distance a ray traverses in empty space to leap its neighboring rays. Our technique works with parallel as well as perspective volume rendering, does not require any preprocessing or 3D data structures, and is independent of the transfer function. Being an image-space technique, it is independent of the complexity of the data being rendered. It can be used to accelerate both time-coherent and noncoherent animation sequences.
Keywords: computational complexity; computational geometry; computer animation; empty space skipping; image sequences; image-space technique; light coherence; noncoherent animation sequences; perspective volume rendering; ray casting; ray coherence; ray tracing; rendering (computer graphics); space leaping technique;
Author: Lakare, S.; Kaufman, A.

Year: 2004
Title: Projecting tetrahedra without rendering artifacts
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372176
Abstract:  Hardware-accelerated direct volume rendering of unstructured volumetric meshes is often based on tetrahedral cell projection, in particular, the projected tetrahedra (PT) algorithm and its variants. Unfortunately, even implementations of the most advanced variants of the PT algorithm are very prone to rendering artifacts. In this work, we identify linear interpolation in screen coordinates as a cause for significant rendering artifacts and implement the correct perspective interpolation for the PT algorithm with programmable graphics hardware. We also demonstrate how to use features of modern graphics hardware to improve the accuracy of the coloring of individual tetrahedra and the compositing of the resulting colors, in particular, by employing a logarithmic scale for the preintegrated color lookup table, using textures with high color resolution, rendering to floating-point color buffers, and alpha dithering. Combined with a correct visibility ordering, these techniques result in the first implementation of the PT algorithm without objectionable rendering artifacts. Apart from the important improvement in rendering quality, our approach also provides a test bed for different implementations of the PT algorithm that allows us to study the particular rendering artifacts introduced by these variants.
Keywords: colour graphics; computational geometry; computer graphic equipment; data visualisation; floating-point color buffers; hardware-accelerated direct volume rendering; image resolution; image texture; image textures; interpolation; linear interpolation; mesh generation; preintegrated color lookup table; programmable graphics hardware; projected tetrahedra algorithm; ray tracing; rendering (computer graphics); table lookup; tetrahedral cell projection; unstructured volumetric meshes; volume visualization;
Author: Kraus, M.; Wei Qiao; Ebert, D.S.

Year: 2004
Title: Flow field clustering via algebraic multigrid
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372177
Abstract:  We present a novel multiscale approach for flow visualization. We define a local alignment tensor that encodes a measure for alignment to the direction of a given flow field. This tensor induces an anisotropic differential operator on the flow domain, which is discretized with a standard finite element technique. The entries of the corresponding stiffness matrix represent the anisotropically weighted couplings of adjacent nodes of the domain mesh. We use an algebraic multigrid algorithm to generate a hierarchy of fine to coarse descriptions for the above coupling data. This hierarchy comprises a set of coarse grid nodes, a multiscale of basis functions and their corresponding supports. We use these supports to obtain a multilevel decomposition of the flow structure. Standard streamline icons are used to visualize this decomposition at any user-selected level of detail. The method provides a single framework for vector field decomposition independent on the domain dimension or mesh type. Applications are shown in 2D, for flow fields on curved surfaces, and for 3D volumetric flow fields.
Keywords: 3D volumetric flow fields; algebraic multigrid algorithm; anisotropic differential operator; data visualisation; differential equations; finite element technique; flow structure decomposition; flow visualisation; flow visualization; image texture; local alignment tensor; matrix algebra; mesh generation; stiffness matrix; streamline icons; tensors; vector field decomposition;
Author: Griebel, M.; Preusser, T.; Rumpf, M.; Schweitzer, M.A.; Telea, A.

Year: 2004
Title: Centroidal Voronoi tessellation based algorithms for vector fields visualization and segmentation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372178
Abstract:  A new method for the simplification and the visualization of vector fields is presented based on the notion of centroidal Voronoi tessellations (CVT's). A CVT is a special Voronoi tessellation for which the generators of the Voronoi regions in the tessellation are also the centers of mass (or means) with respect to a prescribed density. A distance function in both the spatial and vector spaces is introduced to measure the similarity of the spatially distributed vector fields. Based on such a distance, vector fields are naturally clustered and their simplified representations are obtained. Our method combines simple geometric intuitions with the rigorously established optimality properties of the CVTs. It is simple to describe, easy to understand and implement. Numerical examples are also provided to illustrate the effectiveness and competitiveness of the CVT-based vector simplification and visualization methodology.
Keywords: centroidal Voronoi tessellations; computational geometry; data visualisation; flow visualisation; flow visualization; image segmentation; image segmentation; pattern clustering; vector field visualization; vector simplification;
Author: Qiang Du; Xiaoquiang Wang

Year: 2004
Title: Investigating swirl and tumble flow with a comparison of visualization techniques
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372179
Abstract:  We investigate two important, common fluid flow patterns from computational fluid dynamics (CFD) simulations, namely, swirl and tumble motion typical of automotive engines. We study and visualize swirl and tumble flow using three different flow visualization techniques: direct, geometric, and texture-based. When illustrating these methods side-by-side, we describe the relative strengths and weaknesses of each approach within a specific spatial dimension and across multiple spatial dimensions typical of an engineer's analysis. Our study is focused on steady-state flow. Based on this investigation we offer perspectives on where and when these techniques are best applied in order to visualize the behavior of swirl and tumble motion.
Keywords: CFD simulations; automotive engines; computational fluid dynamics; computational fluid dynamics; computational geometry; data visualisation; direct visualization; flow simulation; flow visualisation; flow visualization techniques; fluid flow patterns; geometric visualization; in-cylinder flow; spatial dimensions; steady-state flow; surface texture; swirl flow; swirling flow; texture-based visualization; tumble motion;
Author: Laramee, R.S.; Weiskopf, D.; Schneider, J.; Hauser, H.

Year: 2004
Title: Visualizing gyrokinetic simulations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372180
Abstract:  The continuing advancement of plasma science is central to realizing fusion as an inexpensive and safe energy source. Gryokinetic simulations of plasmas are fundamental to the understanding of turbulent transport in fusion plasma. This work discusses the visualization challenges presented by gyrokinetic simulations using magnetic field line following coordinates, and presents an effective solution exploiting programmable graphics hardware to enable interactive volume visualization of 3D plasma flow on a toroidal coordinate system. The new visualization capability can help scientists better understand three-dimensional structures of the modeled phenomena. Both the limitations and future promise of the hardware-accelerated approach are also discussed.
Keywords: 3D plasma flow; computational fluid dynamics; computer graphic equipment; data visualisation; flow simulation; fusion plasma science; gyrokinetic simulations; interactive volume visualization; magnetic field line; magnetic fields; mesh generation; nonrectilinear mesh; plasma flow; plasma physics; plasma simulation; plasma toroidal confinement; plasma turbulence; programmable graphics hardware; rendering (computer graphics); scientific visualization; texture methods; toroidal coordinate system; turbulent transport;
Author: Crawford, D.; Ma, K.-L.; Min-Yu Huang; Klasky, S.; Ethier, S.

Year: 2004
Title: Hardware-accelerated adaptive EWA volume splatting
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372181
Abstract:  We present a hardware-accelerated adaptive EWA (elliptical weighted average) volume splatting algorithm. EWA splatting combines a Gaussian reconstruction kernel with a low-pass image filter for high image quality without aliasing artifacts or excessive blurring. We introduce a novel adaptive filtering scheme to reduce the computational cost of EWA splatting. We show how this algorithm can be efficiently implemented on modern graphics processing units (GPUs). Our implementation includes interactive classification and fast lighting. To accelerate the rendering we store splat geometry and 3D volume data locally in GPU memory. We present results for several rectilinear volume datasets that demonstrate the high image quality and interactive rendering speed of our method.
Keywords: 3D volume data; GPU memory; Gaussian processes; Gaussian reconstruction kernel; adaptive filtering scheme; adaptive filters; computational geometry; computer graphic equipment; elliptical weighted average volume splatting algorithm; graphics processing units; hardware-accelerated adaptive EWA; image quality; image reconstruction; image texture; interactive direct volume rendering; low-pass filters; low-pass image filter; rectilinear volume datasets; rendering (computer graphics); splat geometry;
Author: Wei Chen; Liu Ren; Zwicker, M.; Pfister, H.

Year: 2004
Title: Generating sub-resolution detail in images and volumes using constrained texture synthesis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372182
Abstract:  A common deficiency of discretized datasets is that detail beyond the resolution of the dataset has been irrecoverably lost. This lack of detail becomes immediately apparent once one attempts to zoom into the dataset and only recovers blur. We describe a method that generates the missing detail from any available and plausible high-resolution data, using texture synthesis. Since the detail generation process is guided by the underlying image or volume data and is designed to fill in plausible detail in accordance with the coarse structure and properties of the zoomed-in neighborhood, we refer to our method as constrained texture synthesis. Regular zooms become "semantic zooms", where each level of detail stems from a data source attuned to that resolution. We demonstrate our approach by a medical application - the visualization of a human liver - but its principles readily apply to any scenario, as long as data at all resolutions are available. We first present a 2D viewing application, called the "virtual microscope", and then extend our technique to 3D volumetric viewing.
Keywords: 2D view; 3D volumetric viewing; constrained texture synthesis; data visualisation; human liver visualization; image resolution; image resolution; image sequences; image texture; liver; medical application; medical image processing; microscopes; semantic zoom; subresolution detail generation; virtual microscope; volume data;
Author: Lujin Wang; Mueller, K.

Year: 2004
Title: Constrained inverse volume rendering for planetary nebulae
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372183
Abstract:  Determining the three-dimensional structure of distant astronomical objects is a challenging task, given that terrestrial observations provide only one viewpoint. For this task, bipolar planetary nebulae are interesting objects of study because of their pronounced axial symmetry due to fundamental physical processes. Making use of this symmetry constraint, we present a technique to automatically recover the axisymmetric structure of bipolar planetary nebulae from two-dimensional images. With GPU-based volume rendering driving a nonlinear optimization, we estimate the nebula's local emission density as a function of its radial and axial coordinates, and we recover the orientation of the nebula relative to Earth. The optimization refines the nebula model and its orientation by minimizing the differences between the rendered image and the original astronomical image. The resulting model enables realistic 3D visualizations of planetary nebulae, e.g. for educational purposes in planetarium shows. In addition, the recovered spatial distribution of the emissive gas allows validating computer simulation results of the astrophysical formation processes of planetary nebulae.
Keywords: GPU-based volume rendering; astronomical image; astronomy computing; astrophysical formation process; axial symmetry; axial symmetry; bipolar planetary nebulae; computer simulation; constrained inverse volume rendering; data visualisation; digital simulation; distant astronomical objects; fundamental physical process; image reconstruction; local emission density; minimisation; nonlinear optimization; planetary nebulae; radial coordinates; realistic 3D visualization; rendering (computer graphics); solid modelling; spatial distribution; terrestrial observations; two-dimensional image; volume reconstruction; volumetric modeling;
Author: Magnor, M.; Kindlmann, G.; Duric, N.; Hansen, C.

Year: 2004
Title: Generating realistic images from hydrothermal plume data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372184
Abstract:  Most data used in the study of seafloor hydrothermal plumes consists of sonar (acoustic) scans and sensor readings. Visual data captures only a portion of the sonar data range due to the prohibitive cost and physical infeasibility of taking sufficient lighting and video equipment to such extreme depths. However, visual images are available from research dives and from the recent IMAX movie, volcanoes of the deep sea. In this application paper, we apply existing lighting models with forward scattering and light attenuation to the 3D sonar data in order to mimic the visual images available. These generated images are compared to existing visual images. This can help the geoscientists understand the relationship between these different data modalities and elucidate some of the mechanisms used to capture the data.
Keywords: 3D sonar data; IMAX movie; acoustic scans; data visualisation; environmental sciences visualization; forward scattering; geophysics computing; light attenuation; lighting; lighting model; realistic image generation; realistic images; rendering (computer graphics); seafloor hydrothermal plume data; seafloor phenomena; sensor readings; sonar imaging; visual image; volume graphics; volume rendering; volume visualization;
Author: Santilli, K.; Bemis, K.; Silver, D.; Dastur, J.; Rona, P.

Year: 2004
Title: Rendering implicit flow volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372185
Abstract:  Traditional flow volumes construct an explicit geometrical or parametrical representation from the vector field. The geometry is updated interactively and then rendered using an unstructured volume rendering technique. Unless a detailed refinement of the flow volume is specified for the interior, information inside the underlying flow volume is lost in the linear interpolation. These disadvantages can be avoided and/or alleviated using an implicit flow model. An implicit flow is a scalar field constructed such that any point in the field is associated with a termination surface using an advection operator on the flow. We present two techniques, a slice-based three-dimensional texture mapping and an interval volume segmentation coupled with a tetrahedron projection-based renderer, to render implicit stream flows. In the first method, the implicit flow representation is loaded as a 3D texture and manipulated using a dynamic texture operation that allows the flow to be investigated interactively. In our second method, a geometric flow volume is extracted from the implicit flow using a high dimensional isocontouring or interval volume routine. This provides a very detailed flow volume or set of flow volumes that can easily change topology, while retaining accurate characteristics within the flow volume. The advantages and disadvantages of these two techniques are compared with traditional explicit flow volumes.
Keywords: advection operator; computational fluid dynamics; computational geometry; data visualisation; flow visualisation; geometric flow volume; image matching; image segmentation; image texture; implicit flow volume rendering technique; implicit stream flows; interval volume segmentation; isocontouring; linear interpolation; rendering (computer graphics); scalar field; slice-based three-dimensional texture mapping; tetrahedron projection-based renderer;
Author: Xue, D.; Zhang, C.; Crawfis, R.

Year: 2004
Title: Anisotropic volume rendering for extremely dense, thin line data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372186
Abstract:  Many large scale physics-based simulations which take place on PC clusters or supercomputers produce huge amounts of data including vector fields. While these vector data such as electromagnetic fields, fluid flow fields, or particle paths can be represented by lines, the sheer number of the lines overwhelms the memory and computation capability of a high-end PC used for visualization. Further, very dense or intertwined lines, rendered with traditional visualization techniques, can produce unintelligible results with unclear depth relationships between the lines and no sense of global structure. Our approach is to apply a lighting model to the lines and sample them into an anisotropic voxel representation based on spherical harmonics as a preprocessing step. Then we evaluate and render these voxels for a given view using traditional volume rendering. For extremely large line based datasets, conversion to anisotropic voxels reduces the overall storage and rendering for O(n) lines to O(1) with a large constant that is still small enough to allow meaningful visualization of the entire dataset at nearly interactive rates on a single commodity PC.
Keywords: anisotropic volume rendering; anisotropic voxel representation; approximation theory; computational complexity; computational geometry; data visualisation; harmonics; image representation; large line based datasets; lighting; lighting model; physics computing; rendering (computer graphics); scientific visualization; single commodity PC; spherical harmonics; thin line data; vector field; volume visualization;
Author: Schussman, G.; Ma, K.-L.

Year: 2004
Title: Display of vector fields using a reaction-diffusion model
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372187
Abstract:  Effective visualization of vector fields relies on the ability to control the size and density of the underlying mapping to visual cues used to represent the field. In this paper we introduce the use of a reaction-diffusion model, already well known for its ability to form irregular spatio-temporal patters, to control the size, density, and placement of the vector field representation. We demonstrate that it is possible to encode vector field information (orientation and magnitude) into the parameters governing a reaction-diffusion model to form a spot pattern with the correct orientation, size, and density, creating an effective visualization. To encode direction we texture the spots using a light to dark fading texture. We also show that it is possible to use the reaction-diffusion model to visualize an additional scalar value, such as the uncertainty in the orientation of the vector field. An additional benefit of the reaction-diffusion visualization technique arises from its automatic density distribution. This benefit suggests using the technique to augment other vector visualization techniques. We demonstrate this utility by augmenting a LIC visualization with a reaction-diffusion visualization. Finally, the reaction-diffusion visualization method provides a technique that can be used for streamline and glyph placement.
Keywords: automatic density distribution; computational fluid dynamics; data visualisation; direction encoding; encoding; fading texture; flow visualisation; flow visualization; glyph placement; image texture; irregular spatio-temporal patters; reaction-diffusion model; reaction-diffusion systems; vector field representation; vector visualization technique;
Author: Sanderson, A.R.; Johnson, C.R.; Kirby, R.M.

Year: 2004
Title: Physically based methods for tensor field visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372188
Abstract:  The physical interpretation of mathematical features of tensor fields is highly application-specific. Existing visualization methods for tensor fields only cover a fraction of the broad application areas. We present a visualization method tailored specifically to the class of tensor field exhibiting properties similar to stress and strain tensors, which are commonly encountered in geomechanics. Our technique is a global method that represents the physical meaning of these tensor fields with their central features: regions of compression or expansion. The method is based on two steps: first, we define a positive definite metric, with the same topological structure as the tensor field; second, we visualize the resulting metric. The eigenvector fields are represented using a texture-based approach resembling line integral convolution (LIC) methods. The eigenvalues of the metric are encoded in free parameters of the texture definition. Our method supports an intuitive distinction between positive and negative eigenvalues. We have applied our method to synthetic and some standard data sets, and "real" data from earth science and mechanical engineering application.
Keywords: convolution; data visualisation; earth science; eigenvalues and eigenfunctions; eigenvector fields; encoding; geomechanics; geophysics computing; image representation; image texture; line integral convolution; mathematical features; mechanical engineering application; positive definite metric; strain tensors; stress tensor; stress-strain relations; tensors; texture-based approach; topological structure;
Author: Hotz, I.; Feng, L.; Hagen, H.; Hamann, B.; Joy, K.; Jeremic, B.

Year: 2004
Title: Quick-VDR: interactive view-dependent rendering of massive models
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372189
Abstract:  We present a novel approach for interactive view-dependent rendering of massive models. Our algorithm combines view-dependent simplification, occlusion culling, and out-of-core rendering. We represent the model as a clustered hierarchy of progressive meshes (CHPM). We use the cluster hierarchy for coarse-grained selective refinement and progressive meshes for fine-grained local refinement. We present an out-of-core algorithm for computation of a CHPM that includes cluster decomposition, hierarchy generation, and simplification. We make use of novel cluster dependencies in preprocess to generate crack-free, drastic simplifications at runtime. The clusters are used for occlusion culling and out-of-core rendering. We add a frame of latency to the rendering pipeline to fetch newly visible clusters from the disk and to avoid stalls. The CHPM reduces the refinement cost for view-dependent rendering by more than an order of magnitude as compared to a vertex hierarchy. We have implemented our algorithm on a desktop PC. We can render massive CAD, isosurface, and scanned models, consisting of tens or a few hundreds of millions of triangles at 10-35 frames per second with little loss in image quality.
Keywords: data visualisation; external memory algorithm; interactive display; interactive systems; interactive view-dependent rendering; levels-of-detail; massive models; mesh generation; occlusion culling; out-of-core rendering; progressive mesh; rendering (computer graphics); solid modelling; storage management; view-dependent simplification;
Author: Sung-Eui Yoon; Salomon, B.; Gayle, R.; Manocha, D.

Year: 2004
Title: Importance-driven volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372190
Abstract:  This work introduces importance-driven volume rendering as a novel technique for automatic focus and context display of volumetric data. Our technique is a generalization of cut-away views, which - depending on the viewpoint - remove or suppress less important parts of a scene to reveal more important underlying information. We automatize and apply this idea to volumetric data. Each part of the volumetric data is assigned an object importance, which encodes visibility priority. This property determines which structures should be readily discernible and which structures are less important. In those image regions, where an object occludes more important structures it is displayed more sparsely than in those areas where no occlusion occurs. Thus the objects of interest are clearly visible. For each object several representations, i.e., levels of sparseness, are specified. The display of an individual object may incorporate different levels of sparseness. The goal is to emphasize important structures and to maximize the information content in the final image. This work also discusses several possible schemes for level of sparseness specification and different ways how object importance can be composited to determine the final appearance of a particular object.
Keywords: data visualisation; image representation; importance-driven volume rendering; level-of-details; levels of sparseness; medical diagnostic computing; nonphotorealistic techniques; object importance; occlusion; rendering (computer graphics); view-dependent visualization;
Author: Viola, I.; Kanitsar, A.; Groller, M.E.

Year: 2004
Title: Visibility culling for time-varying volume rendering using temporal occlusion coherence
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372191
Abstract:  Typically there is a high coherence in data values between neighboring time steps in an iterative scientific software simulation; this characteristic similarly contributes to a corresponding coherence in the visibility of volume blocks when these consecutive time steps are rendered. Yet traditional visibility culling algorithms were mainly designed for static data, without consideration of such potential temporal coherency. We explore the use of temporal occlusion coherence (TOC) to accelerate visibility culling for time-varying volume rendering. In our algorithm, the opacity of volume blocks is encoded by means of plenoptic opacity functions (POFs). A coherence-based block fusion technique is employed to coalesce time-coherent data blocks over a span of time steps into a single, representative block. Then POFs need only be computed for these representative blocks. To quickly determine the subvolumes that do not require updates in their visibility status for each subsequent time step, a hierarchical "TOC tree" data structure is constructed to store the spans of coherent time steps. To achieve maximal culling potential, while remaining conservative, we have extended our previous POP into an optimized POP (OPOP) encoding scheme for this specific scenario. To test our general TOC and OPOF approach, we have designed a parallel time-varying volume rendering algorithm accelerated by visibility culling. Results from experimental runs on a 32-processor cluster confirm both the effectiveness and scalability of our approach.
Keywords: data visualisation; data visualization; iterative scientific software simulation; parallel algorithm; plenoptic opacity functions; rendering (computer graphics); temporal databases; temporal occlusion coherence; time-varying volume rendering; tree data structure; tree data structures; visibility culling;
Author: Jinzhu Gao; Han-Wei Shen; Jian Huang; Kohl, J.A.

Year: 2004
Title: Visualization in grid computing environments
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372192
Abstract:  Grid computing provides a challenge for visualization system designers. In this research, we evolve the dataflow concept to allow parts of the visualization process to be executed remotely in a secure and seamless manner. We see dataflow at three levels: an abstract specification of the intent of the visualization; a binding of these abstract modules to a specific software system; and then a binding of software to processing and other resources. We develop an XML application capable of describing visualization at the three levels. To complement this, we have implemented an extension to a popular visualization system, IRIS Explorer, which allows modules in a dataflow pipeline to run on a set of grid resources. For computational steering applications, we have developed a library that allows a visualization system front-end to connect to a simulation running remotely on a grid resource. We demonstrate the work in two applications: the dispersion of a pollutant under different wind conditions; and the solution of a challenging numerical problem in elastohydrodynamic lubrication.
Keywords: IRIS Explorer; XML; XML; computational steering applications; data flow computing; data visualisation; data visualization; dataflow pipeline; elastohydrodynamic lubrication; grid computing; grid computing environments; natural sciences computing; pollutant dispersion;
Author: Brodlie, K.; Duce, J.; Gallop, J.; Sagar, M.; Walton, J.; Wood, J.

Year: 2004
Title: Visualizing competitive behaviors in multi-user virtual environments
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372193
Abstract:  We present a system for enhancing observation of user interactions in virtual environments. In particular, we focus on analyzing behavior patterns in the popular team-based first-person perspective game Return to Castle Wolfenstein: Enemy Territory. This game belongs to a genre characterized by two moderate-sized teams (usually 6 to 12 players each) competing over a set of objectives. Our system allows spectators to visualize global features such as large-scale behaviors and team strategies, as opposed to the limited, local view that traditional spectating modes provide. We also add overlay visualizations of semantic information related to the action that might be important to a spectator in order to reduce the information overload that plagues traditional overview visualizations. These overlays can visualize information about abstract concepts such as player distribution over time and areas of intense combat activity, and also highlight important features like player paths, fire coverage, etc. This added information allows spectators to identify important game events more easily and reveals large-scale player behaviors that might otherwise be overlooked.
Keywords: behaviour pattern analysis; computer games; computer games; data visualisation; data visualization; human computer interaction; multi-user virtual environment; user interaction; virtual reality;
Author: Hoobler, N.; Humphreys, G.; Agrawala, M.

Year: 2004
Title: Scout: a hardware-accelerated system for quantitatively driven visualization and analysis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372194
Abstract:  Quantitative techniques for visualization are critical to the successful analysis of both acquired and simulated scientific data. Many visualization techniques rely on indirect mappings, such as transfer functions, to produce the final imagery. In many situations, it is preferable and more powerful to express these mappings as mathematical expressions, or queries, that can then be directly applied to the data. We present a hardware-accelerated system that provides such capabilities and exploits current graphics hardware for portions of the computational tasks that would otherwise be executed on the CPU. In our approach, the direct programming of the graphics processor using a concise data parallel language, gives scientists the capability to efficiently explore and visualize data sets.
Keywords: data visualisation; graphics hardware; hardware-accelerated system; parallel language; parallel languages; quantitatively driven visualization; rendering (computer graphics); scientific data visualization; scientific information systems; very large databases; volume rendering;
Author: McCormick, P.S.; Inman, J.; Ahrens, J.P.; Hansen, C.; Roth, G.

Year: 2004
Title: Vorticity based flow analysis and visualization for Pelton turbine design optimization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372195
Abstract:  Vorticity is the quantity used to describe the creation, transformation and extinction of vortices. It is present not only in vortices but also in shear flow. Especially in ducted flows, most of the overall vorticity is usually contained in the boundary layer. When a vortex develops from the boundary layer, this can be described by transport of vorticity. For a better understanding of a flow it is therefore of interest to examine vorticity in all of its different roles. The goal of this application study was not primarily the visualization of vortices but of vorticity distribution and its role in vortex phenomena. The underlying industrial case is a design optimization for a Pelton turbine. An important industrial objective is to improve the quality of the water jets driving the runner. Jet quality is affected mostly by vortices originating in the distributor ring. For a better understanding of this interrelation, it is crucial to not only visualize these vortices but also to analyze the mechanisms of their creation. We used various techniques for the visualization of vorticity, including field lines and modified isosurfaces. For field line based visualization, we extended the image-guided streamline placement algorithm of Turk and Banks to data-guided field line placement on three-dimensional unstructured grids.
Keywords: Pelton turbine design optimization; boundary layer; computational fluid dynamics; data visualisation; feature extraction; feature extraction; field line based visualization; flow visualisation; flow visualization; hydraulic turbines; image-guided streamline placement algorithm; jets; mechanical engineering computing; vortices; vorticity based flow analysis; water jets;
Author: Sadlo, F.; Peikert, R.; Parkinson, E.

Year: 2004
Title: Visualization of intricate flow structures for vortex breakdown analysis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372196
Abstract:  Vortex breakdowns and flow recirculation are essential phenomena in aeronautics where they appear as a limiting factor in the design of modern aircrafts. Because of the inherent intricacy of these features, standard flow visualization techniques typically yield cluttered depictions. The paper addresses the challenges raised by the visual exploration and validation of two CFD simulations involving vortex breakdown. To permit accurate and insightful visualization we propose a new approach that unfolds the geometry of the breakdown region by letting a plane travel through the structure along a curve. We track the continuous evolution of the associated projected vector field using the theoretical framework of parametric topology. To improve the understanding of the spatial relationship between the resulting curves and lines we use direct volume rendering and multidimensional transfer functions for the display of flow-derived scalar quantities. This enriches the visualization and provides an intuitive context for the extracted topological information. Our results offer clear, synthetic depictions that permit new insight into the structural properties of vortex breakdowns.
Keywords: CFD simulation; aeronautics; aerospace computing; computational fluid dynamics; computational fluid dynamics; computational geometry; curve fitting; curve fitting; data visualisation; flow simulation; flow visualisation; flow visualization; geometry; intricate flow structures; multidimensional transfer function; rendering (computer graphics); topology; volume rendering; vortex breakdown analysis; vortices;
Author: Tricoche, X.; Garth, C.; Kindlmann, G.; Deines, E.; Scheuermann, G.; Ruetten, M.; Hansen, C.

Year: 2004
Title: A graphics hardware-based vortex detection and visualization system
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372197
Abstract:  Feature detection in flow fields is a well-researched area, but practical application is often difficult due to the numerical complexity of the algorithms preventing interactive use and due to noise in experimental or high-resolution simulation data sets. We present an integrated system that provides interactive denoising, vortex detection, and visualisation of vector data on Cartesian grids. All three major phases are implemented in such a way that the system runs completely on a modern GPU once the vector field is downloaded into graphics memory. The application aspect of our paper is twofold. First, we show how recently presented, prototypical GPU-based algorithms for filtering, numerical computation, and volume rendering can be combined into one productive system by handling all idiosyncrasies of a chosen graphics card. Second, we demonstrate that the significant speedup achieved compared to an optimized software implementation now allows interactive exploration of characteristic structures in turbulent flow fields.
Keywords: 3D vector field visualization; Cartesian grids; computational fluid dynamics; data visualisation; feature detection; feature extraction; flow simulation; flow visualisation; flow visualization system; graphics hardware-based vortex detection; image denoising; interactive denoising; interactive systems; numerical flow simulation; rendering (computer graphics); turbulence; turbulent flow fields; volume rendering; vortices;
Author: Stegmaier, S.; Ertl, T.

Year: 2004
Title: Radial hermite operators for scattered point cloud data with normal vectors and applications to implicitizing polygon mesh surfaces for generalized CSG operations and smoothing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372198
Abstract:  We describe a new technique for fitting scattered point cloud data. Given a scattered point cloud of 3D data points and associated normal vectors, our new method produces an implicit volume model whose zero level isosurface interpolates the given points and associated normal vectors. We concentrate on certain application of these new volume modeling techniques. We take existing polygon mesh surfaces and use the present methods to construct implicit volume models for these surfaces. Implicit models allow for the application of Boolean operations on these surfaces through the techniques of constructive solid geometry. Also, standard wavelet and filter operators can be applied to the implicit volume model leading to effective smoothing and filtering algorithms, which are simple to implement.
Keywords: Boolean operation; filtering algorithm; interpolation; isosurface generation; mesh generation; normal vectors; polygon mesh surfaces; radial hermite operator; scattered point cloud data; smoothing algorithm; solid geometry; solid modelling; surface fitting; surface reconstruction; surface reconstruction; vectors; volume modeling;
Author: Nielson, G.M.

Year: 2004
Title: Compatible triangulations of spatial decompositions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372199
Abstract:  We describe a general algorithm to produce compatible 3D triangulations from spatial decompositions. Such triangulations match edges and faces across spatial cell boundaries, solving several problems in graphics and visualization including the crack problem found in adaptive isosurface generation, triangulation of arbitrary grids (including unstructured grids), clipping, and the interval tetrahedrization problem. The algorithm produces compatible triangulations on a cell-by-cell basis, using a modified Delaunay triangulation with a simple point ordering rule to resolve degenerate cases and produce unique triangulations across cell boundaries. The algorithm is naturally parallel since it requires no neighborhood cell information, only a unique, global point numbering. We show application of this algorithm to adaptive contour generation; tetrahedrization of unstructured meshes; clipping and interval volume mesh generation.
Keywords: Delaunay triangulation; adaptive contour generation; adaptive grids; adaptive isosurface generation; data visualisation; interval tetrahedrization; mesh generation; octrees; rendering (computer graphics); solid modelling; spatial decomposition; volume mesh generation;
Author: Schroeder, W.J.; Geveci, B.; Malaterre, M.

Year: 2004
Title: Adaptive 4-8 texture hierarchies
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372200
Abstract:  We address the texture level-of-detail problem for extremely large surfaces such as terrain during realtime, view-dependent rendering. A novel texture hierarchy is introduced based on 4-8 refinements of raster tiles, in which the texture grids in effect rotate 45 degrees for each level of refinement. This hierarchy provides twice as many levels of detail as conventional quadtree-style refinement schemes such as mipmaps, and thus provides per-pixel view-dependent filtering that is twice as close to the ideal cutoff frequency for an average pixel. Because of this more gradual change in low-pass filtering, and due to the more precise emulation of the ideal cutoff frequency, we find in practice that the transitions between texture levels of detail are not perceptible. This allows rendering systems to avoid the complexity and performance costs of per-pixel blending between texture levels of detail. The 4-8 texturing scheme is integrated into a variant of the real-time optimally adapting meshes (ROAM) algorithm for view-dependent multiresolution mesh generation. Improvements to ROAM included here are: the diamond data structure as a streamlined replacement for the triangle bintree elements, the use of low-pass-filtered geometry patches in place of individual triangles, integration of 4-8 textures, and a simple out-of-core data access mechanism for texture and geometry tiles.
Keywords: 4-8 texturing hierarchies; data structure; data visualisation; image texture; large data set visualization; level-of-detail technique; low-pass filtering; mesh generation; out-of-core algorithms; quadtree-style refinement; quadtrees; real-time optimally adapting meshes; real-time systems; rendering (computer graphics); view-dependent multiresolution mesh generation;
Author: Hwa, L.M.; Duchaineau, M.A.; Joy, K.I.

Year: 2004
Title: Immersive design of DMA molecules with a tangible interface
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372201
Abstract:  This work presents an experimental immersive interface for designing DNA components for application in nanotechnology. While much research has been done on immersive visualization, this is one of the first systems to apply advanced interface techniques to a scientific design problem. This system uses tangible 3D input devices (tongs, a raygun, and a multipurpose handle tool) to create and edit a purely digital representation of DNA. The tangible controllers are associated with functions (not data) while a virtual display is used to render the model. This interface was built in collaboration with a research group investigating the design of DNA tiles. A user study shows that scientists find the immersive interface more satisfying than a 2D interface due to the enhanced understanding gained by directly interacting with molecules in 3D space.
Keywords: DNA; DNA molecules; augmented reality; augmented reality; data visualisation; immersive interface design; molecular biophysics; molecular modeling; molecular visualization; nanotechnology; rendering (computer graphics); spatial construction; tangible user interface; user interfaces; virtual reality;
Author: Schkolne, S.; Ishii, H.; Schroder, P.

Year: 2004
Title: Augmented reality with tangible auto-fabricated models for molecular biology applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372202
Abstract:  The evolving technology of computer auto-fabrication ("3D printing") now makes it possible to produce physical models for complex biological molecules and assemblies. We report on an application that demonstrates the use of auto-fabricated tangible models and augmented reality for research and education in molecular biology, and for enhancing the scientific environment for collaboration and exploration. We have adapted an augmented reality system to allow virtual 3D representations (generated by the Python Molecular Viewer) to be overlaid onto a tangible molecular model. Users can easily change the overlaid information, switching between different representations of the molecule, displays of molecular properties such as electrostatics, or dynamic information. The physical model provides a powerful, intuitive interface for manipulating the computer models, streamlining the interface between human intent, the physical model, and the computational activity.
Keywords: augmented reality; augmented reality; auto-fabricated tangible model; biology computing; data visualisation; genetics; molecular biology; molecular biophysics; molecular visualization; physical model; user interfaces; virtual 3D representation;
Author: Gillet, A.; Sanner, M.; Stoffler, D.; Goodsell, D.; Olson, A.

Year: 2004
Title: TexMol: interactive visual exploration of large flexible multi-component molecular complexes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372203
Abstract:  While molecular visualization software has advanced over the years, today, most tools still operate on individual molecular structures with limited facility to manipulate large multicomponent complexes. We approach this problem by extending 3D image-based rendering via programmable graphics units, resulting in an order of magnitude speedup over traditional triangle-based rendering. By incorporating a biochemically sensitive level-of-detail hierarchy into our molecular representation, we communicate appropriate volume occupancy and shape while dramatically reducing the visual clutter that normally inhibits higher-level spatial comprehension. Our hierarchical, image based rendering also allows dynamically computed physical properties data (e.g. electrostatics potential) to be mapped onto the molecular surface, tying molecular structure to molecular function. Finally, we present another approach to interactive molecular exploration using volumetric and structural rendering in tandem to discover molecular properties that neither rendering mode alone could reveal. These visualization techniques are realized in a high-performance, interactive molecular exploration tool we call TexMol, short for Texture Molecular viewer.
Keywords: 3D image-based rendering; Texture Molecular viewer; biology computing; computer graphics; data visualisation; image texture; imposter rendering; interactive molecular exploration; interactive systems; level-of-detail hierarchy; molecular biophysics; molecular visualization; multicomponent molecular complexes; programmable graphics hardware; rendering (computer graphics); volume rendering;
Author: Chandrajit Bajaj; Djeu, P.; Vinay Siddavanahalli; Thane, A.

Year: 2004
Title: Rough interface reconstruction using the level set method
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372204
Abstract:  We present a new level set method for reconstructing interfaces from point aggregations. Although level-set-based methods are advantageous because they can handle complicated topologies and noisy data, most tend to smooth the inherent roughness of the original data. Our objective is to enhance the quality of a reconstructed surface by preserving certain roughness-related characteristics of the original dataset. Our formulation employs the total variation of the surface as a roughness measure. The algorithm consists of two steps: a roughness-capturing flow and a roughness-preserving flow. The roughness capturing step attempts to construct a surface for which the original roughness is captured - distance flow is well suited for roughness capturing. Surface reconstruction is enhanced by using a total variation preserving (TVP) scheme for the roughness-preserving flow. The shock filter formulation of Osher and Rudin is exploited to achieve this goal. In practice, we have found that better results arc obtained by balancing the TVP term with a smoothing term based on curvature. The algorithm is applied to both fractal surface growth simulations and scanned data sets to demonstrate the efficacy of our approach.
Keywords: aggregation; interface roughness; level set method; mesh generation; point sampled data; rough interface reconstruction; shock filter formulation; surface fitting; surface reconstruction; surface reconstruction; total variation preserving;
Author: Kim, Y.; Raghu Machiraju; Thompson, D.

Year: 2004
Title: Surface reconstruction of noisy and defective data sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372205
Abstract:  We present a novel surface reconstruction algorithm that can recover high-quality surfaces from noisy and defective data sets without any normal or orientation information. A set of new techniques is introduced to afford extra noise tolerability, robust orientation alignment, reliable outlier removal, and satisfactory feature recovery. In our algorithm, sample points are first organized by an octree. The points are then clustered into a set of monolithically singly-oriented groups. The inside/outside orientation of each group is determined through a robust voting algorithm. We locally fit an implicit quadric surface in each octree cell. The locally fitted implicit surfaces are then blended to produce a signed distance field using the modified Shepard's method. We develop sophisticated iterative fitting algorithms to afford improved noise tolerance both in topology recognition and geometry accuracy. Furthermore, this iterative fitting algorithm, coupled with a local model selection scheme, provides a reliable sharp feature recovery mechanism even in the presence of bad input.
Keywords: computer graphics; computer graphics; defective data sets; feature extraction; feature recovery mechanism; image reconstruction; iterative fitting algorithm; iterative methods; modified Shepard method; noise tolerance; octrees; robust voting algorithm; surface fitting; surface reconstruction; surface reconstruction; topology recognition;
Author: Xie, H.; McDonnell, K.T.; Qin, H.

Year: 2004
Title: Optimal global conformal surface parameterization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372206
Abstract:  All orientable metric surfaces are Riemann surfaces and admit global conformal parameterizations. Riemann surface structure is a fundamental structure and governs many natural physical phenomena, such as heat diffusion and electro-magnetic fields on the surface. A good parameterization is crucial for simulation and visualization. This paper provides an explicit method for finding optimal global conformal parameterizations of arbitrary surfaces. It relies on certain holomorphic differential forms and conformal mappings from differential geometry and Riemann surface theories. Algorithms are developed to modify topology, locate zero points, and determine cohomology types of differential forms. The implementation is based on a finite dimensional optimization method. The optimal parameterization is intrinsic to the geometry, preserves angular structure, and can play an important role in various applications including texture mapping, remeshing, morphing and simulation. The method is demonstrated by visualizing the Riemann surface structure of real surfaces represented as triangle meshes.
Keywords: Riemann surface theory; computational geometry; computational geometry; data visualisation; differential geometry; finite dimensional optimization; global conformal parameterization; image representation; image texture; mesh generation; mesh generation; object modeling; solid modelling; surface fitting; surface representation; texture mapping;
Author: Jin, M.; Wang, Y.; Yau, S.-T.; Gu, X.

Year: 2004
Title: Local and global comparison of continuous functions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372207
Abstract: We introduce local and global comparison measures for a collection of k &le; d real-valued smooth functions on a common d-dimensional Riemannian manifold. For k = d = 2 we relate the measures to the set of critical points of one function restricted to the level sets of the other. The definition of the measures extends to piecewise linear functions for which they are easy to compute. The computation of the measures forms the centerpiece of a software tool which we use to study scientific datasets.
Keywords: Riemannian manifold; continuous functions; data visualisation; data visualization; functions; piecewise linear functions; piecewise linear techniques; real-valued smooth functions; scientific datasets;
Author: Edelsbrunner, H.; Harer, J.; Natarajan, V.; Pascucci, V.

Year: 2004
Title: Light Collages: lighting design for effective visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372208
Abstract:  We introduce Light Collages - a lighting design system for effective visualization based on principles of human perception. Artists and illustrators enhance perception of features with lighting that is locally consistent and globally inconsistent. Inspired by these techniques, we design the placement of light sources to convey a greater sense of realism and better perception of shape with globally inconsistent lighting. Our algorithm segments the objects into local surface patches and uses a number of perceptual heuristics, such as highlights, shadows, and silhouettes, to enhance the perception of shape. We show our results on scientific and sculptured datasets.
Keywords: Light Collages; data visualisation; data visualization; human perception; image segmentation; light sources; lighting; lighting design system; object segmentation; proximity shadows; realistic images; rendering (computer graphics); scientific datasets; sculptured datasets; silhouette enhancement; surface patches; visual perception;
Author: Lee, C.H.; Xuejun Hao; Varshney, A.

Year: 2004
Title: Lighting transfer functions using gradient aligned sampling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372209
Abstract:  An important task in volume rendering is the visualization of boundaries between materials. This is typically accomplished using transfer functions that increase opacity based on a voxel's value and gradient. Lighting also plays a crucial role in illustrating surfaces. In this paper we present a multi-dimensional transfer function method for enhancing surfaces, not through the variation of opacity, but through the modification of surface shading. The technique uses a lighting transfer function that takes into account the distribution of values along a material boundary and features a novel interface for visualizing and specifying these transfer functions. With our method, the user is given a means of visualizing boundaries without modifying opacity, allowing opacity to be used for illustrating the thickness of homogeneous materials through the absorption of light.
Keywords: data visualisation; gradient aligned sampling; homogeneous materials; image colour analysis; image sampling; image texture; lighting; lighting transfer functions; multidimensional transfer functions; opacity; opacity; realistic images; rendering (computer graphics); surface enhancement; surface shading; transfer functions; volume rendering; volume visualization;
Author: Lum, E.B.; Ma, K.-L.

Year: 2004
Title: Haptic display of interaction between textured models
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372210
Abstract:  Surface texture is among the most salient haptic characteristics of objects; it can induce vibratory contact forces that lead to perception of roughness. We present a new algorithm to display haptic texture information resulting from the interaction between two textured objects. We compute contact forces and torques using low-resolution geometric representations along with texture images that encode surface details. We also introduce a novel force model based on directional penetration depth and describe an efficient implementation on programmable graphics hardware that enables interactive haptic texture rendering of complex models. Our force model takes into account important factors identified by psychophysics studies and is able to haptically display interaction due to fine surface textures that previous algorithms do not capture.
Keywords: computational geometry; computer graphic equipment; geometric representation; haptic display; haptic interfaces; haptic texture information; image resolution; image texture; interactive haptic texture rendering; interactive systems; programmable graphics hardware; psychophysics study; rendering (computer graphics); roughness perception; solid modelling; surface texture; texture images; textured model; vibratory contact forces; visual perception;
Author: Otaduy, M.A.; Jain, N.; Sud, A.; Lin, M.C.

Year: 2004
Title: On the role of color in the perception of motion in animated visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372211
Abstract:  Although luminance contrast plays a predominant role in motion perception, significant additional effects are introduced by chromatic contrasts. In this paper, relevant results from psychophysical and physiological research are described to clarify the role of color in motion detection. Interpreting these psychophysical experiments, we propose guidelines for the design of animated visualizations, and a calibration procedure that improves the reliability of visual motion representation. The guidelines are applied to examples from texture-based flow visualization, as well as graph and tree visualisation.
Keywords: animated visualization; chromatic contrast; color perception; colour vision; computer animation; data visualisation; flow visualisation; graph visualisation; human visual system; image colour analysis; image motion analysis; image representation; image texture; information visualization; luminance contrast; motion analysis; motion detection; motion perception; physiological research; psychophysical research; realistic images; texture-based flow visualization; tree visualisation; visual motion representation; visual perception;
Author: Weiskopf, D.

Year: 2004
Title: Topological lines in 3D tensor fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372212
Abstract:  Visualization of 3D tensor fields continues to be a major challenge in terms of providing intuitive and uncluttered images that allow the users to better understand their data. The primary focus of this paper is on finding a formulation that lends itself to a stable numerical algorithm for extracting stable and persistent topological features from 2nd order real symmetric 3D tensors. While features in 2D tensors can be identified as either wedge or trisector points, in 3D, the corresponding stable features are lines, not just points. These topological feature lines provide a compact representation of the 3D tensor field and are essential in helping scientists and engineers understand their complex nature. Existing techniques work by finding degenerate points and are not numerically stable, and worse, produce both false positive and false negative feature points. This work seeks to address this problem with a robust algorithm that can extract these features in a numerically stable, accurate, and complete manner.
Keywords: 3D tensor field visualization; computational geometry; data visualisation; feature extraction; feature extraction; hyperstreamlines; image representation; numerical algorithm; real symmetric 3D tensor; tensors; topological feature line; uncluttered images;
Author: Zheng, X.; Pang, A.

Year: 2004
Title: Stream line and path line oriented topology for 2D time-dependent vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372213
Abstract:  Topological methods aim at the segmentation of a vector field into areas of different flow behavior. For 2D time-dependent vector fields, two such segmentations are possible: either concerning the behavior of stream lines, or of path lines. While stream line oriented topology is well established, we introduce path line oriented topology as a new visualization approach in this paper. As a contribution to stream line oriented topology we introduce new methods to detect global bifurcations like saddle connections and cyclic fold bifurcations. To get the path line oriented topology we segment the vector field into areas of attracting, repelling and saddle-like behavior of the path lines. We compare both kinds of topologies and apply them to a number of data sets.
Keywords: 2D time-dependent vector fields; computational geometry; cyclic fold bifurcation; data visualisation; flow visualisation; flow visualization; image segmentation; path line-oriented topology; saddle connection; stream line-oriented topology; topological methods; vector field segmentation; vectors;
Author: Theisel, H.; Weinkauf, T.; Hege, H.-C.; Seidel, H.-P.

Year: 2004
Title: Tracking of vector field singularities in unstructured 3D time-dependent datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372214
Abstract:  We present an approach for monitoring the positions of vector field singularities and related structural changes in time-dependent datasets. The concept of singularity index is discussed and extended from the well-understood planar case to the more intricate three-dimensional setting. Assuming a tetrahedral grid with linear interpolation in space and time, vector field singularities obey rules imposed by fundamental invariants (Poincare index), which we use as a basis for an efficient tracking algorithm. We apply the presented algorithm to CFD datasets to illustrate its purpose. We examine structures that exhibit topological variations with time and describe some of the insight gained with our method. Examples are given that show a correlation in the evolution of physical quantities that play a role in vortex breakdown.
Keywords: 3D time-dependent datasets; CFD datasets; Poincare index; aerodynamics; computational fluid dynamics; computational geometry; data visualisation; flow visualisation; flow visualization; interpolation; linear interpolation; temporal databases; tetrahedral grid; tracking; vector field singularity tracking algorithm; vectors;
Author: Garth, C.; Tricoche, X.; Scheuermann, G.

Year: 2004
Title: Topology visualization of the optical power flow through a novel C-shaped nano-aperture
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372215
Abstract:  An ideal visualization tool that has not been used before in studying the optical behavior of near-field apertures is three-dimensional vector field topology. The global view of the vector field structure is deduced by locating singularities (critical points) within the field and augmenting these points with nearby streamlines. We have used for the first time, to the best of our knowledge, three-dimensional topology to analyze the topological differences between a resonant C-shaped nano-aperture and various nonresonant conventional apertures. The topological differences between these apertures are related to the superiority in power throughput of the C-aperture versus conventional round and square sub-wavelength apertures. We demonstrate how topological visualization techniques provide significant insight into the energy enhancement mechanism of the C aperture, and also shed light on critical issues related to the interaction between multiple apertures located in close proximity to each other, which gives rise to cross-talk, for example as a function of distance. Topological techniques allow us to develop design rules for the geometry of these apertures and their desired spot sizes and brightness. The performance of various sub-wavelength apertures can also be compared quantitatively based on their topology. Since topological methods are generically applicable to tensor and vector fields, our approach can be readily extended to provide insight into the broader category of finite-difference-time-domain nano-photonics and nano-science problems.
Keywords: C-shaped nano-aperture; aperture geometry; brightness; brightness; computational electromagnetics; computational geometry; data visualisation; energy flow topology; finite difference time-domain analysis; finite-difference-time-domain nano-photonics; flow visualisation; light transmission; metallic thin films; nano-science problem; optical behavior; optical power flow; three-dimensional topology visualization tool; three-dimensional vector field topology;
Author: Sun, L.; Batra, R.K.; Xiaolei Shi; Hesselink, L.

Year: 2004
Title: Interactive exploration of large remote micro-CT scans
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372216
Abstract:  Datasets of tens of gigabytes are becoming common in computational and experimental science. This development is driven by advances in imaging technology, producing detectors with growing resolutions, as well as availability of cheap processing power and memory capacity in commodity-based computing clusters. We describe the design of a visualization system that allows scientists to interactively explore large remote data sets in an efficient and flexible way. The system is broadly applicable and currently used by medical scientists conducting an osteoporosis research project. Human vertebral bodies are scanned using a high resolution microCT scanner producing scans of roughly 8 GB size each. All participating research groups require access to the centrally stored data. Due to the rich internal bone structure, scientists need to interactively explore the full dataset at coarse levels, as well as visualize subvolumes of interest at the highest resolution. Our solution is based on HDF5 and GridFTP. When accessing data remotely, the HDF5 data processing pipeline is modified to support efficient retrieval of subvolumes. We reduce the overall latency and optimize throughput by executing high-level operations on the remote side. The GridFTP protocol is used to pass the HDF5 requests to a customized server. The approach takes full advantage of local graphics hardware for rendering. Interactive visualization is accomplished using a background thread to access the datasets stored in a multiresolution format. A hierarchical volume tenderer provides seamless integration of high resolution details with low resolution overviews.
Keywords: GridFTP protocol; computerised tomography; data processing pipeline; data visualisation; grid computing; hierarchical volume tenderer; human vertebral body; image resolution; image resolution; imaging technology; interactive visualization; medical image processing; remote microCT scans;
Author: Prohaska, S.; Hutanu, A.; Kahler, R.; Hege, H.-C.

Year: 2004
Title: Interactive terascale particle visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372217
Abstract:  This work describes the methods used to produce an interactive visualization of a 2 TB computational fluid dynamics (CFD) data set using particle tracing (streaklines). We use the method introduced by Bruckschen el al. (2001) that precomputes a large number of particles, stores them on disk using a space-filling curve ordering that minimizes seeks, then retrieves and displays the particles according to the user's command. We describe how the particle computation can be performed using a PC cluster, how the algorithm can be adapted to work with a multiblock curvilinear mesh, how scalars can be extracted and used to color the particles, and how the out-of-core visualization can be scaled to 293 billion particles while still achieving interactive performance on PC hardware. Compared to the earlier work, our data set size and total number of particles are an order of magnitude larger. We also describe a new compression technique that losslessly reduces the amount of particle storage by 41% and speeds the particle retrieval by about 20%.
Keywords: 2 TB turbopump data set; CFD; PC clusters; computational fluid dynamics; computational fluid dynamics; computational geometry; curve fitting; data visualisation; interactive terascale particle visualization; mesh generation; multiblock curvilinear mesh; out-of-core visualization; particle tracing;
Author: Ellsworth, D.; Green, B.; Moran, P.

Year: 2004
Title: Intuitive and interactive modification of large finite element models
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372218
Abstract:  Virtual prototyping is increasingly replacing real mock-ups and experiments in industrial product development. Part of this process is the simulation of structural and functional properties, which is in many cases based on finite element analysis (FEA). One prominent example from the automotive industry is the safety improvement resulting from crash worthiness simulations. A simulation model for this purpose usually consists of up to one million finite elements and is assembled from many parts, which are individually meshed out of their CAD representation. In order to accelerate the development cycle, simulation engineers want to be able to modify their FE models without going back to the CAD department. Furthermore, valid CAD models might even not be available in preliminary design stages. However, in contrast to CAD, there is a lack of tools that offer the possibility of modification and processing of finite element components while maintaining the properties relevant to the simulation. In this application paper we present interactive algorithms for intuitive and fast editing of FE models and appropriate visualization techniques to support engineers in understating these models. This includes new kinds of manipulators, feedback mechanisms and facilities for virtual reality and immersion at the workplace, e.g. autostereoscopic displays and haptic devices.
Keywords: CAD; CAD; automobile industry; automotive engineering; automotive industry; autostereoscopy; data visualisation; data visualization; engineering graphics; finite element analysis; finite element models; industrial product development; interactive modification; interactive systems; manipulators; product development; virtual prototyping; virtual prototyping; virtual reality; virtual reality;
Author: Rose, D.; Bidmon, K.; Ertl, T.

Year: 2004
Title: Visualization of salt-induced stress perturbations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372219
Abstract:  An important challenge encountered during post-processing of finite element analyses is the visualizing of three-dimensional fields of real-valued second-order tensors. Namely, as finite element meshes become more complex and detailed, evaluation and presentation of the principal stresses becomes correspondingly problematic. In this paper, we describe techniques used to visualize simulations of perturbed in-situ stress fields associated with hypothetical salt bodies in the Gulf of Mexico. We present an adaptation of the Mohr diagram, a graphical paper and pencil method used by the material mechanics community for estimating coordinate transformations for stress tensors, as a new tensor glyph for dynamically exploring tensor variables within three-dimensional finite element models. This interactive glyph can be used as either a probe or a filter through brushing and linking.
Keywords: Mohr circles; data visualisation; data visualization; finite element analysis; finite element analysis; mechanical engineering; salt-induced stress perturbation; tensors; tensors field visualization; three-dimensional fields; visual debugging;
Author: Crossno, P.; Rogers, D.H.; Brannon, R.M.; Coblentz, D.

Year: 2004
Title: 800Exploration of the brain's white matter pathways with dynamic queries
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372220
Abstract:  Diffusion tensor imaging (DTI) is a magnetic resonance imaging method that can be used to measure local information about the structure of white matter within the human brain. Combining DTI data with the computational methods of MR tractography, neuroscientists can estimate the locations and sizes of nerve bundles (white matter pathways) that course through the human brain. Neuroscientists have used visualization techniques to better understand tractography data, but they often struggle with the abundance and complexity of the pathways. We describe a novel set of interaction techniques that make it easier to explore and interpret such pathways. Specifically, our application allows neuroscientists to place and interactively manipulate box-shaped regions (or volumes of interest) to selectively display pathways that pass through specific anatomical areas. A simple and flexible query language allows for arbitrary combinations of these queries using Boolean logic operators. Queries can be further restricted by numerical path properties such as length, mean fractional anisotropy, and mean curvature. By precomputing the pathways and their statistical properties, we obtain the speed necessary for interactive question-and-answer sessions with brain researchers. We survey some questions that researchers have been asking about tractography data and show how our system can be used to answer these questions efficiently.
Keywords: Boolean logic operator; MR tractography; biomedical MRI; brain; data visualisation; data visualization; diffusion tensor imaging; human brain; human computer interaction; interactive question-and-answer session; interactive systems; magnetic resonance imaging; medical computing; query language; query processing;
Author: Akers, D.; Sherbondy, A.; Mackenzie, R.; Dougherty, R.; Wandell, B.

Year: 2004
Title: The VesselGlyph: focus & context visualization in CT-angiography
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372221
Abstract:  Accurate and reliable visualization of blood vessels is still a challenging problem, notably in the presence of morphologic changes resulting from atherosclerotic diseases. We take advantage of partially segmented data with approximately identified vessel centerlines to comprehensively visualize the diseased peripheral arterial tree. We introduce the VesselGlyph as an abstract notation for novel focus & context visualization techniques of tubular structures such as contrast-medium enhanced arteries in CT-angiography (CTA). The proposed techniques combine direct volume rendering (DVR) and curved planar reformation (CPR) within a single image. The VesselGlyph consists of several regions where different rendering methods are used. The region type, the used visualization method and the region parameters depend on the distance from the vessel centerline and on viewing parameters as well. By selecting proper rendering techniques for different regions, vessels are depicted in a naturally looking and undistorted anatomic context. This may facilitate the diagnosis and treatment planning of patients with peripheral arterial occlusive disease. In this paper we furthermore present a way of how to implement the proposed techniques in software and by means of modern 3D graphics accelerators.
Keywords: 3D graphics accelerators; CT-angiography; atherosclerotic diseases; biomedical MRI; blood vessels; blood vessels; computerised tomography; context visualization; curved planar reformation; data visualisation; direct volume rendering; diseases; patient diagnosis; patient treatment; peripheral arterial occlusive disease; rendering (computer graphics); solid modelling;
Author: Straka, M.; Cervenansky, M.; La Cruz, A.; Kochl, A.; Sramek, M.; Groller, E.; Fleischmann, D.

Year: 2004
Title: Non-linear model fitting to parameterize diseased blood vessels
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372222
Abstract:  Accurate estimation of vessel parameters is a prerequisite for automated visualization and analysis of healthy and diseased blood vessels. The objective of this research is to estimate the dimensions of lower extremity arteries, imaged by computed tomography (CT). These parameters are required to get a good quality visualization of healthy as well as diseased arteries using a visualization technique such as curved planar reformation (CPR). The vessel is modeled using an elliptical or cylindrical structure with specific dimensions, orientation and blood vessel mean density. The model separates two homogeneous regions: its inner side represents a region of density for vessels, and its outer side a region for background. Taking into account the point spread function (PSF) of a CT scanner, a function is modeled with a Gaussian kernel, in order to smooth the vessel boundary in the model. A new strategy for vessel parameter estimation is presented. It stems from vessel model and model parameter optimization by a nonlinear optimization procedure, i.e., the Levenberg-Marquardt technique. The method provides center location, diameter and orientation of the vessel as well as blood and background mean density values. The method is tested on synthetic data and real patient data with encouraging results.
Keywords: Gaussian kernel; Levenberg-Marquardt technique; blood vessels; computed tomography; computerised tomography; curved planar reformation; data visualisation; data visualization; diseased blood vessel detection; diseases; feature extraction; image segmentation; image segmentation; medical image processing; nonlinear optimization; point spread function;
Author: La Cruz, A.; Straka, M.; Kochl, A.; Sramek, M.; Groller, E.; Fleischmann, D.

Year: 2004
Title: Visualizing cortical waves and timing from data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372223
Abstract:  Waves are a fundamental mechanism for conveying information in many physical problems. Direct visualization techniques are often used to display wave fronts. However, the information derived from such visualizations may not be as central to an investigation as an understanding of how the location, structure and time course of the wave change as key experimental parameters are varied. In experimental data, these questions are confounded by noise and incomplete data. Recognition of waves in networks of neurons is additionally complicated by the presence of long-range physical connections and recurrent excitation. This work applies visual techniques to analyze the structural details of waves in response data from the turtle visual cortex. We emphasize low-cost visualizations that allow comparisons across neural data sets and variables to reconstruct the choreography for a complex response.
Keywords: cortical waves; data visualisation; direct visualization; flow visualisation; flow visualization; medical signal processing; neural nets; neural networks; neurophysiology; rendering (computer graphics); turtle visual cortex; visual techniques; wave fronts;
Author: Robbins, K.A.; Robinson, M.; Senseman, D.M.

Year: 2004
Title: Rendering planar cuts through quadratic and cubic finite elements
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372224
Abstract:  Coloring higher order scientific data is problematic using standard linear methods as found in OpenGL. The visual results are inaccurate when there is a large scalar gradient over an element or when the scalar field is nonlinear. In addition to shading nonlinear data, last and accurate rendering of planar cuts through parametric elements can be implemented using programmable shaders on current graphics hardware. The intersection of a planar cut with geometrically curved volume elements can be rendered using a combination of selective refinement and programmable shaders. This hybrid algorithm also handles curved 2D planar triangles.
Keywords: computational geometry; cubic finite elements; curved 2D planar triangles; cut planes; finite element analysis; graphics hardware; higher order elements; planar cuts rendering; programmable shaders; quadratic finite elements; rendering (computer graphics);
Author: Brasher, M.; Haimes, R.

Year: 2004
Title: LoD volume rendering of FEA data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372225
Abstract:  A new multiple resolution volume rendering method for finite element analysis (FEA) data is presented. Our method is composed of three stages: in the first stage, the Gauss points of the FEA cells are calculated. The function values, gradients, diffusions, and influence scopes of the Gauss points are computed. By representing the Gauss points as graph vertices and connecting adjacent Gauss points with edges, an adjacency graph is created. The adjacency graph is used to represent the FEA data in the subsequent computation. In the second stage, a hierarchical structure is established upon the adjacency graph. Any two neighboring vertices with similar function values are merged into a new vertex. The similarity is measured by using a user-defined threshold. Consequently, a new adjacency graph is constructed. Then the threshold is increased, and the graph reduction is triggered again to generate another adjacency graph. By repeating the processing, multiple adjacency graphs are computed, and a level of detail (LoD) representation of the FEA data is established. In the third stage, the LoD structure is rendered by using a splatting method. At first, a level of adjacency graph is selected by users. The graph vertices arc sorted based on their visibility orders and projected onto the image plane in back-to-front order. Billboards are used to render the vertices in the projection. The function values, gradients, and influence scopes of the vertices are utilized to decide the colors, opacities, orientations, and shapes of the billboards. The billboards are then modulated with texture maps to generate the footprints of the vertices. Finally, these footprints are composited to produce the volume rendering image.
Keywords: Gauss points; adjacency graph; billboards; computational geometry; data visualisation; finite element analysis; finite element analysis; graph theory; level of detail volume rendering method; multiple resolution volume rendering method; rendering (computer graphics); scientific visualization; splatting method; texture maps; unstructured data;
Author: Shyh-Kuang Ueng; Yan-Jen Su; Chi-Tang Chang

Year: 2004
Title: Pixel-exact rendering of spacetime finite element solutions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372226
Abstract:  Computational simulation of time-varying physical processes is of fundamental importance for many scientific and engineering applications. Most frequently, time-varying simulations are performed over multiple spatial grids at discrete points in time. We investigate a new approach to time-varying simulation: spacetime discontinuous Galerkin finite element methods. The result of this simulation method is a simplicial tessellation of spacetime with per-element polynomial solutions for physical quantities such as strain, stress, and velocity. To provide accurate visualizations of the resulting solutions, we have developed a method for per-pixel evaluation of solution data on the GPU. We demonstrate the importance of per-pixel rendering versus simple linear interpolation for producing high quality visualizations. We also show that our system can accommodate reasonably large datasets - spacetime meshes containing up to 20 million tetrahedra are not uncommon in this domain.
Keywords: Galerkin method; data visualisation; digital simulation; discontinuous Galerkin method; finite element analysis; linear interpolation; pixel shaders; pixel-exact rendering; pixel-exact visualization; rendering (computer graphics); spacetime finite element methods; time-varying simulation;
Author: Yuan Zhou; Garland, M.; Haber, R.

Year: 2004
Title: TetSplat: real-time rendering and volume clipping of large unstructured tetrahedral meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372227
Abstract:  We present a novel approach to interactive visualization and exploration of large unstructured tetrahedral meshes. These massive 3D meshes are used in mission-critical CFD and structural mechanics simulations, and typically sample multiple field values on several millions of unstructured grid points. Our method relies on the preprocessing of the tetrahedral mesh to partition it into nonconvex boundaries and internal fragments that are subsequently encoded into compressed multiresolution data representations. These compact hierarchical data structures are then adaptively rendered and probed in real-time on a commodity PC. Our point-based rendering algorithm, which is inspired by QSplat, employs a simple but highly efficient splatting technique that guarantees interactive frame-rates regardless of the size of the input mesh and the available rendering hardware. It furthermore allows for real-time probing of the volumetric data-set through constructive solid geometry operations as well as interactive editing of color transfer functions for an arbitrary number of field values. Thus, the presented visualization technique allows end-users for the first time to interactively render and explore very large unstructured tetrahedral meshes on relatively inexpensive hardware.
Keywords: computational fluid dynamics; computational geometry; constructive solid geometry; data visualisation; hierarchical data structures; interactive visualization; mesh generation; mission-critical CFD; real-time rendering; real-time systems; rendering (computer graphics); splatting technique; structural mechanics simulation; unstructured tetrahedral mesh;
Author: Museth, K.; Lombeyda, S.

Year: 2004
Title: Efficient point-based isosurface exploration using the span-triangle
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372228
Abstract:  We introduce a novel span-triangle data structure, based on the span-space representation for isosurfaces. It stores all necessary cell information for dynamic manipulation of the isovalue in an efficient way. We have found that using our data structure in combination with point-based techniques, implemented on graphics hardware, effects in real-time rendering and exploration. Our extraction algorithm utilizes an incremental and progressive update scheme, enabling smooth interaction without significant latency. Moreover, the corresponding visualization pipeline is capable of processing large data sets by utilizing all three levels of memory: disk, system and graphics. We address practical usability in actual medical applications, achieving a new level of interactivity.
Keywords: data structures; data visualisation; hardware acceleration; isosurface exploration; medical applications; medical computing; point-based visualization; real-time rendering; rendering (computer graphics); span-triangle data structure; surface fitting;
Author: von Rymon-Lipinski, B.; Hanssen, N.; Jansen, T.; Ritter, L.; Keeve, E.

Year: 2004
Title: Volume refinement fairing isosurfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372229
Abstract:  We propose an interpolating refinement method for two- and three-dimensional scalar fields defined on hexahedral grids. Iterative fairing of the underlying contours (isosurfaces) provides the function values of new grid points. Our method can be considered as a nonlinear variational subdivision scheme for volumes. It can be applied locally for adaptive mesh refinement in regions of high geometric complexity. We use our scheme to increase the quality of low-resolution data sets and to reduce interpolation artifacts in texture-based volume rendering.
Keywords: adaptive mesh refinement; computational geometry; geometric complexity; hexahedral grids; image texture; interpolation; interpolation artifacts; isosurfaces; mesh generation; nonlinear variational subdivision scheme; rendering (computer graphics); surface fitting; texture-based volume rendering; variational modeling; variational techniques;
Author: Bertram, M.

Year: 2004
Title: Interactive point-based isosurface extraction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372230
Abstract:  We propose a novel point-based approach to view dependent isosurface extraction. We introduce a fast visibility query system for the view dependent traversal, which exhibits moderate memory requirements. This technique allows for an interactive interrogation of the full visible woman dataset (1GB) at four to fifteen frames per second on a desktop computer. The point-based approach is built on an extraction scheme that classifies different sections of the isosurface into four categories, depending on the size of the geometry when projected onto the screen. In particular, we use points to represent small and subpixel triangles, as well as larger sections of the isosurface whose projection has subpixel size. To assign consistent and robust normals to individual points representing such regions, we propose to compute them during post processing of the extracted isosurface and provide the corresponding hardware implementation.
Keywords: data visualisation; feature extraction; interactive point-based isosurface extraction; query processing; surface fitting; view dependent traversal; visibility query system;
Author: Livnat, Y.; Tricoche, X.

Year: 2004
Title: Detection and visualization of anomalous structures in molecular dynamics simulation data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372231
Abstract:  We explore techniques to detect and visualize features in data from molecular dynamics (MD) simulations. Although the techniques proposed are general, we focus on silicon (Si) atomic systems. The first set of methods use 3D location of atoms. Defects are detected and categorized using local operators and statistical modeling. Our second set of exploratory techniques employ electron density data. This data is visualized to glean the defects. We describe techniques to automatically detect the salient isovalues for isosurface extraction and designing transfer functions. We compare and contrast the results obtained from both sources of data. Essentially, we find that the methods of defect (feature) detection are at least as robust as those based on the exploration of electron density for Si systems.
Keywords: Si; crystal defects; crystal structure; data mining; data mining; data visualisation; defect dynamics; electron density; elemental semiconductors; feature detection; feature extraction; feature extraction; isosurface; molecular dynamics method; molecular dynamics simulation; physics computing; rendering (computer graphics); scientific data visualization; silicon; silicon atomic system; statistical modeling; transfer functions; transfer functions;
Author: Mehta, S.; Hazzard, K.; Machiraju, R.; Parthasarathy, S.; Wilkins, J.

Year: 2004
Title: PQuad: visualization of predicted peptides and proteins
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372232
Abstract:  New high-throughput proteomic techniques generate data faster than biologists can analyze it. Hidden within this massive and complex data are answers to basic questions about how cells function. The data afford an opportunity to take a global or systems approach studying whole proteomes comprising all the proteins in an organism. However, the tremendous size and complexity of the high-throughput data make it difficult to process and interpret. Existing tools for studying a few proteins at a time are not suitable for global analysis. Visualization provides powerful analysis capabilities for enormous, complex data at multiple resolutions. We developed a novel interactive visualization tool, PQuad, for the visual analysis of proteins and peptides identified from high-throughput data on biological samples. PQuad depicts the peptides in the context of their source protein and DNA, thereby integrating proteomic and genomic information. A wrapped line metaphor is applied across key resolutions of the data, from a compressed view of an entire chromosome to the actual nucleotide sequence. PQuad provides a difference visualization for comparing peptides from samples prepared under different experimental conditions. We describe the requirements for such a visual analysis tool, the design decisions, and the novel aspects of PQuad.
Keywords: DNA; DNA; cellular biophysics; data visualisation; genetics; genomic information; interactive visualization tool; peptides; proteins; proteins; proteomic technique; visual analysis; wrapped line metaphor;
Author: Havre, S.L.; Singhal, M.; Payne, D.A.; Webb-Robertson, B.-J.M.

Year: 2004
Title: Guaranteed quality triangulation of molecular skin surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372233
Abstract: We present an efficient algorithm to mesh the macromolecules surface model represented by the skin surface defined by Edelsbrunner. Our algorithm overcomes several challenges residing in current surface meshing methods. First, we guarantee the mesh quality with a provable lower bound of 21&deg; on its minimum angle. Second, we ensure the triangulation is homeomorphic to the original surface. Third, we improve the efficiency of constructing the restricted Delaunay triangulation (RDT) of smooth surfaces. We achieve this by constructing the RDT using the advancing front method without computing the Delaunay tetrahedrization of the sample points on the surfaces. The difficulty of handling the front collision problem is tackled by employing the Morse theory. In particular, we construct the Morse-Smale complex to simplify the topological changes of the front. Our implementation results suggest that the algorithm decrease the time of generating high quality homeomorphic skin mesh from hours to a few minutes.
Keywords: DNA; Morse-Smale complex; data visualisation; guaranteed quality triangulation; homeomorphism; macromolecules surface model; mesh generation; molecular skin surface; restricted Delaunay triangulation; skin; smooth surfaces; surface fitting; surface meshing;
Author: Ho-Lun Cheng; Xinwei Shi

Year: 2004
Title: Dual marching cubes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372234
Abstract:  We present the definition and computational algorithms for a new class of surfaces which are dual to the isosurface produced by the widely used marching cubes (MC) algorithm. These new isosurfaces have the same separating properties as the MC surfaces but they are comprised of quad patches that tend to eliminate the common negative aspect of poorly shaped triangles of the MC isosurfaces. Based upon the concept of this new dual operator, we describe a simple, but rather effective iterative scheme for producing smooth separating surfaces for binary, enumerated volumes which are often produced by segmentation algorithms. Both the dual surface algorithm and the iterative smoothing scheme are easily implemented.
Keywords: computational algorithms; computational geometry; dual graph; dual marching cubes; dual surface algorithm; graph theory; image segmentation; iterative smoothing scheme; mesh generation; segmentation algorithms; solid modelling; surface fitting; triangular mesh;
Author: Nielson, G.M.

Year: 2004
Title: Simplifying flexible isosurfaces using local geometric measures
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372235
Abstract:  The contour tree, an abstraction of a scalar field that encodes the nesting relationships of isosurfaces, can be used to accelerate isosurface extraction, to identify important isovalues for volume-rendering transfer functions, and to guide exploratory visualization through a flexible isosurface interface. Many real-world data sets produce unmanageably large contour trees which require meaningful simplification. We define local geometric measures for individual contours, such as surface area and contained volume, and provide an algorithm to compute these measures in a contour tree. We then use these geometric measures to simplify the contour trees, suppressing minor topological features of the data. We combine this with a flexible isosurface interface to allow users to explore individual contours of a dataset interactively.
Keywords: computational geometry; contour tree; data visualisation; feature extraction; graphical user interfaces; image segmentation; isosurface extraction; isosurface interface; local geometric measures; real-world data sets; rendering (computer graphics); surface fitting; topological feature suppression; trees (mathematics); visual databases; volume-rendering transfer functions;
Author: Carr, H.; Snoeyink, J.; van de Panne, M.

Year: 2004
Title: Dual contouring with topology-preserving simplification using enhanced cell representation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372236
Abstract:  We present a fast, topology-preserving approach for isosurface simplification. The underlying concept behind our approach is to preserve the disconnected surface components in cells during isosurface simplification. We represent isosurface components in a novel representation, called enhanced cell, where each surface component in a cell is represented by a vertex and its connectivity information. A topology-preserving vertex clustering algorithm is applied to build a vertex octree. An enhanced dual contouring algorithm is applied to extract error-bounded multiresolution isosurfaces from the vertex octree while preserving the finest resolution isosurface topology. Cells containing multiple vertices are properly handled during contouring. Our approach demonstrates better results than existing octree-based simplification techniques.
Keywords: computational geometry; data visualisation; dual contouring; edge detection; enhanced cell representation; error-bounded multiresolution isosurfaces; feature extraction; image representation; image resolution; isosurface extraction; isosurface simplification; octrees; pattern clustering; surface fitting; topology-preserving simplification; vertex clustering algorithm; vertex octree;
Author: Nan Zhang; Wei Hong; Kaufman, A.

Year: 2004
Title: STEPS - an application for simulation of transsphenoidal endonasal pituitary surgery
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372237
Abstract:  Endonasal transsphenoidal pituitary surgery is a minimally invasive endoscopic procedure, applied to remove various kinds of pituitary tumors. To reduce the risk associated with this treatment, the surgeon must be skilled and well-prepared. Virtual endoscopy can be beneficial as a tool for training, preoperative planning and intraoperative support. This work introduces STEPS, a virtual endoscopy system designed to aid surgeons in getting acquainted with the endoscopic view, the handling of instruments, the transsphenoidal approach and challenges associated with the procedure. STEPS also assists experienced surgeons in planning a real endoscopic intervention by getting familiar with the individual patient anatomy, identifying landmarks, planning the approach and deciding upon the ideal target position of the actual surgical activity. Besides interactive visualization using two different first-hit ray casting techniques, the application provides navigation and perception aids and the possibility to simulate the procedure, including haptic feedback and simulation of surgical instruments.
Keywords: STEPS; digital simulation; endonasal transsphenoidal pituitary surgery; endoscopes; first-hit ray casting techniques; haptic feedback; haptic interfaces; image segmentation; interactive visualization; medical image processing; minimally invasive endoscopic procedure; pituitary tumors; ray tracing; surgery; surgical instrument simulation; tumours; virtual endoscopy; virtual reality;
Author: Neubauer, A.; Mroz, L.; Wolfsberger, S.; Wegenkittl, R.; Forster, M.-T.; Buhler, K.

Year: 2004
Title: Interactive thickness visualization of articular cartilage
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372238
Abstract:  This work describes a method to visualize the thickness of curved thin objects. Given the MRI volume data of articular cartilage, medical doctors investigate pathological changes of the thickness. Since the tissue is very thin, it is impossible to reliably map the thickness information by direct volume rendering. Our idea is based on unfolding of such structures preserving their thickness. This allows to perform anisotropic geometrical operations (e.g., scaling the thickness). However, flattening of a curved structure implies a distortion of its surface. The distortion problem is alleviated through a focus-and-context minimization approach. Distortion is smallest close to a focal point which can be interactively selected by the user.
Keywords: MRI volume data; anisotropic geometrical operations; articular cartilage; biomedical MRI; bone; computational geometry; data visualisation; direct volume rendering; distortion problem; graphical user interfaces; interactive thickness visualization; medicine visualization; rendering (computer graphics);
Author: Mlejnek, M.; Vilanova, A.; Groller, M.E.

Year: 2004
Title: ImageSurfer: a tool for visualizing correlations between two volume scalar fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372239
Abstract:  ImageSurfer is a tool designed to explore correlations between two 3D scalar fields. Our scientific goal was to determine where a protein is located, and how much its concentration varies along the membrane of a neuronal dendrite. The 3D scalar field data sets fall into two categories: dendritic plasma membranes (defining the structure) and immunofluorescent staining (defining protein concentration along the structure). ImageSurfer enables scientists to analyze relationships between multiple data sets obtained with confocal microscopy by providing 3D surface view, height field, and graphing tools. Each tool reduces the complexity of the problem by extracting a restricted subset of data: finding a region of interest in 3D; getting a sense of relative concentrations in 2D, and getting exact concentration values in 1D. The current design is presented, along with the rationale for each design decision. The tool is already proving useful for data exploration, analysis, and presentation.
Keywords: 3D scalar fields; ImageSurfer; confocal microscopy; correlation visualization; data exploration; data visualisation; dendrites; dendritic plasma membranes; feature extraction; graphical user interfaces; image segmentation; immunofluorescent staining; microscopy; neuronal dendrite; neurophysiology; protein; proteins; rendering (computer graphics); scientific visualization; visual databases;
Author: Jen, D.; Parente, P.; Robbins, J.; Weigle, C.; Taylor, R.M., II; Burette, A.; Weinberg, R.

Year: 2004
Title: Interactive design of multi-perspective images for visualizing urban landscapes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372240
Abstract:  Multiperspective images are a useful way to visualize extended, roughly planar scenes such as landscapes or city blocks. However, constructing effective multiperspective images is something of an art. We describe an interactive system for creating multiperspective images composed of serially blended cross-slits images. Beginning with a sideways-looking video of the scene as might be captured from a moving vehicle, we allow the user to interactively specify a set of cross-slits cameras, possibly with gaps between them. In each camera, one of the slits is defined to be the camera path, which is typically horizontal, and the user is left to choose the second slit, which is typically vertical. The system then generates intermediate views between these cameras using a novel interpolation scheme, thereby producing a multiperspective image with no seams. The user can also choose the picture surface in space onto which viewing rays are projected, thereby establishing a parameterization for the image. We show how the choice of this surface can be used to create interesting visual effects. We demonstrate our system by constructing multiperspective images that summarize city blocks, including corners, blocks with deep plazas and other challenging urban situations.
Keywords: cameras; city block; cross-slits images; data visualisation; graphical user interfaces; image segmentation; interactive design; interpolation; interpolation scheme; multiperspective images; ray tracing; town and country planning; urban landscape visualization;
Author: Roman, A.; Garg, G.; Levoy, M.

Year: 2004
Title: Real-time motion estimation and visualization on graphics cards
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372241
Abstract: We present a tool for real-time visualization of motion features in 2D image sequences. The motion is estimated through an eigenvector analysis of the spatio-temporal structure tensor at every pixel location. This approach is computationally demanding but allows reliable velocity estimates as well as quality indicators for the obtained results. We use a 2D color map and a region of interest selector for the visualization of the velocities. On the selected velocities we apply a hierarchical smoothing scheme which allows the choice of the desired scale of the motion field. We demonstrate several examples of test sequences in which some persons are moving with different velocities than others. These persons are visually marked in the real-time display of the image sequence. The tool is also applied to angiography sequences to emphasize the blood flow and its distribution. An efficient processing of the data streams is achieved by mapping the operations onto the stream architecture of standard graphics cards. The card receives the images and performs both the motion estimation and visualization, taking advantage of the parallelism in the graphics processor and the superior memory bandwidth. The integration of data processing and visualization also saves on unnecessary data transfers and thus allows the real-time analysis of 320&times;240 images. We expect that on the newest generation of graphics hardware our tool could run in real time for the standard VGA format.
Keywords: 2D color map; 2D image sequences; angiography sequences; computer graphic equipment; data visualisation; data visualization; eigenvalues and eigenfunctions; eigenvector analysis; feature extraction; graphics cards; graphics hardware; hierarchical smoothing scheme; image colour analysis; image resolution; image sequences; motion estimation; motion visualization; real-time motion estimation; spatio-temporal structure tensor; structure tensor;
Author: Strzodka, R.; Garbe, C.

Year: 2004
Title: Dispersion simulation and visualization for urban security
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372242
Abstract:  We present a system for simulating and visualizing the propagation of dispersive contaminants with an application to urban security. In particular, we simulate airborne contaminant propagation in open environments characterised by sky-scrapers and deep urban canyons. Our approach is based on the multiple relaxation time lattice Boltzmann model (MRTLBM), which can efficiently handle complex boundary conditions such as buildings. In addition, we model thermal effects on the flow field using the hybrid thermal MRTLBM. Our approach can also accommodate readings from various sensors distributed in the environment and adapt the simulation accordingly. We accelerate the computation and efficiently render many buildings with small textures on the GPU. We render streamlines and the contaminant smoke with self-shadowing composited with the textured buildings.
Keywords: air pollution; airborne contaminant propagation simulation; data visualisation; digital simulation; dispersive contaminant propagation visualization; flow field; flow visualisation; image texture; multiple relaxation time lattice Boltzmann model; rendering (computer graphics); sky-scrapers; urban canyons; urban security;
Author: Feng Qiu; Ye Zhao; Zhe Fan; Xiaoming Wei; Lorenz, H.; Jianning Wang; Yoakum-Stover, S.; Kaufman, A.; Mueller, K.

Year: 2004
Title: Panel 1: Can We Determine the Top Unresolved Problems of Visualization?
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372243
Abstract:  Many of us working in visualization have our own list of our top 5 or 10 unresolved problems in visualization. We have assembled a group of panelists to debate and perhaps reach concensus on the top problems in visualization that still need to be explored. We include panelists from both the information and scientific visualization domains. After our presentations, we encourage interaction with the audience to see if we can further formulate and perhaps finalize our list of top unresolved problems in visualization.
Keywords: top unresolved problems; visualization;
Author: Rhyne, T.; Hibbard, B.; Johnson, C.; Chaomei Chen; Eick, S.

Year: 2004
Title: Panel 2: In the Eye of the Beholder: The Role of Perception in Scientific Visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372244
Abstract:  The evolution of computational science over the last decade has resulted in a dramatic increase in raw problem solving capabilities. This growth has given rise to advances in scientific and engineering simulations that have put a high demand on tools for high-performance large-scale data exploration and analysis. These simulations have the potential to generate large amounts of data. Humans, however are relatively poor at gaining insight from raw numerical data, and as a result, have used visualization as a tool for understanding, interpreting and exploring data of all types and sizes. Allowing for efficient visual explorations of data, however, requires that the ratio of knowledge gained versus the cost of the visualization be maximized. This, in turn, mandates the integration of principles from human perception. Understanding perception as it relates to visualization requires that we understand not only the biology of the human visual system, but principles from vision theory, and perceptual psychology as well. This panel is the result of bringing together practioners and researchers from a broad spectrum of interests relating to the ability to maximize the amount of information that is effectively perceived from a given visualization. Position statements will be given by researchers interested in perceptual psychology and the perception of natural images, integrating art and design principles, non-photorealistic rendering techniques, and the use of global illumination methods to provide benefical perceptual cues.
Keywords: human visual system; perception; visualization;
Author: Gaither, K.; Ebert, D.; Geisler, B.; Laidlaw, D.

Year: 2004
Title: Panel 3: The Future Visualization Platform
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372245
Abstract:  Advances in graphics hardware and rendering methods are shaping the future of visualization. For example, programmable graphics processors are redefining the traditional visualization cycle. In some cases it is now possible to run the computational simulation and associated visualization side-by-side on the same chip. Moreover, global illumination and non-photorealistic effects promise to deliver imagery which enables greater insight into high resolution, multivariate, and higher-dimensional data. The panelists will offer distinct viewpoints on the direction of future graphics hardware and its potential impact on visualization, and on the nature of advanced visualizationrelated tools and techniques. Presentation of these viewpoints will be followed by audience participation in the form of a question and answer period moderated by the panel organizer.
Keywords: future; hardware; techniques; visualization;
Author: Johnson, G.; Ebert, D.; Hansen, C.; Kirk, D.; Mark, B.; Pfister, H.

Year: 2004
Title: Panel 4: What Should We Teach in a Scientific Visualization Class?
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1372246
Abstract:  Scientific Visualization (SciVis) has evolved past the point where one undergraduate course can cover all of the necessary topics. So the question becomes "how do we teach SciVis to this generation of students?" Some examples of current courses are: A graduate Computer Science (CS) course that prepares the next generation of SciVis researchers. An undergraduate CS course that prepares the future software architects/developers of packages such as vtk, vis5D and AVS. A class that teaches students how to do SciVis with existing software packages and how to deal with the lack of interoperability between those packages (via either a CS service course or a supercomputing center training course). An inter-disciplinary course designed to prepare computer scientists to work with the "real" scientists (via either a CS or Computational Science course). In this panel, we will discuss these types of courses and the advantages and disadvantages of each. We will also talk about some issues that you have probably encountered at your university: How do we keep the graphics/vis-oriented students from going to industry? How does SciVis fit in with evolving Computational Science programs? Is SciVis destined to be a service course at most universities? How do we deal with the diverse backgrounds of students that need SciVis?
Keywords: "><meta name="citation_conference" content="Visualization, 2004. IEEE
Author: Genetti, J.D.; Bailey, M.J.; Laidlaw, D.H.; Moorhead, R.J.; Whitaker, R.T.

Year: 2003
Title: Exploring curved anatomic structures with surface sections
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250351
Abstract: The extraction of planar sections from volume images is the most commonly used technique for inspecting and visualizing anatomic structures. We propose to generalize the concept of planar section to the extraction of curved cross-sections (free form surfaces). Compared with planar slices, curved cross-sections may easily follow the trajectory of tubular structures and organs such as the aorta or the colon. They may be extracted from a 3D volume, displayed as a 3D view and possibly flattened. Flattening of curved cross-sections allows to inspect spatially complex relationship between anatomic structures and their neighborhood. They also allow to carry out measurements along a specific orientation. For the purpose of facilitating the interactive specification of free form surfaces, users may navigate in real time within the body and select the slices on which the surface control points will be positioned. Immediate feedback is provided by displaying boundary curves as cylindrical markers within a 3D view composed of anatomic organs, planar slices and possibly free form surface sections. Extraction of curved surface sections is an additional service that is available online as a Java applet (http://visiblehuman.epfl.ch). It may be used as an advanced tool for exploring and teaching anatomy.
Keywords: 3D image;3D volume;anatomic structures;computerised tomography;curved cross-sections;curved sections;data visualisation;data visualization;feature extraction;free form surfaces;interactive flattening;interactive specification;medical computing;planar sections;surface extraction;surface sections;tubular structures;volume images;
Author: Saroul, L.; Gerlach, S.; Herch, R.D.

Year: 2003
Title: Psychophysical scaling of a cardiovascular information display
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250352
Abstract: A new method was developed to increase the saliency of changing variables in a cardiovascular visualization for use by anesthesiologists in the operating room (OR). Clinically meaningful changes in patient physiology were identified and then mapped to the inherent psychophysical properties of the visualization. A long history of psychophysical research has provided an understanding of the parameters within which the human information processing system is able to detect changes in the size, shape and color of visual objects (Gescheider, 1976, Spence, 1990, and Baird, 1970). These detection thresholds are known as just noticeable differences (JNDs) which characterize the amount of change in an object's attribute that is recognizable 50% of the time. A prototype version of the display has been demonstrated to facilitate anesthesiologist's performance while reducing cognitive workload during simulated cardiac events (Agutter et al., 2002). In order to further improve the utility of the new cardiovascular visualization, the clinically relevant changes in cardiovascular variables are mapped to noticeable perceptual changes in the representational elements of the display. The results of the method described in this paper are used to merge information from the psychophysical properties of the cardiovascular visualization, with clinically relevant changes in the patient's cardiovascular physiology as measured by the clinical meaningfulness questionnaire. The result of this combination will create a visualization that is sensitive to changes in the cardiovascular health of the patient and communicates this information to the user in a meaningful, salient and intuitive manner.
Keywords: anesthesia;cardiovascular health;cardiovascular information display;cardiovascular system;cardiovascular visualization;data visualisation;human information processing;just noticeable differences;medical computing;patent vital sign monitor;patient monitoring;patient physiology;patient vital sign phenomena;psychophysical scaling;surgery;user interfaces;
Author: Albert, R.; Syroid, N.; Zhang, Y.; Agutter, J.; Drews, F.; Strayer, D.; Hutchinson, G.; Westenskow, D.

Year: 2003
Title: Advanced curved planar reformation: flattening of vascular structures
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250353
Abstract: Traditional volume visualization techniques may provide incomplete clinical information needed for applications in medical visualization. In the area of vascular visualization important features such as the lumen of a diseased vessel segment may not be visible. Curved planar reformation (CPR) has proven to be an acceptable practical solution. Existing CPR techniques, however, still have diagnostically relevant limitations. In this paper, we introduce two advances methods for efficient vessel visualization, based on the concept of CPR. Both methods benefit from relaxation of spatial coherence in favor of improved feature perception. We present a new technique to visualize the interior of a vessel in a single image. A vessel is resampled along a spiral around its central axis. The helical spiral depicts the vessel volume. Furthermore, a method to display an entire vascular tree without mutually occluding vessels is presented. Minimal rotations at the bifurcations avoid occlusions. For each viewing direction the entire vessel structure is visible.
Keywords: angiocardiography;blood vessels;cardiovascular system;computed tomography angiography;computerised tomography;curved planar reformation;data visualisation;feature perception;helical spiral;medical image processing;medical visualization;rendering (computer graphics);spatial coherence;vascular structures;vascular tree;vascular visualization;vessel analysis;vessel visualization;vessel volume;
Author: Kanitsar, A.; Wegenkittl, R.; Fleischmann, D.; Groller, M.E.

Year: 2003
Title: Counting cases in marching cubes: toward a generic algorithm for producing substitopes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250354
Abstract: We describe how to count the cases that arise in a family of visualization techniques, including marching cubes, sweeping simplices, contour meshing, interval volumes, and separating surfaces. Counting the cases is the first step toward developing a generic visualization algorithm to produce substitopes (geometric substitution of polytopes). We demonstrate the method using a software system ("GAP") for computational group theory. The case-counts are organized into a table that provides taxonomy of members of the family; numbers in the table are derived from actual lists of cases, which are computed by our methods. The calculation confirms previously reported case-counts for large dimensions that are too large to check by hand, and predicts the number of cases that will arise in algorithms that have not yet been invented.
Keywords: algorithm theory;cases counting;combinatorial mathematics;computational geometry;computational group theory;contour meshing;generic algorithm;geometric substitution;group theory;interval volumes;isosurface;marching cubes;polytopes;separating surfaces;substitopes;visualization techniques;
Author: Banks, D.C.; Linton, S.

Year: 2003
Title: MC*: star functions for marching cubes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250355
Abstract: We describe a modification of the widely used marching cubes method that leads to the useful property that the resulting isosurfaces are locally single valued functions. This implies that conventional interpolation and approximation methods can be used to locally represent the surface. These representations can be used for computing approximations for local surface properties. We utilize this possibility in order to develop algorithms for locally approximating Gaussian and mean curvature, methods for constrained smoothing of isosurface, and techniques for the parameterization of isosurfaces.
Keywords: Gaussian curvature;Gaussian processes;approximation methods;approximation theory;computational geometry;constrained smoothing;interpolation;interpolation methods;isosurface parameterization;local surface properties;marching cubes;mean curvature;mesh generation;single valued functions;solid modelling;star functions;triangular mesh;
Author: Nielson, G.M.

Year: 2003
Title: Extraction of topologically simple isosurfaces from volume datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250356
Abstract: There are numerous algorithms in graphics and visualization whose performance is known to decay as the topological complexity of the input increases. On the other hand, the standard pipeline for 3D geometry acquisition often produces 3D models that are topologically more complex than their real forms. We present a simple and efficient algorithm that allows us to simplify the topology of an isosurface by alternating the values of some number of voxels. Its utility and performance are demonstrated on several examples, including signed distance functions from polygonal models and CT scans.
Keywords: 3D geometry acquisition;CT scans;computational geometry;data visualisation;data visualization;isosurfaces;polygonal models;solid modelling;topological complexity;topology;topology;volume datasets;
Author: Szymczak, A.; Vanderhyde, J.

Year: 2003
Title: Interactive deformation and visualization of level set surfaces using graphics hardware
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250357
Abstract: Deformable isosurfaces, implemented with level-set methods, have demonstrated a great potential in visualization for applications such as segmentation, surface processing, and surface reconstruction. Their usefulness has been limited, however, by their high computational cost and reliance on significant parameter tuning. This paper presents a solution to these challenges by describing graphics processor (GPU) based on algorithms for solving and visualizing level-set solutions at interactive rates. Our efficient GPU-based solution relies on packing the level-set isosurface data into a dynamic, sparse texture format. As the level set moves, this sparse data structure is updated via a novel GPU to CPU message passing scheme. When the level-set solver is integrated with a real-time volume renderer operating on the same packed format, a user can visualize and steer the deformable level-set surface as it evolves. In addition, the resulting isosurface can serve as a region-of-interest specifier for the volume renderer. This paper demonstrates the capabilities of this technology for interactive volume visualization and segmentation.
Keywords: GPU-based solution;computational geometry;data visualisation;deformable models;graphics hardware;graphics processor;image rendering;image segmentation;image segmentation;interactive deformation;isosurfaces;level-set methods;message passing;region-of-interest specifier;rendering (computer graphics);sparse texture format;streaming computation;surface processing;surface reconstruction;volume visualization;
Author: Lefohn, A.E.; Kniss, J.M.; Hansen, C.D.; Whitaker, R.T.

Year: 2003
Title: Signed distance transform using graphics hardware
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250358
Abstract: This paper presents a signed distance transform algorithm using graphics hardware, which computes the scalar valued function of the Euclidean distance to a given manifold of co-dimension one. If the manifold is closed and orientable, the distance has a negative sign on one side of the manifold and a positive sign on the other. Triangle meshes are considered for the representation of a two-dimensional manifold and the distance function is sampled on a regular Cartesian grid. In order to achieve linear complexity in the number of grid points, to each primitive we assign a simple polyhedron enclosing its Voronoi cell. Voronoi cells are known to contain exactly all points that lay closest to its corresponding primitive. Thus, the distance to the primitive only has to be computed for grid points inside its polyhedron. Although Voronoi cells partition space, the polyhedrons enclosing these cells do overlap. In regions where these overlaps occur, the minimum of all computed distances is assigned to a grid point. In order to speed up computations, points inside each polyhedron are determined by scan conversion of grid slices using graphics hardware. For this task, a fragment program is used to perform the nonlinear interpolation and minimization of distance values.
Keywords: Cartesian grid;Euclidean distance;GPU-based algorithms;Voronoi diagram;algorithm theory;computational geometry;data visualisation;data visualization;deformable isosurfaces;distance field;fragment program;graphics hardware;graphics processor;grid points;image rendering;image segmentation;linear complexity;nonlinear interpolation;polyhedron;rendering (computer graphics);scalar valued function;scan conversion;signed distance transform;triangle meshes;
Author: Sigg, C.; Peikert, R.; Gross, M.

Year: 2003
Title: Piecewise C1 continuous surface reconstruction of noisy point clouds via local implicit quadric regression
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250359
Abstract: This paper addresses the problem of surface reconstruction of highly noisy point clouds. The surfaces to be reconstructed are assumed to be 2-manifolds of piecewise C<sup>1</sup> continuity, with isolated small irregular regions of high curvature, sophisticated local topology or abrupt burst of noise. At each sample point, a quadric field is locally fitted via a modified moving least squares method. These locally fitted quadric fields are then blended together to produce a pseudo-signed distance field using Shepard's method. We introduce a prioritized front growing scheme in the process of local quadrics fitting. Flatter surface areas tend to grow faster. The already fitted regions will subsequently guide the fitting of those irregular regions in their neighborhood.
Keywords: Piecewise C1;Shepard method;computational geometry;computer graphics;continuous surface reconstruction;flatter surface areas;image reconstruction;local implicit quadric regression;moving least squares;noisy point clouds;pseudosigned distance field;quadric fields;solid modeling;solid modelling;surface fitting;surface reconstruction;surface representation;topology;
Author: Hui Xie; Jianning Wang; Jing Hua; Hong Qin; Kaufman, A.

Year: 2003
Title: Feature-sensitive subdivision and isosurface reconstruction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250360
Abstract: We present improved subdivision and isosurface reconstruction algorithms for polygonizing implicit surfaces and performing accurate geometric operations. Our improved reconstruction algorithm uses directed distance fields (Kobbelt et al., 2001) to detect multiple intersections along an edge, separates them into components and reconstructs an isosurface locally within each components using the dual contouring algorithm (Ju et al., 2002). It can reconstruct thin features without creating handles and results in improved surface extraction from volumetric data. Our subdivision algorithm takes into account sharp features that arise from intersecting surfaces or Boolean operations and generates an adaptive grid such that each voxel has at most one sharp feature. The subdivision algorithm is combined with our improved reconstruction algorithm to compute accurate polygonization of Boolean combinations or offsets of complex primitives that faithfully reconstruct the sharp features. We have applied these algorithms to polygonize complex CAD models designed using thousands of Boolean operations on curved primitives.
Keywords: Boolean algebra;Boolean operations;computational geometry;directed distance fields;dual contouring algorithm;feature extraction;feature-sensitive subdivision;geometric operations;image reconstruction;implicit modeling;isosurface reconstruction;marching cubes;polygonization;solid modelling;surface extraction;
Author: Varadhan, G.; Krishnan, S.; Kim, Y.J.; Manocha, D.

Year: 2003
Title: A texture-based framework for spacetime-coherent visualization of time-dependent vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250361
Abstract: We propose unsteady flow advection-convolution (UFAC) as a novel visualization approach for unsteady flows. It performs time evolution governed by pathlines, but builds spatial correlation according to instantaneous streamlines whose spatial extent is controlled by the flow unsteadiness. UFAC is derived from a generic framework that provides spacetime-coherent dense representations of time dependent-vector fields by a two-step process: 1) construction of continuous trajectories in spacetime for temporal coherence; and 2) convolution along another set of paths through the above spacetime for spatially correlated patterns. Within the framework, known visualization techniques-such as Lagrangian-Eulerian advection, image-based flow visualization, unsteady flow LIC, and dynamic LIC-can be reproduced, often with better image quality, higher performance, or increased flexibility of the visualization style. Finally, we present a texture-based discretization of the framework and its interactive implementation on graphics hardware, which allows the user to gradually balance visualization speed against quality.
Keywords: Lagrangian-Eulerian advection;data visualisation;dynamic LIC;flow visualisation;graphics hardware;hardware acceleration;image processing;image quality;image-based flow visualization;spacetime-coherent visualization;spatial correlation;temporal coherence;texture advection;texture-based discretization;time evolution;time-dependent vector fields;unsteady flow LIC;unsteady flow advection-convolution;
Author: Weiskopf, D.; Erlebacher, G.; Ertl, T.

Year: 2003
Title: Effectively visualizing multi-valued flow data using color and texture
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250362
Abstract: In this paper we offer several new insights and techniques for effectively using color and texture to simultaneously convey information about multiple 2D scalar and vector distributions, in a way that facilitates allowing each distribution to be understood both individually and in the context of one or more of the other distributions. Specifically, we introduce the concepts of: color weaving for simultaneously representing information about multiple co-located color encoded distributions; and texture stitching for achieving more spatially accurate multi-frequency line integral convolution representations of combined scalar and vector distributions. The target application for our research is the definition, detection and visualization of regions of interest in a turbulent boundary layer flow at moderate Reynolds number. In this work, we examine and analyze streamwise-spanwise planes of three-component velocity vectors with the goal of identifying and characterizing spatially organized packets of hairpin vortices.
Keywords: Reynolds number;color weaving;colour graphics;convolution;data visualisation;data visualization;flow visualisation;flow visualization;image processing;information representation;line integral convolution;multiple co-located color encoded distributions;multivalued flow data;scalar distributions;streamwise-spanwise planes;texture stitching;vector distributions;
Author: Urness, T.; Interrante, V.; Marusic, I.; Longmire, E.; Ganapathisubramani, B.

Year: 2003
Title: Image based flow visualization for curved surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250363
Abstract: A new method for the synthesis of dense, vector-field aligned textures on curved surfaces is presented, called IBFVS. The method is based on image based flow visualization (IBFV). In IBFV two-dimensional animated textures are produced by defining each frame of a flow animation as a blend between a warped version of the previous image and a number of filtered white noise images. We produce flow aligned texture on arbitrary three-dimensional triangular meshes in the same spirit as the original method: texture is generated directly in image space. We show that IBFVS is efficient and effective. High performance (typically fifty frames or more per second) is achieved by exploiting graphics hardware. Also, IBFVS can easily be implemented and a variety of effects can be achieved. Applications are flow visualization and surface rendering. Specifically, we show how to visualize the wind field on the earth and how to render a dirty bronze bunny.
Keywords: animated textures;computational fluid dynamics;computational fluid dynamics;curved surfaces;data visualisation;digital simulation;flow animation;flow visualisation;graphics hardware;image space;image texture;image-based flow visualization;line integral convolution;rendering (computer graphics);surface rendering;texture mapping;triangular meshes;white noise images;
Author: van Wijk, J.J.

Year: 2003
Title: Image space based visualization of unsteady flow on surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250364
Abstract: We present a technique for direct visualization of unsteady flow on surfaces from computational fluid dynamics. The method generates dense representations of time-dependent vector fields with high spatio-temporal correlation using both Lagrangian-Eulerian advection and image based flow visualization as its foundation. While the 3D vector fields are associated with arbitrary triangular surface meshes, the generation and advection of texture properties is confined to image space. Frame rates of up to 20 frames per second are realized by exploiting graphics card hardware. We apply this algorithm to unsteady flow on boundary surfaces of, large, complex meshes from computational fluid dynamics composed of more than 250,000 polygons, dynamic meshes with time-dependent geometry and topology, as well as medical data.
Keywords: Lagrangian-Eulerian advection;computational fluid dynamics;computational fluid dynamics;data visualisation;digital simulation;dynamic meshes;flow visualisation;flow visualization;image space based visualization;image texture;spatio-temporal correlation;surface representation;surface unsteady flow;texture mapping;time-dependent geometry;time-dependent topology;time-dependent vector fields;
Author: Laramee, R.S.; Jobard, B.; Hauser, H.

Year: 2003
Title: A multi-resolution data structure for two-dimensional Morse-Smale functions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250365
Abstract: We combine topological and geometric methods to construct a multi-resolution data structure for functions over two-dimensional domains. Starting with the Morse-Smale complex, we construct a topological hierarchy by progressively canceling critical points in pairs. Concurrently, we create a geometric hierarchy by adapting the geometry to the changes in topology. The data structure supports mesh traversal operations similarly to traditional multi-resolution representations.
Keywords: Morse-Smale complex;computational geometry;computer graphics;critical point theory;geographic information systems;geometric hierarchy;geometric methods;mesh traversal operations;multiresolution data structure;terrain;terrain mapping;topological methods;topology;two-dimensional functions;
Author: Bremer, P.-T.; Edelsbrunner, H.; Hamann, B.; Pascucci, V.

Year: 2003
Title: Planet-sized batched dynamic adaptive meshes (P-BDAM)
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250366
Abstract: We describe an efficient technique for out-of-core management and interactive rendering of planet sized textured terrain surfaces. The technique, called planet-sized batched dynamic adaptive meshes (P-BDAM), extends the BDAM approach by using as basic primitive a general triangulation of points on a displaced triangle. The proposed framework introduces several advances with respect to the state of the art: thanks to a batched host-to-graphics communication model, we outperform current adaptive tessellation solutions in terms of rendering speed; we guarantee overall geometric continuity, exploiting programmable graphics hardware to cope with the accuracy issues introduced by single precision floating points; we exploit a compressed out of core representation and speculative prefetching for hiding disk latency during rendering of out-of-core data; we efficiently construct high quality simplified representations with a novel distributed out of core simplification algorithm working on a standard PC network.
Keywords: P-BDAM;computational geometry;core simplification algorithm;geometric continuity;graphics hardware;host-to-graphics communication;image resolution;interactive rendering;multiresolution;out-of-core management;planet-sized batched dynamic adaptive meshes;points triangulation;rendering (computer graphics);single precision floating points;terrain mapping;terrain surfaces;
Author: Cignoni, P.; Ganovelli, F.; Gobbetti, E.; Marton, F.; Ponchio, F.; Scopigno, R.

Year: 2003
Title: Real-time refinement and simplification of adaptive triangular meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250367
Abstract: In this paper we present a generic method for incremental mesh adaptation based on hierarchy of semi-regular meshes. Our method supports any refinement rule mapping vertices onto vertices such as 1-to-4 split or &radic;3-subdivision. Resulting adaptive mesh has subdivision connectivity and hence good aspect ratio of triangles. Hierarchic representation of the mesh allows incremental local refinement and simplification operations exploiting frame-to-frame coherence. We also present an out-of-core storage layout scheme designed for semi-regular meshes of arbitrary subdivision connectivity. It provides high cache coherency in the data retrieval and relies on the interleaved storage of resolution levels and maintaining good geometrical proximity within each level. The efficiency of the proposed method is demonstrated with applications in physically-based cloth simulation, real-time terrain visualization and procedural modeling.
Keywords: adaptive meshes;adaptive triangular meshes;cloth simulation;computational geometry;data retrieval;data visualisation;geometrical proximity;image resolution;multiresoluton;out-of-core storage layout;procedural modeling;real-time refinement;real-time simplification;real-time terrain visualization;refinement rule mapping;semiregular meshes;terrain mapping;
Author: Volkov, V.; Ling Li

Year: 2003
Title: Interactive view-dependent rendering with conservative occlusion culling in complex environments
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250368
Abstract: This paper presents an algorithm combining view-dependent rendering and conservative occlusion culling for interactive display of complex environments. A vertex hierarchy of the entire scene is decomposed into a cluster hierarchy through a novel clustering and partitioning algorithm. The cluster hierarchy is then used for view-frustum and occlusion culling. Using hardware accelerated occlusion queries and frame-to-frame coherence, a potentially visible set of clusters is computed. An active vertex front and face list is computed from the visible clusters and rendered using vertex arrays. The integrated algorithm has been implemented on a Pentium IV PC with a NVIDIA GeForce 4 graphics card and applied in two complex environments composed of millions of triangles. The resulting system can render these environments at interactive rates with little loss in image quality and minimal popping artifacts.
Keywords: cluster hierarchy;clustering;computational geometry;conservative occlusion culling;data visualisation;frame-to-frame coherence;hardware-accelerated occlusion queries;image quality;interactive display;interactive rendering;multiresolution hierarchies;partitioning algorithm;popping artifacts;rendering (computer graphics);solid modelling;view-dependent rendering;
Author: Sung-Eui Yoon; Salomon, B.; Manocha, D.

Year: 2003
Title: Fast volume segmentation with simultaneous visualization using programmable graphics hardware
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250369
Abstract: Segmentation of structures from measured volume data, such as anatomy in medical imaging, is a challenging data-dependent task. In this paper, we present a segmentation method that leverages the parallel processing capabilities of modern programmable graphics hardware in order to run significantly faster than previous methods. In addition, collocating the algorithm computation with the visualization on the graphics hardware circumvents the need to transfer data across the system bus, allowing for faster visualization and interaction. This algorithm is unique in that it utilizes sophisticated graphics hardware functionality (i.e., floating point precision, render to texture, computational masking, and fragment programs) to enable fast segmentation and interactive visualization.
Keywords: computational masking;computerised tomography;data visualisation;data visualization;fast volume segmentation;floating point precision;fragment programs;graphics processor;image segmentation;image segmentation;medical image processing;medical imaging;parallel processing;parallel processing;programmable graphics hardware;region growing;rendering (computer graphics);streaming computation;structure segmentation;
Author: Sherbondy, A.; Houston, M.; Napel, S.

Year: 2003
Title: Hybrid segmentation and exploration of the human lungs
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250370
Abstract: Segmentation of the tracheo-bronchial tree of the lungs is notoriously difficult. This is due to the fact that the small size of some of the anatomical structures is subject to partial volume effects. Furthermore, the limited intensity contrast between the participating materials (air, blood, and tissue) increases the segmentation of difficulties. In this paper, we propose a hybrid segmentation method which is based on a pipeline of three segmentation stages to extract the lower airways down to the seventh generation of the bronchi. User interaction is limited to the specification of a seed point inside the easily detectable trachea at the upper end of the lower airways. Similarly, the complementary vascular tree of the lungs can be segmented. Furthermore, we modified our virtual endoscopy system to visualize the vascular and airway system of the lungs along with other features, such as lung tumors.
Keywords: airway system;anatomical structures;bronchi;computerised tomography;endoscopes;human lungs;hybrid segmentation;image segmentation;image segmentation;intensity contrast;lower airways;lung;lung tumors;medical image processing;multislice CT;partial volume effects;seed point;tracheo-bronchial tree;user interaction;vascular system;vascular tree;virtual endoscopy system;virtual reality;
Author: Bartz, D.; Mayer, D.; Fischer, J.; Ley, S.; del Rio, A.; Thust, S.; Heussel, C.P.; Kauczor, H.-U.; Strasser, W.

Year: 2003
Title: Feature-space analysis of unstructured meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250371
Abstract: Unstructured meshes are often used in simulations and imaging applications. They provide advanced flexibility in modeling abilities but are more difficult to manipulate and analyze than regular data. This work provides a novel approach for the analysis of unstructured meshes using feature-space clustering and feature-detection. Analyzing and revealing underlying structures in data involve operators on both spatial and functional domains. Slicing concentrates more on the spatial domain, while iso-surfacing or volume rendering concentrate more on the functional domain. Nevertheless, many times it is the combination of the two domains which provides real insight on the structure of the data. In this work, a combined feature-space is defined on top of unstructured meshes in order to search for structure in the data. A point in feature-space includes the spatial coordinates of the point in the mesh domain and all chosen attributes defined on the mesh. A distance measures between points in feature-space is defined enabling the utilization of clustering using the mean shift procedure (previously used for images) on unstructured meshes. Feature space analysis is shown to be useful for feature-extraction, for data exploration and partitioning.
Keywords: computational geometry;data exploration;data structure;data visualisation;feature detection;feature extraction;feature extraction;feature space clustering;feature-space analysis;functional domain;image partitioning;image processing;image segmentation;imaging applications;iso-surfacing;mean shifting;rendering (computer graphics);simulations;spatial coordinates;spatial domain;unstructured meshes;volume rendering;
Author: Shamir, A.

Year: 2003
Title: Clifford convolution and pattern matching on vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250372
Abstract: The goal of this paper is to define a convolution operation which transfers image processing and pattern matching to vector fields from flow visualization. For this, a multiplication of vectors is necessary. Clifford algebra provides such a multiplication of vectors. We define a Clifford convolution on vector fields with uniform grids. The Clifford convolution works with multivector filter masks. Scalar and vector masks can be easily converted to multivector fields. So, filter masks from image processing on scalar fields can be applied as well as vector and scalar masks. Furthermore, a method for pattern matching with Clifford convolution on vector fields is described. The method is independent of the direction of the structures. This provides an automatic approach to feature detection. The features can be visualized using any known method like glyphs, isosurfaces or streamlines. The features are defined by filter masks instead of analytical properties and thus the approach is more intuitive.
Keywords: Clifford algebra;Clifford convolution;convolution operation;data visualisation;feature detection;feature extraction;flow visualisation;flow visualization;glyphs;image processing;isosurfaces;multivector filter masks;pattern matching;pattern matching;scalar masks;streamlines;vector fields;vector multiplication;
Author: Ebling, J.; Scheuermann, G.

Year: 2003
Title: Space efficient fast isosurface extraction for large datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250373
Abstract: In this paper, we present a space efficient algorithm for speeding up isosurface extraction. Even though there exist algorithms that can achieve optimal search performance to identify isosurface cells, they prove impractical for large datasets due to a high storage overhead. With the dual goals of achieving fast isosurface extraction and simultaneously reducing the space requirement, we introduce an algorithm based on transform coding to compress the interval information of the cells in a dataset. Compression is achieved by first transforming the cell intervals (minima, maxima) into a form which allows more efficient compaction. It is followed by a dataset optimized non-uniform quantization stage. The compressed data is stored in a data structure that allows fast searches in the compression domain, thus eliminating the need to retrieve the original representation of the intervals at run-time. The space requirement of our search data structure is the mandatory cost of storing every cell ID once, plus an overhead for quantization information. The overhead is typically in the order of a few hundredths of the dataset size.
Keywords: data compression;data compression;data retrieval;data structure;data structures;data visualisation;dataset cells;feature extraction;interval information compression;isosurface cells;isosurface extraction;nonuniform quantization;optimal search performance;space efficiency;space efficient algorithm;storage overhead;transform coding;transform coding;
Author: Bordoloi, U.D.; Han-Wei Shen

Year: 2003
Title: Volume tracking using higher dimensional isosurfacing
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250374
Abstract: Tracking and visualizing local features from a time-varying volumetric data allows the user to focus on selected regions of interest, both in space and time, which can lead to a better understanding of the underlying dynamics. In this paper, we present an efficient algorithm to track time-varying isosurfaces and interval volumes using isosurfacing in higher dimensions. Instead of extracting the data features such as isosurfaces or interval volumes separately from multiple time steps and computing the spatial correspondence between those features, our algorithm extracts the correspondence directly from the higher dimensional geometry and thus can more efficiently follow the user selected local features in time. In addition, by analyzing the resulting higher dimensional geometry, it becomes easier to detect important topological events and the corresponding critical time steps for the selected features. With our algorithm, the user can interact with the underlying time-varying data more easily. The computation cost for performing time-varying volume tracking is also minimized.
Keywords: computational geometry;computer graphics;critical time steps;data visualisation;feature extraction;higher dimensional geometry;higher dimensional isosurfacing;interval volumes;local feature tracking;local feature visualization;optical tracking;time-varying data;time-varying isosurfaces;time-varying volumetric data;topological event detection;user selected local features;volume tracking;
Author: Guangfeng Ji; Han-Wei Shen; Wenger, R.

Year: 2003
Title: Out-of-core isosurface extraction of time-varying fields over irregular grids
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250375
Abstract: In this paper, we propose a novel out-of-core isosurface extraction technique for large time-varying fields over irregular grids. We employ our meta-cell technique to explore the spatial coherence of the data, and our time tree algorithm to consider the temporal coherence as well. Our one-time preprocessing phase first partitions the dataset into meta-cells that cluster spatially neighboring cells together and are stored in disk. We then build a time tree to index the meta-cells for fast isosurface extraction. The time tree takes advantage of the temporal coherence among the scalar values at different time steps, and uses BBIO trees as secondary structures, which are stored in disk and support I/O-optimal interval searches. The time tree algorithm employs a novel meta-interval collapsing scheme and the buffer technique, to take care of the temporal coherence in an I/O-efficient way. We further make the time tree cache-oblivious, so that searching on it automatically performs optimal number of block transfers between any two consecutive levels of memory hierarchy (such as between cache and main memory and between main memory and disk) simultaneously. At run-time, we perform optimal cache-oblivious searches in the time tree, together with I/O-optimal searches in the BBIO trees, to read the active meta-cells from disk and generate the queried isosurface efficiently. The experiments demonstrate the effectiveness of our new technique. In particular, compared with the query-optimal main-memory algorithm by Cignoni et al. (1997) (extended for time-varying fields) when there is not enough main memory, our technique can speed up the isosurface queries from more than 18 hours to less than 4 minutes.
Keywords: BBIO trees;I/O-optimal interval searches;buffer storage;buffer technique;cache oblivious searches;data structures;data visualisation;disk storage;feature extraction;irregular grids;isosurface queries;memory hierarchy;meta cell indexing;meta cell technique;meta interval collapsing scheme;out-of-core isosurface extraction;preprocessing phase;spatial coherence;temporal coherence;time tree algorithm;time-varying fields;
Author: Yi-Jen Chiang

Year: 2003
Title: Saddle connectors - an approach to visualizing the topological skeleton of complex 3D vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250376
Abstract: One of the reasons that topological methods have a limited popularity for the visualization of complex 3D flow fields is the fact that such topological structures contain a number of separating stream surfaces. Since these stream surfaces tend to hide each other as well as other topological features, for complex 3D topologies the visualizations become cluttered and hardly interpretable. This paper proposes to use particular stream lines called saddle connectors instead of separating stream surfaces and to depict single surfaces only on user demand. We discuss properties and computational issues of saddle connectors and apply these methods to complex flow data. We show that the use of saddle connectors makes topological skeletons available as a valuable visualization tool even for topologically complex 3D flow data.
Keywords: 3D flow fields;complex 3D vector fields;complex flow data;computational fluid dynamics;critical points;data visualisation;flow visualisation;saddle connectors;separatrices;stream lines;stream surfaces;topological skeleton visualization;vector field topology;visualization tool;
Author: Theisel, H.; Weinkauf, T.; Hege, H.-C.; Seidel, H.-P.

Year: 2003
Title: 3D IBFV: hardware-accelerated 3D flow visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250377
Abstract: We present a hardware-accelerated method for visualizing 3D flow fields. The method is based on insertion, advection, and decay of dye. To this aim, we extend the texture-based IBFV technique presented by van Wijk (2001) for 2D flow visualization in two main directions. First, we decompose the 3D flow visualization problem in a series of 2D instances of the mentioned IBFV technique. This makes our method benefit from the hardware acceleration the original IBFV technique introduced. Secondly, we extend the concept of advected gray value (or color) noise by introducing opacity (or matter) noise. This allows us to produce sparse 3D noise pattern advections, thus address the occlusion problem inherent to 3D flow visualization. Overall, the presented method delivers interactively animated 3D flow, uses only standard OpenGL 1.1 calls and 2D textures, and is simple to understand and implement.
Keywords: 2D flow visualization;2D instances;2D textures;3D IBFV;3D flow visualization;OpenGL;advected gray value;color noise;computational fluid dynamics;dye advection;dye decay;dye insertion;flow visualisation;hardware acceleration;hardware-accelerated method;image texture;occlusion problem;opacity noise;texture advection;texture-based IBFV;
Author: Telea, A.; van Wijk, J.J.

Year: 2003
Title: Chameleon: an interactive texture-based rendering framework for visualizing three-dimensional vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250378
Abstract: In this paper we present an interactive texture-based technique for visualizing three-dimensional vector fields. The goal of the algorithm is to provide a general volume rendering framework allowing the user to compute three-dimensional flow textures interactively, and to modify the appearance of the visualization on the fly. To achieve our goal, we decouple the visualization pipeline into two disjoint stages. First, streamlines are generated from the 3D vector data. Various geometric properties of the streamlines are extracted and converted into a volumetric form using a hardware-assisted slice sweeping algorithm. In the second phase of the algorithm, the attributes stored in the volume are used as texture coordinates to look up an appearance texture to generate both informative and aesthetic representations of the underlying vector field. Users can change the input textures and instantaneously visualize the rendering results. With our algorithm, visualizations with enhanced structural perception using various visual cues can be rendered in real time. A myriad of existing geometry-based and texture-based visualization techniques can also be emulated.
Keywords: 3D flow textures;3D vector fields visualization;chameleon rendering;computer animation;geometry-based visualization;hardware-assisted slice sweeping algorithm;image enhancement;image texture;interactive texture-based rendering;rendering (computer graphics);streamlines generation;structural perception;texture coordinates;texture mapping;texture-based visualization;visual cues;visualization pipeline decoupling;volume rendering framework;
Author: Guo-Shi Li; Bordoloi, U.D.; Han-Wei Shen

Year: 2003
Title: HyperLIC
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250379
Abstract: We introduce a new method for visualizing symmetric tensor fields. The technique produces images and animations reminiscent of line integral convolution (LIC). The technique is also slightly related to hyperstreamlines in that it is used to visualize tensor fields. However, the similarity ends there. HyperLIC uses a multi-pass approach to show the anisotropic properties in a 2D or 3D tensor field. We demonstrate this technique using data sets from computational fluid dynamics as well as diffusion-tensor MRI.
Keywords: HyperLIC;animation production;anisotropic properties;computational fluid dynamics;computational fluid dynamics;computer animation;data visualisation;diffusion-tensor MRI;direct volume rendering;hyperstreamlines;image processing;image production;line integral convolution;magnetic resonance imaging;multipass approach;symmetric tensor fields visualization;
Author: Xiaoqiang Zheng; Pang, A.

Year: 2003
Title: Quasi-static approach approximation for 6 degrees-of-freedom haptic rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250380
Abstract: In this paper, we propose a quasi-static approximation (QSA) approach to simulate the movement of the movable object in 6-degrees-of-freedom (DOF) haptic rendering. In our QSA approach, we solve for static equilibrium during each haptic time step, ignoring any dynamical properties such as inertia. The major contribution of this approach is to overcome the computational instability problem in overly stiff systems arising from numerical integration of second-order differential equations in previous dynamic models. Our primary experimental results on both simulated aircraft geometry and a large-scale real-world aircraft engine showed that our QSA approach was capable of maintaining the 1000Hz haptic refresh rate with more robust collision avoidance and more reliable force and torque feedback.
Keywords: 1000 Hz;6-degrees-of-freedom haptics;aerospace computing;aircraft engine;engineering graphics;haptic interfaces;haptic refresh rate;haptic rendering;movable object simulation;numerical integration;physically based modeling;quasistatic approximation;rendering (computer graphics);robust collision avoidance;second-order differential equations;simulated aircraft geometry;static equilibrium;stiff systems;torque feedback;virtual coupling;virtual reality;voxel sampling;
Author: Ming Wan; McNeely, W.A.

Year: 2003
Title: A constraint-based technique for haptic volume exploration
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250381
Abstract: We present a haptic rendering technique that uses directional constraints to facilitate enhanced exploration modes for volumetric datasets. The algorithm restricts user motion in certain directions by incrementally moving a proxy point along the axes of a local reference frame. Reaction forces are generated by a spring coupler between the proxy and the data probe, which can be tuned to the capabilities of the haptic interface. Secondary haptic effects including field forces, friction, and texture can be easily incorporated to convey information about additional characteristics of the data. We illustrate the technique with two examples: displaying fiber orientation in heart muscle layers and exploring diffusion tensor fiber tracts in brain white matter tissue. Initial evaluation of the approach indicates that haptic constraints provide an intuitive means or displaying directional information in volume data.
Keywords: brain white matter tissue;constraint-based technique;data probe;data visualisation;diffusion tensor fiber tracts;directional constraints;directional information;exploration modes;fiber orientation;field forces;haptic effects;haptic interfaces;haptic rendering;haptic volume exploration;heart muscle layers;human-computer interaction;immersive visualization;medical computing;reaction forces;spring coupler;transfer functions;virtual reality;volumetric datasets;
Author: Ikits, M.; Brederson, J.D.; Hansen, C.D.; Johnson, C.R.

Year: 2003
Title: Voxels on fire [computer animation]
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250382
Abstract: We introduce a method for the animation of fire propagation and the burning consumption of objects represented as volumetric data sets. Our method uses a volumetric fire propagation model based on an enhanced distance field. It can simulate the spreading of multiple fire fronts over a specified isosurface without actually having to create that isosurface. The distance field is generated from a specific shell volume that rapidly creates narrow spatial bands around the virtual surface of any given isovalue. The complete distance field is then obtained by propagation from the initial bands. At each step multiple fire fronts can evolve simultaneously on the volumetric object. The flames of the fire are constructed from streams of particles whose movement is regulated by a velocity field generated with the hardware-accelerated Lattice Boltzmann Model (LBM). The LBM provides a physically-based simulation of the air flow around the burning object. The object voxels and the splats associated with the flame particles are rendered in the same pipeline so that the volume data with its external and internal structures can be displayed along with the fire.
Keywords: Boltzmann machines;GPU acceleration;burning consumption;computational geometry;computer animation;enhanced distance field;fire propagation animation;fires;flames;hardware-accelerated Lattice Boltzmann Model;isosurfaces;multiple fire fronts;object voxels;physically-based simulation;rendering (computer graphics);shell volume;splats;volumetric data sets;volumetric fire propagation model;
Author: Ye Zhao; Xiaoming Wei; Zhe Fan; Kaufman, A.; Hong Qin

Year: 2003
Title: Visually accurate multi-field weather visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250383
Abstract: Weather visualization is a difficult problem because it comprises volumetric multi-field data and traditional surface-based approaches obscure details of the complex three-dimensional structure of cloud dynamics. Therefore, visually accurate volumetric multi-field visualization of storm scale and cloud scale data is needed to effectively and efficiently communicate vital information to weather forecasters, improving storm forecasting, atmospheric dynamics models, and weather spotter training. We have developed a new approach to multi-field visualization that uses field specific, physically-based opacity, transmission, and lighting calculations per-field for the accurate visualization of storm and cloud scale weather data. Our approach extends traditional transfer function approaches to multi-field data and to volumetric illumination and scattering.
Keywords: atmospheric dynamics models;cloud dynamics;cloud scale;clouds;computer animation;data visualisation;image enhancement;lighting calculations;multifield weather visualization;physically-based opacity;rendering (computer graphics);storm forecasting;storm scale;surface-based approaches;transfer function approaches;visually accurate visualization;volumetric illumination;volumetric multifield data;weather forecasting;weather forecasting;weather spotter training;
Author: Riley, K.; Ebert, D.; Hansen, C.; Levit, J.

Year: 2003
Title: Acceleration techniques for GPU-based volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250384
Abstract: Nowadays, direct volume rendering via 3D textures has positioned itself as an efficient tool for the display and visual analysis of volumetric scalar fields. It is commonly accepted, that for reasonably sized data sets appropriate quality at interactive rates can be achieved by means of this technique. However, despite these benefits one important issue has received little attention throughout the ongoing discussion of texture based volume rendering: the integration of acceleration techniques to reduce per-fragment operations. In this paper, we address the integration of early ray termination and empty-space skipping into texture based volume rendering on graphical processing units (GPU). Therefore, we describe volume ray-casting on programmable graphics hardware as an alternative to object-order approaches. We exploit the early z-test to terminate fragment processing once sufficient opacity has been accumulated, and to skip empty space along the rays of sight. We demonstrate performance gains up to a factor of 3 for typical renditions of volumetric data sets on the ATI 9700 graphics card.
Keywords: 3D textures;ATI 9700 graphics card;GPU;GPU-based volume rendering;acceleration technique;computer graphic equipment;direct volume rendering;display analysis;early ray termination;empty-space skipping;fragment processing;graphical processing units;image texture;per-fragment operation;programmable graphics hardware;ray tracing;rendering (computer graphics);solid modelling;texture based volume rendering;visual analysis;volume ray-casting;volumetric scalar fields;
Author: Kruger, J.; Westermann, R.

Year: 2003
Title: Compression domain volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250385
Abstract: A survey of graphics developers on the issue of texture mapping hardware for volume rendering would most likely find that the vast majority of them view limited texture memory as one of the most serious drawbacks of an otherwise fine technology. In this paper, we propose a compression scheme for static and time-varying volumetric data sets based on vector quantization that allows us to circumvent this limitation. We describe a hierarchical quantization scheme that is based on a multiresolution covariance analysis of the original field. This allows for the efficient encoding of large-scale data sets, yet providing a mechanism to exploit temporal coherence in non-stationary fields. We show, that decoding and rendering the compressed data stream can be done on the graphics chip using programmable hardware. In this way, data transfer between the CPU and the graphics processing unit (GPU) can be minimized thus enabling flexible and memory efficient real-time rendering options. We demonstrate the effectiveness of our approach by demonstrating interactive renditions of Gigabyte data sets at reasonable fidelity on commodity graphics hardware.
Keywords: CPU;GPU;commodity graphics hardware;compression domain volume rendering;computer graphic equipment;data transfer;gigabyte data sets;graphics processing unit;hierarchical quantization;image texture;multiresolution covariance analysis;programmable hardware;real-time rendering;rendering (computer graphics);temporal coherence;texture mapping hardware;texture memory;time-varying volumetric data set;vector quantisation;vector quantization;
Author: Schneider, J.; Westermann, R.

Year: 2003
Title: High-quality two-level volume rendering of segmented data sets on consumer graphics hardware
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250386
Abstract: One of the most important goals in volume rendering is to be able to visually separate and selectively enable specific objects of interest contained in a single volumetric data set, which can be approached by using explicit segmentation information. We show how segmented data sets can be rendered interactively on current consumer graphics hardware with high image quality and pixel-resolution filtering of object boundaries. In order to enhance object perception, we employ different levels of object distinction. First, each object can be assigned an individual transfer function, multiple of which can be applied in a single rendering pass. Second, different rendering modes such as direct volume rendering, iso-surfacing, and non-photorealistic techniques can be selected for each object. A minimal number of rendering passes is achieved by processing sets of objects that share the same rendering mode in a single pass. Third, local compositing modes such as alpha blending and MIP can be selected for each object in addition to a single global mode, thus enabling high-quality two-level volume rendering on GPUs.
Keywords: MIP;alpha blending;consumer graphics hardware;direct volume rendering;image quality;image segmentation;iso-surfacing;nonphotorealistic rendering;pixel-resolution filtering;rendering (computer graphics);rendering mode;segmentated data sets;single rendering pass;solid modelling;volumetric data set;
Author: Hadwiger, M.; Berger, C.; Hauser, H.

Year: 2003
Title: Hardware-based nonlinear filtering and segmentation using high-level shading languages
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250387
Abstract: Non-linear filtering is an important task for volume analysis. This paper presents hardware-based implementations of various non-linear filters for volume smoothing with edge preservation. The Cg high-level shading language is used in combination with latest PC consumer graphics hardware. Filtering is divided into pervertex and per-fragment stages. In both stages we propose techniques to increase the filtering performance. The vertex program pre-computes texture coordinates in order to address all contributing input samples of the operator mask. Thus additional computations are avoided in the fragment program. The presented fragment programs preserve cache coherence, exploit 4D vector arithmetic, and internal fixed point arithmetic to increase performance. We show the applicability of non-linear filters as part of a GPU-based segmentation pipeline. The resulting binary mask is compressed and decompressed in the graphics memory on-the-fly.
Keywords: 4D vector arithmetic;GPU;cache coherence;computer graphic equipment;computer graphics;consumer graphics hardware;edge preservation;graphical processing unit;graphics memory;hardware-based nonlinear filtering;high-level shading languages;image segmentation;image segmentation;nonlinear filters;visual languages;visual programming;volume analysis;volume smoothing;
Author: Viola, I.; Kanitsar, A.; Groller, M.E.

Year: 2003
Title: Empty space skipping and occlusion clipping for texture-based volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250388
Abstract: We propose methods to accelerate texture-based volume rendering by skipping invisible voxels. We partition the volume into sub-volumes, each containing voxels with similar properties. Sub-volumes composed of only voxels mapped to empty by the transfer function are skipped. To render the adaptively partitioned sub-volumes in visibility order, we reorganize them into an orthogonal BSP tree. We also present an algorithm that computes incrementally the intersection of the volume with the slicing planes, which avoids the overhead of the intersection and texture coordinates computation introduced by the partitioning. Rendering with empty space skipping is 2 to 5 times faster than without it. To skip occluded voxels, we introduce the concept of orthogonal opacity map, that simplifies the transformation between the volume coordinates and the opacity map coordinates, which is intensively used for occlusion detection. The map is updated efficiently by the GPU. The sub-volumes are then culled and clipped against the opacity map. We also present a method that adaptively adjusts the optimal number of the opacity map updates. With occlusion clipping, about 60% of non-empty voxels can be skipped and an additional 80% speedup on average is gained for iso-surface-like rendering.
Keywords: computer graphic equipment;empty space skipping;image texture;invisible voxels;iso-surface-like rendering;occlusion clipping;orthogonal BSP tree;orthogonal opacity map;rendering (computer graphics);solid modelling;texture coordinate;texture-based volume rendering;transfer function;
Author: Wei Li; Mueller, K.; Kaufman, A.

Year: 2003
Title: Hierarchical clustering for unstructured volumetric scalar fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250389
Abstract: We present a method to represent unstructured scalar fields at multiple levels of detail. Using a parallelizable classification algorithm to build a cluster hierarchy, we generate a multiresolution representation of a given volumetric scalar data set. The method uses principal component analysis (PCA) for cluster generation and a fitting technique based on radial basis functions (RBFs). Once the cluster hierarchy has been generated, we utilize a variety of techniques for extracting different levels of detail. The main strength of this work is its generality. Regardless of grid type, this method can be applied to any discrete scalar field representation, even one given as a "point cloud".
Keywords: PCA;algorithm theory;cluster generation;cluster hierarchy;data visualisation;hierarchical clustring;multiresolution representation;parallelizable classification algorithm;point cloud;principal component analysis;principal component analysis;radial basis function;rendering (computer graphics);scalar field representation;solid modelling;unstructure volumetric scalar fields;volumetric scalar data set;
Author: Co, C.S.; Heckel, B.; Hagen H; Hamann, B.; Joy, K.I.

Year: 2003
Title: Hardware-based ray casting for tetrahedral meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250390
Abstract: We present the first implementation of a volume ray casting algorithm for tetrahedral meshes running on off-the-shelf programmable graphics hardware. Our implementation avoids the memory transfer bottleneck of the graphics bus since the complete mesh data is stored in the local memory of the graphics adapter and all computations, in particular ray traversal and ray integration, are performed by the graphics processing unit. Analogously to other ray casting algorithms, our algorithm does not require an expensive cell sorting. Provided that the graphics adapter offers enough texture memory, our implementation performs comparable to the fastest published volume rendering algorithms for unstructured meshes. Our approach works with cyclic and/or non-convex meshes and supports early ray termination. Accurate ray integration is guaranteed by applying pre-integrated volume rendering. In order to achieve almost interactive modifications of transfer functions, we propose a new method for computing three-dimensional pre-integration tables.
Keywords: computer graphic equipment;cyclic mesh;early ray termination;graphics adapter;hardware-based ray casting;image processing;memory transfer bottleneck;mesh data;nonconvex mesh;off-the-shelf programmable graphics hardware;ray integration;ray tracing;ray traversal;rendering (computer graphics);rendering algorithm;tetrahedral meshes;three-dimensional pre-integration tables;unstructured mesh;
Author: Weiler, M.; Kraus, M.; Merz, M.; Ertl, T.

Year: 2003
Title: Visibility culling using plenoptic opacity functions for large volume visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250391
Abstract: Visibility culling has the potential to accelerate large data visualization in significant ways. Unfortunately, existing algorithms do not scale well when parallelized, and require full re-computation whenever the opacity transfer function is modified. To address these issues, we have designed a Plenoptic Opacity Function (POF) scheme to encode the view-dependent opacity of a volume block. POFs are computed off-line during a pre-processing stage, only once for each block. We show that using POFs is (i) an efficient, conservative and effective way to encode the opacity variations of a volume block for a range of views, (ii) flexible for re-use by a family of opacity transfer functions without the need for additional off-line processing, and (iii) highly scalable for use in massively parallel implementations. Our results confirm the efficacy of POFs for visibility culling in large-scale parallel volume rendering; we can interactively render the Visible Woman dataset using software ray-casting on 32 processors, with interactive modification of the opacity transfer function on-the-fly.
Keywords: POF;data set;data visualisation;data visualization;image classification;large volume visualization;off-line processing;opacity transfer function;parallel implementation;parallel volume rendering;plenoptic opacity function;ray casting;ray tracing;rendering (computer graphics);solid modelling;visibility culling;
Author: Jinzhu Gao; Jian Huang; Han-Wei Shen; Kohl, J.A.

Year: 2003
Title: Conveying shape and features with image-based relighting
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250392
Abstract: Hand-crafted illustrations are often more effective than photographs for conveying the shape and important features of an object, but they require expertise and time to produce. We describe an image compositing system and user interface that allow an artist to quickly and easily create technical illustrations from a set of photographs of an object taken from the same point of view under variable lighting conditions. Our system uses a novel compositing process in which images are combined using spatially-varying light mattes, enabling the final lighting in each area of the composite to be manipulated independently. We describe an interface that provides for the painting of local lighting effects (e.g. shadows, highlights, and tangential lighting to reveal texture) directly onto the composite. We survey some of the techniques used in illustration and lighting design to convey the shape and features of objects and describe how our system can be used to apply these techniques.
Keywords: archaeology;compositing process;highlights;image classification;image compositing system;image intensifiers;image processing;image texture;image texture;image-based relighting;photographs;rendering (computer graphics);shadows;tangential lighting;technical illustration;user interface;
Author: Akers, D.; Losasso, F.; Klingner, J.; Agrawala, M.; Rick, J.; Hanrahan, P.

Year: 2003
Title: Vicinity shading for enhanced perception of volumetric data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250394
Abstract: This paper presents a shading model for volumetric data which enhances the perception of surfaces within the volume. The model incorporates uniform diffuse illumination, which arrives equally from all directions at each surface point in the volume. This illumination is attenuated by occlusions in the local vicinity of the surface point, resulting in shadows in depressions and crevices. Experiments by other authors have shown that perception of a surface is superior under uniform diffuse lighting, compared to illumination from point source lighting.
Keywords: image classification;perceptual cues;point source lighting;rendering (computer graphics);shading model;solid modelling;uniform diffuse illumination;vicinity shading;volume rendering;volumetric data;
Author: Stewart, A.J.

Year: 2003
Title: LightKit: a lighting system for effective visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250395
Abstract: LightKit is a system for lighting three-dimensional synthetic scenes. LightKit simplifies the task of producing visually pleasing, easily interpretable images for visualization while making it harder to produce results where the scene illumination distracts from the visualization process. LightKit is based on lighting designs developed by artists and photographers and shown in previous studies to enhance shape perception. A key light provides natural overhead illumination of the scene, augmented by fill, head, and back lights. By default, lights are attached to a normalized, subject-centric, camera-relative coordinate frame to ensure consistent lighting independent of camera location or orientation. This system allows all lights to be positioned by specifying just six parameters. The intensity of each light is specified as a ratio to the key light intensity, allowing the scene's brightness to be adjusted using a single parameter. The color of each light is specified by a single normalized color parameter called warmth that is based on color temperature of natural sources. LightKit's default values for light position, intensity, and color are chosen to produce good results for a variety of scenes. LightKit is designed to work with both hardware graphics systems and, potentially, higher quality off-line rendering systems. We provide examples of images created using a LightKit implementation within the VTK visualization toolkit software framework.
Keywords: LightKit;VTK visualization toolkit;hardware graphics;image classification;light intensity;lighting;off-line rendering;rendering (computer graphics);scene illumination;solid modelling;three-dimensional synthetic scene;visualization process;
Author: Halle, M.; Meng, J.

Year: 2003
Title: Mental registration of 2D and 3D visualizations (an empirical study)
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250396
Abstract: 2D and 3D views are used together in many visualization domains, such as medical imaging, flow visualization, oceanographic visualization, and computer aided design (CAD). Combining these views into one display can be done by: (1) orientation icon (i.e., separate windows), (2) in-place methods (e.g., clip and cutting planes), and (3) a new method called ExoVis. How 2D and 3D views are displayed affects ease of mental registration (understanding the spatial relationship between views), an important factor influencing user performance. This paper compares the above methods in terms of their ability to support mental registration. Empirical results show that mental registration is significantly easier with in-place displays than with ExoVis, and significantly easier with ExoVis than with orientation icons. Different mental transformation strategies can explain this result. The results suggest that ExoVis may be a better alternative to orientation icons when in-place displays are not appropriate (e.g., when in-place methods hide data or cut the 3D view into several pieces).
Keywords: 2D visualization;3D visualization;CAD;CAD;ExoVis;computer aided design;data visualisation;flow visualization;graphical user interfaces;image processing;in-place method;magnetic resonance imaging;medical imaging;mental registration;oceanographic visualization;orientation icon;solid modelling;visualization domain;
Author: Tory, M.

Year: 2003
Title: Visualization of noisy and biased volume data using first and second order derivative techniques
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250397
Abstract: The quality of volume visualization depends strongly on the quality of the underlying data. In virtual colonoscopy, CT data should be acquired at a low radiation dose that results in a low signal-to-noise ratio. Alternatively, MRI data is acquired without ionizing radiation, but suffers from noise and bias (global signal fluctuations). Current volume visualization techniques often do not produce good results with noisy or biased data. This paper describes methods for volume visualization that deal with these imperfections. The techniques are based on specially adapted edge detectors using first and second order derivative filters. The filtering is integrated into the visualization process. The first order derivative method results in good quality images but suffers from localization bias. The second order method has better surface localization, especially in highly curved areas. It guarantees minimal detail smoothing resulting in a better visualization of polyps.
Keywords: CT data;MRI;bias field;biased volume data;data visualisation;data visualization;direct volume rendering;edge detector;first order derivative technique;global signal fluctuation;localization bias;medical image processing;medical imaging;noisy volume data;polyps;rendering (computer graphics);second order derivative technique;signal filtering;signal-to-noise ratio;surface extraction;surface localization;virtual colonoscopy;volume visualization;
Author: Persoon, M.P.; Serlie, I.W.O.; Post, F.H.; Truyen, R.; Vos, F.M.

Year: 2003
Title: Fairing scalar fields by variational modeling of contours
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250398
Abstract: Volume rendering and isosurface extraction from three-dimensional scalar fields are mostly based on piecewise trilinear representations. In regions of high geometric complexity such visualization methods often exhibit artifacts, due to trilinear interpolation. In this work, we present an iterative fairing method for scalar fields interpolating function values associated with grid points while smoothing the contours inside the grid cells based on variational principles. We present a local fairing method providing a piecewise bicubic representation of two-dimensional scalar fields. Our algorithm generalizes to the trivariate case and can be used to increase the resolution of data sets either locally or globally, reducing interpolation artifacts. In contrast to filtering methods, our algorithm does not reduce geometric detail supported by the data.
Keywords: algorithm;approximation theory;artifacts;contour;data set;filtering;image enhancement;interpolation;isosurface extraction;optimisation;rendering (computer graphics);resolution;scalar fields fairing;solid modelling;three-dimensional scalar field;trilinear interpolation;trilinear representation;two-dimensional scalar field;variational modeling;variational techniques;visualization;volume rendering;
Author: Bertram, M.

Year: 2003
Title: Visualization of volume data with quadratic super splines
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250399
Abstract: We develop a new approach to reconstruct non-discrete models from gridded volume samples. As a model, we use quadratic trivariate super splines on a uniform tetrahedral partition &Delta;. The approximating splines are determined in a natural and completely symmetric way by averaging local data samples, such that appropriate smoothness conditions are automatically satisfied. On each tetra-hedron of &Delta; , the quasi-interpolating spline is a polynomial of total degree two which provides several advantages including efficient computation, evaluation and visualization of the model. We apply Bernstein-Bezier techniques well-known in CAGD to compute and evaluate the trivariate spline and its gradient. With this approach the volume data can be visualized efficiently e.g., with isosurface ray-casting. Along an arbitrary ray the splines are univariate, piecewise quadratics and thus the exact intersection for a prescribed isovalue can be easily determined in an analytic and exact way. Our results confirm the efficiency of the quasi-interpolating method and demonstrate high visual quality for rendered isosurfaces.
Keywords: Bernstein-Bezier techniques;CAGD;computational geometry;data visualisation;image reconstruction;isosurface ray casting;isosurface rendering;nondiscrete model reconstruction;quadratic super splines;quadratic trivariate super spline;quasiinterpolating spline;ray tracing;ray-casting;rendered isosurface;rendering (computer graphics);super spline reconstruction;tetrahedral partitioning;uniform tetrahedral partition;volume data visualization;volume rendering;
Author: Rossl, C.; Zeilfelder, F.; Nurnberger, G.; Seidel, H.-P.

Year: 2003
Title: Using deformations for browsing volumetric data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250400
Abstract: Many traditional techniques for "looking inside" volumetric data involve removing portions of the data, for example using various cutting tools, to reveal the interior. This allows the user to see hidden parts of the data, but has the disadvantage of removing potentially important surrounding contextual information. We explore an alternate strategy for browsing that uses deformations, where the user can cut into and open up, spread apart, or peel away parts of the volume in real time, making the interior visible while still retaining surrounding context. We consider various deformation strategies and present a number of interaction techniques based on different metaphors. Our designs pay special attention to the semantic layers that might compose a volume (e.g. the skin, muscle, bone in a scan of a human). Users can apply deformations to only selected layers, or apply a given deformation to a different degree to each layer, making browsing more flexible and facilitating the visualization of relationships between layers. Our interaction techniques are controlled with direct, "in place" manipulation, using pop-up menus and 3D widgets, to avoid the divided attention and awkwardness that would come with panels of traditional widgets. Initial user feedback indicates that our techniques are valuable, especially for showing portions of the data spatially situated in context with surrounding data.
Keywords: 3D widgets;data visualisation;graphical user interfaces;image deformation;interaction techniques;pop-up menu;rendering (computer graphics);semantic layers;solid modelling;spatial data;volumetric data browsing;
Author: McGuffin, M.J.; Tancau, L.; Balakrishnan, R.

Year: 2003
Title: Video visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250401
Abstract: Video data, generated by the entertainment industry, security and traffic cameras, video conferencing systems, video emails, and so on, is perhaps most time-consuming to process by human beings. In this paper, we present a novel methodology for "summarizing" video sequences using volume visualization techniques. We outline a system pipeline for capturing videos, extracting features, volume rendering video and feature data, and creating video visualization. We discuss a collection of image comparison metrics, including the linear dependence detector, for constructing "relative" and "absolute" difference volumes that represent the magnitude of variation between video frames. We describe the use of a few volume visualization techniques, including volume scene graphs and spatial transfer functions, for creating video visualization. In particular, we present a stream-based technique for processing and directly rendering video data in real time. With the aid of several examples, we demonstrate the effectiveness of using video visualization to convey meaningful information contained in video sequences.
Keywords: data visualisation;image comparison metrics;image sequences;linear dependence detector;security camera;spatial transfer technique;stream-based technique;traffic camera;video capturing;video conferencing system;video data;video email;video processing;video rendering;video sequences;video signal processing;video visualization;volume rendering video;volume scene graph;volume visualization;
Author: Daniel, G.; Min Chen

Year: 2003
Title: High dimensional direct rendering of time-varying volumetric data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250402
Abstract: We present an alternative method for viewing time-varying volumetric data. We consider such data as a four-dimensional data field, rather than considering space and time as separate entities. If we treat the data in this manner, we can apply high dimensional slicing and projection techniques to generate an image hyperplane. The user is provided with an intuitive user interface to specify arbitrary hyperplanes in 4D, which can be displayed with standard volume rendering techniques. From the volume specification, we are able to extract arbitrary hyperslices, combine slices together into a hyperprojection volume, or apply a 4D raycasting method to generate the same results. In combination with appropriate integration operators and transfer functions, we are able to extract and present different space-time features to the user.
Keywords: 4D raycasting;data visualisation;four-dimensional data field;high dimensional direct rendering;high dimensional projection;high dimensional slicing;hyperplanes;hyperprojection volume;hyperslice;image classification;image hyperplane;integration operator;ray tracing;rendering (computer graphics);solid modelling;space-time feature;time-varying data;time-varying systems;time-varying volumetric data;transfer function;user interface;volume rendering;volume specification;
Author: Woodring, J.; Chaoli Wang; Han-Wei Shen

Year: 2003
Title: A frequency-sensitive point hierarchy for images and volumes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250403
Abstract: This paper introduces a method for converting an image or volume sampled on a regular grid into a space-efficient irregular point hierarchy. The conversion process retains the original frequency characteristics of the dataset by matching the spatial distribution of sample points with the required frequency. To achieve good blending, the spherical points commonly used in volume rendering are generalized to ellipsoidal point primitives. A family of multiresolution, oriented Gabor wavelets provide the frequency-space analysis of the dataset. The outcome of this frequency analysis is the reduced set of points, in which the sampling rate is decreased in originally oversampled areas. During rendering, the traversal of the hierarchy can be controlled by any suitable error metric or quality criteria. The local level of refinement is also sensitive to the transfer function. Areas with density ranges mapped to high transfer function variability are rendered at higher point resolution than others. Our decomposition is flexible and can be used for iso-surface rendering, alpha compositing and X-ray rendering of volumes. We demonstrate our hierarchy with an interactive splatting volume renderer, in which the traversal of the point hierarchy for rendering is modulated by a user-specified frame rate.
Keywords: Gavor wavelet;X-ray rendering;ellipsoidal point primitives;error metric;frequency characteristics;frequency-sensitive point hierarchy;frequency-space analysis;image conversion;image processing;interactive splatting volume renderer;iso-surface rendering;quality criteria;rendering (computer graphics);sampling rate;space-efficient irregular point hierarchy;spherical point;transfer function;user-specified frame rate;
Author: Welsh, T.; Mueller, K.

Year: 2003
Title: Herarchical splatting of scattered data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250404
Abstract: Numerical particle simulations and astronomical observations create huge data sets containing uncorrelated 3D points of varying size. These data sets cannot be visualized interactively by simply rendering millions of colored points for each frame. Therefore, in many visualization applications a scalar density corresponding to the point distribution is resampled on a regular grid for direct volume rendering. However, many fine details are usually lost for voxel resolutions which still allow interactive visualization on standard workstations. Since no surface geometry is associated with our data sets, the recently introduced point-based rendering algorithms cannot be applied as well. In this paper we propose to accelerate the visualization of scattered point data by a hierarchical data structure based on a PCA clustering procedure. By traversing this structure for each frame we can trade-off rendering speed vs. image quality. Our scheme also reduces memory consumption by using quantized relative coordinates and it allows for fast sorting of semi-transparent clusters. We analyze various software and hardware implementations of our renderer and demonstrate that we can now visualize data sets with tens of millions of points interactively with sub-pixel screen space error on current PC graphics hardware employing advanced vertex shader functionality.
Keywords: 3D points;PCA clustering;algorithm theory;astronomical observation;colored points;data visualisation;data visualization;direct volume rendering;hierarchical splatting;hierarchical visualization;image processing;image quality;interactive visualization;numerical particle simulation;pattern clustering;point distribution;point-based rendering algorithm;rendering (computer graphics);scalar density;scattered data;solid modelling;surface geometry;vertex shader;visualization application;voxel resolution;
Author: Hopf, M.; Ertl, T.

Year: 2003
Title: A framework for sample-based rendering with O-buffers
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250405
Abstract: We present an innovative modeling and rendering primitive, called the O-buffer, for sample-based graphics, such as images, volumes and points. The 2D or 3D O-buffer is in essence a conventional image or a volume, respectively, except that samples are not restricted to a regular grid. A sample position in the O-buffer is recorded as an offset to the nearest grid point of a regular base grid (hence the name O-buffer). The offset is typically quantized for compact representation and efficient rendering. The O-buffer emancipates pixels and voxels from the regular grids and can greatly improve the modeling power of images and volumes. It is a semi-regular structure which lends itself to efficient construction and rendering. Image quality can be improved by storing more spatial information with samples and by avoiding multiple resamplings and delaying reconstruction to the final rendering stage. Using O-buffers, more accurate multi-resolution representations can be developed for images and volumes. It can also be exploited to represent and render unstructured primitives, such as points, particles, curvilinear or irregular volumes. The O-buffer is therefore a uniform representation for a variety of graphics primitives and supports mixing them in the same scene. We demonstrate the effectiveness of the O-buffer with hierarchical O-buffers, layered depth O-buffers, and hybrid volume rendering with O-buffers.
Keywords: 2D O-buffer;3D O-buffer;antialiasing;delaying reconstruction;frame buffer;hierarchical O-buffers;hybrid rendering;hybrid volume rendering;image quality;image representation;image-based rendering;irregular sampling;layered depth O-buffers;layered depth image;multiple resamplings;regular base grid;rendering (computer graphics);sample-based graphics;sample-based rendering;spatial information;
Author: Huamin Qu; Kaufman, A.; Ran Shao; Kumar, A.

Year: 2003
Title: Monte Carlo volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250406
Abstract: In this paper a novel volume-rendering technique based on Monte Carlo integration is presented. As a result of a preprocessing, a point cloud of random samples is generated using a normalized continuous reconstruction of the volume as a probability density function. This point cloud is projected onto the image plane, and to each pixel an intensity value is assigned which is proportional to the number of samples projected onto the corresponding pixel area. In such a way a simulated X-ray image of the volume can be obtained. Theoretically, for a fixed image resolution, there exists an M number of samples such that the average standard deviation of the estimated pixel intensities us under the level of quantization error regardless of the number of voxels. Therefore Monte Carlo Volume Rendering (MCVR) is mainly proposed to efficiently visualize large volume data sets. Furthermore, network applications are also supported, since the trade-off between image quality and interactivity can be adapted to the bandwidth of the client/server connection by using progressive refinement.
Keywords: MCVR;Monte Carlo Volume Rendering;Monte Carlo integration;Monte Carlo methods;Monte Carlo volume rendering;X-ray image;client/server connection;image interactivity;image processing;image quality;image resolution;pixel intensity;probability;probability density function;progressive refinement;quantization error;rendering (computer graphics);volume reconstruction;
Author: Csebfalvi, B.; Szirmay-Kalos, L.

Year: 2003
Title: Visibility based methods and assessment for detail-recovery
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250407
Abstract: In this paper we propose a new method for the creation of normal maps for recovering the detail on simplified meshes and a set of objective techniques to metrically evaluate the quality of different recovering techniques. The proposed techniques, that automatically produces a normal-map texture for a simple 3D model that "imitates" the high frequency detail originally present in a second, much higher resolution one, is based on the computation of per-texel visibility and self-occlusion information. This information is used to define a point-to-point correspondence between simplified and hires meshes. Moreover, we introduce a number of criteria for measuring the quality (visual or otherwise) of a given mapping method, and provide efficient algorithms to implement them. Lastly, we apply them to rate different mapping methods, including the widely used ones and the new one proposed here.
Keywords: detail recovery;geometry texture;hires meshes;image restoration;image texture;mapping method;mesh generation;normal mapping;per-texel visibility;recovering technique;rendering (computer graphics);self-occlusion information;simplified meshes;texture mapping;visibility based assessment;visibility based method;
Author: Tarini, M.; Cignoni, P.; Scopigno, R.

Year: 2003
Title: Large mesh simplification using processing sequences
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250408
Abstract: In this paper we show how out-of-core mesh processing techniques can be adapted to perform their computations based on the new processing sequence paradigm (Isenburg, et al., 2003), using mesh simplification as an example. We believe that this processing concept will also prove useful for other tasks, such a parameterization, remeshing, or smoothing, for which currently only in-core solutions exist. A processing sequence represents a mesh as a particular interleaved ordering of indexed triangles and vertices. This representation allows streaming very large meshes through main memory while maintaining information about the visitation status of edges and vertices. At any time, only a small portion of the mesh is kept in-core, with the bulk of the mesh data residing on disk. Mesh access is restricted to a fixed traversal order, but full connectivity and geometry information is available for the active elements of the traversal. This provides seamless and highly efficient out-of-core access to very large meshes for algorithms that can adapt their computations to this fixed ordering. The two abstractions that are naturally supported by this representation are boundary-based and buffer-based processing. We illustrate both abstractions by adapting two different simplification methods to perform their computation using a prototype of our mesh processing sequence API. Both algorithms benefit from using processing sequences in terms of improved quality, more efficient execution, and smaller memory footprints.
Keywords: API;abstractions;application program interfaces;boundary-based processing;buffer-based processing;connectivity information;geometry information;image sequences;mesh access;mesh data;mesh processing sequence;mesh simplification;out-of-core access;out-of-core algorithm;out-of-core mesh processing;solid modelling;traversal active elements;traversal order;
Author: Isenburg, M.; Lindstrom, P.; Gumhold, S.; Snoeyink, J.

Year: 2003
Title: Appearance-preserving view-dependent visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250409
Abstract: In this paper a new quadric-based view-dependent simplification scheme is presented. The scheme provides a method to connect mesh simplification controlled by a quadric error metric with a level-of-detail hierarchy that is accessed continuously and efficiently based on current view parameters. A variety of methods for determining the screen-space metric for the view calculation are implemented and evaluated, including an appearance-preserving method that has both geometry- and texture-preserving aspects. Results are presented and compared for a variety of models.
Keywords: appearance-preserving visualization;computational geometry;data visualisation;geometry-preserving aspect;level-of-detail hierarchy;mesh simplification;multiresolution models;quadric error metric;quadric-based simplification;screen-space metric;texture-preserving aspect;view-dependent simplification;view-dependent visualization;
Author: Jang, J.; Ribarsky, W.; Shaw, C.; Wonka, P.

Year: 2003
Title: Shape simplification based on the medial axis transform
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250410
Abstract: We present a new algorithm for simplifying the shape of 3D objects by manipulating their medial axis transform (MAT). From an unorganized set of boundary points, our algorithm computes the MAT, decomposes the axis into parts, then selectively removes a subset of these parts in order to reduce the complexity of the overall shape. The result is simplified MAT that can be used for a variety of shape operations. In addition, a polygonal surface of the resulting shape can be directly generated from the filtered MAT using a robust surface reconstruction method. The algorithm presented is shown to have a number of advantages over other existing approaches.
Keywords: 3D objects;MAT;computational geometry;image reconstruction;medial axis transform;polygonal surface;shape simplification;solid modelling;surface reconstruction;surface reconstruction method;topology preservation;
Author: Tam, R.; Heidrich, W.

Year: 2003
Title: Adaptive design of a global opacity transfer function for direct volume rendering of ultrasound data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250411
Abstract: While there are a couple of transfer function design approaches for CT and MRI (magnetic resonance imaging) data, direct volume rendering of ultrasound data still relies on manual adjustment of an inflexible piecewise linear opacity transfer function (OTF) on a trial-and-error basis. The main challenge of automatically designing an OTF for visualization of sonographic data is the low signal-to-noise ratio in combination with real time data acquisition at frame rates up to 25 volumes per second. In this paper, we present an efficient solution of this task. Our approach is based on the evaluation of tube cores, i.e., collections of voxels gathered by traversing the volume in rendering directions. We use information about the probable position of an interface between tissues of different echogenicity to adaptively design an OTF in a multiplicative way. We show the appropriateness of our approach by examples, deliberately on data sets of moderate quality arising frequently in clinical settings.
Keywords: 3D ultrasound;CT data;MRI data;biomedical MRI;data acquisition;direct volume rendering;echogenicity;global OTF;linear OTF;magnetic resonance imaging;opacity transfer function;realistic images;rendering (computer graphics);signal-to-noise ratio;sonographic data;transfer functions;tube cores;voxels;
Author: Honigmann, D.; Ruisz, J.; Haider, C.

Year: 2003
Title: Gaussian transfer functions for multi-field volume visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250412
Abstract: Volume rendering is a flexible technique for visualizing dense 3D volumetric datasets. A central element of volume rendering is the conversion between data values and observable quantities such as color and opacity. This process is usually realized through the use of transfer functions that are precomputed and stored in lookup tables. For multidimensional transfer functions applied to multivariate data, these lookup tables become prohibitively large. We propose the direct evaluation of a particular type of transfer functions based on a sum of Gaussians. Because of their simple form (in terms of number of parameters), these functions and their analytic integrals along line segments can be evaluated efficiently on current graphics hardware, obviating the need for precomputed lookup tables. We have adopted these transfer functions because they are well suited for classification based on a unique combination of multiple data values that localize features in the transfer function domain. We apply this technique to the visualization of several multivariate datasets (CT, cryosection) that are difficult to classify and render accurately at interactive rates using traditional approaches.
Keywords: 3D volumetric datasets;CT;Gaussian distribution;Gaussian transfer functions;cryosection;data visualisation;graphics hardware;multidimensional transfer function;multifield visualization;multivariate data;realistic images;rendering (computer graphics);transfer functions;volume rendering;volume visualization;
Author: Kniss, J.; premoze, S.; Ikits, M.; Lefohn, A.; Hansen, C.; Praun, E.

Year: 2003
Title: A novel interface for higher-dimensional classification of volume data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250413
Abstract: In the traditional volume visualization paradigm, the user specifies a transfer function that assigns each scalar value to a color and opacity by defining an opacity and a color map function. The transfer function has two limitations. First, the user must define curves based on histogram and value rather than seeing and working with the volume itself. Second, the transfer function is inflexible in classifying regions of interest, where values at a voxel such as intensity and gradient are used to differentiate material, not talking into account additional properties such as texture and position. We describe an intuitive user interface for specifying the classification functions that consists of the users painting directly on sample slices of the volume. These painted regions are used to automatically define high-dimensional classification functions that can be implemented in hardware for interactive rendering. The classification of the volume is iteratively improved as the user paints samples, allowing intuitive and efficient viewing of materials of interest.
Keywords: artificial neural network;classification function;color map function;graphics hardware;image segmentation;interactive rendering;interactive visualization;knowledge acquisition;multidimensional transfer function;neural nets;opacity map function;realistic images;rendering (computer graphics);transfer functions;user interface;user interfaces;volume data;volume visualization;voxel;
Author: Fan-Yin Tzeng; Lum, E.B.; Kwan-Liu Ma

Year: 2003
Title: Curvature-based transfer functions for direct volume rendering: methods and applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250414
Abstract: Direct volume rendering of scalar fields uses a transfer function to map locally measured data properties to opacities and colors. The domain of the transfer function is typically the one-dimensional space of scalar data values. This paper advances the use of curvature information in multi-dimensional transfer functions, with a methodology for computing high-quality curvature measurements. The proposed methodology combines an implicit formulation of curvature with convolution-based reconstruction of the field. We give concrete guidelines for implementing the methodology, and illustrate the importance of choosing accurate filters for computing derivatives with convolution. Curvature-based transfer functions are shown to extend the expressivity and utility of volume rendering through contributions in three different application areas: nonphotorealistic volume rendering, surface smoothing via anisotropic diffusion, and visualization of isosurface uncertainty.
Keywords: anisotropic diffusion;convolution-based differentiation;convolution-based reconstruction;curvature information;curvature-based transfer function;direct volume rendering;flowline curvature;image processing;isosurface uncertainty visualization;multidimensional transfer function;nonphotorealistic volume rendering;realistic images;rendering (computer graphics);scalar field;surface curvature;surface smoothing;transfer functions;
Author: Kindlmann, G.; Whitaker, R.; Tasdizen, T.; Moller, T.

Year: 2003
Title: A visual exploration process for the analysis of Internet routing data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250415
Abstract: The Internet pervades many aspects of our lives and is becoming indispensable to critical functions in areas such as commerce, government, production and general information dissemination. To maintain the stability and efficiency of the Internet, every effort must be made to protect it against various forms of attacks, malicious users, and errors. A key component in the Internet security effort is the routine examination of Internet routing data, which unfortunately can be too large and complicated to browse directly. We have developed an interactive visualization process which proves to be very effective for the analysis of Internet routing data. In this application paper, we show how each step in the visualization process helps direct the analysis and glean insights from the data. These insights include the discovery of patterns, detection of faults and abnormal events, understanding of event correlations, formation of causation hypotheses, and classification of anomalies. We also discuss lessons learned in our visual analysis study.
Keywords: Internet;Internet routing data analysis;Internet security;Internet stability;data visualisation;graphical user interfaces;homeland security;information visualization;network visualization;security of data;text visualization;visual exploration;
Author: Soon Tee Teoh; Kwan-Liu Ma; Wu, S.F.

Year: 2003
Title: Visualization, optimization, business strategy: a case study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250416
Abstract: We describe a visualization application intended for operational use in formulating business strategy in the customer service arena. The visualization capability provided in this application implicitly allows the user to better formulate the objective function for large optimization runs which act to minimize costs based on certain input parameters. Visualization is necessary because many of the inputs to the optimization runs are themselves strategic business decisions which are not pre-ordained. Both information visualization presentations and three-dimensional visualizations are included to help users better understand the cost/benefit tradeoffs of these strategic business decisions. Here, visualization explicitly provides value not possible algorithmically, as the perceived benefit of different combinations of service level does not have an a priori mathematical formulation. Thus, we take advantage of the fundamental power of visualization, bringing the user's intuition and pattern recognition skills into the solution, while simultaneously taking advantage of the strength of algorithmic approaches to quickly and accurately find an optimal solution to a well-defined problem.
Keywords: VisAD;a priori mathematical formulation;business strategy;data visualisation;graphical user interfaces;information visualization;optimisation;optimization;pattern recognition;pattern recognition;
Author: Gresh, D.L.; Kelton, E.I.

Year: 2003
Title: Interactive 3D visualization of rigid body systems
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250417
Abstract: Simulation of rigid body dynamics has been a field of active research for quite some time. However, the presentation of simulation results has received far less attention so far. We present an interactive and intuitive 3D visualization framework for rigid body simulation data. We introduce various glyphs representing vector attributes such as force and velocity as well as angular attributes including angular velocity and torque. We have integrated our visualization method into an application developed at one of the leading companies in automotive engine design and simulation. We apply our principles to visualization of chain and belt driven timing drives in engines.
Keywords: automobile industry;automotive engine design;automotive engine simulation;automotive industry;colour graphics;data visualisation;digital simulation;engine belt driven timing drive visualization;engine chain visualization;glyph based visualization;graphical user interfaces;iconic visualization;interactive 3D visualization;interactive systems;intuitive 3D visualization;rigid body dynamics;rigid body simulation;three-dimensional visualization;
Author: Konyha, Z.; Matkovic, K.; Hauser, H.

Year: 2003
Title: Visualizing industrial CT volume data for nondestructive testing applications
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250418
Abstract: This paper describes a set of techniques developed for the visualization of high-resolution volume data generated from industrial computed tomography for nondestructive testing (NDT) applications. Because the data are typically noisy and contain fine features, direct volume rendering methods do not always give us satisfactory results. We have coupled region growing techniques and a 2D histogram interface to facilitate volumetric feature extraction. The new interface allows the user to conveniently identify, separate or composite, and compare features in the data. To lower the cost of segmentation, we show how partial region growing results can suggest a reasonably good classification function for the rendering of the whole volume. The NDT applications that we work on demand visualization tasks including not only feature extraction and visual inspection, but also modeling and measurement of concealed structures in volumetric objects. An efficient filtering and modeling process for generating surface representation of extracted features is also introduced. Four CT data sets for preliminary NDT are used to demonstrate the effectiveness of the new visualization strategy that we have developed.
Keywords: computed tomography;computerised tomography;data visualisation;data visualization;feature extraction;feature extraction;graphical user interfaces;hardware-acceleration rendering;image processing;industrial CT volume data;interactive visualization;nondestructive testing;nondestructive testing;rendering (computer graphics);scientific visualization;solid modelling;surface modeling;user interface;volume rendering;volume visualization;
Author: Huang, R.; Kwan-Liu Ma; McCormick, P.; Ward, W.

Year: 2003
Title: Visualization of steep breaking waves and thin spray sheets around a ship
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250419
Abstract: The simulation of breaking of waves, the formation of thin spray sheets, and the entertainment of air around the next generation of naval surface combatants is an ongoing 3-year Department of Defense (DoD) Challenge Project. The goal of this project is a validated computation capability to model the full hydrodynamics around a surface combatant including all of the processes that affect mission and performance. Visualization of these large-scale simulations is paramount to understanding the complex physics involved. These simulations produce enormous data sets with both surface and volumetric qualities. Wave breaking, spray sheets, and air entertainment can be visualized using isosurfaces of scalar data. Visualization of quantities such as the vorticity field also provides insight into the dynamics of droplet and bubble formation. This paper documents the techniques used, results obtained, and lessons learned from the visualization of the hydrodynamics of naval vessels.
Keywords: breaking wave simulation;computational fluid dynamics;data visualisation;hydrodynamics;hydrodynamics;isosurfaces;large-scale simulations;marching cubes;multilevel parallelism;naval engineering computing;naval vessels;parallel programming;scalar data;spray sheets;steep breaking wave visualization;steep breaking waves;thin spray sheet simulation;thin spray sheet visualization;waves;
Author: Adams, P.; Dommermuth, D.

Year: 2003
Title: Accelerating large data analysis by exploiting regularities
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250420
Abstract: We present techniques for discovering and exploiting regularity in large curvilinear data sets. The data can be based on a single mesh or a mesh composed of multiple submeshes (also known as zones). Multi-zone data are typical in Computational Fluid Dynamics (CFD) simulations. Regularities include axis-aligned rectilinear and cylindrical meshes as well as cases where one zone is equivalent to a rigid body transformation of another. Our algorithms can also discover rigid-body motion of meshes in time-series data. Next, we describe a data model where we can utilize the results from the discovery process in order to accelerate large data visualizations. Where possible, we replace general curvilinear zones with rectilinear or cylindrical zones. In rigid-body motion cases, we replace a time-series of meshes with a transformed mesh object where a reference mesh is dynamically transformed based on a given time value in order to satisfy geometry requests, on demand. The data model enables us to make these substitutions and dynamic transformations transparently with respect to the visualization algorithms. We present results with large data sets where we combine our mesh replacement and transformation techniques with out-of-core paging in order to achieve analysis speedups ranging from 1.5 to 2.
Keywords: C++ language;CFD simulation;computational fluid dynamics;curvilinear data sets;cylindrical meshes;data analysis;data analysis;data models;data models;data visualisation;data visualization;demand-driven evaluation;large data sets;mesh replacement;mesh replacements;mesh rigid-body motion discovery;mesh transformation;multizone data;object-oriented methods;object-oriented programming;out-of-core paging;regularity finding;rigid body motion;scientific visualization;time series;time-series data;visualization algorithms;
Author: Ellsworth, D.; Moran, P.J.

Year: 2003
Title: Visualizing spatial and temporal variability in coastal observatories
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250421
Abstract: In this paper, we describe a set of 3D and 4D visualization tools and techniques for CORIE, a complex environmental observation and forecasting system (EOFS) for the Columbia River. The Columbia River, a complex and highly variable estuary, is the target of numerous cross-disciplinary ecosystem research projects and is at the heart of multiple sustainable development issues with long reaching implications for the Pacific Northwest. However, there has been until recently no comprehensive and objective system available for modeling this environment, and as a consequence, researchers and agencies have had inadequate tools for evaluating the effects of natural resource management decisions. CORIE was designed to address this gap and is a major step towards the vision of a scalable, multi-use, real-time EOFS. Although CORIE already had a rich set of visualization tools, most of them produced 2D visualizations and did not allow for interactive visualization. Our work adds advanced interactive 3D tools to CORIE, which can be used for further inspection of the simulated and measured data.
Keywords: 3D visualization tools;4D visualization tools;CORIE;Columbia River;coastal observatories;data visualisation;digital simulation;environmental observation;forecasting systems;graphical user interfaces;interactive visualization;rivers;software tools;solid modelling;spatial variability visualization;temporal variability visualization;
Author: Jimenez, W.H.; Correa, W.T.; Silva, C.T.; Baptista, A.M.

Year: 2003
Title: Producing high-quality visualizations of large-scale simulation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250422
Abstract: This paper describes the work of a team of researchers in computer graphics, geometric computing, and civil engineering to produce a visualization of the September 2001 attack on the Pentagon. The immediate motivation for the project was to understand the behavior of the building under the impact. The longer term motivation was to establish a path for producing high-quality visualizations of large scale simulations. The first challenge was managing the enormous complexity of the scene to fit within the limits of state-of-the art simulation software systems and supercomputing resources. The second challenge was to integrate the simulation results into a high-quality visualization. To meet this challenge, we implemented a custom importer that simplifies and loads the massive simulation data in a commercial animation system. The surrounding scene is modeled using image-based techniques and is also imported in the animation system where the visualization is produced. A specific issue for us was to federate the simulation and the animation systems, both commercial systems not under our control and following internally different conceptualizations of geometry and animation. This had to be done such that scalability was achieved. The reusable link created between the two systems allows communicating the results to non-specialists and the public at large, as well as facilitating communication in teams with members having diverse technical backgrounds.
Keywords: Pentagon;civil engineering;commercial animation;computational geometry;computer animation;computer graphics;data visualisation;digital simulation;geometric computing;geometric programming;high-quality visualization;image-based technique;large-scale simulation;simulation data;solid modelling;state-of-the-art simultion;
Author: Popescu, V.; Hoffmann, C.; Kilic, S.; Sozen, M.; Meador, S.

Year: 2003
Title: Interactive protein manipulation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250423
Abstract: We describe an interactive visualization and modeling program for the creation of protein structures "from scratch." The input to our program is an amino acid sequence - decoded from a gene - and a sequence of predicted secondary structure types for each amino acid - provided by external structure prediction programs. Our program can be used in the set-up phase of a protein structure prediction process; the structures created with it serve as input for a subsequent global internal energy minimization, or another method of protein structure prediction. Our program supports basic visualization methods for protein structures, interactive manipulation based on inverse kinematics, and visualization guides to aid a user in creating "good" initial structures.
Keywords: amino acid sequence;computational science;computer graphics;data visualisation;gene coding;genetics;graphical user interfaces;interactive protein manipulation;interactive visualization;inverse kinematics;medical computing;modeling program;molecular modeling;protein structure prediction;proteins;solid modelling;
Author: Kreylos, O.; Max, N.L.; Hamann, B.; Crivelli, S.N.; Wes Bethel, E.

Year: 2003
Title: Holographic video display of time-series volumetric medical data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250424
Abstract: We describe an animated electro-holographic visualization of brain lesions due to the progression of multiple sclerosis. A research case study is used which documents the expression of visible brain lesions in a series of magnetic resonance imaging (MRI) volumes collected over the interval of one year. Some of the salient information resident within this data is described, and the motivation for using a dynamic spatial display to explore its spatial and temporal characteristics is stated. We provide a brief overview of spatial displays in medical imaging applications, and then describe our experimental visualization pipeline, from the processing of MRI datasets, through model construction, computer graphic rendering, and hologram encoding. The utility, strengths and shortcomings of the electro-holographic visualization are described and future improvements are suggested.
Keywords: MRI dataset;animated electro-holographic visualization;brain lesion;computer graphic equipment;computer graphic rendering;hologram encoding;holographic video display;holography;magnetic resonance imaging;medical image processing;medical imaging;multiple sclerosis;rendering (computer graphics);spatial display;time-series volumetric medical data;
Author: Plesniak, W.; Halle, M.; Pieper, S.D.; Wells, W.; Jakab, M.; Meier, D.S.; Benton, S.A.; Guttmann, R.G.; Kikinis, R.

Year: 2003
Title: Heart-muscle fiber reconstruction from diffusion tensor MRI
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1250425
Abstract: In this paper we use advanced tensor visualization techniques to study 3D diffusion tensor MRI data of a heart. We use scalar and tensor glyph visualization methods to investigate the data and apply a moving least squares (MLS) fiber tracing method to recover and visualize the helical structure and the orientation of the heart muscle fibers.
Keywords: 3D diffusion tensor MRI data;adaptive filters;biomedical MRI;digital simulation;fiber tracing;heart-muscle fiber reconstruction;magnetic resonance imaging;magnetic resonance imaging;medical image processing;moving least squares;scalar and tensor glyph visualization;solid modelling;tensor visualization;tensors;
Author: Zhukov, L.; Barr, A.H.

Year: 2002
Title: Integration of measurement tools in medical 3d visualizations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183752
Abstract: We discuss 3d interaction techniques for the quantitative analysis of spatial relations in medical visualizations. We describe the design and implementation of measurement tools to measure distances, angles and volumes in 3d visualizations. The visualization of measurement tools as recognizable 3d objects and a 3d interaction, which is both intuitive and precise, determines the usability of such facilities. Measurements may be carried out in 2d visualizations of the original radiological data and in 3d visualizations. The result of a measurement carried out in one view is also displayed in the other view appropriately. We discuss the validation of the obtained measures. Finally, we describe how some important measurement tasks may be solved automatically.
Keywords: 3D interaction techniques;computer-assisted surgery;data visualisation;integration tools;interactive systems;measurement tools;medical 3D visualizations;medical image processing;medical visualizations;quantitative analysis;spatial relations;surgery;
Author: Preim, B.; Tietjen, C.; Spindler, W.; Peitgen, H.-O.

Year: 2002
Title: Fast visualization of plane-like structures in voxel data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183753
Abstract: We present a robust, noise-resistant criterion characterizing plane-like skeletons in binary voxel objects. It is based on a distance map and the geodesic distance along the object's boundary. A parameter allows us to control the noise sensitivity. If needed, homotopy with the original object might be reconstructed in a second step, using an improved distance ordered thinning algorithm. The skeleton is analyzed to create a geometric representation for rendering. Plane-like parts are transformed into an triangulated surface not enclosing a volume by a suitable triangulation scheme. The resulting surfaces have lower triangle count than those created with standard methods and tend to maintain the original geometry, even after simplification with a high decimation rate. Our algorithm allows us to interactively render expressive images of complex 3D structures, emphasizing independently plane-like and rod-like structures. The methods are applied for visualization of the microstructure of bone biopsies.
Keywords: binary voxel objects;bone;bone biopsy microstructure;complex 3D structures;data visualisation;differential geometry;distance map;distance ordered thinning;expressive images;geodesic distance;geometric representation;homotopy;image reconstruction;image thinning;interactive rendering;interactive systems;medical image processing;mesh generation;noise sensitivity;object reconstruction;plane-like skeletons;rendering (computer graphics);rod-like structures;triangle count;triangulated surface;visualization;voxel data;
Author: Prohaska, S.; Hege, H.-C.

Year: 2002
Title: CPR - curved planar reformation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183754
Abstract: Visualization of tubular structures such as blood vessels is an important topic in medical imaging. One way to display tubular structures for diagnostic purposes is to generate longitudinal cross-sections in order to show their lumen, wall, and surrounding tissue in a curved plane. This process is called curved planar reformation (CPR). We present three different methods to generate CPR images. A tube-phantom was scanned with computed tomography (CT) to illustrate the properties of the different CPR methods. Furthermore we introduce enhancements to these methods: thick-CPR, rotating-CPR and multi-path-CPR.
Keywords: blood vessels;blood vessels;computed tomography;computerised tomography;curved planar reformation;data visualisation;diagnostic purposes;image generation;longitudinal cross-sections;medical image processing;medical imaging;multi-path-CPR;rendering (computer graphics);rotating-CPR;surrounding tissue;thick-CPR;tubular structures;visualization;
Author: Kanitsar, A.; Fleischmann, D.; Wegenkittl, R.; Felkel, P.; Groller, E.

Year: 2002
Title: Direct surface extraction from 3D freehand ultrasound images
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183755
Abstract: This paper presents a new technique for the extraction of surfaces from 3D ultrasound data. Surface extraction from ultrasound data is challenging for a number of reasons including noise and artifacts in the images and nonuniform data sampling. A method is proposed to fit an approximating radial basis function to the group of data samples. An explicit surface is then obtained by iso-surfacing the function. In most previous 3D ultrasound research, a pre-processing step is taken to interpolate the data into a regular voxel array and a corresponding loss of resolution. We are the first to represent the set of semi-structured ultrasound pixel data as a single function. From this we are able to extract surfaces without first reconstructing the irregularly spaced pixels into a regular 3D voxel array.
Keywords: 3D freehand ultrasound images;approximating radial basis function;computational geometry;computational geometry;data samples;data visualisation;direct surface extraction;feature extraction;image sampling;iso-surfacing;medical image processing;radial basis function networks;semi-structured ultrasound pixel data;single function;ultrasonic imaging;
Author: Youwei Zhang; Rohling, R.; Pai, D.K.

Year: 2002
Title: Interactive rendering of large volume data sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183757
Abstract: We present a new algorithm for rendering very large volume data sets at interactive frame rates on standard PC hardware. The algorithm accepts scalar data sampled on a regular grid as input. The input data is converted into a compressed hierarchical wavelet representation in a preprocessing step. During rendering, the wavelet representation is decompressed on-the-fly and rendered using hardware texture mapping. The level of detail used for rendering is adapted to the local frequency spectrum of the data and its position relative to the viewer. Using a prototype implementation of the algorithm we were able to perform an interactive walkthrough of large data sets such as the visible human on a single off-the-shelf PC.
Keywords: compressed hierarchical wavelet representation;data compression;data visualisation;hardware texture mapping;image representation;image sampling;image texture;interactive frame rates;interactive rendering;interactive systems;interactive walkthrough;large volume data sets;local frequency spectrum;medical image processing;on-the-fly decompression;regular grid;rendering (computer graphics);scalar data sampling;standard PC hardware;visible human;wavelet transforms;
Author: Guthe, S.; Wand, M.; Gonser, J.; Strasser, W.

Year: 2002
Title: Semotus Visum: a flexible remote visualization framework
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183758
Abstract: By offering more detail and precision, large data sets can provide greater insights to researchers than small data sets. However, these data sets require greater computing resources to view and manage. Remote visualization techniques allow the use of computers that cannot be operated locally. The Semotus Visum framework applies a high-performance client-server paradigm to the problem. The framework utilizes both client and server resources via multiple rendering methods. Experimental results show the framework delivers high frame rates and low latency across a wide range of data sets.
Keywords: Semotus Visum;client server resources;client-server systems;data visualisation;flexible remote visualization framework;frame rates;high-performance system;large data sets;latency;multiple rendering methods;rendering (computer graphics);
Author: Luke, E.J.; Hansen, C.D.

Year: 2002
Title: Out-of-core rendering of massive geometric environments
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183759
Abstract: We present an external memory algorithm for fast display of very large and complex geometric environments. We represent the model using a scene graph and employ different culling techniques for rendering acceleration. Our algorithm uses a parallel approach to render the scene as well as fetch objects from the disk in a synchronous manner. We present a novel prioritized prefetching technique that takes into account LOD-switching and visibility-based events between successive frames. We have applied our algorithm to large gigabyte-sized environments that are composed of thousands of objects and tens of millions of polygons. The memory overhead of our algorithm is output sensitive and is typically tens of megabytes. In practice, our approach scales with the model sizes, and its rendering performance is comparable to that of an in-core algorithm.
Keywords: LOD-switching;computational geometry;culling techniques;data visualisation;external memory algorithm;level-of-detail switching;massive geometric environments;out-of-core rendering;parallel algorithm;parallel algorithms;performance;polygons;prioritized prefetching;rendering (computer graphics);rendering acceleration;scene graph;storage management;successive frames;visibility-based events;
Author: Varadhan, G.; Manocha, D.

Year: 2002
Title: Optimized view-dependent rendering for large polygonal datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183760
Abstract: In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.
Keywords: computational geometry;graphics hardware;large datasets rendering;object modeling;rendering (computer graphics);spatial subdivision;spatial tree;tree data structures;view-dependence trees data-structure;view-dependent rendering;
Author: El-Sana, J.; Bachmat, E.

Year: 2002
Title: Volumetric shadows using splatting
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183761
Abstract: This paper describes an efficient algorithm to model the light attenuation due to a participating media with low albedo. The light attenuation is modeled using splatting volume renderer for both the viewer and the light source. During the rendering, a 2D shadow buffer attenuates the light for each pixel. When the contribution of a footprint is added to the image buffer, as seen from the eye, we add the contribution to the shadow buffer, as seen from the light source. We have generated shadows for point lights and parallel lights using this algorithm. The shadow algorithm has been extended to deal with multiple light sources and projective textured lights.
Keywords: 2D shadow buffer;data visualisation;light attenuation;multiple light sources;parallel lights;point lights;projective textured lights;rendering;rendering (computer graphics);splatting volume renderer;visualization;volumetric shadows;
Author: Caixia Zhang; Crawfis, R.

Year: 2002
Title: Volume clipping via per-fragment operations in texture-based volume visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183762
Abstract: We propose new clipping methods that are capable of using complex geometries for volume clipping. The clipping tests exploit per-fragment operations on the graphics hardware to achieve high frame rates. In combination with texture-based volume rendering, these techniques enable the user to interactively select and explore regions of the data set. We present depth-based clipping techniques that analyze the depth structure of the boundary representation of the clip geometry to decide which parts of the volume have to be clipped. In another approach, a voxelized clip object is used to identify the clipped regions.
Keywords: complex geometries;computational geometry;data set;data visualisation;depth structure;hardware acceleration;interpolation;perfragment operations;texture-based volume rendering;texture-based volume visualization;volume clipping;voxelized clip object;
Author: Weiskopf, D.; Engel, K.; Ertl, T.

Year: 2002
Title: Interactive spectral volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183763
Abstract: We describe a method for volume rendering using a spectral representation of colour instead of the traditional RGB model. It is shown how to use this framework for a novel exploration of datasets through enhanced transfer function design. Furthermore, our framework is extended to allow real-time re-lighting of the scene created with any rendering method. The technique of post-illumination is introduced to generate new spectral images for arbitrary light colours in real-time. Also a tool is described to design a palette of lights and materials having certain properties such as selective metamerism or colour constancy. Applied to spectral transfer functions, different light colours can accentuate or hide specific qualities of the data. In connection with post-illumination this provides a new degree of freedom for guided exploration of volumetric data, which cannot be achieved using the RGB model.
Keywords: colour constancy;colour graphics;colour representation;data visualisation;datasets;interactive spectral volume rendering;palette;post-illumination;real-time scene relighting;real-time systems;realism;realistic images;rendering (computer graphics);selective metamerism;solid modelling;spectral transfer functions;three-dimensional graphics;transfer function design;volumetric data;volumetric visualization;
Author: Bergner, S.; Moller, T.; Drew, M.S.; Finlayson, G.D.

Year: 2002
Title: Interactive translucent volume rendering and procedural modeling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183764
Abstract: Direct volume rendering is a commonly used technique in visualization applications. Many of these applications require sophisticated shading models to capture subtle lighting effects and characteristics of volumetric data and materials. Many common objects and natural phenomena exhibit visual quality that cannot be captured using simple lighting models or cannot be solved at interactive rates using more sophisticated methods. We present a simple yet effective interactive shading model which captures volumetric light attenuation effects to produce volumetric shadows and the subtle appearance of translucency. We also present a technique for volume displacement or perturbation that allows realistic interactive modeling of high frequency detail for real and synthetic volumetric data.
Keywords: 3D graphics;data visualisation;interactive shading model;interactive translucent volume rendering;lighting;lighting;procedural modeling;realistic images;realistic interactive modeling;rendering (computer graphics);shading models;solid modelling;visual quality;visualization;volumetric light attenuation effects;volumetric shadows;
Author: Kniss, J.; Premoze, S.; Hansen, C.; Ebert, D.

Year: 2002
Title: A multiphase approach to efficient surface simplification
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183765
Abstract: We present a new multiphase method for efficiently simplifying polygonal surface models of arbitrary size. It operates by combining an initial out-of-core uniform clustering phase with a subsequent in-core iterative edge contraction phase. These two phases are both driven by quadric error metrics, and quadrics are used to pass information about the original surface between phases. The result is a method that produces approximations of a quality comparable to quadric-based iterative edge contraction, but at a fraction of the cost in terms of running time and memory consumption.
Keywords: computational geometry;computational geometry;data visualisation;in-core iterative edge contraction;memory consumption;multiphase approach;object modeling;out-of-core uniform clustering phase;polygonal surface models;quadric error metrics;quadric-based iterative edge contraction;solid modelling;surface simplification;visualization;
Author: Garland, M.; Shaffer, E.

Year: 2002
Title: Geometric surface smoothing via anisotropic diffusion of normals
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183766
Abstract: This paper introduces a method for smoothing complex, noisy surfaces, while preserving (and enhancing) sharp, geometric features. It has two main advantages over previous approaches to feature preserving surface smoothing. First is the use of level set surface models, which allows us to process very complex shapes of arbitrary and changing topology. This generality makes it well suited for processing surfaces that are derived directly from measured data. The second advantage is that the proposed method derives from a well-founded formulation, which is a natural generalization of anisotropic diffusion, as used in image processing. This formulation is based on the proposition that the generalization of image filtering entails filtering the normals of the surface, rather than processing the positions of points on a mesh.
Keywords: anisotropic diffusion of normals;changing topology;computational geometry;computational geometry;data visualisation;feature preserving surface smoothing;geometric surface smoothing;image filtering;image processing;level set surface models;object modeling;sharp geometric features;solid modelling;visualization;
Author: Tasdizen, T.; Whitaker, R.; Burchard, P.; Osher, S.

Year: 2002
Title: TetFusion: an algorithm for rapid tetrahedral mesh simplification
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183767
Abstract: This paper introduces an algorithm for rapid progressive simplification of tetrahedral meshes: TetFusion. We describe how a simple geometry decimation operation steers a rapid and controlled progressive simplification of tetrahedral meshes, while also taking care of complex mesh-inconsistency problems. The algorithm features a high decimation ratio per step, and inherently discourages any cases of self-intersection of boundary, element-boundary intersection at concave boundary-regions, and negative volume tetrahedra (flipping). We achieved rigorous reduction ratios of up to 98% for meshes consisting of 827,904 elements in less than 2 minutes, progressing through a series of level-of-details (LoDs) of the mesh in a controlled manner. We describe how the approach supports a balanced re-distribution of space between tetrahedral elements, and explain some useful control parameters that make it faster and more intuitive than 'edge collapse'-based decimation methods for volumetric meshes. Finally, we discuss how this approach can be employed for rapid LoD prototyping of large time-varying datasets as an aid to interactive visualization.
Keywords: TetFusion;computational complexity;computational geometry;computer graphics;data visualisation;element boundary intersection;geometry decimation operation;interactive visualization;mesh-inconsistency problems;rapid LoD prototyping;rapid tetrahedral mesh simplification;time-varying datasets;volume tetrahedra;
Author: Chopra, P.; Meyer, J.

Year: 2002
Title: Compressing polygon mesh geometry with parallelogram prediction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183768
Abstract: We present a generalization of the geometry coder by Touma and Gotsman (1998) to polygon meshes. We let the polygon information dictate where to apply the parallelogram rule that they use to predict vertex positions. Since polygons tend to be fairly planar and fairly convex, it is beneficial to make predictions within a polygon rather than across polygons. This, for example, avoids poor predictions due to a crease angle between polygons. Up to 90 percent of the vertices can be predicted this way. Our strategy improves geometry compression by 10 to 40 percent depending on (a) how polygonal the mesh is and (b) on the quality (planarity/convexity) of the polygons.
Keywords: computational geometry;computational geometry;data compression;data visualisation;geometry coder;linear prediction;object modeling;parallelogram prediction;polygon mesh geometry compression;solid modelling;vertex position prediction;visualization;
Author: Isenburg, M.; Alliez, P.

Year: 2002
Title: Probabilistic surfaces: point based primitives to show surface uncertainty
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183769
Abstract: Efficient and informative visualization of surfaces with uncertainties is an important topic with many applications in science and engineering. Examples include environmental pollution borderline identification, identification of the limits of an oil basin, or discrimination between contaminated and healthy tissue in medicine. This paper presents an approach for such visualization using points as display primitives. The approach is to render each polygon as a collection of points and to displace each point from the surface in the direction of the surface normal by an amount proportional to some random number multiplied by the uncertainty level at that point. This approach can be used in combination with other techniques such as pseudo-coloring and shading to give rise to efficient and revealing visualizations. The method is used to visualize real and simulated tumor formations with uncertainty of tumor boundaries.
Keywords: computational geometry;computational geometry;data visualisation;display primitives;medical computing;medicine;object modeling;point based primitives;polygon rendering;probabilistic surfaces;pseudo-coloring;rendering (computer graphics);shading;solid modelling;surface uncertainty;surface visualization;tumor formations;tumours;
Author: Grigoryan, G.; Rheingans, P.

Year: 2002
Title: PMR: point to mesh rendering, a feature-based approach
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183770
Abstract: Within the field of computer graphics and visualization, it is often necessary to visualize polygonal models with large number of polygons. Display quality is mandatory, but it is also desirable to have the ability to rapidly update the display in order to facilitate interactive use. Point based rendering methods have been shown effective for this task. Building on this paradigm we introduce the PMR system which uses a hierarchy both in points and triangles for rendering. This hierarchy is fundamentally different from the ones used in existing methods. It is based on the feature geometry in the object space rather than its projection in the screen space. This provides certain advantages over the existing methods.
Keywords: PMR system;Voronoi diagram;computational geometry;computational geometry;computer graphics;data visualisation;display quality;feature geometry;feature-based approach;object modeling;point to mesh rendering;polygonal models;rendering (computer graphics);solid modelling;visualization;
Author: Dey, T.K.; Hudson, J.

Year: 2002
Title: Efficient simplification of point-sampled surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183771
Abstract: We introduce, analyze and quantitatively compare a number of surface simplification methods for point-sampled geometry. We have implemented incremental and hierarchical clustering, iterative simplification, and particle simulation algorithms to create approximations of point-based models with lower sampling density. All these methods work directly on the point cloud, requiring no intermediate tesselation. We show how local variation estimation and quadric error metrics can be employed to diminish the approximation error and concentrate more samples in regions of high curvature. To compare the quality of the simplified surfaces, we have designed a new method for computing numerical and visual error estimates for point-sampled surfaces. Our algorithms are fast, easy to implement, and create high-quality surface approximations, clearly demonstrating the effectiveness of point-based surface simplification.
Keywords: 3D objects;approximation error;computational geometry;data visualisation;geometry;hierarchical clustering;incremental clustering;intermediate tesselation;iterative simplification;local variation estimation;particle simulation algorithms;point-sampled geometry;point-sampled surface simplification;quadric error metrics;rendering;rendering (computer graphics);sampling density;solid modelling;visualization;
Author: Pauly, M.; Gross, M.; Kobbelt, L.P.

Year: 2002
Title: Exploring scalar fields using critical isovalues
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183772
Abstract: Isosurfaces are commonly used to visualize scalar fields. Critical isovalues indicate isosurface topology changes: the creation of new surface components, merging of surface components or the formation of holes in a surface component. Therefore, they highlight interesting isosurface behavior and are helpful in exploration of large trivariate data sets. We present a method that detects critical isovalues in a scalar field defined by piecewise trilinear interpolation over a rectilinear grid and describe how to use them when examining volume data. We further review varieties of the marching cubes (MC) algorithm, with the intention of preserving topology of the trilinear interpolant when extracting an isosurface. We combine and extend two approaches in such a way that it is possible to extract meaningful isosurfaces even when a critical value is chosen as the isovalue.
Keywords: critical isovalues;data visualisation;hole formation;interpolation;isosurface topology changes;large trivariate data set exploration;marching cubes algorithm;piecewise linear techniques;piecewise trilinear interpolation;rectilinear grid;scalar field visualization;surface component merging;topology preservation;trilinear interpolant;volume data;
Author: Weber, G.H.; Scheuermann, G.; Hagen, H.; Hamann, B.

Year: 2002
Title: Level set segmentation from multiple non-uniform volume datasets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183773
Abstract: Typically 3-D MR and CT scans have a relatively high resolution in the scanning X-Y plane, but much lower resolution in the axial Z direction. This non-uniform sampling of an object can miss small or thin structures. One way to address this problem is to scan the same object from multiple directions. In this paper we describe a method for deforming a level set model using velocity information derived from multiple volume datasets with non-uniform resolution in order to produce a single high-resolution 3D model. The method locally approximates the values of the multiple datasets by fitting a distance-weighted polynomial using moving least-squares. The proposed method has several advantageous properties: its computational cost is proportional to the object surface area, it is stable with respect to noise, imperfect registrations and abrupt changes in the data, it provides gain-correction, and it employs a distance-based weighting to ensures that the contributions from each scan are properly merged into the final result. We have demonstrated the effectiveness of our approach on four multi-scan datasets, a Griffin laser scan reconstruction, a CT scan of a teapot and MR scans of a mouse embryo and a zucchini.
Keywords: 3D reconstruction;CT scan;computerised tomography;data visualisation;distance-weighted polynomial;image reconstruction;image segmentation;imperfect registrations;laser scan reconstruction;level set;level set models;level set segmentation;medical image processing;moving least-squares;multiple volume datasets;segmentation;visualization;
Author: Museth, K.; Breen, D.E.; Zhukov, L.; Whitaker, R.T.

Year: 2002
Title: Efficient computation of the topology of level sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183774
Abstract: This paper introduces two efficient algorithms that compute the Contour Tree of a 3D scalar field &Fscr; and its augmented version with the Betti numbers of each isosurface. The Contour Tree is a fundamental data structure in scientific visualization that is used to preprocess the domain mesh to allow optimal computation of isosurfaces with minimal overhead storage. The Contour Tree can also be used to build user interfaces reporting the complete topological characterization of a scalar field. The first part of the paper presents a new scheme that augments the Contour Tree with the Betti numbers of each isocontour in linear time. We show how to extend the scheme with the Betti number computation without increasing its complexity. Thus, we improve on the time complexity from our previous approach from O(m log m) to O(n log n+m), where m is the number of tetrahedra and n is the number of vertices in the domain of &Fscr;. The second part of the paper introduces a new divide-and-conquer algorithm that computes the Augmented Contour Tree with improved efficiency. The central part of the scheme computes the output Contour Tree by merging two intermediate Contour Trees and is independent of the interpolant. In this way we confine any knowledge regarding a specific interpolant to an oracle that computes the tree for a single cell. We have implemented this oracle for the trilinear interpolant and plan to replace it with higher order interpolants when needed. The complexity of the scheme is O(n+t log n), where t is the number of critical points of &Fscr;. For the first time we can compute the Contour Tree in linear time in many practical cases when t=O(n<sup>1-&epsi;</sup>). Lastly, we report the running times for a parallel implementation of our algorithm, showing good scalability with the number of processors.
Keywords: Betti numbers;Contour Tree;computational complexity;computational geometry;data visualisation;divide and conquer methods;divide-and-conquer algorithm;domain mesh;efficient algorithms;fundamental data structure;isosurfaces;level set topology;scalability;scientific visualization;time complexity;topology;tree data structures;
Author: Pascucci, V.; Cole-McLaughlin, K.

Year: 2002
Title: Fast and reliable space leaping for interactive volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183775
Abstract: We present a fast and reliable space-leaping scheme to accelerate ray casting during interactive navigation in a complex volumetric scene, where we combine innovative space-leaping techniques in a number of ways. First, we derive most of the pixel depths at the current frame by exploiting the temporal coherence during navigation, where we employ a novel fast cell-based reprojection scheme that is more reliable than the traditional intersection-point based reprojection. Next, we exploit the object space coherence to quickly detect the remaining pixel depths, by using a precomputed accurate distance field that stores the Euclidean distance from each empty (background) voxel toward its nearest object boundary. In addition, we propose an effective solution to the challenging new-incoming-objects problem during navigation. Our algorithm has been implemented on a 16-processor SGI Power Challenge and reached interactive rendering rates at more than 10 Hz during the navigation inside 512<sup>3</sup> volume data sets acquired from both a simulation phantom and actual patients.
Keywords: Euclidean distance;SGI Power Challenge;cell-based reprojection scheme;complex volumetric scene;computational geometry;data visualisation;interactive navigation;interactive rendering;interactive systems;interactive volume rendering;object space coherence;ray casting;reliable space leaping;rendering (computer graphics);temporal coherence;
Author: Ming Wan; Sadiq, A.; Kaufman, A.

Year: 2002
Title: A new object-order ray-casting algorithm
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183776
Abstract: Many direct volume rendering algorithms have been proposed during the last decade to render 256<sup>3</sup> voxels interactively. However a lot of limitations are inherent to all of them, like low-quality images, a small viewport size or a fixed classification. In contrast, interactive high quality algorithms are still a challenge nowadays. We introduce here an efficient and accurate technique called object-order ray-casting that can achieve up to 10 fps on current workstations. Like usual ray-casting, colors and opacities are evenly sampled along the ray, but now within a new object-order algorithm. Thus, it allows to combine the main advantages of both worlds in term of speed and quality. We also describe an efficient hidden volume removal technique to compensate for the loss of early ray termination.
Keywords: biomedical imaging;data visualisation;hidden volume removal;medical imaging;object-order ray-casting;ray tracing;ray tracing;ray-casting;rendering (computer graphics);scientific visualization;volume rendering;
Author: Mora, B.; Jessel, J.-P.; Caubet, R.

Year: 2002
Title: Non-photorealistic volume rendering using stippling techniques
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183777
Abstract: Simulating hand-drawn illustration techniques can succinctly express information in a manner that is communicative and informative. We present a framework for an interactive direct volume illustration system that simulates traditional stipple drawing. By combining the principles of artistic and scientific illustration, we explore several feature enhancement techniques to create effective, interactive visualizations of scientific and medical datasets. We also introduce a rendering mechanism that generates appropriate point lists at all resolutions during an automatic preprocess, and modifies rendering styles through different combinations of these feature enhancements. The new system is an effective way to interactively preview large, complex volume datasets in a concise, meaningful, and illustrative manner. Volume stippling is effective for many applications and provides a quick and efficient method to investigate volume models.
Keywords: automatic preprocess;data visualisation;feature enhancement;interactive direct volume illustration;interactive visualizations;rendering;rendering (computer graphics);stipple drawing;stippling;volume rendering;
Author: Aidong Lu; Morris, C.J.; Ebert, D.S.; Rheingans, P.; Hansen, C.

Year: 2002
Title: Interactive visualization of complex plant ecosystems
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183778
Abstract: We present a method for interactive rendering of large outdoor scenes. Complex polygonal plant models and whole plant populations are represented by relatively small sets of point and line primitives. This enables us to show landscapes faithfully using only a limited percentage of primitives. In addition, a hierarchical data structure allows us to smoothly reduce the geometrical representation to any desired number of primitives. The scene is hierarchically divided into local portions of geometry to achieve large reduction factors for distant regions. Additionally, the data reduction is adapted to the visual importance of geometric objects. This allows us to maintain the visual fidelity of the representation while reducing most of the geometry drastically. With our system, we are able to interactively render very complex landscapes with good visual quality.
Keywords: complex landscapes;data reduction;data visualisation;ecosystems;geometrical representation;hierarchical data structure;interactive rendering;natural scenes;outdoor scenes;point-based rendering;polygonal plant models;rendering (computer graphics);whole plant populations;
Author: Deussen, O.; Colditz, C.; Stamminger, M.; Drettakis, G.

Year: 2002
Title: Simulating fire with texture splats
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183779
Abstract: We propose the use of textured splats as the basic display primitives for an open surface fire model. The high-detail textures help to achieve a smooth boundary of the fire and gain the small-scale turbulence appearance. We utilize the Lattice Boltzmann Model (LBM) to simulate physically-based equations describing the fire evolution and its interaction with the environment (e.g., obstacles, wind and temperature). The property of fuel and non-burning objects are defined on the lattice of the computation domain. A temperature field is also incorporated to model the generation of smoke from the fire due to incomplete combustion. The linear and local characteristics of the LBM enable us to accelerate the computation with graphics hardware to reach real-time simulation speed, while the texture splat primitives enable interactive rendering frame rates.
Keywords: Boltzmann equation;Lattice Boltzmann Model;computer graphics;data visualisation;display primitives;fires;high-detail textures;interactive rendering;open surface fire model;real-time simulation;realistic images;textured splats;turbulence;
Author: Xiaoming Wei; Wei Li; Mueller, K.; Kaufman, A.

Year: 2002
Title: Visualizing dynamic molecular conformations
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183780
Abstract: The bioactivity of a molecule strongly depends on its metastable conformational shapes and the transitions between these. Therefore, conformation analysis and visualization is a basic prerequisite for the understanding of biochemical processes. We present techniques for visual analysis of metastable molecular conformations. Core of these are flexibly applicable methods for alignment of molecular geometries, as well as methods for depicting shape and 'fuzziness' of metastable conformations. All analysis tools are provided in an integrated working environment. The described techniques are demonstrated with pharmaceutically active biomolecules.
Keywords: bioactivity;biochemical processes;biochemistry;biomolecules;conformation analysis;data visualisation;metastable conformational shapes;metastable molecular conformations;molecular biophysics;molecular configurations;visual analysis;visualization;
Author: Schmidt-Ehrenberg, J.; Baum, D.; Hege, H.-C.

Year: 2002
Title: GeneVis: visualization tools for genetic regulatory network dynamics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183781
Abstract: GeneVis provides a visual environment for exploring the dynamics of genetic regulatory networks. At present time, genetic regulation is the focus of intensive research worldwide, and computational aids are being called for to help in the research of factors that are difficult to observe directly. GeneVis provides a particle-based simulation of genetic networks and visualizes the process of this simulation as it occurs. Two dynamic visualization techniques are provided, a visualization of the movement of the regulatory proteins and a visualization of the relative concentrations of these proteins. Several interactive tools relate the dynamic visualizations to the underlying genetic network structure.
Keywords: GeneVis;biological visualization;data visualisation;dynamic visualizations;genetic networks;genetic regulation;genetic regulatory networks;genetics;particle-based simulation;visual environment;
Author: Baker, C.A.H.; Carpendale, M.S.T.; Prusinkiewicz, P.; Surette, M.G.

Year: 2002
Title: Isometric embedding by surface reconstruction from distances
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183782
Abstract: To display the intuitive meaning of an abstract metric it is helpful to look on an embedded surface with the same inner geometry as the given metric. The resulting partial differential equations have no standard solution. Only for some special cases satisfactory methods are known. I present a new algorithmic approach which is not based on differential equations. In contrast to other methods this technique also works if the embedding exists only locally. The fundamental idea is to estimate Euclidean distances, from which the surface is built up. In this paper I focus on the reconstruction of a surface from these estimated distances. Particular the influence of a perturbation of the distances on the shape of the resulting surface is investigated.
Keywords: Euclidean distances;abstract metric;computational geometry;computational physics;data visualisation;image reconstruction;inner geometry;isometric embedding;partial differential equations;partial differential equations;reconstruction;tensor fields;
Author: Hotz, I.

Year: 2002
Title: Fast view-dependent level-of-detail rendering using cached geometry
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183783
Abstract: Level-of-detail rendering is essential for rendering very large, detailed worlds in real-time. Unfortunately, level-of-detail computations can be expensive, creating a bottleneck at the CPU. This paper presents the CABTT algorithm, an extension to existing binary-triangle-tree-based level-of-detail algorithms. Instead of manipulating triangles, the CABTT algorithm instead operates on clusters of geometry called aggregate triangles. This reduces CPU overhead, eliminating a bottleneck common to level-of-detail algorithms. Since aggregate triangles stay fixed over several frames, they may be cached on the video card. This further reduces CPU load and fully utilizes the hardware accelerated rendering pipeline on modern video cards. These improvements result in a fourfold increase in frame rate over ROAM at high detail levels. Our implementation renders an approximation of an 8 million triangle height field at 42 frames per second with an maximum error of 1 pixel on consumer hardware.
Keywords: CABTT algorithm;CPU overhead;aggregate triangles;binary triangle tree based level of detail algorithms;cached geometry;computational geometry;fast view-dependent level of detail rendering;frame rate;geometry clusters;hardware accelerated rendering pipeline;rendering (computer graphics);video card;video signal processing;
Author: Levenberg, J.

Year: 2002
Title: Visibility-guided simplification
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183784
Abstract: For some graphics applications, object interiors and hard-to-see regions contribute little to the final images and need not be processed. In this paper, we define a view-independent visibility measure on mesh surfaces based on the visibility function between the surfaces and a surrounding sphere of cameras. We demonstrate the usefulness of this measure with a visibility-guided simplification algorithm. Mesh simplification reduces the polygon counts of 3D models and speeds up the rendering process. Many mesh simplification algorithms are based on sequences of edge collapses that minimize geometric and attribute errors. By combining the surface visibility measure with a geometric error measure, we obtain simplified models with improvement proportional to the number of low visibility regions in the original models.
Keywords: 3D models;attribute error minimization;computer graphics;edge collapse sequences;geometric error minimization;graphics;low visibility regions;mesh simplification;mesh surfaces;polygon counts;rendering;surrounding camera sphere;view-independent visibility measure;visibility;visibility function;visibility-guided simplification algorithm;
Author: Zhang, E.; Turk, G.

Year: 2002
Title: Maximum entropy light source placement
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183785
Abstract: Finding the "best" viewing parameters for a scene is a difficult but very important problem. Fully automatic procedures seem to be impossible as the notion of "best" strongly depends on human judgment as well as on the application. In this paper a solution to the sub-problem of placing light sources for given camera parameters is proposed. A light position is defined to be optimal, when the resulting illumination reveals more about the scene than illuminations from all other light positions, i.e. the light position maximizes information that is added to the image through the illumination. With the help of an experiment with several subjects we could adapt the information measure to the actually perceived information content. We present fast global optimization procedures and solutions for two and more light sources.
Keywords: camera parameters;data visualisation;fast global optimization procedures;illumination;information measure;light position;light sources;lighting;maximum entropy light source placement;maximum entropy methods;optimisation;viewing parameters;
Author: Gumhold, S.

Year: 2002
Title: Computing singularities of 3D vector fields with geometric algebra
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183786
Abstract: Critical points of a vector field are key to their characterization. Their positions as well as their indexes are crucial for understanding vector fields. Considerable work exists in 2D, but less is available for 3D or higher dimensions. Geometric algebra is a derivative of Clifford algebra that not only enables a succinct definition of the index of a critical point in higher dimension; it also provides insight and computational pathways for calculating the index. We describe the problems in terms of geometric algebra and present an octree based solution using the algebra for finding critical points and their index in a 3D vector field.
Keywords: 3D vector field singularities;Clifford algebra;computational geometry;critical points;data visualisation;geometric algebra;indexes;octree based solution;positions;vectors;
Author: Mann, S.; Rockwood, A.

Year: 2002
Title: Seamster: inconspicuous low-distortion texture seam layout
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183787
Abstract: Surface texturing aids the visualization of polygonal meshes by providing additional surface orientation cues and feature annotations. Such texturing is usually implemented via texture mapping, which is easier and more effective when the distortion of the mapping from the surface to the texture map is kept small. We have previously shown that distortion occurs when areas of high surface curvature are flattened into the texture map. By cutting the surface in these areas one can reduce texture map distortion at the expense of additional seam artifacts. This paper describes a faster technique for guiding a texture map seam through high distortion regions, while restricting the seam to regions of low visibility. This results in distortion reducing seams that are less visually distracting and take less time to compute. We have also observed that visibility considerations improve the speed of a recent method that adds cuts to reduce a surface genus.
Keywords: Seamster;data visualisation;feature annotations;high surface curvature;image texture;inconspicuous low-distortion texture seam layout;low visibility regions;polygonal meshes;surface genus;surface orientation cues;surface texturing;texture mapping;visibility;visualization;
Author: Sheffer, A.; Hart, J.C.

Year: 2002
Title: Face-based luminance matching for perceptual colormap generation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183788
Abstract: Most systems used for creating and displaying colormap-based visualizations are not photometrically calibrated. That is, the relationship between RGB input levels and perceived luminance is usually not known, due to variations in the monitor, hardware configuration, and the viewing environment. However, the luminance component of perceptually based colormaps should be controlled, due to the central role that luminance plays in our visual processing. We address this problem with a simple and effective method for performing luminance matching on an uncalibrated monitor. The method is akin to the minimally distinct border technique (a previous method of luminance matching used for measuring luminous efficiency), but our method relies on the brain's highly developed ability to distinguish human faces. We present a user study showing that our method produces equivalent results to the minimally distinct border technique, but with significantly improved precision. We demonstrate how results from our luminance matching method can be directly applied to create new univariate colormaps.
Keywords: RGB input levels;colormap-based visualizations;computer graphics;computer vision;data visualisation;face-based luminance matching;hardware configuration;image matching;image processing;image representation;image representation;luminance matching;perceptual colormap generation;viewing environment;visual processing;
Author: Kindlmann, G.; Reinhard, E.; Creem, S.

Year: 2002
Title: Geometric verification of swirling features in flow fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183789
Abstract: In this paper, we present a verification algorithm for swirling features in flow fields, based on the geometry of streamlines. The features of interest in this case are vortices. Without a formal definition, existing detection algorithms lack the ability to accurately identify these features, and the current method for verifying the accuracy of their results is by human visual inspection. Our verification algorithm addresses this issue by automating the visual inspection process. It is based on identifying the swirling streamlines that surround the candidate vortex cores. We apply our algorithm to both numerically simulated and procedurally generated datasets to illustrate the efficacy of our approach.
Keywords: automated visual inspection;automatic optical inspection;computational fluid dynamics;computational geometry;data visualisation;flow fields;flow simulation;geometric verification;numerically simulated datasets;procedurally generated datasets;streamline geometry;swirling features;swirling streamlines;vortex cores;vortices;vortices;
Author: Ming Jiang; Machiraju, R.; Thompson, D.

Year: 2002
Title: Comparative evaluation of visualization and experimental results using image comparison metrics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183790
Abstract: Comparative evaluation of visualization and experimental results is a critical step in computational steering. In this paper, we present a study of image comparison metrics for quantifying the magnitude of difference between visualization of a computer simulation and a photographic image captured from an experiment. We examined eleven metrics, including three spatial domain, four spatial-frequency domain and four HVS (human-vision system) metrics. Among these metrics, a spatial-frequency domain metric called 2nd-order Fourier comparison was proposed specifically for this work. Our study consisted of two stages: base cases and field trials. The former is a general study on a controlled comparison space using purposely selected data, and the latter involves imagery results from computational fluid dynamics and a rheological experiment. This study has introduced a methodological framework for analyzing image-level methods used in comparative visualization. For the eleven metrics considered, it has offered a set of informative indicators as to the strengths and weaknesses of each metric. In particular, we have identified three image comparison metrics that are effective in separating "similar" and "different" image groups. Our 2nd-order Fourier comparison metric has compared favorably with others in two of the three tests, and has shown its potential to be used for steering computer simulation quantitatively.
Keywords: 2nd-order Fourier comparison;base cases;comparative evaluation;computational fluid dynamics;computational fluid dynamics;computational steering;computer simulation;controlled comparison space;data visualisation;digital simulation;field trials;human vision system metrics;image comparison metrics;image processing;imagery;photographic image;rheological experiment;rheology;spatial domain metrics;spatial-frequency domain metrics;visualization;
Author: Hualin Zhou; Min Chen; Webster, M.F.

Year: 2002
Title: A model for the visualization exploration process
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183791
Abstract: The current state of the art in visualization research places strong emphasis on different techniques to derive insight from disparate types of data. However, little work has investigated the visualization process itself. The information content of the visualization process - the results, history, and relationships between those results - is addressed by this work. A characterization of the visualization process is discussed, leading to a general model of the visualization exploration process. The model, based upon a new parameter derivation calculus, can be used for automated reporting, analysis, or visualized directly. An XML-based language for expressing visualization sessions using the model is also described. These sessions can then be shared and reused by collaborators. The model, along with the XML representation, provides an effective means to utilize information within the visualization process to further data exploration.
Keywords: XML-based language;automated analysis;automated reporting;data exploration;data visualisation;hypermedia markup languages;information content;model;parameter derivation calculus;visualization exploration process;
Author: Jankun-Kelly, T.J.; Kwan-Liu Ma; Gertz, M.

Year: 2002
Title: Sea of images
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183792
Abstract: A long-standing research problem in computer graphics is to reproduce the visual experience of walking through a large photorealistic environment interactively. On one hand, traditional geometry-based rendering systems fall short of simulating the visual realism of a complex environment. On the other hand, image-based rendering systems have to date been unable to capture and store a sampled representation of a large environment with complex lighting and visibility effects. In this paper, we present a "sea of images," a practical approach to dense sampling, storage, and reconstruction of the plenoptic function in large, complex indoor environments. We use a motorized cart to capture omnidirectional images every few inches on a eye-height plane throughout an environment. The captured images are compressed and stored in a multiresolution hierarchy suitable for real-time prefetching during an interactive walkthrough. Later, novel images are reconstructed for a simulated observer by resampling nearby captured images. Our system acquires 15,254 images over 1,050 square feet at an average image spacing of 1.5 inches. The average capture and processing time is 7 hours. We demonstrate realistic walkthroughs of real-world environments reproducing specular reflections and occlusion effects while rendering 15-25 frames per second.
Keywords: complex lighting effects;complex visibility effects;computer graphics;dense reconstruction;dense sampling;dense storage;eye-height plane;image coding;image reconstruction;image resampling;image storage;images compression;interactive walkthrough;large complex indoor environments;large photorealistic environment;motorized cart;multiresolution hierarchy;occlusion effects;omnidirectional image capture;plenoptic function;real-time prefetching;real-time systems;rendering;rendering (computer graphics);sea of images;simulated observer;specular reflections;storage management;visual experience;
Author: Aliaga, D.G.; Funkhouser, T.; Yanovsky, D.; Carlbom, I.

Year: 2002
Title: Scalable alignment of large-format multi-projector displays using camera homography trees
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183793
Abstract: This paper presents a vision-based geometric alignment system for aligning the projectors in an arbitrarily large display wall. Existing algorithms typically rely on a single camera view and degrade in accuracy as the display resolution exceeds the camera resolution by several orders of magnitude. Naive approaches to integrating multiple zoomed camera views fail since small errors in aligning adjacent views propagate quickly over the display surface to create glaring discontinuities. Our algorithm builds and refines a camera homography tree to automatically register any number of uncalibrated camera images; the resulting system is both faster and significantly more accurate than competing approaches, reliably achieving alignment errors of 0.55 pixels on a 24-projector display in under 9 minutes. Detailed experiments compare our system to two recent display wall alignment algorithms, both on our 18 Megapixel display wall and in simulation. These results indicate that our approach achieves sub-pixel accuracy even on displays with hundreds of projectors.
Keywords: calibration;camera homography tree;camera homography trees;computer vision;feature extraction;large-format multi-projector displays;multiple zoomed camera;scalable alignment;uncalibrated camera images;vision-based geometric alignment system;
Author: Han Chen; Sukthankar, R.; Wallace, G.; Kai Li

Year: 2002
Title: Efficient compression and rendering of multi-resolution meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183794
Abstract: We present a method to code the multiresolution structure of a 3D triangle mesh in a manner that allows progressive decoding and efficient rendering at a client machine. The code is based on a special ordering of the mesh vertices which has good locality and continuity properties, inducing a natural multiresolution structure. This ordering also incorporates information allowing efficient rendering of the mesh at all resolutions using the contemporary vertex buffer mechanism. The performance of our code is shown to be competitive with existing progressive mesh compression methods, while achieving superior rendering speed.
Keywords: decoding;decoding;encoding;geometry coding;multiresolution meshes compression;multiresolution meshes rendering;rendering (computer graphics);vertex buffer mechanism;wavelet transforms;wavelets;
Author: Karni, Z.; Bogomjakov, A.; Gotsman, C.

Year: 2002
Title: Bounded-distortion piecewise mesh parameterization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183795
Abstract: Many computer graphics operations, such as texture mapping, 3D painting, remeshing, mesh compression, and digital geometry processing, require finding a low-distortion parameterization for irregular connectivity triangulations of arbitrary genus 2-manifolds. This paper presents a simple and fast method for computing parameterizations with strictly bounded distortion. The new method operates by flattening the mesh onto a region of the 2D plane. To comply with the distortion bound, the mesh is automatically cut and partitioned on-the-fly. The method guarantees avoiding global and local self-intersections, while attempting to minimize the total length of the introduced seams. To our knowledge, this is the first method to compute the mesh partitioning and the parameterization simultaneously and entirely automatically, while providing guaranteed distortion bounds. Our results on a variety of objects demonstrate that the method is fast enough to work with large complex irregular meshes in interactive applications.
Keywords: 3D painting;arbitrary genus 2-manifolds;bounded-distortion piecewise mesh parameterization;complex irregular meshes;computational geometry;computer graphics;data compression;digital geometry processing;distortion bound;image coding;mesh compression;mesh partitioning;remeshing;rendering (computer graphics);strictly bounded distortion;texture mapping;
Author: Sorkine, O.; Cohen-Or, D.; Goldenthal, R.; Lischinski, D.

Year: 2002
Title: XFastMesh: fast view-dependent meshing from external memory
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183796
Abstract: We present a novel disk-based multiresolution triangle mesh data structure that supports paging and view-dependent rendering of very large meshes at interactive frame rates from external memory. Our approach, called XFastMesh, is based on a view-dependent mesh simplification framework that represents half-edge collapse operations in a binary hierarchy known as a merge-tree forest. The proposed technique partitions the merge-tree forest into so-called detail blocks, which consist of binary subtrees, that are stored on disk. We present an efficient external memory data structure and file format that stores all detail information of the multiresolution triangulation method using significantly less storage then previously reported approaches. Furthermore, we present a paging algorithm that provides efficient loading and interactive rendering of large meshes from external memory at varying and view-dependent level-of-detail. The presented approach is highly efficient both in terms of space cost and paging performance.
Keywords: XFastMesh;binary subtrees;data structures;external memory data structure;file format;merge-tree forest;mesh generation;multiresolution triangle mesh data structure;multiresolution triangulation;paged storage;paging;rendering (computer graphics);space cost;view-dependent meshing;view-dependent rendering;
Author: DeCoro, C.; Pajarola, R.

Year: 2002
Title: Tensor field visualisation using adaptive filtering of noise fields combined with glyph rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183797
Abstract: While many methods exist for visualising scalar and vector data, visualisation of tensor data is still troublesome. We present a method for visualising second order tensors in three dimensions using a hybrid between direct volume rendering and glyph rendering. An overview scalar field is created by using three-dimensional adaptive filtering of a scalar field containing noise. The filtering process is controlled by the tensor field to be visualised, creating patterns that characterise the tensor field. By combining direct volume rendering of the scalar field with standard glyph rendering methods for detailed tensor visualisation, a hybrid solution is created. A combined volume and glyph renderer was implemented and tested with both synthetic tensors and strain-rate tensors from the human heart muscle, calculated from phase contrast magnetic resonance image data. A comprehensible result could be obtained, giving both an overview of the tensor field as well as detailed information on individual tensors.
Keywords: adaptive filtering;biomedical MRI;data visualisation;data visualisation;direct volume rendering;glyph rendering;human heart muscle;noise fields;phase contrast magnetic resonance image data;rendering (computer graphics);strain-rate tensors;tensor field visualisation;three-dimensional adaptive filtering;
Author: Sigfridsson, A.; Ebbers, T.; Heiberg, E.; Wigstrom, L.

Year: 2002
Title: Volume deformation for tensor visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183798
Abstract: Visualizing second-order 3D tensor fields continue to be a challenging task. Although there are several algorithms that have been presented, no single algorithm by itself is sufficient for the analysis because of the complex nature of tensor fields. In this paper, we present two new methods, based on volume deformation, to show the effects of the tensor field upon its underlying media. We focus on providing a continuous representation of the nature of the tensor fields. Each of these visualization algorithms is good at displaying some particular properties of the tensor field.
Keywords: continuous representation;data visualisation;eigenvalues and eigenfunctions;second-order 3D tensor fields visualization;volume deformation;
Author: Xiaoqiang Zheng; Pang, A.

Year: 2002
Title: Oriented tensor reconstruction: tracing neural pathways from diffusion tensor MRI
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183799
Abstract: In this paper we develop a new technique for tracing anatomical fibers from 3D tensor fields. The technique extracts salient tensor features using a local regularization technique that allows the algorithm to cross noisy regions and bridge gaps in the data. We applied the method to human brain DT-MRI data and recovered identifiable anatomical structures that correspond to the white matter brain-fiber pathways. The images in this paper are derived from a dataset having 121&times;88&times;60 resolution. We were able to recover fibers with less than the voxel size resolution by applying the regularization technique, i.e., using a priori assumptions about fiber smoothness. The regularization procedure is done through a moving least squares filter directly incorporated in the tracing algorithm.
Keywords: 3D tensor fields;a priori assumptions;anatomical fibers tracing;biomedical MRI;brain-fiber pathways;computer graphics;data visualisation;diffusion tensor MRI;eigenvalues and eigenfunctions;human brain DT-MRI data;identifiable anatomical structures;interpolation;least squares approximations;least squares filter;neural pathways tracing;oriented tensor reconstruction;voxel size resolution;
Author: Zhukov, L.; Barr, A.H.

Year: 2002
Title: QuadTIN: quadtree based triangulated irregular networks
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183800
Abstract: Interactive visualization of large digital elevation models is of continuing interest in scientific visualization, GIS, and virtual reality applications. Taking advantage of the regular structure of grid digital elevation models, efficient hierarchical multiresolution triangulation and adaptive level-of-detail (LOD) rendering algorithms have been developed for interactive terrain visualization. Despite the higher triangle count, these approaches generally outperform mesh simplification methods that produce irregular triangulated network (TIN) based LOD representations. In this project we combine the advantage of a TIN based mesh simplification preprocess with high-performance quadtree based LOD triangulation and rendering at run-time. This approach, called QuadTIN, generates an efficient quadtree triangulation hierarchy over any irregular point set that may originate from irregular terrain sampling or from reducing oversampling in high-resolution grid digital elevation models.
Keywords: QuadTIN;adaptive level-of-detail rendering algorithms;computational geometry;computational geometry;data visualisation;digital elevation models;interactive terrain visualization;interactive visualization;irregular triangulated network;multiresolution triangulation;quadtree based triangulated irregular networks;quadtrees;rendering (computer graphics);scientific visualization;terrain sampling;virtual reality;virtual reality;
Author: Pajarola, R.; Antonijuan, M.; Lario, R.

Year: 2002
Title: Horizon occlusion culling for real-time rendering of hierarchical terrains
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183801
Abstract: We present a technique to perform occlusion culling for hierarchical terrains at run-time. The algorithm is simple to implement and requires minimal pre-processing and additional storage, yet leads to 2-4 times improvement in framerate for views with high degrees of occlusion. Our method is based on the well-known occlusion horizon algorithm. We show how to adapt the algorithm for use with hierarchical terrains. The occlusion horizon is constructed as the terrain is traversed in an approximate front to back ordering. Regions of the terrain are compared to the horizon to determine when they are completely occluded from the viewpoint. Culling these regions leads to significant savings in rendering.
Keywords: data visualisation;hierarchical terrains;horizon occlusion culling;minimal preprocessing;real-time rendering;rendering;rendering (computer graphics);
Author: Lloyd, B.; Egbert, P.

Year: 2002
Title: Evaluation of a multimodal interface for 3D terrain visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183802
Abstract: Novel speech and/or gesture interfaces are candidates for use in future mobile or ubiquitous applications. This paper describes an evaluation of various interfaces for visual navigation of a whole Earth 3D terrain model. A mouse driven interface, a speech interface, a gesture interface, and a multimodal speech and gesture interface were used to navigate to targets placed at various points on the Earth. This study measured each participant's recall of target identity, order, and location as a measure of cognitive load. Timing information as well as a variety of subjective measures including discomfort and user preference were taken. While the familiar and mature mouse interface scored best by most measures, the speech interface also performed well. The gesture and multimodal interface suffered from weaknesses in the gesture modality. Weaknesses in the speech and multimodal modalities are identified and areas for improvement are discussed.
Keywords: 3D terrain visualization;Earth 3D terrain model;GIS;data visualisation;geographic information systems;gesture interface;gesture recognition;gesture recognition;mouse driven interface;multimodal interface;multimodal speech interface;speech interface;speech recognition;speech recognition;virtual reality;virtual reality;visual navigation;
Author: Krum, D.M.; Omoteso, O.; Ribarsky, W.; Starner, T.; Hodges, L.F.

Year: 2002
Title: Assisted navigation for large information spaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183803
Abstract: This paper presents a new technique for visualizing large, complex collections of data. The size and dimensionality of these datasets make them challenging to display in an effective manner. The images must show the global structure of spatial relationships within the dataset, yet at the same time accurately represent the local detail of each data element being visualized. We propose combining ideas from information and scientific visualization together with a navigation assistant, a software system designed to help users identify and explore areas of interest within their data. The assistant locates data elements of potential importance to the user, clusters them into spatial regions, and builds underlying graph structures to connect the regions and the elements they contain. Graph traversal algorithms, constraint-based viewpoint construction, and intelligent camera planning techniques can then be used to design animated tours of these regions. In this way, the navigation assistant can help users to explore any of the areas of interest within their data. We conclude by demonstrating how our assistant is being used to visualize a multidimensional weather dataset.
Keywords: animated tours;camera planning;camera planning techniques;constraint-based viewpoint construction;data visualisation;data. visualization;database management systems;graph traversal;navigation assistant;scientific visualization;
Author: Dennis, B.M.; Healey, C.G.

Year: 2002
Title: BM3D: motion estimation in time dependent volume data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183804
Abstract: This paper describes BM3D: a method for the analysis of motion in time dependent volume data. From a sequence of volume data sets a sequence of vector data sets representing the movement of the data is computed. A block matching technique is used for the reconstruction of data movement. The derived vector field can be used for the visualization of time dependent volume data. The method is illustrated in two applications.
Keywords: BM3D;block matching technique;data movement reconstruction;data visualisation;motion estimation;motion estimation;time dependent volume data;vector data set sequence;volume data set sequence;
Author: de Leeuw, W.; van Liere, R.

Year: 2002
Title: Kinetic visualization: a technique for illustrating 3D shape and structure
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183805
Abstract: Motion provides strong visual cues for the perception of shape and depth, as demonstrated by cognitive scientists and visual artists. This paper presents a novel visualization technique-kinetic visualization -that uses particle systems to add supplemental motion cues which can aid in the perception of shape and spatial relationships of static objects. Based on a set of rules following perceptual and physical principles, particles flowing over the surface of an object not only bring out, but also attract attention to, essential information on the shape of the object that might not be readily visible with conventional rendering that uses lighting and view changes. Replacing still images with animations in this fashion, we demonstrate with both surface and volumetric models in the accompanying videos that in many cases the resulting visualizations effectively enhance the perception of three-dimensional shape and structure. The results of a preliminary user study that we have conducted also show evidence that the supplemental motion cues help.
Keywords: 3D shape perception;3D structure perception;animations;computer animation;data visualisation;depth;flowing particles;image sequences;kinetic visualization;motion;motion cues;particle systems;rendering (computer graphics);spatial relationships;static objects;surface models;video signal processing;videos;visual cues;volumetric models;
Author: Lum, E.B.; Stompel, A.; Kwan-Liu Ma

Year: 2002
Title: A radial focus+context visualization for multi-dimensional functions
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183806
Abstract: The analysis of multidimensional functions is important in many engineering disciplines, and poses a major problem as the number of dimensions increases. Previous visualization approaches focus on representing three or fewer dimensions at a time. This paper presents a new focus+context visualization that provides an integrated overview of an entire multidimensional function space, with uniform treatment of all dimensions. The overview is displayed with respect to a user-controlled polar focal point in the function's parameter space. Function value patterns are viewed along rays that emanate from the focal point in all directions in the parameter space, and represented radially around the focal point in the visualization. Data near the focal point receives proportionally more screen space than distant data. This approach scales smoothly from two dimensions to 10-20, with a 1000 pixel range on each dimension.
Keywords: data visualisation;data visualization;graphical user interfaces;graphical user interfaces;multi-dimensional functions;multidimensional function space;radial focus+context visualization;user-controlled polar focal point;
Author: Jayaraman, S.; North, C.

Year: 2002
Title: BLIC: Bi-Level Isosurface Compression
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183807
Abstract: In this paper we introduce a new and simple algorithm to compress isosurface data. This is the data extracted by isosurface algorithms from scalar functions defined on volume grids, and used to generate polygon meshes or alternative representations. In this algorithm the mesh connectivity and a substantial proportion of the geometric information are encoded to a fraction of a bit per marching cubes vertex with a context based arithmetic coder closely related to the JBIG binary image compression standard. The remaining optional geometric information that specifies the location of each marching cubes vertex more precisely along its supporting intersecting grid edge, is efficiently encoded in scan-order with the same mechanism. Vertex normals can optionally be computed as normalized gradient vectors by the encoder and included in the bitstream after quantization and entropy encoding, or computed by the decoder in a postprocessing smoothing step. These choices are determined by trade-offs associated with an in-core vs. out-of-core decoder structure. The main features of our algorithm are its extreme simplicity and high compression rates.
Keywords: BLIC;JBIG binary image compression;bi-level isosurface compression;computational geometry;context based arithmetic;data compression;data visualisation;entropy encoding;image coding;isosurface algorithms;isosurface data compression;marching cubes vertex;mesh connectivity;polygon meshes;scalar functions;solid modelling;volume grids;
Author: Taubin, G.

Year: 2002
Title: Approximating normals for marching cubes applied to locally supported isosurfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183808
Abstract: We present some new methods for computing estimates of normal vectors at the vertices of a triangular mesh surface approximation to an isosurface which has been computed by the marching cube algorithm. These estimates are required for the smooth rendering of triangular mesh surfaces. The conventional method of computing estimates based upon divided difference approximations of the gradient can lead to poor estimates in some applications. This is particularly true for isosurfaces obtained from a field function, which is defined only for values near to the isosurface. We describe some efficient methods for computing the topology of the triangular mesh surface, which is used for obtaining local estimates of the normals. In addition, a new, one pass, approach for these types of applications is described and compared to existing methods.
Keywords: Gouraud shading;cubes marching;data visualisation;interpolation;locally supported isosurfaces;normals approximation;rendering (computer graphics);triangular mesh surface approximation;
Author: Nielson, G.M.; Huang, A.; Sylvester, S.

Year: 2002
Title: Volume warping for adaptive isosurface extraction
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183809
Abstract: Polygonal approximations of isosurfaces extracted from uniformly sampled volumes are increasing in size due to the availability of higher resolution imaging techniques. The large number of I primitives represented hinders the interactive exploration of the dataset. Though many solutions have been proposed to this problem, many require the creation of isosurfaces at multiple resolutions or the use of additional data structures, often hierarchical, to represent the volume. We propose a technique for adaptive isosurface extraction that is easy to implement and allows the user to decide the degree of adaptivity as well as the choice of isosurface extraction algorithm. Our method optimizes the extraction of the isosurface by warping the volume. In a warped volume, areas of importance (e.g. containing significant details) are inflated while unimportant ones are contracted. Once the volume is warped, any extraction algorithm can be applied. The extracted mesh is subsequently unwarped such that the warped areas are rescaled to their initial proportions. The resulting isosurface is represented by a mesh that is more densely sampled in regions decided as important.
Keywords: adaptive isosurface extraction;computational geometry;computational geometry;data structures;data visualisation;imaging techniques;interactive exploration;interpolation;isosurfaces;object modeling;polygonal approximations;solid modelling;solid modelling;uniformly sampled volumes;volume warping;
Author: Balmelli, L.; Morris, C.J.; Taubin, G.; Bernardini, F.

Year: 2002
Title: Interactive view-dependent rendering of large isosurfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183810
Abstract: We present an algorithm for interactively extracting and rendering isosurfaces of large volume datasets in a view-dependent fashion. A recursive tetrahedral mesh refinement scheme, based on longest edge bisection, is used to hierarchically decompose the data into a multiresolution structure. This data structure allows fast extraction of arbitrary isosurfaces to within user specified view-dependent error bounds. A data layout scheme based on hierarchical space filling curves provides access to the data in a cache coherent manner that follows the data access pattern indicated by the mesh refinement.
Keywords: computational geometry;computational geometry;data structure;data structures;edge bisection;graphics data structures;interactive view-dependent rendering;large isosurfaces rendering;mesh refinement;multiresolution structure;object modeling;recursive tetrahedral mesh refinement;rendering (computer graphics);solid modelling;view-dependent fashion;
Author: Gregorski, B.; Duchaineau, M.; Lindstrom, P.; Pascucci, V.; Joy, K.I.

Year: 2002
Title: Case study: hardware-accelerated selective LIC volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183811
Abstract: Line Integral Convolution (LIC) is a promising method for visualizing 2D dense flow fields. Direct extensions of the LIC method to 3D have not been considered very effective, because optical integration in viewing directions tends to spoil the coherent structures along 3D local streamlines. In our previous reports, we have proposed a selective approach to volume rendering of LIC solid texture using 3D significance map (S-map), derived from the characteristics of flow structures, and a specific illumination model for 3D streamlines. In this paper, we take full advantage of scalar volume rendering hardware, such as VolumePro, to realize a realtime 3D flow field visualization environment with the LIC volume rendering method.
Keywords: 2D dense flow fields visualization;3D local streamlines;3D significance map;VolumePro;flow structures;flow visualisation;flow visualization;hardware-accelerated selective LIC volume rendering;line integral convolution;rendering (computer graphics);solid texture;viewing directions;
Author: Suzuki, Y.; Fujishiro, I.; Chen, L.; Nakamura, H.

Year: 2002
Title: Christmas tree case study: computed tomography as a tool for mastering complex real world objects with applications in computer graphics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183812
Abstract: We report on using computed tomography (CT) as a model acquisition tool for complex objects in computer graphics. Unlike other modeling and scanning techniques the complexity of the object is irrelevant in CT, which naturally enables to model objects with, for example, concavities, holes, twists or fine surface details. Once the data is scanned, one can apply post-processing techniques for data enhancement, modification or presentation. For demonstration purposes we chose to scan a Christmas tree which exhibits high complexity which is difficult or even impossible to handle with other techniques. However, care has to be taken to achieve good scanning results with CT. Further, we illustrate post-processing by means of data segmentation and photorealistic as well as non-photorealistic surface and volume rendering techniques.
Keywords: Christmas tree scanning;complex real world objects;computational complexity;computed tomography;computer graphics;computerised tomography;data enhancement;data presentation;data visualisation;model acquisition too;solid modelling;volume rendering;
Author: Kanitsar, A.; Theussl, T.; Mroz, L.; Sramek, M.; Bartroli, A.V.; Csebfalvi, B.; Hladuvka, J.; Fleischmann, D.; Knapp, M.; Wegenkittl, R.; Felkel, P.; Rottger, S.; Guthe, S.; Purgathofer, W.; Groller, M.E.

Year: 2002
Title: Case study: Visualization and analysis of high Rayleigh number - 3D convection in the Earth's mantle
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183813
Abstract: Data sets from large-scale simulations (up to 501<sup>3</sup> grid points) of mantle convection are analyzed with volume rendering of the temperature field and a new critical point analysis of the velocity field. As the Rayleigh number Ra is increased the thermal field develops increasingly thin plume-like structures along which heat is convected. These eventually break down and become turbulent. Visualization methods are used to distinguish between various models of heat conductivity and to develop an intuitive understanding of the structure of the flow.
Keywords: 3D convection;Earth Mantle;critical point analysis;data visualisation;feature extraction;geophysics computing;heat conductivity;high Rayleigh number visualization;large-scale simulations;plume-like structures;rendering (computer graphics);velocity field;volume rendering;
Author: Erlebacher, G.; Yuen, D.A.; Dubuffet, F.

Year: 2002
Title: Immersive volume visualization of seismic simulations: A case study of techniques invented and lessons learned
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183814
Abstract: This paper is a documentation of techniques invented, results obtained and lessons learned while creating visualization algorithms to render outputs of large-scale seismic simulations. The objective is the development of techniques for a collaborative simulation and visualization shared between structural engineers, seismologists, and computer scientists. The computer graphics research community has been witnessing a large number of exemplary publications addressing the challenges faced while trying to visualize both large-scale surface and volumetric datasets lately. From a visualization perspective, issues like data preprocessing (simplification, sampling, filtering, etc.); rendering algorithms (surface and volume), and interaction paradigms (large-scale, highly interactive, highly immersive, etc.) have been areas of study. In this light, we outline and describe the milestones achieved in a large-scale simulation and visualization project, which opened the scope for combining existing techniques with new methods, especially in those cases where no existing methods were suitable. We elucidate the data simplification and reorganization schemes that we used, and discuss the problems we encountered and the solutions we found. We describe both desktop (high-end local as well as remote) interfaces and immersive visualization systems that we developed to employ interactive surface and volume rendering algorithms. Finally, we describe the results obtained, challenges that still need to be addressed, and ongoing efforts to meet the challenges of large-scale visualization.
Keywords: collaborative simulation;computer graphics;data visualisation;geophysics computing;immersive volume visualization;rendering (computer graphics);rendering algorithms;seismic simulations;seismology;volumetric datasets;
Author: Chopra, P.; Meyer, J.; Fernandez, A.

Year: 2002
Title: Case study: A look of performance expression
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183815
Abstract: For most of the time, we enjoy and appreciate music performances as they are. Once we try to understand the performance not in subjective terms but in an objective way and share it with other people, visualizing the performance parameters is indispensable. In this paper, a figure for visualizing performance expressions is described. This figure helps people understand the cause and position of the performance expression as it has expressive cues, which coincide with the cognitive meaning of musical performance, and not by using only MIDI parameter values. The differences we hear between performances are clarified by visualized figures.
Keywords: art;data visualisation;music;musical performance;performance expression;performance parameters visualization;rendering (computer graphics);
Author: Hiraga, R.

Year: 2002
Title: Case study: Interactive visualization for Internet security
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183816
Abstract: Internet connectivity is defined by a set of routing protocols which let the routers that comprise the Internet backbone choose the best route for a packet to reach its destination. One way to improve the security and performance of Internet is to routinely examine the routing data. In this case study, we show how interactive visualization of Border Gateway Protocol (BGP) data helps characterize routing behavior, identify weaknesses in connectivity which could potentially cripple the Internet, as well as detect and explain actual anomalous events.
Keywords: Internet;Internet security;anomaly detection;border gateway protocol;data visualisation;graph drawing;graphical user interfaces;graphical user interfaces;information visualization;interactive systems;interactive visualization;routing protocols;routing protocols;security of data;
Author: Soon Tee Teoh; Kwan-Liu Ma; Wu, S.F.; Xiaoliang Zhao

Year: 2002
Title: PRIMA: A case study of using information visualization techniques for patient record analysis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183817
Abstract: We have created an application, called PRIMA (Patient Record intelligent Monitoring and Analysis), which can be used to visualize and understand patient record data. It was developed to better understand a large collection of patient records of bone marrow transplants at Hadassah Hospital in Jerusalem, Israel. It is based on an information visualization toolkit, Opal, which has been developed at the IBM T.J. Watson Research Center. Opal allows intelligent, interactive visualization of a wide variety of different types of data. The PRIMA application is generally applicable to a wide range of patient record data, as the underlying toolkit is flexible with regard to the form of the input data. This application is a good example of the usefulness of information visualization techniques in the bioinformatics domain, as these techniques have been developed specifically to deal with diverse sets of often unfamiliar data. We illustrate several unanticipated findings which resulted from the use of a flexible and interactive information visualization environment.
Keywords: Opal;PRIMA;bioinformatics domain;bone marrow transplants;data visualisation;information visualization;medical information systems;patient record intelligent monitoring and analysis;
Author: Gresh, D.L.; Rabenhorst, D.A.; Shabo, A.; Slavin, S.

Year: 2002
Title: Case study: A virtual environment for genomic data visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183818
Abstract: With the completion of the human genome sequence, and with the proliferation of genome-related annotation data, the need for scalable and more intuitive means for analysis becomes critical, At Variagenics and Small Design Firm, we have addressed this problem with a coherent three-dimensional space in which all data can be seen in a single context. This tool aids in integrating information at vastly divergent scales while maintaining accurate spatial and size relationships. Our visualization was successful in communicating to project teams with diverse backgrounds the magnitude and biological implication of genetic variation.
Keywords: genomic data visualization;human genome sequence;medical computing;virtual environment;virtual reality;
Author: Adams, R.M.; Stancampiano, B.; McKenna, M.; Small, D.

Year: 2002
Title: Case study: Visual debugging of finite element codes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183819
Abstract: We present an innovative application developed at Sandia National Laboratories for visual debugging of unstructured finite element physics codes. Our tool automatically locates anomalous regions, such as inverted elements or nodes whose variable values lie outside a prescribed range, then extracts mesh subsets around these features for detailed examination. The subsets are viewed using color coding of variable values superimposed on the mesh structure. This allows the values and their relative spatial locations within the mesh to be correlated at a glance. Both topological irregularities and hot spots within the data stand out visually, allowing the user to explore the exact numeric values of the grid at surrounding points over time. We demonstrate the utility of this approach by debugging a cell inversion in a simulation of an exploding wire.
Keywords: cell inversion;color coding;data visualisation;finite element analysis;finite element codes;mathematics computing;mesh subsets;program debugging;visual debugging;
Author: Crossno, P.; Rogers, D.H.; Garasi, C.J.

Year: 2002
Title: Case study: Interactive rendering of adaptive mesh refinement data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183820
Abstract: Adaptive mesh refinement (AMR) is a popular computational simulation technique used in various scientific and engineering fields. Although AMR data is organized in a hierarchical multi-resolution data structure, the traditional volume visualization algorithms such as ray-casting and splatting cannot handle the form without converting it to a sophisticated data structure. In this paper, we present a hierarchical multi-resolution splatting technique using k-d trees and octrees for AMR data that is suitable for implementation on the latest consumer PC graphics hardware. We describe a graphical user interface to set transfer function and viewing/rendering parameters interactively. Experimental results obtained on a general purpose PC equipped with NVIDIA GeForce card are presented to demonstrate that the technique can interactively render AMR data (over 20 frames per second). Our scheme can easily be applied to parallel rendering of time-varying AMR data.
Keywords: AMR data;PC graphics hardware;adaptive mesh refinement data;computational simulation technique;graphical user interface;graphical user interfaces;hierarchical multiresolution data structure;interactive rendering;interactive systems;k-d trees;mesh generation;octrees;octrees;rendering (computer graphics);splatting;transfer function NVIDIA GeForce card;volume visualization algorithms;
Author: Sanghun Park; Bajaj, C.L.; Siddavanahalli, V.

Year: 2002
Title: A case study in selective visualization of unsteady 3D flow
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183821
Abstract: In this case study, we explore techniques for the purpose of visualizing isolated flow structures in time-dependent data. Our primary industrial application is the visualization of the vortex rope, a rotating helical structure which builds up in the draft tube of a water turbine. The vortex rope can be characterized by high values of normalized helicity, which is a scalar field derived from the given CFD velocity data. In two related applications, the goal is to visualize the cavitation regions near the runner blades of a Kaplan turbine and a water pump, respectively. Again, the flow structure of interest can be defined by a scalar field, namely by low pressure values. We propose a particle seeding scheme based on quasi-random numbers, which minimizes visual artifacts such as clusters or patterns. By constraining the visualization to a region of interest, occlusion problems are reduced and storage efficiency is gained.
Keywords: Kaplan turbine;computational fluid dynamics;feature extraction;flow visualisation;interpolation;isolated flow structures;low pressure values;particle seeding scheme;selective visualization;time-dependent data;unsteady 3D flow;vortex rope visualization;water pump;
Author: Bauer, D.; Peikert, R.; Sato, M.; Sick, M.

Year: 2002
Title: Case study: Visualizing ocean flow vertical motions using Lagrangian-Eulerian time surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183822
Abstract: Ocean model simulations commonly assume the ocean is hydrostatic, resulting in near zero vertical motion. The vertical motion found is typically associated with the variations of the thermocline depth over time, which are mainly a result of the development and movement of ocean fronts, eddies, and internal waves. A new technique, extended from Lagrangian-Eulerian Advection, is presented to help understand the variation of vertical motion associated with the change in thermocline depth over time. A time surface is correctly deformed in a single direction according to the flow. The evolution of the time surface is computed via a mixture of Eulerian and Lagrangian techniques. The dominant horizontal motion is textured onto the surface using texture advection, while both the horizontal and vertical motions are used to displace the surface. The resulting surface is shaded for enhanced contrast. Timings indicate that the overhead over standard 2D texture advection is no more than 12%.
Keywords: Lagrangian-Eulerian time surfaces;flow simulation;flow visualisation;internal waves;near zero vertical motion;ocean flow vertical motions visualization;ocean model simulations;oceanographic techniques;thermocline depth;
Author: Grant, J.; Erlebacher, G.; O'Brien, J.

Year: 2002
Title: A case study on multiresolution visualization of local rainfall from weather radar measurements
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183823
Abstract: Weather radars can measure the backscatter from rain drops in the atmosphere. A complete radar scan provides three-dimensional precipitation information. For the understanding of the underlying atmospheric processes interactive visualization of these data sets is necessary. This is a challenging task due to the size, structure and required context of the data. In this case study, a multiresolution approach for real-time simultaneous visualization of radar measurements together with the corresponding terrain data is illustrated.
Keywords: atmospheric precipitation;backscatter;computational geometry;computational geometry;data visualisation;interactive visualization;level-of-detail;local rainfall;meteorological radar;multiresolution visualization;object modeling;rain;rain drops;real-time simultaneous visualization;rendering (computer graphics);solid modelling;solid modelling;three-dimensional precipitation information;weather radar measurements;
Author: Gerstner, T.; Meetschen, D.; Crewel, S.; Griebel, M.; Simmer, C.

Year: 2002
Title: Rendering the first star in the Universe - A case study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183824
Abstract: For quantitative examination of phenomena that simultaneously occur on very different spatial and temporal scales, adaptive hierarchical schemes are required. A special numerical multilevel technique, associated with a particular hierarchical data structure, is so-called adaptive mesh refinement (AMR). It allows one to bridge a wide range of spatial and temporal resolutions and therefore gains increasing popularity. We describe the interplay of several visualization and VR software packages for rendering time dependent AMR simulations of the evolution of the first star in the universe. The work was done in the framework of a television production for Discovery Channel television, "The Unfolding Universe.". Parts of the data were taken from one of the most complex AMR simulation ever carried out: It contained up to 27 levels of resolution, requiring modifications to the texture based AMR volume rendering algorithm that was used to depict the density distribution of the gaseous interstellar matter. A voice and gesture controlled CAVE application was utilized to define camera paths following the interesting features deep inside the computational domains. Background images created from cosmological computational data were combined with the final renderings.
Keywords: adaptive hierarchical schemes;adaptive mesh refinement;astronomy computing;data structures;data visualisation;data visualization;hierarchical data structure;mesh generation;numerical multilevel technique;quantitative examination;rendering;rendering (computer graphics);spatial scales;temporal scales;
Author: Kahler, R.; Cox, D.; Patterson, R.; Levy, S.; Hege, H.-C.; Abel, T.

Year: 2002
Title: NASA's great zooms: a case study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183825
Abstract: This paper examines a series of NASA outreach visualizations created using several layers of remote sensing satellite data ranging from 4-kilometers per pixel to I-meter per pixel. The viewer is taken on a seamless, cloud free journey from a global view of the Earth down to ground level where buildings, streets, and cars are visible. The visualizations were produced using a procedural shader that takes advantage of accurate georegistration and color matching between images. The shader accurately and efficiently maps the data sets to geometry allowing for animations with few perceptual transitions among data sets. We developed a pipeline to facilitate the production of over twenty zoom visualizations. Millions of people have seen these visualizations through national and international media coverage.
Keywords: Earth;NASA great zooms;NASA outreach visualizations;animations;cloud free journey;color matching;data visualisation;geophysics computing;georegistration;remote sensing satellite data;rendering (computer graphics);terrain mapping;
Author: Shirah, G.W.; Mitchell, H.G.

Year: 2002
Title: A case study on automatic camera placement and motion for visualizing historical data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183826
Abstract: In this paper, we address the problem of automatic camera positioning and automatic camera path generation in the context of historical data visualization. After short description of the given data, we elaborate on the constraints for the positioning of a virtual camera in such a way that not only the projected area is maximized, but also the depth of the displayed scene. This is especially important when displaying terrain models, which do not provide good 3D impression when only the projected area is maximized. Based on this concept, we present a method for computing an optimal camera position for each instant of time. Since the explored data are not static, but change depending on the explored scene time, we also discuss a method for animation generation. In order to avoid sudden changes of the camera position, when the previous method is applied for each frame (point in time), we introduce pseudo-events in time, which expand the bounding box defined by the currently active events of interest. In particular, this technique allows events happening in a future point in time to be taken into account such that when this time becomes current, all events of interest are already within the current viewing frustum of the camera.
Keywords: animation generation;automatic camera path generation;automatic camera placement;automatic camera positioning;computer animation;data visualisation;graphical user interfaces;graphical user interfaces;historical data visualization;optimal camera position;
Author: Stoev, S.L.; Strasser, W.

Year: 2002
Title: Case study on the adaptation of interactive visualization applications to Web-based production for operational mesoscale weather models
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183827
Abstract: Visualization is required for the effective utilization of data from a weather simulation. Appropriate mapping of user goals to the design of pictorial content has been useful in the development of interactive applications with sufficient bandwidth for timely access to the model data. When remote access to the model visualizations is required the limited bandwidth becomes the primary bottleneck. To help address these problems, visualizations are presented on a Web page as a meta-representation of the model output and serve as an index to simplify finding other visualizations of relevance. To provide consistency with extant interactive products and to leverage their cost of development, the aforementioned applications are adapted to automatically populate a Web site with images and interactions for an operational weather forecasting system.
Keywords: Web design;Web page;Web site;Web-based production;data visualisation;geophysics computing;interactive systems;interactive visualization applications;meta data;meta-representation;operational mesoscale weather models;remote access;weather forecasting;weather forecasting system;weather simulation;
Author: Treinish, L.A.

Year: 2002
Title: Exploring surface characteristics with interactive Gaussian images (a case study)
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183828
Abstract: The Gauss map projects surface normals to a unit sphere, providing a powerful visualization of the geometry of a graphical object. it can be used to predict visual events caused by changes in lighting, shading, and camera control. We present an interactive technique for portraying the Gauss map of polygonal models, mapping surface normals and the magnitudes of surface curvature using a spherical projection. Unlike other visualizations of surface curvature, we create our Gauss map directly from polygonal meshes without requiring any complex intermediate calculations of differential geometry. For anything other than simple shapes, surface information is densely mapped into the Gaussian normal image, inviting the use of visualization techniques to amplify and emphasize details hidden within the wealth of data. We present the use of interactive visualization tools such as brushing and linking to explore the surface properties of solid shapes. The Gauss map is shown to be simple to compute, easy to view dynamically, and effective at portraying important features of polygonal models.
Keywords: Gauss map;Gaussian distribution;Gaussian normal image;brushing;computational geometry;computational geometry;data visualisation;dense mapping;graphical object geometry;hidden details;illumination;interactive Gaussian images;interactive systems;interactive visualization tools;linking;polygonal meshes;polygonal models;shading;spherical projection;surface characteristics;surface curvature;
Author: Lowekamp, B.; Rheingans, P.; Yoo, T.S.

Year: 2002
Title: A case study on the applications of a generic library for low-cost polychromatic passive stereo
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183829
Abstract: Active stereo has been used by engineers and industrial designers for several years to enhance the perception of computer generated three-dimensional images. Unfortunately, active stereo requires specialized hardware. Therefore, as ubiquitous computing and teleworking gain importance, using active stereo becomes a problem. The goal of this case study is to examine the concept of a generic library for polychromatic passive stereo to make stereo vision available everywhere.
Keywords: computer graphics;computer vision;data visualisation;generic library;image generation;low-cost polychromatic passive stereo;software libraries;stereo image processing;stereo vision;teleworking;ubiquitous computing;
Author: Stegmaier, S.; Rose, D.; Ertl, T.

Year: 2002
Title: Case study: the Office of Real Soon Now for visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1183830
Abstract: As part of a larger effort exploring alternative display systems, Lawrence Livermore National Laboratory has installed systems in two offices that extend and update the previously described "Office of Real Soon Now" project to improve the value for visualization tasks. These new systems use higher resolution projectors driven by workstations that run Unix-based applications via Linux and support hardware-accelerated 3D graphics, even across the boundary between displays.
Keywords: Lawrence Livermore National Laboratory;Linux;Office of Real Soon Now project;Unix;Unix-based applications;computer displays;data visualisation;display systems;hardware-accelerated 3D graphics;high-resolution projectors;office automation;visualization;workstations;workstations;
Author: Uselton, S.P.

Year: 2001
Title: Point set surfaces
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964489
Abstract: We advocate the use of point sets to represent shapes. We provide a definition of a smooth manifold surface from a set of points close to the original surface. The definition is based on local maps from differential geometry, which are approximated by the method of moving least squares (MLS). We present tools to increase or decrease the density of the points, thus, allowing an adjustment of the spacing among the points to control the fidelity of the representation. To display the point set surface, we introduce a novel point rendering technique. The idea is to evaluate the local maps according to the image resolution. This results in high quality shading effects and smooth silhouettes at interactive frame rates.
Keywords: 3D acquisition;differential geometry;moving least squares;point set surface;point sets;rendering;rendering (computer graphics);smooth manifold surface;surface fitting;surface reconstruction;surface representation;
Author: Alexa, M.; Behr, J.; Cohen-Or, D.; Fleishman, S.; Levin, D.; Silva, C.T.

Year: 2001
Title: EWA volume splatting
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964490
Abstract: In this paper we present a novel framework for direct volume rendering using a splatting approach based on elliptical Gaussian kernels. To avoid aliasing artifacts, we introduce the concept of a resampling filter combining a reconstruction with a low-pass kernel. Because of the similarity to Heckbert's EWA (elliptical weighted average) filter for texture mapping we call our technique EWA volume splatting. It provides high image quality without aliasing artifacts or excessive blurring even with non-spherical kernels. Hence it is suitable for regular, rectilinear, and irregular volume data sets. Moreover, our framework introduces a novel approach to compute the footprint function. It facilitates efficient perspective projection of arbitrary elliptical kernels at very little additional cost. Finally, we show that EWA volume reconstruction kernels can be reduced to surface reconstruction kernels. This makes our splat primitive universal in reconstructing surface and volume data.
Keywords: EWA voIume splatting;direct volume rendering;elliptical Gaussian kernels;footprint function;high image quality;rendering (computer graphics);splatting;surface fitting;volume rendering;
Author: Zwicker, M.; Pfister, H.; van Baar, J.; Gross, M.

Year: 2001
Title: Hybrid simplification: combining multi-resolution polygon and point rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964491
Abstract: Multi-resolution hierarchies of polygons and more recently of points are familiar and useful tools for achieving interactive rendering rates. We present an algorithm for tightly integrating the two into a single hierarchical data structure. The trade-off between rendering portions of a model with points or with polygons is made automatically. Our approach to this problem is to apply a bottom-up simplification process involving not only polygon simplification operations, but point replacement and point simplification operations as well. Given one or more surface meshes, our algorithm produces a hybrid hierarchy comprising both polygon and point primitives. This hierarchy may be optimized according to the relative performance characteristics of these primitive types on the intended rendering platform. We also provide a range of aggressiveness for performing point replacement operations. The most conservative approach produces a hierarchy that is better than a purely polygonal hierarchy in some places, and roughly equal in others. A less conservative approach can trade reduced complexity at the far viewing ranges for some increased complexity at the near viewing ranges. We demonstrate our approach on a number of input models, achieving primitive counts that are 1.3 to 4.7 times smaller than those of triangle-only simplification.
Keywords: complexity;computational complexity;computational geometry;multi-resolution;point primitives;point replacement;point simplification;polygon primitives;polygon simplification;rendering;rendering (computer graphics);surface meshes;
Author: Cohen, J.D.; Aliaga, D.G.; Weiqiang Zhang

Year: 2001
Title: Transport and anisotropic diffusion in time-dependent flow visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964494
Abstract: The visualization of time-dependent flow is an important and challenging topic in scientific visualization. Its aim is to represent transport phenomena governed by time-dependent vector fields in an intuitively understandable way, using images and animations. Here we pick up the recently presented anisotropic diffusion method, expand and generalize it to allow a multiscale visualization of long-term, complex transport problems. Instead of streamline type patterns generated by the original method now streakline patterns are generated and advected. This process obeys a nonlinear transport diffusion equation with typically dominant transport. Starting from some noisy initial image, the diffusion actually generates and enhances patterns which are then transported in the direction of the flow field. Simultaneously the image is again sharpened in the direction orthogonal to the flow field. A careful adjustment of the models parameters is derived to balance diffusion and transport effects in a reasonable way. Properties of the method can be discussed for the continuous model, which is solved by an efficient upwind finite element discretization. As characteristic for the class of multiscale image processing methods, we can in advance select a suitable scale for representing the flow field.
Keywords: data visualisation;flow field;flow visualisation;flow visualization;image processing;multiscale image processing;scientific visualization;time-dependent flow;transport diffusion;transport effects;upwind method;
Author: Burkle, D.; Preusser, T.; Rumpf, M.

Year: 2001
Title: Undersampling and oversampling in sample based shape modeling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964497
Abstract: Shape modeling is an integral part of many visualization problems. Recent advances in scanning technology and a number of surface reconstruction algorithms have opened up a new paradigm for modeling shapes from samples. Many of the problems currently faced in this modeling paradigm can be traced back to two anomalies in sampling, namely undersampling and oversampling. Boundaries, non-smoothness and small features create undersampling problems, whereas oversampling leads to too many triangles. We use Voronoi cell geometry as a unified guide to detect undersampling and oversampling. We apply these detections in surface reconstruction and model simplification. Guarantees of the algorithms can be proved. The authors show the success of the algorithms empirically on a number of interesting data sets.
Keywords: Voronoi cell geometry;computational geometry;computational geometry;data sets;data visualisation;geometric modeling;image reconstruction;image sampling;mesh generation;model simplification;modeling paradigm;non-smoothness;oversampling;polygonal mesh reduction;rendering (computer graphics);sample based shape modeling;scanning technology;surface reconstruction;surface reconstruction algorithms;undersampling;visualization problems;
Author: Dey, T.K.; Giesen, J.; Goswami, S.; Hudson, J.; Wenger, R.; Wulue Zhao

Year: 2001
Title: Optimal regular volume sampling
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964498
Abstract: The classification of volumetric data sets as well as their rendering algorithms are typically based on the representation of the underlying grid. Grid structures based on a Cartesian lattice are the de-facto standard for regular representations of volumetric data. In this paper we introduce a more general concept of regular grids for the representation of volumetric data. We demonstrate that a specific type of regular lattice-the so-called body-centered cubic-is able to represent the same data set as a Cartesian grid to the same accuracy but with 29.3% fewer samples. This speeds up traditional volume rendering algorithms by the same ratio, which we demonstrate by adopting a splatting implementation for these new lattices. We investigate different filtering methods required for computing the normals on this lattice. The lattice representation results also in lossless compression ratios that are better than previously reported. Although other regular grid structures achieve the same sample efficiency, the body-centered cubic is particularly easy to use. The only assumption necessary is that the underlying volume is isotropic and band-limited-an assumption that is valid for most practical data sets.
Keywords: Cartesian lattice;body-centered cubic;hexagonal sampling;rendering;rendering (computer graphics);sampling methods;splatting implementation;volumetric data;volumetric data sets;
Author: Theussl, T.; Moller, T.; Groller, M.E.

Year: 2001
Title: Simplicial subdivisions and sampling artifacts
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964499
Abstract: We review several schemes for dividing cubical cells into simplices (tetrahedra) in 3-D for interpolating from sampled data to R<sup> 3</sup> or for computing isosurfaces by barycentric interpolation. We present test data that reveal the geometric artifacts that these subdivision schemes generate, and discuss how these artifacts relate to the filter kernels that correspond to the subdivision schemes.
Keywords: barycentric interpolation;computational geometry;computer graphics;computing isosurfaces;cubical cells;interpolated function;interpolating;interpolation;regular meshes;segmentation;simplices;simplicial subdivisions;tetrahedra;
Author: Carr, H.; Moller, T.; Snoeyink, J.

Year: 2001
Title: A simple algorithm for surface denoising
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964500
Abstract: We present a simple denoising technique for geometric data represented as a semiregular mesh, based on locally adaptive Wiener filtering. The degree of denoising is controlled by a single parameter (an estimate of the relative noise level) and the time required for denoising is independent of the magnitude of the estimate. The performance of the algorithm is sufficiently fast to allow interactive local denoising.
Keywords: Gaussian scale mixture model;complexity;computational geometry;computer graphics;computer graphics;denoising;filtering theory;geometric data;geometric modeling;multiresolution surfaces;performance;reparameterization;semiregular mesh;surface fitting;
Author: Jianbo Peng; Strela, V.; Zorin, D.

Year: 2001
Title: Attribute preserving dataset simplification
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964501
Abstract: The paper describes a novel application of feature preserving mesh simplification to the problem of managing large, multidimensional datasets during scientific visualization. To allow this, we view a scientific dataset as a triangulated mesh of data elements, where the attributes embedded in each element form a set of properties arrayed across the surface of the mesh. Existing simplification techniques were not designed to address the high dimensionality that exists in these types of datasets. In addition, vertex operations that relocate, insert, or remove data elements may need to be modified or restricted. Principal component analysis provides an algorithm-independent method for compressing a dataset's dimensionality during simplification. Vertex locking forces certain data elements to maintain their spatial locations; this technique is also used to guarantee a minimum density in the simplified dataset. The result is a visualization that significantly reduces the number of data elements to display, while at the same time ensuring that high-variance regions of potential interest remain intact. We apply our techniques to a number of well-known feature preserving algorithms, and demonstrate their applicability in a real-world context by simplifying a multidimensional weather dataset. Our results show a significant improvement in execution time with only a small reduction in accuracy; even when the dataset was simplified to 10% of its original size, average per attribute error was less than 1%.
Keywords: algorithm-independent method;computational geometry;computational geometry;data elements;data visualisation;data visualization;dataset dimensionality compression;feature preserving algorithms;feature preserving mesh simplification;geometric algorithms;high-variance regions;large multidimensional dataset management;minimum density;multidimensional weather dataset;object modeling;principal component analysis;principal component analysis;real-world context;scientific dataset;scientific visualization;simplification techniques;simplified dataset;spatial locations;triangulated mesh;vertex operations;visual databases;
Author: Walter, J.D.; Healey, C.G.

Year: 2001
Title: A memory insensitive technique for large model simplification
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964502
Abstract: The authors propose three simple, but significant improvements to the OoCS (Out-of-Core Simplification) algorithm of P. Lindstrom (2000) which increase the quality of approximations and extend the applicability of the algorithm to an even larger class of compute systems. The original OoCS algorithm has memory complexity that depends on the size of the output mesh, but no dependency on the size of the input mesh. That is, it can be used to simplify meshes of arbitrarily large size, but the complexity of the output mesh is limited by the amount of memory available. Our first contribution is a version of OoCS that removes the dependency of having enough memory to hold (even) the simplified mesh. With our new algorithm, the whole process is made essentially independent of the available memory on the host computer. Our new technique uses disk instead of main memory, but it is carefully designed to avoid costly random accesses. Our two other contributions improve the quality of the approximations generated by OoCS. We propose a scheme for preserving surface boundaries which does not use connectivity information, and a scheme for constraining the position of the "representative vertex" of a grid cell to an optimal position inside the cell.
Keywords: OoCS;Out-of-Core Simplification algorithm;approximation quality;computational geometry;computational geometry;compute systems;connectivity information;external sorting;grid cell;input mesh;large data;memory complexity;object modeling;optimal position;out-of-core algorithms;output mesh;polygonal surface simplification;quadric error metrics;random accesses;sorting;storage management;surface boundaries;very large databases;visual databases;
Author: Lindstrom, P.; Silva, C.T.

Year: 2001
Title: Connectivity shapes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964504
Abstract: We describe a method to visualize the connectivity graph of a mesh using a natural embedding in 3D space. This uses a 3D shape representation that is based solely on mesh connectivity: the connectivity shape. Given a connectivity, we define its natural geometry as a smooth embedding in space with uniform edge lengths and describe efficient techniques to compute it. Our main contribution is to demonstrate that a surprising amount of geometric information is implicit in the connectivity. We also show how to generate connectivity shapes that approximate given 3D shapes. Potential applications of connectivity shapes to modeling and mesh coding are described.
Keywords: 3D space;connectivity graph visualization;connectivity shapes;data visualisation;geometric information;graph theory;implicit geometry;mesh coding;mesh connectivity;mesh generation;natural embedding;natural geometry;polygon meshes;shape compression;shape representation;smooth embedding;uniform edge lengths;
Author: Isenburg, M.; Gumhold, S.; Gotsman, C.

Year: 2001
Title: Quantitative comparative evaluation of 2D vector field visualization methods
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964505
Abstract: Presents results from a user study that compared six visualization methods for 2D vector data. Two methods used different distributions of short arrows, two used different distributions of integral curves, one used wedges located to suggest flow lines, and the final one was line-integral convolution (LIC). We defined three simple but representative tasks for users to perform using visualizations from each method: (1) locating all critical points in an image, (2) identifying critical point types, and (3) advecting a particle. The results show different strengths and weaknesses for each method. We found that users performed better with methods that: (1) showed the sign of vectors within the vector field, (2) visually represented integral curves, and (3) visually represented the locations of critical points. These results provide quantitative support for some of the anecdotal evidence concerning visualization methods. The tasks and testing framework also provide a basis for comparing other visualization methods, for creating more effective methods and for defining additional tasks to further understand tradeoffs among methods. They may also be useful for evaluating 2D vectors on 2D surfaces embedded in 3D and for defining analogous tasks for 3D visualization methods.
Keywords: 2D surfaces;2D vector field visualization methods;computational fluid dynamics;critical point location;critical point types;critical points;data visualisation;flow lines;flow visualisation;fluid dynamics;graphical user interfaces;human factors;iconic textures;image texture;image-guided streamlines;integral curve distributions;jittered grid icons;line-integral convolution;particle advection;quantitative comparative evaluation;scientific visualization;short arrow distributions;testing framework;tradeoffs;user performance study;vector sign;vectors;visual representation;wedges;
Author: Laidlaw, D.H.; Kirby, R.M.; Davidson, J.S.; Miller, T.S.; da Silva, M.; Warren, W.H.; Tarr, M.

Year: 2001
Title: A tetrahedra-based stream surface algorithm
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964506
Abstract: This paper presents a new algorithm for the calculation of stream surfaces for tetrahedral grids. It propagates the surface through the tetrahedra, one at a time, calculating the intersections with the tetrahedral faces. The method allows us to incorporate topological information from the cells, e.g. critical points. The calculations are based on barycentric coordinates, since this simplifies the theory and the algorithm. The stream surfaces are ruled surfaces inside each cell, and their construction starts with line segments on the faces. Our method supports the analysis of velocity fields resulting from computational fluid dynamics (CFD) simulations.
Keywords: barycentric coordinates;computational fluid dynamics;computational fluid dynamics simulations;critical points;data visualisation;digital simulation;flow simulation;flow surface;flow visualisation;flow visualization;line segments;ruled surfaces;surface propagation;tetrahedra-based stream surface algorithm;tetrahedral face intersections;tetrahedral grids;topological information;unstructured grid;vector field visualization;vectors;velocity fields;
Author: Scheuermann, G.; Bobach, T.; Hagen, H.; Mahrous, K.; Hamann, B.; Joy, K.I.; Kollmann, W.

Year: 2001
Title: Continuous topology simplification of planar vector fields
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964507
Abstract: Vector fields can present complex structural behavior, especially in turbulent computational fluid dynamics. The topological analysis of these data sets reduces the information, but one is usually still left with too many details for interpretation. In this paper, we present a simplification approach that removes pairs of critical points from the data set, based on relevance measures. In contrast to earlier methods, no grid changes are necessary, since the whole method uses small local changes of the vector values defining the vector field. An interpretation in terms of bifurcations underlines the continuous, natural flavor of the algorithm.
Keywords: bifurcation;bifurcations;computational fluid dynamics;continuous topology simplification;critical point pair removal;critical points;data visualisation;flow visualisation;flow visualization;grid changes;local vector value changes;planar vector fields;relevance measures;structural behavior;topology;turbulence;turbulent computational fluid dynamics;unstructured grid;vectors;
Author: Tricoche, X.; Scheuermann, G.; Hagen, H.

Year: 2001
Title: PixelFlex: a reconfigurable multi-projector display system
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964508
Abstract: This paper presents PixelFlex - a spatially reconfigurable multi-projector display system. The PixelFlex system is composed of ceiling-mounted projectors, each with computer-controlled pan, tilt, zoom and focus; and a camera for closed-loop calibration. Working collectively, these controllable projectors function as a single logical display capable of being easily modified into a variety of spatial formats of differing pixel density, size and shape. New layouts are automatically calibrated within minutes to generate the accurate warping and blending functions needed to produce seamless imagery across planar display surfaces, thus giving the user the flexibility to quickly create, save and restore multiple screen configurations. Overall, PixelFlex provides a new level of automatic reconfigurability and usage, departing from the static, one-size-fits-all design of traditional large-format displays. As a front-projection system, PixelFlex can be installed in most environments with space constraints and requires little or no post-installation mechanical maintenance because of the closed-loop calibration.
Keywords: PixelFlex;blending functions;calibration;camera-based registration;cameras;ceiling-mounted projectors;closed-loop calibration;computer displays;computer-controlled focus;computer-controlled pan;computer-controlled tilt;computer-controlled zoom;controllable projectors;display layouts;flexibility;front-projection system;multiple screen configurations;optical projectors;pixel density;pixel shape;pixel size;planar display surfaces;post-installation mechanical maintenance;seamless imagery;space constraints;spatial formats;spatially reconfigurable multi-projector display system;warping functions;
Author: Ruigang Yang; Gotz, D.; Hensley, J.; Towles, H.; Brown, M.S.

Year: 2001
Title: The Which Blair project: a quick visual method for evaluating perceptual color maps
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964510
Abstract: We have developed a fast, perceptual method for selecting color scales for data visualization that takes advantage of our sensitivity to luminance variations in human faces. To do so, we conducted experiments in which we mapped various color scales onto the intensity values of a digitized photograph of a face and asked observers to rate each image. We found a very strong correlation between the perceived naturalness of the images and the degree to which the underlying color scales increased monotonically in luminance. Color scales that did not include a monotonically increasing luminance component produced no positive rating scores. Since color scales with monotonic luminance profiles are widely recommended for visualizing continuous scalar data, a purely visual technique for identifying such color scales could be very useful, especially in situations where color calibration is not integrated into the visualization environment, such as over the Internet.
Keywords: colour graphics;data visualisation;data visualization;digitized photograph;human face luminance variation sensitivity;human factors;perceptual color map visual evaluation;visual perception;
Author: Rogowitz, B.E.; Kalvin, A.D.

Year: 2001
Title: Circular incident edge lists: a data structure for rendering complex unstructured grids
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964511
Abstract: We present the circular incident edge lists (CIEL), a new data structure and a high-performance algorithm for generating a series of iso-surfaces in a highly unstructured grid. Slicing-based volume rendering is also considered. The CIEL data structure represents all the combinatorial information of the grid, making it possible to optimize the classical propagation from local minima paradigm. The usual geometric structures are replaced by a more efficient combinatorial structure. An active edges list is maintained, and iteratively propagated from an iso-surface to the next one in a very efficient way. The intersected cells incident to each active edge are retrieved, and the intersection polygons are generated by circulating around their facets. This latter feature enables arbitrary irregular cells to be treated, such as those encountered in certain computational fluid dynamics (CFD) simulations. Since the CIEL data structure solely depends on the connections between the cells, it is possible to take into account dynamic changes in the geometry of the mesh and in property values, which only requires the sorted extrema list to be updated. Experiments have shown that our approach is significantly faster than classical methods. The major drawback of our method is its memory consumption, higher than most classical methods. However, experimental results show that it stays within a practical range.
Keywords: CFD simulations;CIEL;active edges list;circular incident edge lists;combinatorial information;combinatorial mathematics;complex unstructured grid rendering;computational complexity;computational fluid dynamics simulations;data structure;data visualisation;data visualization;geometric structures;intersected cells;intersection polygons;irregular cells;iso-surface series;iterative methods;iterative propagation;memory consumption;rendering (computer graphics);slicing-based volume rendering;spatial data structures;unstructured grid;
Author: Levy, B.; Caumon, G.; Conreaux, S.; Cavin, X.

Year: 2001
Title: Hardware-software-balanced resampling for the interactive visualization of unstructured grids
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964512
Abstract: In this paper we address the problem of interactively resampling unstructured grids. Three algorithms are presented. They all allow adaptive resampling of an unstructured grid on a multiresolution hierarchy of arbitrarily sized cartesian grids according to a varying element size. Two of the algorithms presented take advantage of hardware accelerated polygon rendering and 2D texture mapping. In exploiting new features of modem PC graphics adapters, the first algorithm tries to significantly minimize the number of polygons to be rendered. Reducing rasterization requirements is the main goal of the second algorithm, which distributes the computational workload differently between the main processor and the graphics chip. By comparing them to a new pure software approach, an optimal software-hardware balance is studied. We end up with a hybrid approach which greatly improves the performance of hardware assisted resampling by involving the main processor to a higher degree and thus enabling resampling at nearly interactive rates.
Keywords: 2D texture mapping;Hardware-software-balanced resampling;PC graphics adapters;arbitrarily sized cartesian grids;data visualisation;distributes the computational workload;hardware accelerated polygon rendering;interactive systems;interactive visualization;minimisation;minimize;multiresolution hierarchy;optimal software-hardware balance;rasterization requirements;rendering (computer graphics);unstructured grids;
Author: Weiler, M.; Ertl, T.

Year: 2001
Title: The perspective shear-warp algorithm in a virtual environment
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964513
Abstract: Since the original paper of Lacroute and Levoy (1994), where the shear-warp factorization was also shown for perspective projections, a lot of work has been carried out using the shear-warp factorization with parallel projections. However, none of it has proved or improved the algorithm for the perspective projection. Also in Lacroute's Volpack library, the perspective shear-warp volume rendering algorithm is missing. This paper reports on an implementation of the perspective shear-warp algorithm, which includes enhancements for its application in immersive virtual environments. Furthermore, a mathematical proof for the correctness of the permutation of projection and warp is provided, so far a basic assumption of the shear-warp perspective projection.
Keywords: Volpack library;immersive virtual environments;parallel projections;perspective projections;perspective shear-warp volume rendering algorithm;rendering (computer graphics);virtual reality;
Author: Schulze, R.P.; Niemeier, R.; Lang, U.

Year: 2001
Title: Cell-projection of cyclic meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964514
Abstract: We present the first algorithm that employs hardware-accelerated cell-projection for direct volume rendering of cyclic meshes, i.e., meshes with visibility cycles. The visibility sorting of a cyclic mesh is performed by an extended topological sorting, which computes and isolates visibility cycles. Measured sorting times are comparable to previously published algorithms, which are, however, restricted to acyclic meshes. In practice, our algorithm is also useful for acyclic meshes as numerical instabilities can lead to false visibility cycles. Our method includes a simple, hardware-assisted algorithm based on image compositing that renders visibility cycles correctly. For tetrahedral meshes this algorithm allows us to render each tetrahedral cell (whether it is part of a cycle or not) by hardware-accelerated cell-projection. In its basic form our method applies only to convex cyclic meshes; however, we present an exact and a simpler but inexact extension of our method for nonconvex meshes.
Keywords: acyclic meshes;cyclic meshes;data visualisation;direct volume rendering;directed graphs;extended topological sorting;hardware-accelerated cell-projection;rendering (computer graphics);tetrahedral meshes;visibility cycles;visibility sorting;visualization;
Author: Kraus, M.; Ertl, T.

Year: 2001
Title: Fast detection of meaningful isosurfaces for volume data visualization
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964515
Abstract: Automatic detection of meaningful isosurfaces is important for producing informative visualizations of volume data, especially when no information about the data origin and imaging protocol is available. We propose a computationally efficient method for the automated detection of intensity transitions in volume data. In this approach, the dominant transitions correspond to clear maxima in cumulative Laplacian-weighted gray value histograms. Only one pass through the data volume is required to compute the histogram. Several other features which may be useful for exploration of data of unknown origin can be efficiently computed in a similar manner. The detected intensity transitions can be used for setting of visualization parameters for surface rendering, as well as for direct volume rendering of 3D datasets. When using surface rendering, the detected dominant intensity transition values correspond to the optimal surface isovalues for extraction of boundaries of the objects of interest. In direct volume rendering, such transitions are important for generation of the transfer functions, which are used to assign visualization properties to data voxels and determine the appearance of the rendered image. The proposed method is illustrated by examples with synthetic data as well as real biomedical datasets.
Keywords: biomedical datasets;computational complexity;computationally efficient method;cumulative Laplacian-weighted gray value histograms;data visualisation;data voxels;direct volume rendering;dominant transitions;intensity transitions;meaningful isosurfaces;optimisation;rendering (computer graphics);surface rendering;transfer function generation;transfer functions;volume data visualization;
Author: Pekar, V.; Wiemker, R.; Hempel, D.

Year: 2001
Title: Salient iso-surface detection with model-independent statistical signatures
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964516
Abstract: Volume graphics has not been accepted for widespread use. One of the inhibiting reasons is the lack of general methods for data-analysis and simple interfaces for data exploration. An error-and-trial iterative procedure is often used to select a desirable transfer function or mine the dataset for salient iso-values. New semi-automatic methods that are also data-centric have shown much promise. However, general and robust methods are still needed for data-exploration and analysis. In this paper, we propose general model-independent statistical methods based on central moments of data. Using these techniques we show how salient iso-surfaces at material boundaries can be determined. We provide examples from the medical and computational domain to demonstrate the effectiveness of our methods.
Keywords: computation;data analysis;data exploration;data mining;data mining;data visualisation;dataset mining;error-and-trial iterative procedure;iterative methods;material boundaries;medicine;model-independent statistical signatures;rendering (computer graphics);salient iso-surface detection;statistical analysis;statistical methods;transfer function;transfer functions;trial-and-error iterative procedure;volume graphics;
Author: Tenginakai, S.; Jinho Lee; Machiraju, R.

Year: 2001
Title: Distance-field based skeletons for virtual navigation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964517
Abstract: We present a generic method for rapid flight planning, virtual navigation and effective camera control in a volumetric environment. Directly derived from an accurate distance from boundary (DFB) field, our automatic path planning algorithm rapidly generates centered flight paths, a skeleton, in the navigable region of the virtual environment. Based on precomputed flight paths and the DFB field, our dual-mode physically based camera control model supports a smooth, safe, and sticking-free virtual navigation with six degrees of freedom. By using these techniques, combined with accelerated volume rendering, we have successfully developed a real-time virtual colonoscopy system on low-cost PCs and confirmed the high speed, high accuracy and robustness of our techniques on more than 40 patient datasets.
Keywords: DFB field;distance-field based skeletons;distance-from-boundary field;dual-mode physically-based camera control model;effective camera control;image thinning;low-cost PC;rapid flight planning;real-time virtual colonoscopy system;virtual navigation;virtual reality;volumetric environment;
Author: Ming Wan; Dachille, F.; Kaufman, A.

Year: 2001
Title: A complete distance field representation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964518
Abstract: Distance fields are an important volume representation. A high quality distance field facilitates accurate surface characterization and gradient estimation. However, due to Nyquist's law, no existing volumetric methods based on the linear sampling theory can fully capture surface details, such as comers and edges, in 3D space. We propose a novel complete distance field representation (CDFR) that does not rely on Nyquist's sampling theory. To accomplish this, we construct a volume where each voxel has a complete description of all portions of surface that affect the local distance field. For any desired distance, we are able to extract a surface contour in true Euclidean distance, at any level of accuracy, from the same CDFR representation. Such point-based iso-distance contours have faithful per-point gradients and can be interactively visualized using splatting, providing per-point shaded image quality. We also demonstrate applying CDFR to a cutting edge design for manufacturing application involving high-complexity parts at unprecedented accuracy using only commonly available computational resources.
Keywords: CDFR;Euclidean distance;Nyquist criterion;Nyquist law;complete distance field representation;computer graphics;corners;cutting edge design;gradient estimation;interactive systems;interactive visualization;linear sampling theory;per-point shaded image quality;sampling theory;solid modelling;splatting;surface characterization;surface contour extraction;volume representation;
Author: Jian Huang; Yan Li; Crawfis, R.; Shao-Chiung Lu; Shuh-Yuan Liou

Year: 2001
Title: Interactive volume rendering using multi-dimensional transfer functions and direct manipulation widgets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964519
Abstract: Most direct volume renderings produced today employ one-dimensional transfer functions, which assign color and opacity to the volume based solely on the single scalar quantity which comprises the dataset. Though they have not received widespread attention, multi-dimensional transfer functions are a very effective way to extract specific material boundaries and convey subtle surface properties. However, identifying good transfer functions is difficult enough in one dimension, let alone two or three dimensions. This paper demonstrates an important class of three-dimensional transfer functions for scalar data (based on data value, gradient magnitude, and a second directional derivative), and describes a set of direct manipulation widgets which make specifying such transfer functions intuitive and convenient. We also describe how to use modem graphics hardware to interactively render with multi-dimensional transfer functions. The transfer functions, widgets, and hardware combine to form a powerful system for interactive volume exploration.
Keywords: computational complexity;computational geometry;computational geometry;data visualisation;dataset;direct manipulation widgets;direct volume renderings;gradient magnitude;graphics hardware;interactive volume exploration;interactive volume rendering;interpolation;multidimensional transfer functions;object modelling;rendering (computer graphics);time series;transfer functions;volume visualization;widgets;
Author: Kniss, J.; Kindlmann, G.; Hansen, C.

Year: 2001
Title: Accelerated volume ray-casting using texture mapping
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964521
Abstract: Acceleration techniques for volume ray-casting are primarily based on pre-computed data structures that allow one to efficiently traverse empty or homogeneous regions. In order to display volume data that successively undergoes color lookups, however, the data structures have to be re-built continuously. In this paper we propose a technique that circumvents this drawback using hardware accelerated texture mapping. In a first rendering pass we employ graphics hardware to interactively determine for each ray where the material is hit. In a second pass ray-casting is performed, but ray traversal starts right in front of the previously determined regions. The algorithm enables interactive classification and it considerably accelerates the view dependent display of selected materials and surfaces from volume data. In contrast to other techniques that are solely based on texture mapping our approach requires less memory and accurately performs the composition of material contributions along the ray.
Keywords: accelerated volume ray-casting;color lookups;computational complexity;data structures;data visualisation;graphics hardware;interactive classification;interactive systems;pre-computed data structures;rendering (computer graphics);texture mapping;
Author: Westermann, R.; Sevenich, B.

Year: 2001
Title: RTVR-a flexible Java library for interactive volume rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964522
Abstract: This paper presents several distinguishing design features of RTVR-a Java-based library for real-time volume rendering. We describe, how the careful design of data structures, which in our case are based on voxel enumeration, and an intelligent use of lookup tables enable interactive volume rendering even on low-end PC hardware. By assigning voxels to distinct objects within the volume and by using an individual setup and combination of look-up tables for each object, object-aware rendering is performed: different transfer functions, shading models, and also compositing modes can be mixed within a single scene to depict each object in the most appropriate way, while still providing rendering results in real-time. While providing frame rates similar to volume visualization using 3D consumer hardware, the approach utilized by RTVR offers much more flexibility and extensibility due to its pure software nature. Furthermore, due to the memory-efficiency of the data representation and the implementation in Java, RTVR can be used to provide volume viewing facilities over low-bandwidth networks, with almost full control over rendering and visualization mapping parameters (clipping, shading, compositing, transfer function) for the user. This paper also addresses specific problems which arise by the use of Java for interactive visualization.
Keywords: Java;RTVR;data structures;data structures;data visualisation;design features;flexible Java library;interactive volume rendering;lookup tables;low-end PC hardware;object-aware rendering;rendering (computer graphics);shading models;table lookup;transfer functions;transfer functions;visualization mapping parameters;voxel enumeration;
Author: Mroz, L.; Hauser, H.

Year: 2001
Title: Multiresolution feature extraction for unstructured meshes
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964523
Abstract: We present a framework to extract mesh features from unstructured two-manifold surfaces. Our method computes a collection of piecewise linear curves describing the salient features of surfaces, such as edges and ridge lines. We extend these basic techniques to a multiresolution setting which improves the quality of the results and accelerates the extraction process. The extraction process is semi-automatic, that is, the user is required to input a few control parameters and to select the operators to be applied to the input surface. Our mesh feature extraction algorithm can be used as a preprocessor for a variety of applications in geometric modeling including mesh fairing, subdivision and simplification.
Keywords: feature extraction;geometric modeling;mesh feature extraction algorithm;mesh generation;multiresolution feature extraction;multiresolution setting;piecewise linear curves;preprocessor;program processors;rendering (computer graphics);ridge lines;unstructured meshes;unstructured two-manifold surfaces;
Author: Hubeli, A.; Gross, M.

Year: 2001
Title: Fast extraction of adaptive multiresolution meshes with guaranteed properties from volumetric data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964524
Abstract: We present a new algorithm for extracting adaptive multiresolution triangle meshes from volume datasets. The algorithm guarantees that the topological genus of the generated mesh is the same as the genus of the surface embedded in the volume dataset at all levels of detail. In addition to this "hard constraint" on the genus of the mesh, the user can choose to specify some number of soft geometric constraints, such as triangle aspect ratio, minimum or maximum total number of vertices, minimum and/or maximum triangle edge lengths, maximum magnitude of various error metrics per triangle or vertex, including maximum curvature (area) error, maximum distance to the surface, and others. The mesh extraction process is fully automatic and does not require manual adjusting of parameters to produce the desired results as long as the user does not specify incompatible constraints. The algorithm robustly handles special topological cases, such as trimmed surfaces (intersections of the surface with the volume boundary), and manifolds with multiple disconnected components (several closed surfaces embedded in the same volume dataset). The meshes may self-intersect at coarse resolutions. However, the self-intersections are corrected automatically as the resolution of the meshes increase. We show several examples of meshes extracted from complex volume datasets.
Keywords: adaptive multiresolution meshes extraction;data visualisation;guaranteed properties;interpolation;maximum curvature trimmed surfaces;rendering (computer graphics);volume datasets;volumetric data;
Author: Gavriliu, M.; Carranza, J.; Breen, D.E.; Barr, A.H.

Year: 2001
Title: Wavelet representation of contour sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964525
Abstract: We present a new wavelet compression and multiresolution modeling approach for sets of contours (level sets). In contrast to previous wavelet schemes, our algorithm creates a parametrization of a scalar field induced by its contours and compactly stores this parametrization rather than function values sampled on a regular grid. Our representation is based on hierarchical polygon meshes with subdivision connectivity whose vertices are transformed into wavelet coefficients. From this sparse set of coefficients, every set of contours can be efficiently reconstructed at multiple levels of resolution. When applying lossy compression, introducing high quantization errors, our method preserves contour topology, in contrast to compression methods applied to the corresponding field function. We provide numerical results for scalar fields defined on planar domains. Our approach generalizes to volumetric domains, time-varying contours, and level sets of vector fields.
Keywords: computational geometry;contour sets;contours;data compression;data compression;geometry compression;hierarchical polygon meshes;interpolation;level sets;multiresolution modeling approach;planar domains;regular grid;rendering (computer graphics);scalar field;scalar fields;subdivision connectivity;time-varying contours;vector fields;wavelet compression;wavelet representation;wavelet transforms;
Author: Bertram, M.; Laney, D.E.; Duchaineau, M.A.; Hansen, C.D.; Hamann, B.; Joy, K.I.

Year: 2001
Title: User-centric viewpoint computation for haptic exploration and manipulation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964526
Abstract: We present several techniques for user-centric viewing of the virtual objects or datasets under haptic exploration and manipulation. Depending on the type of tasks performed by the user, our algorithms compute automatic placement of the user viewpoint to navigate through the scene, to display the near-optimal views, and to reposition the viewpoint for haptic visualization. This is accomplished by conjecturing the user's intent based on the user's actions, the object geometry, and intra- and inter-object occlusion relationships. These algorithms have been implemented and interfaced with both a 3-DOF and a 6-DOF PHANToM arms. We demonstrate their application on haptic exploration and visualization of a complex structure, as well as multiresolution modeling and 3D painting with a haptic interface.
Keywords: 3-DOF;3D painting;6-DOF PHANToM arms;automatic placement;data visualisation;datasets;haptic exploration;haptic interfaces;haptic manipulation;haptic visualization;multiresolution modeling;object geometry;rendering (computer graphics);user-centric viewpoint computation;virtual objects;
Author: Otaduy, M.A.; Lin, M.C.

Year: 2001
Title: Nonmanifold subdivision
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964528
Abstract: Commonly-used subdivision schemes require manifold control meshes and produce manifold surfaces. However, it is often necessary to model nonmanifold surfaces, such as several surface patches meeting at a common boundary. In this paper, we describe a subdivision algorithm that makes it possible to model nonmanifold surfaces. Any triangle mesh, subject only to the restriction that no two vertices of any triangle coincide, can serve as an input to the algorithm. Resulting surfaces consist of collections of manifold patches joined along nonmanifold curves and vertices. If desired, constraints may be imposed on the tangent planes of manifold patches sharing a curve or a vertex. The algorithm is an extension of a well-known Loop subdivision scheme, and uses techniques developed for piecewise smooth surfaces.
Keywords: computational geometry;geometric modeling;geometric programming;loop subdivision scheme;manifold control meshes;manifold patches;manifold surfaces;nonmanifold subdivision;piecewise smooth surfaces;rendering (computer graphics);solid modelling;surface patches;triangle mesh;
Author: Lexing Ying; Zorin, D.

Year: 2001
Title: Normal bounds for subdivision-surface interference detection
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964529
Abstract: Subdivision surfaces are an attractive representation when modeling arbitrary-topology free-form surfaces and show great promise for applications in engineering design and computer animation. Interference detection is a critical tool in many of these applications. In this paper, we derive normal bounds for subdivision surfaces and use these to develop an efficient algorithm for (self-) interference detection.
Keywords: CAD;Gauss map;computational geometry;computer animation;computer animation;engineering design;free-form surfaces;interference;loop scheme;multi-resolution surfaces;normal bounds;self-interference detection;solid modelling;subdivision surface interference detection;topology;topology;
Author: Grinspun, E.; Schroder, P.

Year: 2001
Title: Smooth approximation and rendering of large scattered data sets
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964530
Abstract: Presents an efficient method to automatically compute a smooth approximation of large functional scattered data sets given over arbitrarily shaped planar domains. Our approach is based on the construction of a C<sup> 1</sup>-continuous bivariate cubic spline and our method offers optimal approximation order. Both local variation and nonuniform distribution of the data are taken into account by using local polynomial least squares approximations of varying degree. Since we only need to solve small linear systems and no triangulation of the scattered data points is required, the overall complexity of the algorithm is linear in the total number of points. Numerical examples dealing with several real-world scattered data sets with up to millions of points demonstrate the efficiency of our method. The resulting spline surface is of high visual quality and can be efficiently evaluated for rendering and modeling. In our implementation we achieve real-time frame rates for typical fly-through sequences and interactive frame rates for recomputing and rendering a locally modified spline surface.
Keywords: C/sup 1/-continuous bivariate cubic spline;approximation theory;arbitrarily shaped planar domains;computational complexity;computational geometry;data compression;fly-through sequences;interactive frame rates;large scattered data sets;least squares approximations;linear complexity;linear systems;local data variation;local polynomial least squares approximations;locally modified spline surface recomputation;nonuniform data distribution;optimal approximation order;real-time frame rates;real-time systems;rendering (computer graphics);scattered data approximation;smooth approximation;smooth rendering;spline surface;splines (mathematics);terrain visualization;visual quality;
Author: Haber, J.; Zeilfelder, F.; Davydov, O.; Seidel, H.-P.

Year: 2001
Title: Real-time decompression and visualization of animated volume data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964531
Abstract: Interactive exploration of animated volume data is required by many application, but the huge amount of computational time and storage space needed for rendering does not yet allow the visualization of animated volumes. In this paper, we introduce an algorithm running at interactive frame rates using 3D wavelet transforms that allows for any wavelet, motion compensation techniques and various encoding schemes of the resulting wavelet coefficients to be used. We analyze different families and orders of wavelets for compression ratio and the introduced error. We use a quantization that has been optimized for the visual impression of the reconstructed volume, independent of the viewing algorithm. This enables us to achieve very high compression ratios while still being able to reconstruct the volume with as few visual artifacts as possible. A further improvement of the compression ratio has been achieved by applying a motion compensation scheme to exploit temporal coherency. Using these schemes, we are able to decompress each volume of our animation at interactive frame rates, while visualizing these decompressed volumes on a single PC. We also present a number of improved visualization algorithms for high-quality display using OpenGL hardware running at interactive frame rates on a standard PC.
Keywords: 3D wavelet transforms;OpenGL hardware;animated volume data;compression ratio;computational time;computer animation;data compression;data visualisation;display quality;error;interactive data exploration;interactive frame rates;motion compensation techniques;optimized quantization;real-time data decompression;real-time data visualization;real-time systems;reconstructed volume;solid modelling;storage space;temporal coherency;time-critical visualization;viewing algorithms;visual artifacts;visual impression;volume rendering;wavelet coefficient encoding schemes;wavelet transforms;
Author: Guthe, S.; Strasser, W.

Year: 2001
Title: Compressing large polygonal models
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964532
Abstract: Presents an algorithm that uses partitioning and gluing to compress large triangular meshes which are too complex to fit in main memory. The algorithm is based largely on the existing mesh compression algorithms, most of which require an 'in-core' representation of the input mesh. Our solution is to partition the mesh into smaller submeshes and compress these submeshes separately using existing mesh compression techniques. Since a direct partition of the input mesh is out of question, instead we partition a simplified mesh and use the partition on the simplified model to obtain a partition on the original model. In order to recover the full connectivity, we present a simple scheme for encoding/decoding the resulting boundary structure from the mesh partition. When compressing large models with few singular vertices, a negligible portion of the compressed output is devoted to gluing information. On desktop computers, we have run experiments on models with millions of vertices, which could not be compressed using standard compression software packages, and have observed compression ratios as high as 17 to 1 using our technique.
Keywords: boundary structure decoding;boundary structure encoding;compression ratios;computational geometry;connectivity;data compression;desktop computers;gluing;large polygonal model compression;large triangular meshes;mesh compression algorithms;mesh generation;partitioning;rendering (computer graphics);simplified mesh;singular vertices;submeshes;
Author: Ho, J.; Kuang-Chih Lee; Kriegman, D.

Year: 2001
Title: Visualization of large terrains made easy
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964533
Abstract: We present an elegant and simple to implement framework for performing out-of-core visualization and view-dependent refinement of large terrain surfaces. Contrary to the trend of increasingly elaborate algorithms for large-scale terrain visualization, our algorithms and data structures have been designed with the primary goal of simplicity and efficiency of implementation. Our approach to managing large terrain data also departs from more conventional strategies based on data tiling. Rather than emphasizing how to segment and efficiently bring data in and out of memory, we focus on the manner in which the data is laid out to achieve good memory coherency for data accesses made in a top-down (coarse-to-fine) refinement of the terrain. We present and compare the results of using several different data indexing schemes, and propose a simple to compute index that yields substantial improvements in locality and speed over more commonly used data layouts. Our second contribution is a new and simple, yet easy to generalize method for view-dependent refinement. Similar to several published methods in this area, we use longest edge bisection in a top-down traversal of the mesh hierarchy to produce a continuous surface with subdivision connectivity. In tandem with the refinement, we perform view frustum culling and triangle stripping. These three components are done together in a single pass over the mesh. We show how this framework supports virtually any error metric, while still being highly memory and compute efficient.
Keywords: coarse-to-fine refinement;continuous surface;data access;data indexing schemes;data structures;data visualisation;error metric;large terrain surfaces;longest edge bisection;memory coherency;mesh hierarchy;out-of-core visualization;quadtrees;rendering (computer graphics);top-down refinement;triangle stripping;view frustum culling;view-dependent refinement;
Author: Lindstrom, P.; Pascucci, V.

Year: 2001
Title: Integrating occlusion culling with view-dependent rendering
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964534
Abstract: We present an approach that integrates occlusion culling within the view-dependent rendering framework. View-dependent rendering provides the ability to change level of detail over the surface seamlessly and smoothly in real-time. The exclusive use of view-parameters to perform level-of-detail selection causes even occluded regions to be rendered in high level of detail. To overcome this serious drawback we have integrated occlusion culling into the level selection mechanism. Because computing exact visibility is expensive and it is currently not possible to perform this computation in real time, we use a visibility estimation technique instead. Our approach reduces dramatically the resolution at occluded regions.
Keywords: computational geometry;data visualisation;directed graphs;level selection mechanism;level-of-detail selection;occluded regions;occlusion culling;rendering (computer graphics);view-dependent rendering;visibility estimation technique;
Author: El-Sana, J.; Sokolovsky, N.; Silva, C.T.

Year: 2001
Title: Approximate shading for the re-illumination of synthetic images
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964535
Abstract: Presents a method to estimate illumination dependent properties in image synthesis prior to rendering. A preprocessing step is described in which a linear image basis is developed and a lighting-independent formulation defined. A reflection function, similar to hemispherical reflectance, approximates normal Lambertian shading. Intensity errors resulting from this approximation are reduced by use of a polynomial gamma correction function and scaling to a normalized display range. This produces images that are similar to normal Lambertian shading without employing the maximum (max) function. For a single object view, images can then be expressed in a linear form so that lighting direction can be factored out. During normal rendering, image quantities for arbitrary light directions can be found without rendering. This method is demonstrated for estimating image intensity and level-of-detail error prior to rendering an object.
Keywords: approximate shading;illumination-dependent properties;image intensity;image metrics;image synthesis;intensity errors;level-of-detail error;lighting-independent formulation;linear image basis;normal Lambertian shading;normalized display range;perception;polynomial gamma correction function;re-illumination;reflection function;reflectivity;rendering (computer graphics);synthetic images;
Author: Scoggins, R.; Machiraju, R.; Moorhead, R.J.

Year: 2001
Title: Visualization and interaction techniques for the exploration of vascular structures
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964538
Abstract: We describe a pipeline of image processing steps for deriving symbolic models of vascular structures from radiological data which reflect the branching pattern and diameter of vessels. For the visualization of these symbolic models, concatenated truncated cones are smoothly blended at branching points. We put emphasis on the quality of the visualizations which is achieved by anti-aliasing operations in different stages of the visualization. The methods presented are referred to as HQVV (high quality vessel visualization). Scalable techniques are provided to explore vascular structures of different orders of magnitude. The hierarchy as well as the diameter of the branches of vascular systems are used to restrict visualizations to relevant subtrees and to emphasize parts of vascular systems. Our research is inspired by clear visualizations in textbooks and is targeted toward medical education and therapy planning. We describe the application of vessel visualization techniques for liver surgery planning. For this application it is crucial to recognize the morphology and branching pattern of vascular systems as well as the basic spatial relations between vessels and other anatomic structures.
Keywords: anatomic structures;anti-aliasing operations;blood vessels;branching pattern;concatenated truncated cones;data visualisation;diagnostic radiography;directed graphs;high quality vessel visualization;image processing;interaction techniques;liver;liver surgery planning;medical image processing;radiological data;scalable techniques;spatial relations;surgery;symbolic models;vascular structures;visualization techniques;
Author: Hahn, H.K.; Preim, B.; Selle, D.; Peitgen, H.-O.

Year: 2001
Title: Variational classification for visualization of 3D ultrasound data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964539
Abstract: We present a new technique for visualizing surfaces from 3D ultrasound data. 3D ultrasound datasets are typically fuzzy, contain a substantial amount of noise and speckle, and suffer from several other problems that make extraction of continuous and smooth surfaces extremely difficult. We propose a novel opacity classification algorithm for 3D ultrasound datasets, based on the variational principle. More specifically, we compute a volumetric opacity function that optimally satisfies a set of simultaneous requirements. One requirement makes the function attain nonzero values only in the vicinity of a user-specified value, resulting in soft shells of finite, approximately constant thickness around isosurfaces in the volume. Other requirements are designed to make the function smoother and less sensitive to noise and speckle. The computed opacity function lends itself well to explicit geometric surface extraction, as well as to direct volume rendering at interactive rates. We also describe a new splatting algorithm that is particularly well suited for displaying soft opacity shells. Several examples and comparisons are included to illustrate our approach and demonstrate its effectiveness on real 3D ultrasound datasets.
Keywords: 3D ultrasound data visualization;3D ultrasound datasets;biomedical ultrasonics;computed opacity function;computer graphics;data visualisation;direct volume rendering;explicit geometric surface extraction;feature extraction;finite approximately constant thickness;image enhancement;interactive rates;isosurface extraction;nonzero values;opacity;opacity classification algorithm;rendering (computer graphics);simultaneous requirements;smooth surfaces;soft opacity shells;speckle;splatting algorithm;surface visualization;user-specified value;variational classification;variational principle;variational techniques;volume rendering;volumetric opacity function;
Author: Fattal, R.; Lischinski, D.

Year: 2001
Title: Nonlinear virtual colon unfolding
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964540
Abstract: The majority of virtual endoscopy techniques tries to simulate a real endoscopy. A real endoscopy does not always give the optimal information due to the physical limitations it is subject to. In this paper, we deal with the unfolding of the surface of the colon as a possible visualization technique for diagnosis and polyp detection. A new two-step technique is presented which deals with the problems of double appearance of polyps and nonuniform sampling that other colon unfolding techniques suffer from. In the first step, a distance map from a central path induces nonlinear rays for unambiguous parameterization of the surface. The second step compensates for locally varying distortions of the unfolded surface. A technique similar to magnification fields in information visualization is hereby applied. The technique produces a single view of a complete, virtually dissected colon.
Keywords: colon unfolding;data visualisation;diagnosis;medical image processing;medical imaging;polyp detection;virtual endoscopy;virtual reality;visualization technique;
Author: Vilanova Bartroli, A.V.; Wegenkittl, R.; Konig, A.; Groller, E.

Year: 2001
Title: Case study: medical Web service for the automatic 3D documentation for neuroradiological diagnosis
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964542
Abstract: The case study presents a medical Web service for the automatic analysis of CTA (computer tomography angiography) datasets. It aims at the detection and evaluation of intracranial aneurysms which are malformations of cerebral blood vessels. To obtain a standardized 3D visualization, digital videos are automatically generated. The time-consuming video production caused by the manual delineation of structures, software based volume rendering, and the interactive definition of an optimized camera path is considerably improved with a fully automatic strategy. Therefore, a previously suggested approach (C. Rezk-Salama, 2000) is applied which uses an optimized transfer function as a template and automatically adapts it to an individual dataset. Furthermore, we introduce hardware-accelerated morphologic filtering in order to detect the location of mid-size and giant aneurysms. The actual generation of the video is finally integrated into a hardware accelerated off-screen rendering process based on 3D texture mapping, ensuring fast visualization of high quality. Overall, clinical routine can be considerably assisted by providing a Web based service combining automatic detection and standardized visualization.
Keywords: 3D texture mapping;CTA;automatic 3D documentation;automatic analysis;automatic detection;case study;clinical routine;computer tomography angiography datasets;computerised tomography;data visualisation;digital videos;fast visualization;fully automatic strategy;hardware accelerated off-screen rendering process;hardware-accelerated morphologic filtering;image texture;information resources;interactive definition;intracranial aneurysm detection;medical Web service;medical diagnostic computing;medical information systems;medical visualization;neuroradiological diagnosis;optimized camera path;optimized transfer function;rendering (computer graphics);software based volume rendering;standardized 3D visualization;standardized visualization;video production;video signal processing;
Author: Iserhardt-Bauer, S.; Hastreiter, P.; Ertl, T.; Eberhardt, K.; Tomandl, B.

Year: 2001
Title: Case study: visual debugging of cluster hardware
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964543
Abstract: This paper presents a novel use of visualization applied to debugging the Cplant<sup> TM</sup> cluster hardware at Sandia National Laboratories. As commodity cluster systems grow in popularity and grow in size, tracking component failures within the hardware will become more and more difficult. We have developed a tool that facilitates visual debugging of errors within the switches and cables connecting the processors. Combining an abstract system model with color-coding for both error and job information enables failing components to be identified.
Keywords: Cplant cluster hardware debugging;abstract system model;cluster hardware;color-coding;commodity cluster systems;component failures;computer debugging;data visualisation;design analysis;job information;performance evaluation;performance optimization;visual debugging;visualization;workstation clusters;
Author: Crossno, P.; Haynes, R.

Year: 2001
Title: Case study on real-time visualization of virtual Tubingen on commodity PC hardware
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964544
Abstract: For psychophysical studies in spatial cognition a virtual model of the picturesque old town of Tubingen has been constructed. In order to perform psychophysical experiments in highly realistic virtual environments the model is based on high quality texture maps adding up to several hundreds of MBytes. To accomplish the required real-time frame updates, view frustum and occlusion culling without visibility pre-processing, levels of detail, and texture compression are applied in an interleaved manner. Shared memory communication and a standard PC with two commodity graphics cards is used to enable the powerful combination of those techniques because this combination is not yet available on a single graphics card.
Keywords: commodity PC hardware;commodity graphics cards;data visualisation;high quality texture maps;occlusion culling;picturesque old town;psychophysical studies;real-time visualization;rendering (computer graphics);shared memory communication;spatial cognition;virtual Tubingen;virtual environments;virtual model;virtual reality;virtual reality;
Author: Meissner, M.; Orman, J.; Braun, S.J.

Year: 2001
Title: An immersive virtual environment for DT-MRI volume visualization applications: a case study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964545
Abstract: We describe a virtual reality environment for visualizing tensor-valued volumetric datasets acquired with diffusion tensor magnetic resonance imaging (DT-MRI). We have prototyped a virtual environment that displays geometric representations of the volumetric second-order diffusion tensor data and are developing interaction and visualization techniques for two application areas: studying changes in white-matter structures after gamma-knife capsulotomy and pre-operative planning for brain tumor surgery. Our feedback shows that compared to desktop displays, our system helps the user better interpret the large and complex geometric models, and facilitates communication among a group of users.
Keywords: DT-MRI volume visualization;biomedical MRI;brain tumor surgery;data visualisation;diffusion tensor magnetic resonance imaging;gamma-knife capsulotomy;geometric representations;immersive virtual environment;programming environments;tensor valued volumetric datasets;virtual reality;virtual reality environment;white-matter structures;
Author: Zhang, S.; Demiralp, C.; Keefe, D.F.; DaSilva, M.; Laidlaw, D.H.; Greenberg, B.D.; Basser, P.J.; Pierpaoli, C.; Chiocca, E.A.; Deisboeck, T.S.

Year: 2001
Title: Chromatin decondensation: case study of tracking features in confocal data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964546
Abstract: In this case study we discuss an interactive feature tracking system and its use for the analysis of chromatin decondensation. Features are described as points in a multidimensional attribute space. Distances between points are used as a measure for feature correspondence. Users can interactively experiment with the correspondence measure in order to gain insight in chromatin movement. In addition, by defining time as an attribute, tracking problems related to noisy confocal data can be circumvented.
Keywords: biomedical imaging;biomedical imaging;chromatin decondensation;computer graphics;confocal data;correspondence measure;feature correspondence;feature extraction;interactive feature tracking system;multidimensional attribute space;multidimensional visualization;noisy confocal data;
Author: de Leeuw, W.; van Liere, R.

Year: 2001
Title: Case study: an environment for understanding protein simulations using game graphics
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964547
Abstract: We describe a visualization system designed for interactive study of proteins in the field of computational biology. Our system incorporates multiple, custom, three-dimensional and two-dimensional linked views of the proteins. We take advantage of modem commodity graphics cards, which are typically designed for games rather than scientific visualization applications, to provide instantaneous linking between views and three-dimensional interactivity on standard personal computers. Furthermore, we anticipate the usefulness of game techniques such as bump maps and skinning for scientific applications.
Keywords: bump maps;commodity graphics cards;computational biology;computer graphics;computer graphics;data visualisation;game graphics;interactive study;protein simulations understanding;skinning;three-dimensional interactivity;visualization system;
Author: Gresh, D.; Suits, F.; Yuk Yin Sham

Year: 2001
Title: Surgical simulator for hysteroscopy: a case study of visualization in surgical training
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964548
Abstract: Computer-based surgical simulation promises to provide a broader scope of clinical training through the introduction of anatomic variation, simulation of untoward events, and collection of performance data. We present a haptically-enabled surgical simulator for the most common techniques in diagnostic and operative hysteroscopy-cervical dilation, endometrial resection and ablation, and lesion excision. Engineering tradeoffs in developing a real-time, haptic-rate simulator are discussed.
Keywords: ablation;anatomic variation;cervical dilation;clinical training;computer aided instruction;data visualisation;data visualization;digital simulation;endometrial resection;haptic interfaces;haptic-rate simulator;hysteroscopy;lesion excision;medical computing;performance data;surgical simulator;surgical training;virtual reality;
Author: Montgomery, K.; Heinrichs, L.R.; Bruyns, C.; Wildermuth, S.; Hasser, C.; Ozenne, S.; Bailey, D.

Year: 2001
Title: Case study: reconstruction, visualization and quantification of neuronal fiber pathways
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964549
Abstract: It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.
Keywords: biomedical MRI;data visualisation;diffusion tensor magnetic resonance imaging;fiber connectivity;human brain;image reconstruction;local orientations;neural nets;neurological studies;neuronal fiber pathways quantification;neuronal fiber pathways reconstruction;neuronal fiber pathways visualization;quantitative studies;visual analysis;
Author: Zhaohua Ding; Gore, J.C.; Anderson, A.W.

Year: 2001
Title: Visualizing 2D probability distributions from EOS satellite image-derived data sets: a case study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964550
Abstract: Maps of biophysical and geophysical variables using Earth Observing System (EOS) satellite image data are an important component of Earth science. These maps have a single value derived at every grid cell and standard techniques are used to visualize them. Current tools fall short, however, when it is necessary to describe a distribution of values at each grid cell. Distributions may represent a frequency of occurrence over time, frequency of occurrence from multiple runs of an ensemble forecast or possible values from an uncertainty model. We identify these "distribution data sets" and present a case study to visualize such 2D distributions. Distribution data sets are different from multivariate data sets in the sense that the values are for a single variable instead of multiple variables. Data for this case study consists of multiple realizations of percent forest cover, generated using a geostatistical technique that combines ground measurements and satellite imagery to model uncertainty about forest cover. We present two general approaches for analyzing and visualizing such data sets. The first is a pixel-wise analysis of the probability density functions for the 2D image while the second is an analysis of features identified within the image. Such pixel-wise and feature-wise views will give Earth scientists a more complete understanding of distribution data sets. See www.cse.ucsc.edu/research/avis/nasa is for additional information.
Keywords: Earth Observing System;Earth science;conditional simulation;data visualisation;distribution data sets;feature-wise;forest cover;geophysics computing;geostatistics;ground measurements;pixel-wise;satellite imagery;uncertainty handling;uncertainty model;
Author: Kao, D.; Dungan, J.L.; Pang, A.

Year: 2001
Title: Case study: application of feature tracking to analysis of autoignition simulation data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964551
Abstract: The focus of this paper is to evaluate the usefulness of some basic feature tracking algorithms as analysis tools for combustion datasets by application to a dataset modeling autoignition. Features defined as areas of high intermediate concentrations were examined to explore the initial phases in the autoignition process.
Keywords: autoignition;combustion;combustion;data visualisation;digital simulation;feature detection;feature extraction;feature tracking;ignition;physics computing;simulation data;turbulent flows;
Author: Koegler, W.S.

Year: 2001
Title: Case study: visualization of particle track data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964552
Abstract: The Relativistic Heavy Ion Collider (RHIC) experiment at the Brookhaven National Lab is designed to study how the universe came into being. It is believed that after the Big Bang, the universe expanded and cooled, consisting of a soup of quarks, gluons, electrons and neutrinos. As the temperature lowered, electrons combined with protons and formed neutral atoms. Later, clouds of atoms contracted into stars. In this paper, we describe how techniques of volume rendering and information visualization are used to visualize the large particle track data set generated from this high energy physics experiment. The system, called TrackVis, is based on our earlier work of VolVis - Volume Visualization software. Example images of real particle collision data are shown, which are helpful to physicists in investigating the behavior of strongly interacting matter at high energy density.
Keywords: Big Bang;Relativistic Heavy Ion Collider experiment;TrackVis;data visualisation;high energy density;high energy physics experiment;high energy physics instrumentation computing;information visualization;neutrinos;nuclear electronics;particle collision data;particle track data visualization;rendering (computer graphics);volume rendering;
Author: Xiaoming Wei; Kaufman, A.E.; Hallman, T.J.

Year: 2001
Title: Case study: interacting with cortical flat maps of the human brain
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964553
Abstract: The complex geometry of the human brain contains many folds and fissures, making it impossible to view the entire surface at once. Since most of the cortical activity occurs on these folds, it is desirable to be able to view the entire surface of the brain in a single view. This can be achieved using quasi-conformal flat maps of the cortical surface. Computational and visualization tools are now needed to be able to interact with these flat maps of the brain to gain information about spatial and functional relationships that might not otherwise be apparent. Such information can contribute to earlier diagnostic tools for diseases and improved treatment. Our group is developing visualization and analysis tools that will help elucidate new information about the human brain through the interaction between a cortical surface and its corresponding quasiconformal flat map.
Keywords: MRI;biomedical imaging;brain;cortical activity;cortical surface;data visualisation;diagnostic tools;human brain;quasi-conformal flat maps;rendering (computer graphics);visualization tools;
Author: Hurdal, M.K.; Kurtz, K.W.; Banks, D.C.

Year: 2001
Title: 4D space-time techniques: a medical imaging case study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964554
Abstract: We present the problem of visualizing time-varying medical data. Two medical imaging modalities are compared-MRI and dynamic SPECT. For each modality, we examine several derived scalar and vector quantities such as the change in intensity over time, the spatial gradient, and the change of the gradient over time. We compare several methods for presenting the data, including isosurfaces, direct volume rendering, and vector visualization using glyphs. These techniques may provide more information and context than methods currently used in practice; thus it is easier to discover temporal changes and abnormalities in a data set.
Keywords: MRI;biomedical MRI;biomedical imaging;data visualisation;direct volume rendering;dynamic SPECT;glyphs;isosurfaces;medical imaging;rendering (computer graphics);single photon emission computed tomography;time-varying medical data;vector visualization;
Author: Tory, M.; Rober, N.; Moller, T.; Celler, A.; Atkins, M.S.

Year: 2001
Title: Computed tomography angiography: a case study of peripheral vessel investigation
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964555
Abstract: This paper deals with vessel exploration based on computed tomography angiography. Large image sequences of the lower extremities are investigated in a clinical environment. Two different approaches for peripheral vessel diagnosis dealing with stenosis and calcification detection are introduced. The paper presents an automated vessel-tracking tool for curved planar reformation. An interactive segmentation tool for bone removal is proposed.
Keywords: biomedical imaging;calcification;computed tomography angiography;computerised tomography;image segmentation;image sequences;image sequences;interactive segmentation;medical image processing;optimal path computation;peripheral vessel diagnosis;stenosis;
Author: Kanitsar, A.; Fleischmann, D.; Wegenkittl, R.; Sandner, D.; Felkel, P.; Groller, E.

Year: 2001
Title: Graphical strategies to convey functional relationships in the human brain: a case study
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964556
Abstract: Brain imaging methods used in experimental brain research such as Positron Emission Tomography (PET) and Functional Magnetic Resonance (fMRI) require the analysis of large amounts of data. Exploratory statistical methods can be used to generate new hypotheses and to provide a reliable measure of a given effect. Typically, researchers report their findings by listing those regions which show significant statistical activity in a group of subjects under some experimental condition or task. A number of methods create statistical parametric maps (SPMs) of the brain on a voxel-basis. In our approach statistics are computed not on individual voxels but on predefined anatomical regions-of-interest (ROIs). A correlation coefficient is used to quantify similarity in response for various regions during an experimental setting. Since the functional inter-relationships can become rather complex and spatially widespread, they are best understood in the context of the underlying 3-D brain anatomy. However despite the power of the 3-D model, the relative location of ROIs in 3-D can be obscured due the inherent problem of presenting 3-D spatial information on a 2-D screen. In order to address this problem, we have explored a number of visualization techniques to aid the brain researcher in exploring the spatial relationships of brain activity. In this paper we present a novel 3-D interface that allows the interactive exploration of correlation datasets.
Keywords: 3-D brain anatomy;PCA;Principal Component Analysis;biomedical imaging;brain;brain imaging;data visualisation;principal component analysis;statistical parametric maps;visualization techniques;
Author: Welsh, T.; Mueller, K.; Wei Zhu; Volkow, N.; Meade, J.

Year: 2001
Title: A case study on interactive exploration and guidance aids for visualizing historical data
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964557
Abstract: In this paper, we address the problem of historical data visualization. We describe the data acquisition, preparation, and visualization. Since the data contain four dimensions, the standard 3D exploration techniques have to be extended or appropriately adapted in order to enable interactive exploration. We discuss in detail two interaction concepts: (1) navigation with one fixed dimension, and (2) quasi 4D navigation allowing to simultaneously explore the four-dimensional space. In addition, we also present a picture-in-picture display mode, enabling the user to interactively view the data, while "flying with" a particular event, tracking its motion in time and space. Finally, we present a technique for guided exploration and animation generation, allowing for a vivid gain of insight into the historical data.
Keywords: animation;data acquisition;data visualisation;guided exploration;historical data visualization;history;interactive exploration;virtual environment;virtual reality;visualization;
Author: Stoev, S.L.; Strasser, W.

Year: 2001
Title: The MetVR case study: meteorological visualization in an immersive virtual environment
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964559
Abstract: Traditional methods for displaying weather products are generally two-dimensional (2D) plots or just text format. It is hard for forecasters to get the entire picture of the atmosphere using these methods. The problems apparent in 2D with comparing and correlating multiple layers are overcome simply by adding a dimension. This is important because pertinent features in the data sets may lie in multiple layers and span several time steps. However, simply using a three-dimensional (3D) approach is not enough. The capacity for analysis of small-scale, but important, features in 2D are lost when transitioning to 3D. We propose that 3D's advantages can be incorporated with 2D's small-scale analysis by using an immersive virtual environment. In this case study, we evaluate our current standing with the project: have we met our goals, and how should we proceed from this point? To evaluate our application, we invited meteorologists to use the application to explore a data set. Then we presented our goals and asked which ones had we met, from a meteorologist's perspective. The results qualitatively reflected that our application was effective and further research would be worthwhile.
Keywords: data visualisation;displaying weather products;meteorology;virtual environments;virtual reality;virtual reality;visualization;weather forecasters;weather forecasting;
Author: Ziegeler, S.; Moorhead, R.J.; Croft, P.J.; Duanjun Lu

Year: 2001
Title: Semi-immersive space mission design and visualization: case study of the Terrestrial Planet Finder mission
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964562
Abstract: The paper addresses visualization issues of the Terrestrial Planet Finder Mission (C.A. Beichman et al., 1999). The goal of this mission is to search for chemical signatures of life in distant solar systems using five satellites flying in formation to simulate a large telescope. To design and visually verify such a delicate mission, one has to analyze and interact with many different 3D spacecraft trajectories, which is often difficult in 2D. We employ a novel trajectory design approach using invariant manifold theory, which is best understood and utilized in an immersive setting. The visualization also addresses multi-scale issues related to the vast differences in distance, velocity, and time at different phases of the mission. Additionally, the parameterization and coordinate frames used for numerical simulations may not be suitable for direct visualization. Relative motion presents a more serious problem where the patterns of the trajectories can only be viewed in particular rotating frames. Some of these problems are greatly relieved by using interactive, animated stereo 3D visualization in a semi-immersive environment such as a Responsive Workbench. Others were solved using standard techniques such as a stratify approach with multiple windows to address the multiscale issues, re-parameterizations of trajectories and associated 2D manifolds and relative motion of the camera to "evoke" the desired patterns.
Keywords: 2D manifolds;3D spacecraft trajectories;Responsive Workbench;Terrestrial Planet Finder Mission;aerospace computing;chemical signatures;computer animation;coordinate frames;data visualisation;direct visualization;distant solar systems;interactive animated stereo 3D visualization;interactive systems;invariant manifold theory;large telescope;multi-scale issues;multiple windows;numerical analysis;numerical simulations;relative motion;rotating frames;semi-immersive environment;semi-immersive space mission design;space research;trajectory design approach;visualization issues;
Author: Museth, K.; Barr, A.; Lo, M.W.

Year: 2001
Title: A virtual environment for simulated rat dissection: a case study of visualization for astronaut training
Link: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=964564
Abstract: Animal dissection for the scientific examination of organ subsystems is a delicate procedure. Performing this procedure under the complex environment of microgravity presents additional challenges because of the limited training opportunities available that can recreate the altered gravity environment. Traditional astronaut crew training often occurs several months in advance of experimentation, provides limited realism, and involves complicated logistics. We have developed an interactive virtual environment that can simulate several common tasks performed during animal dissection. In this paper, we describe the imaging modality used to reconstruct the rat, provide an overview of the simulation environment and briefly discuss some of the techniques used to manipulate the virtual rat.
Keywords: aerospace computing;animal dissection;astronaut crew training;biological experiments;biology computing;computer based training;interactive virtual environment;microgravity;near weightlessness;simulation environment;virtual rat;virtual reality;
Author: Montgomery, K.; Bruyns, C.; Wildermuth, S.

